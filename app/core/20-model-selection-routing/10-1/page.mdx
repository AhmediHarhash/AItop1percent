# 10.1 â€” Model Governance as an Engineering Practice, Not Paperwork

In March 2025, a healthcare technology company discovered during an EU AI Act compliance audit that their production system was using Claude Opus 4.5 for medical triage recommendations, but their governance documentation listed GPT-4o as the approved model. The switch had happened six months earlier when the engineering team found Claude performed better on their evaluation suite. They updated the routing configuration, ran their safety tests, verified the change in staging, and deployed. They forgot to update the model registry spreadsheet that Legal maintained. The auditor flagged this as a governance failure. The company could not produce an approval record for the model change, could not demonstrate that the required stakeholders had reviewed the switch, and could not show that the new model had been assessed against their high-risk AI system criteria. The remediation cost them four months of work: recreating approval workflows, implementing a model registry system that actually reflected production state, and re-documenting every model decision made in the previous eighteen months. The root cause was not malicious non-compliance. It was treating governance as documentation instead of infrastructure.

Most teams approach model governance as a paperwork exercise. They maintain spreadsheets of approved models, write policy documents describing review processes, and ask engineers to fill out forms before deploying changes. This approach fails because it relies on manual synchronization between production systems and governance records. Engineers update code, documentation drifts, and audits reveal that reality diverged from policy months ago. The gap is not the fault of careless engineers. It is the inevitable result of treating governance as a separate layer instead of an integrated part of the engineering system. When governance is paperwork, it becomes stale the moment it is written. When governance is infrastructure, it stays current because it is the mechanism through which changes happen.

## The Governance-as-Code Philosophy

**Governance-as-code** means encoding policies directly into the systems that execute them. Instead of documenting that only approved models can be used in production, you configure your routing layer to reject requests for unapproved models. Instead of requiring engineers to manually record model changes in a registry, your deployment pipeline automatically updates the registry as part of the deployment process. Instead of asking teams to produce audit logs on demand, your infrastructure generates comprehensive audit trails as a byproduct of normal operation. The policies are not descriptions of how things should work. They are the rules that determine how things do work.

This philosophy extends across every aspect of model governance. Your model registry is not a spreadsheet. It is a service that your routing layer queries to determine which models are approved for which use cases. Your approval workflow is not a document describing who should review what. It is a deployment gate that blocks changes until the required approvals are recorded in the system. Your compliance reporting is not a manual assembly of evidence. It is a query against structured data that your systems collect automatically. When governance is code, it cannot drift from reality because it is reality.

The implementation starts with your model registry. You need a source of truth that lists every model your organization is approved to use, the use cases each model is authorized for, the approval date and approving stakeholders, the risk tier assigned to each model-task pairing, and the specific configuration constraints that apply. This registry must be machine-readable so your routing layer can enforce it. When a request comes in for a task, your routing logic checks the registry to confirm the selected model is approved for that use case. If the model is not in the registry or not approved for that task, the request is rejected before it reaches the model provider. This is not a suggestion or a warning. It is a hard constraint enforced by infrastructure.

Your deployment pipeline becomes the enforcement point for approval workflows. When an engineer wants to add a new model to the registry or change the approved use cases for an existing model, they submit a pull request that modifies the registry configuration. The pull request triggers an automated review process that routes the change to the appropriate stakeholders based on the risk tier. For a low-risk change, like switching from GPT-4o to GPT-4.5 for an existing summarization task that already uses GPT-family models, the approval might only require the engineering lead and product owner. For a high-risk change, like introducing a new model family for a regulated use case, the approval requires engineering, product, security, legal, compliance, and a domain expert. The pull request cannot merge until all required approvals are recorded. Once merged, the deployment pipeline updates the production registry automatically, and the change takes effect. The approval record is the pull request history. The audit trail is the git log.

This approach eliminates the synchronization problem. The registry that governance reviews is the same registry that production uses. There is no manual step where an engineer updates code and then separately updates documentation. The code is the documentation. The deployment is the documentation update. If the registry says a model is approved, that model is available in production. If the registry does not list a model, that model cannot be used. The system cannot drift because there is only one system.

## Audit Trails Generated Automatically

Governance requires audit trails. You need to be able to answer questions like: which models were used for this task over the past year, who approved each model change, when did we switch from GPT-4o to Claude Opus 4.5, what evaluation results justified that switch, which requests used which model versions, and how many requests failed because they attempted to use an unapproved model. If you rely on manual logging, you will have gaps. Engineers forget to log changes, logs get lost during system migrations, and the granularity is inconsistent because different people record different levels of detail. Automated audit trails solve this by making logging a built-in consequence of system operation.

Your routing layer should emit structured events for every decision it makes. When a request is routed to a model, log the task identifier, the selected model and version, the routing rule that applied, the timestamp, the request identifier, and the user or system that initiated the request. When a request is rejected because the model is not approved, log the attempted model, the task, the reason for rejection, and the timestamp. When the model registry is updated, log the change, the approving stakeholders, the pull request identifier, and the timestamp. These events flow into a centralized logging system where they can be queried, aggregated, and reported on. The logs are not an afterthought. They are a primary output of the governance infrastructure.

You also need to capture the rationale behind governance decisions. When a model is approved for a use case, the approval should reference the evaluation results that justified it, the safety testing that was completed, the cost analysis that was reviewed, and any constraints or conditions attached to the approval. This rationale should be stored in the same system as the approval record, linked to the registry entry, so that anyone reviewing the decision later can understand why it was made. The best place to store this is in the pull request description and discussion. When someone proposes adding a new model to the registry, they include in the pull request a summary of the evaluation results, links to the detailed eval reports, notes from the safety review, and the cost projections. Reviewers discuss concerns and conditions in the pull request comments. When the change merges, all of this context is preserved in the repository history. The audit trail is not just a log of what happened. It is a record of why it happened.

Some organizations implement a separate governance database that mirrors the model registry and stores additional metadata like evaluation reports, approval justifications, risk assessments, and compliance documentation. This database is updated automatically by the deployment pipeline when registry changes are made. The advantage is that it provides a richer queryable interface for compliance reporting without cluttering the production registry with fields that the routing layer does not need. The disadvantage is that it introduces a second source of truth that must be kept in sync. If you go this route, the synchronization must be automated and enforced by the deployment process. The production registry is always the authoritative source, and the governance database is a derived view that is rebuilt from the registry and associated artifacts.

## The Cost of Governance Debt

Teams that defer governance infrastructure accumulate **governance debt**. They operate without formal approval processes, without a centralized model registry, without automated audit logging. They tell themselves they will build the governance layer later, once the product is more mature and the compliance requirements are clearer. This is a mistake. Governance debt is harder to pay down than technical debt because it requires reconstructing historical decisions and justifications that were never recorded. You cannot retroactively create an audit trail for decisions made eighteen months ago when the people who made those decisions have left the company and the evaluation results that justified them were stored in a Notion page that no longer exists.

A financial services company faced this in late 2025 when they underwent their first SOX audit after going public. The auditors asked for evidence that model changes in their fraud detection system had been reviewed and approved by the appropriate stakeholders, that the models had been tested against the required performance and safety criteria, and that the decision rationale had been documented. The company could not produce this evidence. They had been moving fast, iterating on models, and prioritizing product velocity over process. They had evaluation results scattered across Slack threads, email chains, and personal notebooks. They had no formal approval records. They had no centralized log of which models were used when. The auditors flagged this as a material weakness in internal controls. The remediation required hiring a governance consultant, interviewing everyone who had been involved in model decisions over the past two years, reconstructing timelines from git history and deployment logs, and building a retroactive paper trail that approximated what a proper governance process would have produced. It took seven months and cost over two million dollars. If they had implemented governance infrastructure from the start, the audit would have been a matter of running a few queries and exporting reports.

The problem is that retroactive governance is always incomplete and always suspect. When you try to recreate approval records after the fact, you are relying on memory and inference rather than contemporaneous documentation. You cannot prove that the VP of Engineering actually reviewed and approved the switch to Claude Opus 4.5 for medical triage in June 2025. You can show that they were in the meetings where it was discussed, that they did not object, and that the deployment happened during their tenure, but you cannot produce a signed approval because you were not collecting signed approvals at the time. Auditors and regulators know the difference between real governance and reconstructed governance. They discount retroactive documentation because it is easy to fabricate and hard to verify. The governance infrastructure you build today is credible because it was operating at the time the decisions were made. The governance documentation you assemble later is always questionable.

This is why governance must be built from the start, even when you are small and moving fast. You do not need a heavy process. You need a lightweight process that is automated and integrated into your workflow. A model registry can start as a YAML file in your repository. An approval workflow can start as requiring one reviewer on pull requests that modify the registry. An audit trail can start as structured logging in your routing layer. These are not expensive or slow. They are simple guardrails that ensure decisions are recorded as they are made. You can add rigor and formality later as your compliance requirements grow, but the foundation must be there from day one. The time to implement governance infrastructure is before you need to demonstrate compliance, not after an auditor asks for evidence you do not have.

## What Good Governance Infrastructure Looks Like in 2026

A well-designed governance infrastructure in 2026 has several characteristics. First, it is declarative. The model registry is a configuration file or database that states which models are approved for which tasks, and the routing layer enforces that configuration. Changes to the registry are explicit, version-controlled, and auditable. Second, it is automated. Approvals are workflow steps in your deployment pipeline, not emails or Slack messages. Audit logs are generated by the system, not manually written by engineers. Third, it is integrated. Governance is not a separate tool or process. It is part of your standard deployment and operational workflow. Engineers interact with governance infrastructure the same way they interact with CI/CD pipelines and monitoring dashboards. Fourth, it is transparent. Anyone in the organization can query the model registry to see what is approved, review the approval history to understand why decisions were made, and examine the audit logs to verify compliance. There are no governance secrets, no undocumented exceptions, no informal workarounds.

The model registry includes not just a list of approved models but also the metadata required for compliance and operational decision-making. For each model, you store the provider, the model family and version, the supported tasks, the risk tier for each task, the cost per million tokens, the latency percentiles, the approval date and approving stakeholders, the evaluation results that justified approval, any conditions or constraints on usage, and the deprecation or review date if applicable. This information serves multiple purposes. The routing layer uses it to enforce approval policies and select appropriate models for tasks. The compliance team uses it to generate reports for audits. The finance team uses it to track and forecast model costs. The engineering team uses it to understand model performance and plan upgrades. The registry is not just a governance artifact. It is operational infrastructure.

Your approval workflow should scale with risk. Low-risk changes, like upgrading from GPT-4.5 to GPT-5.2 for an existing non-regulated task, should be fast-tracked. The engineer submits a pull request, runs the evaluation suite to confirm the new model meets or exceeds the performance of the old model, and gets approval from the engineering lead and product owner within a day. High-risk changes, like introducing Claude Opus 4.5 for a new regulated use case, should have a more rigorous review. The engineer prepares a proposal that includes the use case description, the task definition, the evaluation plan and results, the safety testing approach and findings, the cost analysis, the data handling and privacy implications, and the compliance assessment. This proposal is reviewed by engineering, product, security, legal, compliance, and a domain expert. Each reviewer has specific criteria they are responsible for. Security reviews the data handling and provider risk. Legal reviews the contractual and regulatory implications. Compliance reviews the risk tier and required controls. The domain expert reviews the task definition and success criteria. The approval workflow routes the proposal to each reviewer in parallel, collects their feedback, and requires sign-off from all before the change can proceed. This is not bureaucracy. It is appropriate diligence for decisions that carry regulatory and business risk.

The audit trail must be comprehensive and queryable. You need to be able to answer compliance questions quickly and accurately. A query interface over your structured logs and governance database allows you to generate reports like: all model changes in the past twelve months, all requests that used Claude Opus 4.5 for medical triage in Q3 2025, all model approval decisions made by the VP of Engineering, all evaluation results for GPT-5.2 across all tasks, and all requests that were blocked because the model was not approved. These reports should be generated in seconds, not days. If an auditor asks a question, you should be able to run a query and provide an answer during the meeting. This level of responsiveness is only possible if your governance data is structured, indexed, and accessible through a proper interface. Grep-ing through log files or reconstructing timelines from git history is not sufficient at scale.

## The Governance Team Structure

Governance is not the responsibility of one person or one team. It is a shared responsibility across engineering, product, legal, compliance, security, and domain experts. However, ownership must be clear. In most organizations, the engineering lead or a designated AI governance lead owns the governance infrastructure. They are responsible for maintaining the model registry, operating the approval workflow, ensuring audit logs are being collected, and generating compliance reports. They do not make approval decisions alone. They facilitate the process by which the right stakeholders review and approve changes. They are the process owner, not the decision owner.

The stakeholders who participate in the approval process have defined roles. The engineering lead reviews technical feasibility, performance, and operational risk. The product owner reviews alignment with product requirements and user needs. Security reviews data handling, provider security posture, and potential vulnerabilities. Legal reviews contractual terms, intellectual property implications, and regulatory compliance. Compliance reviews risk tiering, required controls, and adherence to internal policies. Domain experts review task definitions, success criteria, and the appropriateness of the model for the specific use case. Each stakeholder has a clear scope and approval authority. They are not reviewing everything. They are reviewing the aspects that fall within their domain of expertise and responsibility.

The governance lead also serves as the point of contact for audits and regulatory inquiries. When an auditor requests evidence of model governance, the governance lead coordinates the response, runs the necessary queries, assembles the documentation, and presents the findings. This role requires both technical knowledge and communication skills. The governance lead must understand how the infrastructure works, what data is available, and how to extract and interpret it. They must also be able to explain the governance process to non-technical stakeholders in a way that demonstrates its rigor and reliability. This is often a senior engineer or engineering manager who has the credibility and authority to represent the organization's governance practices.

Some organizations create a dedicated AI governance team that includes representatives from engineering, product, legal, compliance, and security. This team meets regularly to review model changes, discuss policy updates, assess new compliance requirements, and improve the governance infrastructure. The advantage of this structure is that it ensures governance is a continuous practice, not a reactive response to audits. The team develops expertise in AI risk management, stays current on regulatory developments, and builds relationships across functions that make the approval process smoother and faster. The disadvantage is that it can become a bottleneck if every decision requires a full team meeting. The best approach is a hybrid: a standing governance team that sets policy and reviews high-risk changes, with delegated authority for low-risk changes that follow established patterns.

## Compliance Theater vs Real Governance

The difference between compliance theater and real governance is whether the infrastructure actually constrains behavior or just documents it after the fact. Compliance theater is maintaining a model registry that no one checks, writing policy documents that no one follows, and generating audit reports that describe an idealized process that does not match how decisions are actually made. Real governance is infrastructure that enforces policies, workflows that gate deployments, and audit trails that reflect actual system behavior. If your governance process can be bypassed without anyone noticing, it is theater. If bypassing the process requires deliberately circumventing technical controls, it is real governance.

A technology company thought they had governance because they required engineers to fill out a form before deploying a new model. The form asked for the model name, the use case, the evaluation results, and the approving manager. Engineers filled out the forms and submitted them to a shared folder. No one checked whether the information in the forms was accurate. No one verified that the approving manager had actually reviewed the evaluation results. No one confirmed that the deployed model matched the model listed in the form. The forms were filed and forgotten. During an audit, the company proudly presented hundreds of completed forms as evidence of their governance process. The auditor asked to see evidence that the forms had been reviewed and that the approvals were enforced. The company could not provide this evidence because the forms were not connected to any enforcement mechanism. The governance process was pure theater.

Real governance would have integrated the approval into the deployment pipeline. The engineer would submit a pull request to add the model to the registry. The pull request would trigger a review workflow that notified the appropriate stakeholders and blocked merge until approvals were recorded. The deployment pipeline would read the registry and only allow deployment of models listed in it. The audit trail would be the pull request history and the deployment logs. This is not more work for engineers. It is the same work, structured differently so that governance is a byproduct of the normal deployment process rather than a separate compliance exercise. The key insight is that governance infrastructure should make it easier to do the right thing than to bypass the process. When the path of least resistance is compliance, compliance happens. When compliance requires extra steps that provide no immediate value to the engineer, compliance becomes optional.

The model approval process, which defines who signs off and what they review, is where governance becomes concrete and operational.

