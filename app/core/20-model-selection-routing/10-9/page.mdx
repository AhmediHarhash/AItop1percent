# 10.9 — Data Processing Agreements and Model Provider Contracts

In June 2025, a European financial services company discovered that their primary language model provider, which they had been using for 18 months to power customer support and document analysis, had updated its terms of service to include a new clause: all prompts and outputs would be retained for 90 days and could be used to improve the provider's models unless customers explicitly opted out. The financial services company had never opted out because they were unaware the option existed—it was buried in a developer portal setting, not highlighted in the contract amendment notification. During those 90 days, the company had processed over 400,000 customer interactions containing account numbers, transaction details, and personal financial information. Under GDPR, this data sharing with the model provider without explicit customer consent and without a proper data processing agreement was a serious violation. The company faced a regulatory investigation and ultimately paid a €5.2 million fine. The root cause was not malicious—it was that no one on the legal or engineering team had read the updated data processing terms, and no one had negotiated proper contractual protections before integrating the model into production systems handling regulated data.

Contracts with model providers are not boilerplate terms of service you click through and forget. They are legal instruments that define your data rights, your liability exposure, your regulatory compliance obligations, and your recourse when things go wrong. This subchapter covers what data processing agreements must include, what contract terms to negotiate, how GDPR and HIPAA shape your provider relationships, and how to manage ongoing contract changes.

## What Data Processing Agreements Cover

A **data processing agreement** or DPA is a contract addendum required under GDPR and similar privacy regulations when you share personal data with a third-party service provider. When you send customer prompts to a model provider, and those prompts contain personal data—names, email addresses, medical information, financial details—the model provider becomes a **data processor** and you remain the **data controller**. The DPA defines the processor's obligations: what they can do with your data, how they must protect it, when they must delete it, and how they handle data breaches. Without a valid DPA, you cannot legally send personal data to the provider under GDPR, and doing so exposes you to regulatory fines.

The core elements of a compliant DPA are defined by GDPR Article 28. First, the DPA must specify the **subject matter and duration** of the processing: what data is being processed, for what purpose, and for how long. For a customer support chatbot, the subject matter is customer inquiries and support interactions, the purpose is generating responses, and the duration is the length of your contract with the provider. Second, the DPA must specify the **nature and purpose** of the processing: whether the data is being used only to generate responses for you, or also being used to train or improve the provider's models. This distinction is critical—if the provider uses your data for training, that is a secondary purpose that requires additional legal basis and customer consent.

Third, the DPA must specify the **type of personal data** being processed: names, contact information, financial data, health data, biometric data. You list the categories of data your prompts might contain, and the provider agrees to process only those categories. Fourth, the DPA must specify the **categories of data subjects**: customers, employees, patients, students. This defines whose data is at risk and who has rights under the agreement. Fifth, the DPA must include the **controller's obligations and rights**: your right to audit the provider, your right to instruct the provider to delete data, your right to be notified of data breaches within a specific timeframe—typically 24 to 72 hours.

The DPA must also address **sub-processors**: other companies the model provider uses to deliver the service, such as cloud infrastructure providers or security monitoring vendors. The provider must either list all current sub-processors in the DPA or commit to notifying you before adding new sub-processors, giving you the right to object. If the provider uses AWS to host the model and AWS is not listed as a sub-processor in your DPA, the provider is in breach. You need to know the full chain of data processors because each one is a potential point of data leakage or breach, and each one must have its own compliant DPA with the provider.

A compliant DPA includes **data security requirements**: the provider must implement appropriate technical and organizational measures to protect your data, including encryption, access controls, and regular security assessments. The DPA should reference specific security standards—SOC 2 Type II, ISO 27001, or equivalent—and require the provider to maintain those certifications. It should also specify what happens if the provider suffers a data breach: immediate notification to you, forensic investigation, remediation steps, and cooperation with your regulatory obligations to notify affected individuals and regulators.

Finally, the DPA must address **data deletion and return**: when your contract ends, the provider must either delete all your data or return it to you, at your choice, and certify that deletion has been completed. This is the GDPR right to data portability and the right to erasure applied to the processor relationship. If you terminate your contract with a model provider and they retain your prompts and outputs indefinitely, they are violating the DPA and creating ongoing regulatory risk for you.

## Key Contract Terms Beyond the DPA

Beyond the DPA, your master service agreement or terms of service with the model provider must address several AI-specific terms. **Data retention periods** define how long the provider keeps your prompts, outputs, and metadata. The best provider contracts offer **zero-day retention**—prompts and outputs are processed in memory and never written to persistent storage. This eliminates data retention risk entirely. More commonly, providers retain data for 30 to 90 days for debugging, abuse monitoring, and quality improvement, then delete it. You need to know the exact retention period and ensure it aligns with your own data retention policies and regulatory obligations. If your privacy policy promises customers that their data is deleted immediately after processing, but your model provider retains it for 90 days, you are making a false representation.

**Training opt-out** clauses let you prohibit the provider from using your data to train or improve their models. This is critical for competitive sensitivity and regulatory compliance. If you are a healthcare company sending patient data to a model provider, you cannot allow that data to be used for training—it would violate HIPAA and create risk that patient information leaks into the provider's base model and appears in outputs for other customers. Training opt-out is often a paid feature or available only in enterprise contracts, not in standard pay-as-you-go API access. You must verify that opt-out is enabled for your account, not just available in theory. The European financial services company that faced the €5.2 million fine had training opt-out available but never enabled it because no one knew to look for the setting.

**Liability caps** limit the provider's financial responsibility if something goes wrong. Standard API terms of service typically cap liability at the amount you paid the provider in the preceding 12 months. If you paid $50,000 in API fees and the provider suffers a data breach that exposes your customer data, leading to $5 million in regulatory fines and remediation costs, you can only recover $50,000 from the provider. The rest is your responsibility. For high-risk applications, you negotiate higher liability caps or uncapped liability for certain breach types, such as gross negligence or willful misconduct. You also require the provider to carry adequate cyber liability insurance—typically $10 million to $50 million in coverage—and name you as an additional insured.

**Breach notification timelines** define how quickly the provider must tell you about security incidents. GDPR requires data controllers to notify regulators within 72 hours of becoming aware of a breach, which means you need to know about breaches affecting your data within hours, not days. Your contract should require the provider to notify you within 24 hours of detecting a breach, with preliminary details, followed by a full incident report within 72 hours. The notification must include what data was affected, how many records were compromised, what caused the breach, and what remediation steps the provider is taking. Without fast notification, you cannot meet your own regulatory obligations, and delays increase your liability.

**Service level agreements** or SLAs define uptime guarantees, latency targets, and support response times. For production systems that depend on model availability, you need SLAs that match your own uptime commitments to users. If you promise customers 99.9% uptime but your model provider only guarantees 99.5%, you have a 0.4% gap where you are liable for outages caused by the provider. SLAs should include financial remedies—service credits or refunds—when the provider misses targets, and they should cover not just API availability but also performance degradation. If the model API is technically available but latency spikes to 30 seconds per request, that is an SLA breach even if uptime is 100%.

**Model deprecation and migration terms** define what happens when the provider sunsets a model you depend on. In 2024 and 2025, every major model provider deprecated multiple models with 3 to 6 months notice, forcing customers to migrate to newer models or alternative providers. Your contract should require at least 6 months notice for deprecations, access to replacement models with equivalent or better performance, and migration support from the provider's technical team. It should also prohibit the provider from degrading model quality or increasing prices on deprecated models to force migration. Some providers have reduced rate limits or increased latency on deprecated models to push customers off—this is a breach if not disclosed in advance.

## GDPR Implications and Data Processor Relationships

Under GDPR, when you send personal data to a model provider, the provider is a **data processor** and you are the **data controller**. This relationship creates specific legal obligations. As the controller, you are responsible for having a lawful basis for processing the data—typically legitimate interest or consent—and for ensuring that any processor you use complies with GDPR. You cannot outsource GDPR compliance to the provider. If the provider mishandles your data, you are still liable to your customers and to regulators, in addition to whatever liability the provider faces.

This means you must conduct **due diligence** on the provider's data protection practices before you sign the contract. You review their security certifications, their data breach history, their privacy policy, and their DPA terms. You verify that they have appointed a Data Protection Officer if required, that they conduct regular security audits, and that they have a track record of GDPR compliance. If the provider has been fined for GDPR violations in the past, or if they refuse to provide a compliant DPA, you do not use them for processing personal data, regardless of how good their models are.

The DPA must give you **audit rights**: the right to inspect the provider's data processing practices, either directly or through an independent auditor. Most providers do not allow customer audits of their infrastructure for security and scalability reasons, but they provide third-party audit reports—SOC 2 Type II, ISO 27001, or GDPR-specific audits—that you can review. Your DPA should require the provider to make these audit reports available annually and to notify you immediately if they lose a certification or fail an audit. If the provider's SOC 2 report shows a significant deficiency in access controls, you need to know so you can assess the risk.

GDPR also restricts **international data transfers**. If your users are in the EU and your model provider processes data in the United States or another country outside the EU, the transfer must comply with GDPR Chapter V. After the Schrems II decision invalidated Privacy Shield, the primary mechanisms for lawful transfers are Standard Contractual Clauses or SCCs, and adequacy decisions for certain countries. Your DPA must incorporate the SCCs approved by the European Commission, and the provider must commit to processing your data only in jurisdictions with adequate data protection laws or under SCC protections. If the provider moves data processing to a new country without notifying you and updating the SCCs, they breach the DPA and create regulatory risk.

**Right to erasure** under GDPR Article 17 means that when a customer requests deletion of their data, you must delete it from your systems and instruct your processors to delete it as well. Your DPA must give you the ability to request deletion of specific data from the provider, not just bulk deletion at contract termination. If a customer submits a GDPR erasure request and you delete their data from your database but the model provider still retains their prompts and outputs for 90 days, you have not fully complied with the request. The provider must support targeted deletion based on user identifiers or timestamps, and they must confirm deletion within a reasonable timeframe—typically 7 to 30 days.

## HIPAA Business Associate Agreements

If you process protected health information or PHI under HIPAA, your model provider must sign a **Business Associate Agreement** or BAA in addition to the DPA. HIPAA defines a business associate as any entity that processes PHI on behalf of a covered entity—healthcare providers, insurers, or healthcare clearinghouses. If you are a covered entity using a language model to process patient intake forms, generate clinical summaries, or answer patient questions, the model provider is a business associate and must comply with HIPAA's security and privacy rules.

A compliant BAA includes all the elements of a GDPR DPA plus additional HIPAA-specific requirements. The provider must implement the administrative, physical, and technical safeguards required by the HIPAA Security Rule: encryption of PHI in transit and at rest, access controls that limit who can view PHI, audit logs that track all access to PHI, and regular risk assessments. The provider must also comply with the HIPAA Privacy Rule: they can only use and disclose PHI as permitted by the BAA, they must not use PHI for marketing or fundraising, and they must allow patients to access and amend their PHI.

The BAA must address **breach notification** under the HITECH Act: the provider must notify you within 60 days of discovering a breach affecting your PHI, and the notification must include the nature of the breach, the PHI involved, and the steps being taken to mitigate harm. You then have your own obligation to notify affected patients and the Department of Health and Human Services within 60 days. The 60-day window is tight, which is why your BAA should require faster notification—ideally within 24 to 48 hours—so you have time to investigate and prepare your own notifications.

Not all model providers will sign BAAs. As of early 2026, OpenAI, Anthropic, and Google offer BAAs for enterprise customers, but only for specific products and configurations. You cannot use standard API access with a BAA—you must use dedicated instances, zero-retention configurations, or specific HIPAA-eligible SKUs. You verify that the model endpoint you are using is covered by the BAA, not just that the provider offers a BAA somewhere in their product portfolio. If you integrate a model endpoint that is not covered by the BAA and send it PHI, you are violating HIPAA regardless of what contract you signed.

HIPAA also requires **minimum necessary** use: you can only disclose the minimum amount of PHI necessary to accomplish the intended purpose. This means you redact or anonymize PHI in prompts before sending them to the model whenever possible. If you are summarizing a patient chart, you strip out the patient's name, medical record number, and other identifiers that are not needed for summarization. You include only the clinical details necessary for the task. This reduces the PHI at risk if the provider suffers a breach, and it demonstrates minimum necessary compliance in an audit.

## Zero-Data-Retention Options and Tradeoffs

The safest model provider contracts are those with **zero-data-retention**: prompts and outputs are processed in memory and never written to disk, logs, or backups. As of 2026, several providers offer zero-retention options for enterprise customers, typically at a significant price premium. OpenAI's enterprise tier, Anthropic's dedicated capacity, and Google's Vertex AI private endpoints all support zero-retention configurations. The tradeoff is cost—zero-retention often costs 50% to 200% more than standard API access—and reduced functionality. The provider cannot offer you usage analytics, debugging tools, or quality monitoring if they do not retain your data.

Zero-retention also limits the provider's ability to detect abuse and ensure safety. Model providers use retained data to identify patterns of misuse—attempts to generate illegal content, circumvent safety filters, or exfiltrate training data. With zero retention, the provider processes each request in isolation with no memory of past requests from your account. This makes it harder for them to detect and block abuse, which can increase your risk if users or employees misuse the system. Some providers require customers with zero-retention to implement their own abuse monitoring and agree to stricter acceptable use policies with faster termination for violations.

For applications that do not involve highly sensitive data, **short-retention** options—7 to 30 days—offer a middle ground. The provider retains data long enough to debug issues, respond to abuse reports, and generate aggregated usage analytics, then deletes it automatically. Short retention is sufficient for most compliance frameworks and is significantly cheaper than zero retention. You match the retention period to your own data sensitivity and regulatory obligations. If you are processing customer support inquiries that are not particularly sensitive, 30-day retention may be acceptable. If you are processing financial transactions, 7-day retention or zero retention is more appropriate.

**Encryption in transit and at rest** is a baseline requirement regardless of retention period. All communication with the model API must use TLS 1.2 or higher, and any data the provider stores must be encrypted using AES-256 or equivalent. The provider should manage encryption keys using a hardware security module or cloud key management service, and they should rotate keys regularly. Your contract should specify encryption requirements explicitly—do not assume the provider encrypts data just because they claim to follow security best practices.

Some providers offer **customer-managed encryption keys**, where you control the encryption key used to protect your data in the provider's systems. If you revoke the key, the provider can no longer decrypt your data, giving you an additional layer of control. Customer-managed keys are useful for highly sensitive data and for compliance with regulations that require data to be rendered unreadable if certain conditions are met. The tradeoff is operational complexity—you are responsible for key management, key rotation, and ensuring the provider can access the key when needed to process your requests.

## Contract Negotiation Priorities

Not all contract terms are negotiable, especially with large model providers that serve thousands of customers through standard terms of service. But for enterprise contracts, several terms are worth negotiating. **Liability caps** are the highest priority. Standard caps at 12 months of fees are inadequate for high-risk applications. Negotiate for caps at 24 months of fees, or uncapped liability for breaches involving gross negligence, willful misconduct, or violations of the DPA. If the provider refuses to increase the cap, require them to carry higher insurance limits and name you as an additional insured.

**Data residency** is negotiable for customers with regulatory requirements that data be stored in specific countries or regions. If your users are in the EU and GDPR compliance is critical, negotiate for data processing to occur only in EU data centers, with no transfers outside the EU. If you are subject to data localization laws in China, India, or Russia, negotiate for in-country processing. Data residency requirements often increase cost because the provider must maintain regional infrastructure, but they reduce regulatory risk and simplify compliance.

**Custom SLAs** are negotiable for customers with high availability requirements or specialized performance needs. If you need 99.95% uptime instead of the standard 99.9%, or if you need latency guarantees at the 95th percentile instead of just average latency, you negotiate custom SLA terms. You also negotiate the financial remedies for SLA breaches—service credits may not be adequate if an outage causes significant revenue loss or reputational damage. Some enterprise contracts include liquidated damages clauses where the provider pays you a fixed amount per hour of downtime beyond the SLA threshold.

**Termination and transition assistance** terms define how you exit the relationship if you need to switch providers. You negotiate for termination rights without cause—the ability to end the contract with 30 to 90 days notice for any reason, not just for cause like a breach. You also negotiate for transition assistance: the provider must help you migrate to a new provider, provide data export in a usable format, and continue service during the transition period. Without these terms, you can be locked into a provider relationship even if the service degrades or a better alternative becomes available.

**Price protection** clauses limit how much the provider can increase prices during the contract term. Model API pricing is volatile—providers have increased prices by 50% to 200% when introducing new model versions or adjusting to infrastructure costs. Your contract should cap annual price increases at a specific percentage—typically 5% to 15%—or tie price increases to a public index like CPI. It should also require advance notice of price changes—at least 60 to 90 days—so you can budget for increases or evaluate alternatives.

## Ongoing Contract Management

Contracts with model providers are not static documents you sign and file away. Providers update terms of service, add new sub-processors, change data retention policies, and modify SLAs. You must **monitor contract changes** actively. Set up alerts for provider communications about terms updates. Review provider status pages and change logs regularly. When the provider notifies you of a terms update, have legal review the changes to identify new risks or compliance gaps. Do not auto-accept updated terms without review.

Many providers give you 30 days to object to updated terms or to terminate without penalty if you do not accept the changes. This is your window to negotiate or to plan a migration. If the provider adds a new data retention policy that conflicts with your privacy commitments, you object and negotiate an exception, or you start migrating to an alternative provider. If you do not object within the notice period, you are deemed to have accepted the new terms, and you lose leverage.

**Vendor risk assessments** should be repeated annually, not just at contract signing. You review the provider's security posture, their breach history over the past year, their financial stability, and their compliance with the contract terms. You verify that they still maintain the certifications required by your DPA—SOC 2, ISO 27001, HIPAA compliance. If the provider has suffered multiple breaches, lost a certification, or been fined by regulators, you reassess whether they are an acceptable vendor for your use case.

**Sub-processor tracking** is an ongoing obligation under GDPR. When the provider adds a new sub-processor, they must notify you, and you must assess whether the new sub-processor meets your data protection standards. If the provider starts using a cloud infrastructure vendor in a country without an adequacy decision and without proper SCC protections, you object. If the new sub-processor has a history of breaches, you evaluate the risk and decide whether to accept it or to seek an alternative provider.

You also track **service quality trends** against SLAs. Even if the provider meets the SLA technically—99.9% uptime—you monitor whether performance is trending downward. If uptime was 99.99% for the first year and has declined to 99.91% in the second year, that is a warning sign that infrastructure is strained or that the provider is deprioritizing service quality. You escalate with your account manager and consider whether you need to diversify to multiple providers to reduce dependency risk.

With provider contracts in place and fairness standards met, the final operational concern is defining what data you retain in your own systems, for how long, and under what protections—the subject we turn to next.
