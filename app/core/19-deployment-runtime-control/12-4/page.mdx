# 12.4 — Artifact Integrity and Provenance Verification

The security audit began routinely. An independent firm was validating the financial services company's model governance practices for regulatory compliance. On day three, auditors asked to see the provenance documentation for the fraud detection model running in production. Engineering provided the training logs showing the model was trained on February 3rd, 2025, completed evaluation on February 5th, and was promoted to production on February 6th. The auditors then examined the model file deployed in production. The file's modification timestamp was February 11th—five days after deployment. Someone had modified the production model after it left the training pipeline. Engineering had no record of who made the change, what changed, or why. The model in production was not the model that had been evaluated and approved. The audit failed. The company spent seven months rebuilding their deployment infrastructure with cryptographic signing, hash verification, and immutable provenance tracking. The regulatory fine was $2.8 million. The reputational damage was worse.

The integrity requirement is simple: you must prove that the artifact running in production is byte-for-byte identical to the artifact that passed evaluation, and that the evaluated artifact was produced through your authorized pipeline with no tampering. This proof requires three mechanisms: cryptographic signing of artifacts at creation time, signature and hash verification before deployment, and immutable provenance records documenting the complete lifecycle of each artifact. Without these mechanisms, you have no way to know whether your deployed model is the model you think it is.

## The Integrity Problem: Why Trust Is Insufficient

Traditional software deployment assumes artifacts are trustworthy if they came from your CI/CD system. You build a container, you push it to a registry, you pull it for deployment. You trust the registry. You trust the network. You trust that nobody modified the container between build and deploy. For low-stakes applications, this trust is reasonable. For AI systems making consequential decisions—approving loans, diagnosing medical conditions, routing emergency services—trust is not sufficient. You need proof.

The financial services company's model was modified after deployment for what seemed like a good reason at the time. A data scientist noticed the model was underperforming on a specific fraud pattern. They retrained the model with additional examples, tested it on a few cases, saw improved performance, and quietly swapped the model file in production without going through the full evaluation and approval process. They documented nothing. They told nobody. The modified model worked for five days. Then the audit discovered it. The data scientist's intention was good. The execution violated every governance control the company had built. Those controls only worked if artifacts were immutable and modifications were impossible after approval.

## Cryptographic Signing: Signing Artifacts at Creation Time

Cryptographic signing creates a digital signature that binds an artifact to its creator and proves the artifact has not been modified since signing. The signing process generates a signature by computing a hash of the artifact and encrypting that hash with a private key. The signature and the public key allow anyone to verify that the artifact has not changed and that it was signed by a holder of the private key. This verification is deterministic and does not require trusting intermediaries.

Every artifact produced by your training pipeline, prompt versioning system, or configuration management system should be signed immediately at creation. When a training run completes, the pipeline computes the model file's hash, signs the hash with a private key controlled by the ML platform, and stores both the model file and the signature in your model registry. When a prompt is committed to version control, the system signs the prompt file. When a configuration is generated, the system signs it. Signatures travel with artifacts, making tampering detectable at any later stage.

The financial services company rebuilt their training pipeline to sign every model automatically. Training completed, the pipeline computed a SHA-256 hash of the model weights file, signed the hash using an RSA private key stored in a hardware security module, and wrote the signature to a metadata file alongside the model. The private key never left the HSM. Only the training pipeline could produce valid signatures. If someone modified a model file after training, the signature would no longer match the file, and verification would fail. The modification that bypassed governance became technically impossible.

## Key Management: Protecting Signing Keys

Signing only provides security if private keys are protected. If anyone can access the signing key, anyone can sign malicious artifacts and make them appear legitimate. Key management is the operational discipline of controlling who can use signing keys, under what conditions, and with what audit trail.

Best practice for production AI systems is to store signing keys in hardware security modules or cloud-provided key management services that enforce access controls. The private key never exists outside the HSM. Your training pipeline authenticates to the HSM, requests a signature operation, receives the signature without ever possessing the key. Access to the HSM is logged immutably. If someone wants to sign a malicious artifact, they must either compromise the HSM—difficult and detectable—or compromise the credentials that allow the training pipeline to use the HSM—also logged and detectable.

The financial services company used AWS Key Management Service to manage signing keys. Each artifact type—models, prompts, configurations—had its own signing key. The training pipeline's IAM role could use the model signing key. The prompt management system's IAM role could use the prompt signing key. The configuration system's IAM role could use the configuration signing key. No human had direct access to any signing key. Every signature operation was logged to CloudTrail. Auditors could see every signature ever generated, when it was generated, and which system generated it.

## Signature Verification: Validating Signatures Before Deployment

Signing is useless if nobody checks signatures. Verification must happen automatically at every stage where artifacts are consumed. When the deployment pipeline pulls a model from the registry, it must verify the signature before proceeding. When a serving system loads a model, it must verify the signature before accepting the model. When a configuration system loads a configuration file, it must verify the signature. Verification failure must block execution and trigger alerts.

Verification uses the public key corresponding to the signing key. The verifier computes the hash of the artifact, decrypts the signature using the public key to recover the signed hash, and compares the two hashes. If they match, the artifact is proven authentic and unmodified. If they do not match, the artifact has been tampered with or corrupted, and must be rejected.

The financial services company implemented signature verification in three places. First, the deployment pipeline verified all artifact signatures before running evaluation—no evaluation happened unless signatures were valid. Second, the Kubernetes deployment controller verified model signatures before creating new pods with updated models—pods would not start if signature verification failed. Third, the model serving code verified signatures when loading models into memory—a modified model file would trigger an error and fall back to the previous known-good model. These three verification points made it impossible to deploy unsigned or tampered artifacts.

## Hash Verification: Ensuring Artifacts Match Expected Checksums

Hash verification provides a simpler integrity check than cryptographic signing. Compute the hash of an artifact when it is created. Store the hash in a secure location. Before deploying the artifact, recompute the hash and compare it to the stored hash. If the hashes match, the artifact is unmodified. If they differ, the artifact has changed.

Hashing does not prove who created the artifact or when—it only proves the artifact has not changed since the hash was computed. Hashing is faster than signature verification and sufficient when you trust the storage location of the hash. For example, if you store model hashes in a database with strict access controls and audit logs, you can rely on hash verification to detect tampering without needing full cryptographic signatures.

The financial services company used both signatures and hashes. Signatures proved authenticity and authorization—this model was produced by the training pipeline. Hashes provided fast integrity checks during deployment—this model file matches the expected hash. The deployment pipeline verified signatures once during evaluation to prove authorization, then verified hashes at every deployment stage to catch corruption or tampering. Hash verification was faster and caught bit-flips, incomplete downloads, and accidental corruption in addition to malicious tampering.

## Provenance Tracking: Documenting Exactly How Artifacts Were Created

Provenance is the complete documented history of an artifact: when it was created, how it was created, what inputs it was created from, who authorized its creation, what evaluation it passed, who approved it for deployment, and when it was deployed. Provenance turns an opaque model file into a fully documented asset with a clear chain of custody.

Provenance records should include training run metadata—the dataset version used, the hyperparameters specified, the code version that ran training, the GPU hours consumed, the final loss and metrics. They should include evaluation results—which eval suite ran, what metrics were measured, whether thresholds were met, who reviewed the results. They should include approval records—who signed off on promotion, when they signed off, what policy they applied. They should include deployment history—when the model was deployed to staging, when it was promoted to production, which regions received it, and when rollout completed.

The financial services company built a provenance tracking system that recorded every step of the model lifecycle in an append-only database. When training started, the system logged the dataset hash, code commit SHA, hyperparameters, and assigned a unique training run ID. When training completed, the system logged the final metrics, the model file hash, the model file location, and the signature. When evaluation ran, the system logged the eval suite version, evaluation results, and pass-fail verdict. When a model was promoted, the system logged who approved promotion, at what time, and based on which evaluation results. When deployment happened, the system logged deployment timestamps for each region. This complete provenance record allowed auditors to trace any production model back to the exact dataset, code, and approvals that produced it.

## SLSA Framework: Supply-Chain Levels for Software Artifacts

The Supply-chain Levels for Software Artifacts (SLSA) framework defines a maturity model for artifact integrity. SLSA levels progress from zero—no integrity guarantees—to four—full provenance with signed attestations and verifiable builds. Most organizations operating AI systems in regulated industries should target SLSA Level 3 or higher for models and SLSA Level 2 or higher for prompts and configurations.

SLSA Level 1 requires that builds are fully scripted and that provenance records exist showing how artifacts were built. SLSA Level 2 adds tamper-proof build services and signed provenance. SLSA Level 3 adds strong isolation during builds—builds happen in ephemeral environments where tampering is difficult—and auditable provenance generation. SLSA Level 4 adds hermetic builds where all dependencies are explicitly declared and two-party review of all changes.

The financial services company implemented SLSA Level 3 for model builds. Training runs happened in isolated Kubernetes pods with no persistent storage and no network access except to authorized data sources. The training code, dataset, and hyperparameters were all explicitly versioned. Provenance was generated automatically and signed by the training platform. After the audit failure, they spent seven months reaching Level 3 compliance. The investment meant they could prove to regulators that no model in production was tampered with and that every model was traceable to authorized, auditable processes.

## Provenance Attestation: Machine-Readable Provenance Documents

Provenance attestations are structured, signed documents that encode provenance information in a machine-readable format. The in-toto specification defines a standard format for attestations that include what artifact was created, how it was created, who created it, and what steps were executed. These attestations can be verified automatically and chained together to prove the full supply chain from raw data to deployed model.

An attestation for a model might include the training run ID, the dataset hash, the code commit that ran training, the hyperparameters, the final metrics, and the signature of the training platform. An attestation for deployment might include the model hash, the evaluation results, the approval, and the signature of the deployment system. By chaining these attestations, you prove that the model in production came from a specific training run that used a specific dataset and passed a specific evaluation. Each attestation is independently verifiable, and together they form an unbroken chain of custody.

The financial services company adopted the in-toto attestation format and stored attestations in a separate provenance database. Every artifact—model, prompt, configuration—had an attestation signed by the creating system. The deployment pipeline required attestations for all artifacts and verified signatures before deploying. Auditors could request attestations for any production artifact and independently verify the signatures and provenance claims. This machine-readable provenance turned an opaque audit process into an automated verification system.

## Verification in the Pipeline: Automated Integrity Checks

Integrity verification cannot be manual. Humans forget. Humans skip steps. Integrity checks must be automated and mandatory at every pipeline stage. When the evaluation system loads a model, it verifies the signature first. When the deployment controller provisions new infrastructure, it verifies signatures and hashes before pulling artifacts. When the model serving code loads a model, it verifies integrity before accepting the model.

Automated verification has two outcomes: pass or fail. If verification passes, execution proceeds. If verification fails, execution halts immediately, the failure is logged, and alerts fire. There are no warnings, no "verification failed but proceeding anyway," no manual overrides. Integrity failure is a security incident. The pipeline treats it as such.

The financial services company instrumented every artifact consumption point with integrity verification. The evaluation pipeline's first step was signature verification. The deployment controller's admission webhook verified signatures before admitting new pods. The model serving library's load function verified signatures before loading model weights into memory. Any verification failure triggered a PagerDuty alert to the security team and automatically blocked the operation. In 18 months of operation, they saw four verification failures—all caused by disk corruption during downloads. The automated verification caught all four before any corrupted artifact reached production.

## Compliance Requirements: Regulatory Demands for Provenance

Regulated industries—finance, healthcare, insurance, government—increasingly require provenance and integrity guarantees for AI systems. The EU AI Act requires high-risk AI systems to maintain logs of system behavior and decision rationale. SOX compliance for financial systems requires proving that deployed systems match approved specifications. HIPAA compliance for healthcare systems requires proving models were trained on data with appropriate privacy protections. All these requirements boil down to provenance: prove what you deployed and how it got there.

Your provenance system must support audit queries. An auditor asks, "What model was deployed on March 15th in the US-East region?" Your system provides the model hash, the training run ID, the dataset version, the evaluation results, the approval record, and the deployment timestamp. The auditor asks, "Who approved this model?" Your system provides the approver's identity, the approval timestamp, and the signature proving the approval is authentic. The auditor asks, "Was this model evaluated on demographically diverse data?" Your system provides the eval suite definition showing demographic categories and the evaluation results showing per-category performance.

The financial services company's provenance system supported all these queries through a web interface and an API. Auditors logged in, entered a model hash or a deployment date, and received complete provenance records. The system tracked 18 months of model deployments covering 47 model versions and 312 regional deployments. During the follow-up audit, auditors verified provenance for 20 randomly selected production deployments. All 20 had complete provenance chains from training data to deployment. The audit passed. The fine was refunded. The company's regulatory standing was restored.

## When Verification Fails: Blocking Deployment on Integrity Issues

Integrity verification failure is not a warning. It is a deployment blocker. If a model's signature does not verify, deployment must halt. If a configuration's hash does not match the expected hash, deployment must halt. If provenance attestations are missing or signatures are invalid, deployment must halt. No exceptions.

Failure handling requires immediate notification to both the team responsible for the artifact and the security team. Integrity failures may indicate tampering, compromised credentials, or infrastructure failures. All three scenarios require investigation. The deployment pipeline should log full details of the failure—which artifact, which verification step, what the expected signature or hash was, what was actually found—and create an incident ticket.

The financial services company configured their pipeline to treat verification failures as security incidents. Any failure triggered a PagerDuty alert to the on-call security engineer, a Slack message to the ML platform team, and an automatic incident ticket in their SIEM system. The deployment was blocked until the security team reviewed the failure and either cleared it as a false positive—usually disk corruption—or escalated it as a potential compromise. In 18 months, all four failures were disk corruption. But the process ensured that if a real compromise happened, it would be detected and escalated immediately.

## Why Integrity and Provenance Are Not Optional

The financial services company's $2.8 million fine could have been avoided with integrity and provenance systems that cost less than $100,000 to build. The cryptographic signing, hash verification, and provenance tracking that would have prevented the audit failure are not exotic technologies. They are standard practices in software supply chain security, adapted for AI artifacts. The only reason they were missing is that nobody thought they were necessary until the audit revealed the gap.

Every AI system making consequential decisions should have integrity and provenance guarantees. You should be able to prove what is running in production, how it got there, who authorized it, and what evaluation validated it. This proof is not for auditors—though auditors will demand it. This proof is for your users, who trust your system with decisions that affect their lives. The financial services company learned this expensively. You can learn it from them, and build integrity into your deployment pipeline from the start.

Artifacts with verified integrity and complete provenance flow through your pipeline to the final stage: promotion to production, where they move from staging environments to live traffic, and where the stakes become real. That promotion process—how artifacts move, how rollouts happen, how risk is managed—is the focus of the next chapter.

