# 8.9 — Model Deprecation and Sunset Policies

Every model version you deploy is a commitment you must eventually break. Deprecation policy determines how gracefully you break it. The model you publish today will be outdated next quarter. The prompt template that works perfectly now will become obsolete when requirements change. The configuration that serves production well will need replacement when you adopt new infrastructure. The artifact registry accumulates versions over time. Storage costs grow. Maintenance burden increases. Security vulnerabilities discovered in old dependencies require patching or removal. At some point, you must delete old versions. The question is not whether to deprecate, but how to deprecate without breaking systems that depend on the artifacts you plan to remove.

Deprecation is not deletion. Deprecation is the controlled process of notifying dependents, providing migration paths, enforcing transition periods, and finally removing artifacts once you have verified that nothing depends on them. Teams that skip the controlled process and jump straight to deletion create incidents. An internal team deleted model versions older than 90 days to save storage costs. They notified nobody. Two customer-facing systems that had been stable for months broke the following Tuesday when deployments failed because the model versions they referenced no longer existed. The deployments had not changed. The registry had. The incident lasted six hours while teams identified replacement versions, tested compatibility, and redeployed. The storage cost saved was approximately two hundred dollars per month. The incident cost in engineering time, customer impact, and reputation damage exceeded eighty thousand dollars. Deprecation without process is organizational self-sabotage.

## Why Deprecation Matters Beyond Storage Costs

The obvious reason to deprecate is storage cost. Every model version you keep costs money. If you train models weekly and deploy the best one, you accumulate 52 versions per year. If each version is 15 gigabytes, you are storing 780 gigabytes of model weights annually, growing without bound. The storage cost is measurable and non-trivial, especially when you include backup and redundancy. But storage cost is the least important reason to deprecate. It is just the easiest to quantify.

The more important reason is maintenance burden. Every version you publish creates a potential dependency. Some team, somewhere, might have pinned to that version. If a security vulnerability is discovered in the base model or a dependency, you need to determine whether that vulnerability affects any version still in use. The more versions you maintain, the more combinations you need to evaluate. A company maintaining 400 versions of its core model across three years found that security patch assessment took two full-time engineers five days every quarter. They reduced retention to six months and 30 versions. Security patch assessment now takes one engineer one day. The engineering capacity saved is more valuable than the storage cost saved.

Maintenance burden also includes operational complexity. Every version in the registry is a version someone might accidentally deploy. A developer selecting a model version from a dropdown sees 400 options spanning three years. Most of those options are wrong. Many are broken. Some have known issues. The developer has no way to distinguish the good choices from the bad ones without consulting documentation or asking colleagues. The cognitive load is unnecessary. If you deprecate aggressively, the dropdown contains 15 versions spanning the last six months, all of which are reasonable choices. The developer can make an informed decision without external help. Reducing options improves usability.

Deprecation also enables infrastructure evolution. If you want to change how models are stored, how metadata is structured, or how versioning schemes work, you need to migrate artifacts from the old system to the new one. The more artifacts you maintain, the more complex and risky the migration. A team that kept every version for five years faced a six-month migration project when they needed to change storage backends. The migration required converting 2,400 model versions, validating bit-for-bit equivalence, and updating all references. Teams that deprecate aggressively and keep only recent versions can migrate in days instead of months. The flexibility to evolve infrastructure is worth more than the storage cost of the deprecated artifacts.

## Deprecation Timeline: The Five-Stage Process

Effective deprecation is a sequence of stages with well-defined transitions. Each stage gives dependents time to notice, react, and migrate. Rushing through the stages creates incidents. Extending them unnecessarily delays infrastructure improvements. The timeline needs to balance dependent needs with organizational velocity.

The first stage is deprecation announcement. You mark a version as deprecated in the registry. The version remains fully functional and available. The only change is metadata. The registry now indicates that this version is deprecated, that it will be removed on a specific future date, and that dependents should migrate to a specified replacement version. The announcement is passive. It does not block usage. It provides information. A deprecated version can remain in this state for weeks or months, depending on your policy. The announcement period lets teams discover the deprecation through normal operations before enforcement begins.

The second stage is active warning. The system now logs a warning every time a deprecated version is accessed. If a deployment references a deprecated model, the deployment succeeds, but the logs contain a clear warning that the version is deprecated and will be removed. If an API client requests a deprecated version, the response includes a deprecation header with the sunset date and replacement version. These warnings are visible to operators and developers. They create actionable signals. Monitoring systems can alert on deprecation warnings, allowing teams to proactively identify and migrate dependencies before the sunset date. The active warning period typically lasts weeks to months.

The third stage is soft deprecation. The system still allows access to the deprecated version, but it requires explicit acknowledgment. If a deployment tries to reference a soft-deprecated version, it must include a flag or parameter that says "yes, I know this is deprecated and I accept the risk." This prevents accidental usage while allowing intentional usage for teams that need more time to migrate. Soft deprecation catches cases where a deployment configuration was copied from an old template that nobody noticed was referencing a deprecated version. The explicit acknowledgment forces the developer to notice and make a conscious decision. Soft deprecation typically lasts weeks.

The fourth stage is hard deprecation. The version is no longer accessible for new deployments. Existing deployments that are already running the version continue to work, but new deployments cannot reference it. This protects running systems from disruption while preventing new dependencies from forming. Hard deprecation is the point where "I was not paying attention" stops being an excuse. Any deployment created after this point cannot use the deprecated version. Teams that ignored warnings during the earlier stages now face a forced migration. Hard deprecation lasts days to weeks, long enough to give teams who are actively migrating time to finish, but short enough to maintain momentum toward sunset.

The fifth stage is deletion. The version is removed from the registry. Artifacts are deleted from storage. Metadata is archived but no longer accessible through the normal registry API. Any deployment that references the deleted version will fail. This is the final stage. It is irreversible. Deletion only occurs after you have verified that no active deployments depend on the version. If verification shows dependencies still exist, you extend the hard deprecation period and notify the dependent teams directly. Deletion without verification is negligence.

## Communication Requirements and Dependent Notification

Deprecation communication is not optional. Every team that depends on a version has a right to know it will be removed and when. The communication needs to reach the right people at the right time with enough detail to act on. A registry entry marking a version as deprecated is not sufficient communication. That is metadata. Communication requires active notification to humans who can make decisions.

The minimum communication requirement is email notification to the owners of every system that has deployed the deprecated version. The registry tracks which deployments use which versions. When you announce deprecation, you query the registry for all active deployments of that version, extract the owner contact information, and send personalized notifications. The notification includes the version being deprecated, the sunset date, the recommended replacement version, the reason for deprecation, and a link to migration documentation. It is not a mass email. It is a targeted notification to affected teams. If a team has deployed the version multiple times, they get one notification covering all affected deployments.

The notification timing matters. The announcement should occur at least 90 days before deletion for production systems, longer for regulated industries. This gives teams time to schedule migration work, test replacement versions, and redeploy. If you announce deprecation with a 14-day sunset, you are not giving teams time to migrate. You are creating a deadline-driven scramble that leads to mistakes. The longer timeline respects that teams have priorities and cannot drop everything for a deprecation you announced unilaterally.

Repeat notifications are necessary. The initial announcement goes out 90 days before sunset. A reminder goes out at 60 days. Another at 30 days. Another at 14 days. A final urgent warning at seven days. Each notification includes the countdown to sunset and the current migration status. If the team has already migrated all deployments, the notifications stop. If deployments still exist, the notifications continue. This repetition feels excessive. It is the only way to ensure the notification does not get lost in email or deprioritized beneath other work. People ignore the first notification. They pay attention when the fourth notification arrives with a seven-day countdown.

Communication also needs to be in-product. The registry UI displays deprecation warnings when someone views a deprecated version. The deployment tooling shows warnings when someone attempts to deploy a deprecated version. The API responses include deprecation headers. The logs include deprecation messages. You cannot assume that everyone reads email. Communication has to meet developers where they work. The in-product warnings are what catch the developer who missed the emails or joined the team after the announcement.

## Deprecation Warnings and Operational Visibility

Deprecation warnings need to be operationally visible. It is not enough to mark a version as deprecated in metadata. The deprecation needs to surface in the tools and dashboards that operators use daily. If a deployment references a deprecated version, that fact should be visible in the deployment status UI. If a deprecated version is still in use one week before sunset, that should trigger an alert that pages someone. The warning system turns deprecation from a passive state into an active operational concern.

The deployment pipeline is the primary enforcement point. When a CI/CD system attempts to deploy a version, it queries the registry to check deprecation status. If the version is deprecated, the pipeline surfaces a warning in the build logs and in any notification system the team uses. If the version is soft-deprecated, the pipeline requires an explicit override flag to proceed. If the version is hard-deprecated, the pipeline fails with a clear error message directing the team to the replacement version and migration documentation. The pipeline prevents deprecated versions from being deployed by accident.

Monitoring dashboards need a deprecation view. This view shows all currently deprecated versions, the sunset dates, the number of active deployments still using each version, and the teams responsible for those deployments. The view updates in real time. As teams migrate and redeploy, the deployment counts drop. When the count reaches zero, the version is ready for deletion. The deprecation view is what leadership uses to track deprecation progress and identify teams that need help migrating. It is also what internal communications teams use to target follow-up notifications.

Alerting on deprecation milestones is essential. When a version enters soft deprecation and deployments still exist, an alert fires. When a version is seven days from deletion and deployments still exist, a higher-priority alert fires. The alerts are routed to the teams that own the affected deployments, not to a central operations team. The team that deployed the version is responsible for migrating it. The alert ensures they know their deployment is at risk. If the alert is ignored and the version is deleted, the deployment will fail during the next update or restart. The alert gives them a chance to migrate proactively instead of reactively.

## Grace Periods and Balancing Agility with Stability

The grace period is the time between deprecation announcement and final deletion. The length of this period is a policy decision that balances organizational agility against dependent stability. A short grace period lets you evolve infrastructure quickly and remove obsolete artifacts. A long grace period gives dependents more time to migrate but slows infrastructure evolution. The right balance depends on your organizational context, the maturity of your processes, and the impact of breaking changes on dependents.

A startup with ten engineers and five deployments can use a 30-day grace period. Everyone knows each other. Communication is direct. Migration work can be prioritized quickly. The overhead of tracking deprecations is minimal. A short grace period lets the team iterate rapidly without accumulating legacy versions. A large enterprise with 200 teams and 800 deployments needs a 90-day minimum grace period, often longer. Communication takes time to reach the right people. Teams have roadmaps planned months in advance. Forcing a migration with 30 days notice disrupts those roadmaps and creates resentment. The longer grace period respects that coordination overhead scales with organization size.

Regulated industries often require even longer grace periods due to validation and approval requirements. A healthcare company needs to revalidate any change to a production model, which includes migrating to a new base model version. Revalidation requires generating test results, documenting the change, getting approval from compliance teams, and scheduling deployment during approved maintenance windows. This process takes 60 to 90 days in practice. A 90-day grace period gives them barely enough time to complete one migration. Overlapping deprecations become unmanageable. The company negotiated a 180-day minimum grace period for model deprecations. This feels excessively long to the AI platform team. It is the minimum that dependents can reliably meet given their organizational constraints.

Grace periods can vary by artifact type and severity. Model deprecations get 90 days. Prompt template deprecations get 60 days. Configuration file deprecations get 30 days. The variation reflects the impact and effort of migration. Migrating to a new model version requires revalidation and extensive testing. Migrating to a new prompt template requires testing but not revalidation. Migrating to a new configuration file is often trivial. The grace period should match the migration effort. Security-driven deprecations get shorter grace periods because delay increases risk. A model version with a critical security vulnerability might get a 14-day grace period for soft deprecation followed by immediate hard deprecation. The security risk outweighs the coordination burden.

The grace period is a commitment. Once you announce a deprecation with a specific sunset date, you honor that date. You do not move the deadline up because you want to delete artifacts sooner. You do not move the deadline back because teams did not migrate in time unless there are truly extenuating circumstances. The predictability is what makes deprecation policy trustworthy. If teams know that a 90-day grace period means 90 days, they can plan accordingly. If the deadline is uncertain, they cannot plan. Uncertainty leads to last-minute scrambles.

## Migration Support and Helping Dependents Transition

Announcing deprecation is necessary but not sufficient. Many teams need help migrating, especially if they lack expertise with the replacement version or if the migration requires non-trivial changes. Migration support is what turns deprecation from a disruption into a managed transition. The level of support depends on the complexity of the migration and the criticality of the deprecated artifact.

The minimum support is clear documentation. The deprecation announcement includes a link to migration documentation that explains why the version is being deprecated, what version should replace it, how the replacement differs from the deprecated version, and a step-by-step guide to migrating. If the replacement requires configuration changes, the documentation includes examples. If the replacement has different performance characteristics, the documentation explains what to expect. The goal is that a developer with moderate expertise can complete the migration without asking for help. Good documentation eliminates 80 percent of support requests.

For complex migrations, offer office hours or support channels. A dedicated Slack channel or regular office hours session where teams can ask questions and get help from the platform team accelerates migration. The platform team learns which parts of the migration are confusing and improves documentation accordingly. The dependent teams get unblocked quickly instead of struggling alone. A company deprecating a legacy model version that 40 teams depended on held weekly office hours for the entire 90-day grace period. Attendance was high in the first four weeks and dropped off as teams completed migration. The office hours prevented the deprecation from becoming a bottleneck.

For critical migrations or high-risk dependents, provide hands-on support. The platform team directly helps the dependent team migrate, reviews their changes, and validates that the migration succeeded. This level of support is expensive and does not scale, but for the five most critical systems in your organization, it is worth the investment. A healthcare company provided hands-on support to the three teams responsible for patient-facing diagnostic models during a deprecation. The platform team wrote migration scripts, validated the new model behavior, and participated in the redeployation. The migrations succeeded without incident. The investment in support ensured that high-risk systems did not become casualties of deprecation policy.

Migration tooling can automate repetitive work. If the migration from version 2.4.7 to version 2.5.0 requires updating references in 15 configuration files and rerunning a validation suite, a script can do that. The platform team provides the script along with the deprecation announcement. Dependent teams run the script, review the changes, and redeploy. The script eliminates manual error-prone work and accelerates migration. The effort to build the script is repaid by the reduction in support requests and migration time.

## Emergency Deprecation and Security-Driven Removal

Most deprecations follow the standard five-stage timeline. Emergency deprecations do not. When a security vulnerability is discovered that makes a model version dangerous to run, you cannot wait 90 days for teams to migrate. You need to remove the vulnerable version as quickly as possible while minimizing disruption to systems that depend on it. Emergency deprecation compresses the timeline from months to days or hours.

The emergency deprecation process starts with impact assessment. You query the registry to identify all active deployments using the vulnerable version. You contact the owners of those deployments immediately — not with a scheduled email, but with direct communication through whatever channel reaches them fastest. The notification explains the vulnerability, the risk, and the required action. It includes a recommended replacement version that has been validated as safe and compatible. The notification is not a request. It is an instruction with a deadline measured in hours or days.

Emergency deprecation skips the passive announcement and active warning stages and goes directly to soft deprecation or hard deprecation. If the vulnerability is severe, you hard-deprecate immediately. New deployments cannot reference the vulnerable version. Existing deployments continue running but are flagged for urgent replacement. If the vulnerability is critical — actively being exploited or likely to cause immediate harm — you move to deletion within 24 to 48 hours. This is aggressive. It is justified when the alternative is leaving a known dangerous vulnerability in production.

The challenge with emergency deprecation is that some dependents cannot migrate quickly. A regulated system that requires revalidation cannot complete that process in 24 hours. The team has a choice: run the vulnerable version temporarily with compensating controls, or take the system offline until migration completes. Neither option is good. The compensating controls might include additional monitoring, restricted access, or manual review of outputs. These mitigations reduce risk but do not eliminate it. The decision depends on the severity of the vulnerability versus the impact of downtime. There is no clean answer. Emergency deprecation forces hard trade-offs.

Post-emergency communication is essential. After the emergency deprecation completes, you conduct a postmortem that explains what happened, why the emergency action was necessary, how it was handled, and what the organization will do to prevent similar situations. The postmortem acknowledges the disruption emergency deprecation caused and thanks teams for responding quickly. It also identifies process improvements. Maybe the vulnerability could have been detected earlier. Maybe the emergency communication channels need improvement. Maybe the replacement version should have been pre-validated and ready to go. Emergency deprecation is a failure of planning. The postmortem turns that failure into learning.

## The Long Tail Problem and Confirming Zero Usage

The hardest part of deprecation is confirming that a version is safe to delete. The registry shows zero active deployments. That does not mean zero usage. A version might be referenced in documentation that someone will copy-paste next month. It might be pinned in a deployment configuration that has not been used in six months but will be used again. It might be cached in a developer's local environment. It might be referenced by a one-off script that runs quarterly. The long tail of potential usage is difficult to enumerate.

The conservative approach is to wait. After a version reaches zero active deployments, you leave it in hard deprecation for an additional 30 to 60 days before deleting. This waiting period catches the quarterly script, the forgotten deployment configuration, the developer returning from leave who has the old version cached. If someone tries to access the version during the waiting period, the registry logs the attempt and alerts the platform team. The alert is a signal that usage still exists. You extend the waiting period and investigate. If the waiting period passes with no access attempts, the version is safe to delete.

The aggressive approach is to make deletion reversible. Instead of permanently deleting artifacts, you move them to an archive tier that is not accessible through the normal registry API but can be restored if needed. The archive tier has much lower storage cost than the active registry. If someone needs an archived version, they file a request, and the platform team restores it temporarily. This approach lets you clean up the active registry aggressively while maintaining the ability to recover from mistakes. The downside is that restoration takes time and creates friction. If teams know they can always get an old version back, they might not take deprecation seriously.

The pragmatic approach is to combine waiting periods with usage analytics. The registry tracks access patterns for every version. If a version has not been accessed in 90 days, it is a strong signal that it is unused. If it has been accessed recently, it is in use somewhere. The analytics reduce guesswork. You can delete with confidence when the data shows zero access for an extended period. The analytics also identify versions that are accessed infrequently — the quarterly script case. For those versions, you can extend the deprecation period or keep them in an archived state.

Confirming zero usage is harder for versions that are referenced indirectly. A deployment might not reference model version 2.4.7 directly but instead reference a model bundle that internally references 2.4.7. The registry needs to track transitive dependencies to identify these cases. When you deprecate 2.4.7, the registry identifies all bundles that depend on it and flags those bundles as indirectly affected. The deprecation communication goes to the owners of the bundles, not just to the direct dependents. Transitive dependency tracking is complex but necessary for accurate deprecation.

## Sunset Ceremonies and Final Verification

The final step before deletion is verification. You have announced the deprecation, communicated repeatedly, enforced warnings, waited through the grace period, and confirmed zero active usage. The sunset date arrives. Before deleting the version, you perform one final check. This is the sunset ceremony — the last opportunity to catch a mistake before it becomes an incident.

The sunset ceremony includes querying the registry one more time for active deployments. You manually inspect the results. You cross-check against deployment logs to ensure no recent access attempts. You review the support channel for any last-minute migration issues. You verify that all dependent teams have confirmed completion of migration or explicitly accepted the risk of deletion. This verification takes 15 to 30 minutes. It catches cases where the automated checks missed something or where a team thought they had migrated but did not.

The sunset ceremony also includes a rollback plan. Before you delete the version, you document how to restore it if deletion causes an unexpected incident. This might mean keeping a backup of the artifact for 30 days before final deletion, or documenting the process to restore from archive, or identifying the nearest equivalent version that teams can migrate to in an emergency. The rollback plan is a safety net. You hope to never use it. Having it ready reduces the risk of deletion.

After deletion, you monitor for errors. Deployment failures, registry access errors, and support requests all signal that something still depended on the deleted version. If an error occurs within 24 hours of deletion, you treat it as a deprecation failure and restore the version. If the error occurs weeks later, it is likely an unrelated issue or a long-dormant dependency that should have been caught during the grace period. The monitoring window helps distinguish between deprecation mistakes and inevitable edge cases.

The sunset ceremony is a gate. It is the moment where theory meets practice. All the planning, communication, and policy enforcement converge into a single decision: delete or wait. The ceremony ensures that decision is informed. Deprecation policy without a sunset ceremony is incomplete. The ceremony is what prevents policy from becoming recklessness.

Deprecation is not just about removing old versions. It is about maintaining trust with dependents while evolving infrastructure. The next question is how to organize all these versioned artifacts, how to govern access and promotion, and how to make the registry the single source of truth for what exists and what is deployable. That is where the model registry pattern becomes essential.

