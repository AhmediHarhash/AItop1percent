# 11.3 — Watermarking, Screenshot Blocking, and Copy Controls

The reviewer's screen shows a medical query and a model response. The reviewer is working from home. Their laptop is positioned so their spouse can see the screen while walking past. Their toddler climbs onto their lap mid-shift and stares at the display. A video call in another window is recording because the reviewer forgot to stop the recording from an earlier meeting. None of this is malicious. All of it is exposure. The review interface can't control the physical environment, the other applications, or the human behavior. What it can control is whether the data on the screen can be captured, copied, or exfiltrated without leaving a trace.

Watermarking embeds invisible or visible identifiers into the displayed data so that if a screenshot or photo surfaces later, you can trace it back to the session, the reviewer, and the exact task. Screenshot blocking prevents common screenshot tools from capturing the review interface. Copy controls disable text selection and clipboard events so reviewers can't paste sensitive data into external tools. These controls don't prevent a determined attacker with a camera phone and OCR software. They prevent casual leakage, which accounts for 90% of actual breaches. The goal isn't perfect security — it's raising the cost of exfiltration high enough that accidental leakage becomes rare and intentional leakage becomes detectable.

## Visible Watermarks: Attribution in Plain Sight

A visible watermark displays the reviewer's ID, session ID, and timestamp as a semi-transparent overlay on every page of the review interface. It's rendered in the corner or along the edge, readable but not intrusive. The reviewer knows it's there. If they take a screenshot, the watermark appears in the image. If the screenshot leaks, you know exactly which session produced it.

Visible watermarks are psychological deterrents. They remind the reviewer, constantly, that their access is monitored and traceable. They remind anyone who sees the reviewer's screen that the data is sensitive and attributed. A reviewer is less likely to screenshot a task and share it in Slack when their employee ID is burned into the image. A colleague is less likely to forward a screenshot when it's obviously traced. The deterrent works even when the enforcement is imperfect.

Implementation is straightforward. The review interface renders the watermark as a fixed-position div or canvas overlay with high z-index, partially transparent, in a contrasting color. The watermark includes reviewer pseudonym, session start time, and a unique session token. Some implementations include the company name and a warning: "Confidential Review Data — Do Not Share." The watermark updates every few seconds to include a timestamp, making it harder to forge or reuse old screenshots.

The downside is usability. A watermark in the corner can obscure UI elements. A watermark across the center makes text harder to read. Reviewers complain. You tune the transparency, the size, and the position until it's visible enough to deter but unobtrusive enough not to slow review. The balance is subjective and audience-dependent. Contract reviewers accustomed to working with confidential data tolerate visible watermarks. Casual reviewers in low-stakes environments find them annoying. Tier the control: visible watermarks for high-risk review environments, invisible watermarks for standard environments, no watermarks for public or non-sensitive review.

## Invisible Watermarks: Steganography for Attribution

An invisible watermark embeds identifying information into the pixel data, text formatting, or layout in ways imperceptible to the human eye but detectable by software. If a screenshot leaks, you extract the watermark to identify the source. The reviewer doesn't see the watermark, so it doesn't affect usability. The reviewer also doesn't know it's there, which reduces the deterrent effect but preserves the forensic value.

For images and rendered text, steganographic techniques adjust RGB values by one or two bits per pixel to encode a binary payload — session ID, reviewer ID, timestamp. The changes are invisible at normal viewing distances. Standard screenshot tools capture the watermark along with the content. When a suspicious image surfaces, you run it through a watermark detection algorithm. If the watermark is present and valid, you know which session produced it. If the watermark is absent or corrupted, the image may be forged, recompressed, or edited after capture.

For text-based review interfaces, invisible watermarks use Unicode variation, zero-width characters, or subtle formatting differences. A space might be slightly wider in some positions. A letter might use a visually identical alternate glyph. A line might have an imperceptible extra pixel of padding. These variations encode data. If a reviewer copies text and pastes it into a document, the watermark travels with the text. When the document leaks, you extract the watermark from the formatting or character sequences.

The challenge is robustness. Recompressing an image, cropping it, or converting it to a different format can destroy the watermark. Pasting text into a plain-text editor strips formatting and zero-width characters. OCR from a photo of the screen doesn't preserve pixel-level variations. Invisible watermarks work best when the leakage path is direct — unaltered screenshots, unmodified copy-paste. They fail when the attacker introduces transformations. The forensic value depends on how the data escapes. Against casual leaks, invisible watermarks are effective. Against deliberate exfiltration with countermeasures, they're unreliable.

## Screenshot Blocking: Technical and Psychological

Most screenshot tools on Windows, macOS, and Linux work by calling OS-level APIs to capture the screen buffer. Browser-based screenshot blocking can't prevent those calls — the OS is outside the browser's control. What browsers can prevent is in-page screenshot tools, browser extensions that capture via JavaScript, and some screen-sharing software. The approach is limited but still valuable because it blocks the most common, most casual capture methods.

On the web, the CSS property `user-select: none` prevents text selection, making copy-paste harder. JavaScript can intercept and block context menu events, print dialogs, and certain keyboard shortcuts like Control-C or Command-Shift-3. The browser's built-in screenshot tools can be discouraged by detecting when the window is obscured or the focus is lost, then blanking the interface or showing a warning. These are all client-side controls, easily bypassed by a reviewer with developer tools open or a modified browser.

More aggressive blocking requires native applications or browser plugins. A custom Electron-based review client can use OS-level hooks to detect when screenshot tools are running and either block them, blank the window, or log the attempt. Windows supports flagging application windows as protected content, preventing many screen capture tools from including them. macOS allows apps to request screen recording permissions and detect when those permissions are being used by other apps. These approaches require deploying custom clients, which increases complexity and reduces compatibility, but they provide stronger enforcement than browser-based controls.

The psychological effect matters as much as the technical enforcement. A reviewer who sees a warning — "Screenshots are disabled in this environment" — is deterred even if the technical block is imperfect. A reviewer who tries to screenshot and sees the interface go black knows their attempt was detected and likely logged. Even if they could bypass the block with a camera phone, the friction and the awareness of monitoring reduce casual leakage.

## Copy Controls: Preventing Clipboard Exfiltration

Text selection and clipboard access are default browser behaviors. A review interface displaying sensitive queries and outputs is, by default, fully copy-pasteable. A reviewer can select all, copy, and paste the entire task into a text file, an email draft, a note-taking app, or a chat message. Copy controls disable these behaviors selectively.

The CSS property `user-select: none` prevents text selection with the mouse. It doesn't prevent keyboard-based selection or programmatic selection via JavaScript. To block keyboard shortcuts, JavaScript event listeners intercept Control-C, Command-C, and equivalent keys, call `preventDefault`, and optionally display a warning: "Copy is disabled for this content." This blocks casual copy attempts. It doesn't block a reviewer who opens the browser console and runs `document.body.innerText` to extract text programmatically. Client-side controls deter, not prevent.

For higher assurance, render text as images or canvas elements instead of HTML text. The reviewer sees readable text on screen, but it's pixel data, not selectable characters. Copy-paste doesn't work because there's no text to select. The trade-off is accessibility — screen readers can't parse image-rendered text without alt-text, and alt-text itself becomes a copy vector. You also sacrifice searchability, text reflow on zoom, and internationalization. Image-based rendering is a last resort for the most sensitive environments.

Clipboard monitoring is another layer. JavaScript can detect clipboard write events and log them server-side. If a reviewer manages to copy data despite controls, the system records the attempt — timestamp, content length, session ID. The log doesn't capture what was copied, only that a clipboard write occurred. This provides audit signal: if clipboard events spike for one reviewer, investigate. If clipboard events occur on tasks flagged as high-sensitivity, alert immediately.

## The Watermark-Screenshot-Copy Stack

Deploy these controls in layers. Visible watermarks deter casual screenshots. Invisible watermarks provide forensic traceability if screenshots leak anyway. Screenshot blocking prevents common capture tools. Copy controls prevent text exfiltration via clipboard. No single layer is perfect. Together, they raise the cost of exfiltration high enough that casual mistakes become rare and deliberate attacks leave traces.

For low-sensitivity review, the stack might be: invisible watermarks, no screenshot blocking, no copy controls. Reviewers work in standard browsers with standard tools. Casual leakage is tolerated as low-risk. For high-sensitivity review, the stack is: visible watermarks, screenshot blocking, copy controls, canvas-rendered text, clipboard monitoring, and custom review clients with OS-level protections. Every layer is active. Reviewers are told upfront that the environment is locked down and monitored. The friction is justified by the data sensitivity and the regulatory requirements.

## When Controls Break Legitimate Workflows

Reviewers sometimes need to copy text for legitimate reasons. They're documenting a labeling guideline and need to quote an example. They're reporting a bug and need to paste the exact query that triggered it. They're escalating a task to a senior reviewer and need to share context. Blanket copy controls block all of these. The result is workarounds: reviewers retype text manually, introducing errors. Reviewers take photos with their phones to share with colleagues, creating exactly the leakage risk the controls were meant to prevent.

The solution is selective unblocking. Copy controls can be disabled for specific UI elements — the task ID field, the instructions panel, the feedback text box. These elements don't contain sensitive user data. Reviewers can copy from them freely. The query and output fields remain protected. This preserves usability for common workflows while protecting the most sensitive content.

Another approach is approval-based copy. The interface includes a "Request Copy Access" button. The reviewer clicks it, enters a justification, and submits. The system logs the request and either grants temporary copy access for the current task or queues the request for manual approval. For environments with real-time admin coverage, the approval can happen within seconds. For asynchronous environments, the reviewer moves on and comes back later if access is granted. This creates a paper trail: every copy event is logged with a reason. If a leak occurs, you know not just who copied data but why they said they needed to.

## Forensic Value: What to Do When a Watermark Surfaces

A screenshot appears in a public forum. It shows a user query and a model response, clearly from your review environment. A visible watermark identifies the reviewer and session. You now have attribution. What do you do with it?

First, confirm the watermark is genuine. Check the session logs. Does the session ID match a real session? Does the timestamp fall within the session's active period? Does the reviewer ID correspond to an authorized reviewer? If all match, the screenshot is likely real. If anything mismatches, it may be forged — someone edited the watermark, or someone reconstructed a fake screenshot with a guessed watermark. Cross-check the screenshot content against task logs. Does the query and output pair appear in the tasks assigned to that session? If yes, the leak is confirmed.

Second, contain the breach. Suspend the reviewer's access immediately. Identify all tasks they reviewed in the 30 days prior. Determine whether any other sessions from the same device or IP address show anomalous behavior — high reveal rates, clipboard events, long idle times that might indicate screen recording. Pull the full task list and assess the scope: how many users' data was potentially exposed? The answer determines your regulatory notification obligations.

Third, investigate intent. Was this a deliberate exfiltration or a mistake? Review the session logs. Did the reviewer reveal the full query before taking the screenshot, suggesting intent? Did they reveal it because the task required it, suggesting legitimate use? Interview the reviewer if possible. They may admit it was an accident — they were showing a colleague an example of a confusing guideline and forgot the data was real. Or they may have no explanation, suggesting malicious exfiltration. The distinction affects whether you report to law enforcement and whether you terminate the contract.

Fourth, notify affected users and regulators as required. If the screenshot contains personal data and was shared publicly, it's a breach under GDPR and most other privacy laws. You have 72 hours to notify the regulator. Notification to affected users depends on risk: if the screenshot identified them by name or revealed sensitive attributes, they must be notified. If the data was pseudonymized or redacted, the risk may be low enough that user notification isn't required. Consult legal counsel early — the clock is already running.

## Screenshot Blocking Isn't Foolproof — It's Friction

A reviewer with a camera phone can photograph the screen. A reviewer with a second laptop can screen-capture the review interface from a live video feed. A reviewer with a hardware HDMI capture device can record the screen at the hardware level, invisible to software. No client-side control prevents these attacks. The question is whether the marginal friction is worth the cost.

For most environments, the answer is yes. The reviewer who photographs their screen with a phone is creating evidence — the photo's metadata includes GPS, device ID, and timestamp. If it leaks, you can trace it. The act of pulling out a phone and photographing a screen is also conspicuous. If the reviewer works in a shared office or a monitored space, someone notices. The friction isn't perfect prevention — it's risk elevation. Exfiltration becomes harder, more detectable, and more attributable.

For the highest-risk environments, you may need physical controls: reviewers work in secure facilities with no personal devices allowed, no cameras, no windows. Devices are monitored with endpoint detection. Screens face away from doors and windows. These controls are common in government, defense, and intelligence contexts. They're rare in commercial AI review environments because the cost is prohibitive. The pragmatic approach for most companies is layered software controls that deter 95% of leakage, combined with legal agreements, background checks, and audit trails that enable prosecution of the remaining 5%.

## The Message to Reviewers: We Protect You, Not Just the Data

Watermarking and copy controls can feel like surveillance. If the framing is "we don't trust you," morale collapses. The correct framing is "this data is so sensitive that we need controls to protect you from liability if something goes wrong." If a screenshot leaks and it wasn't watermarked, the reviewer is a suspect. If it was watermarked, the watermark proves who was responsible, exonerating everyone else. If the reviewer never had the ability to copy data, they can't be blamed for data found on their clipboard. The controls create accountability, which creates fairness.

Training should emphasize this. The company isn't assuming reviewers are malicious. The company is assuming that mistakes happen, devices get compromised, and human behavior is unpredictable. The controls exist to make sure that when something goes wrong, the investigation is fast, the scope is knowable, and the responsible party is identifiable. This protects the company, the users, and the reviewers. Everyone benefits from clarity.

The next subchapter covers audit trails and session replay — how to log every action in the review environment so that if a breach occurs, you can reconstruct exactly what happened, when, and by whom.
