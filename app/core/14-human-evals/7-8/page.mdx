# 7.8 — Incident Triage for High-Severity Content

In October 2025, a social platform's trust and safety team encountered what initially appeared to be a routine policy violation report. A reviewer opened the case, saw threatening language, and began the standard review workflow. Three minutes later, they escalated to their team lead. Five minutes after that, the platform's incident response team was on a call with law enforcement. The content described a credible, imminent threat with specific location details and a timeline. The reviewer who first opened the case later said the hardest part was not knowing what to do in the first thirty seconds — the protocol document said "escalate immediately for threats," but not who to escalate to, how to preserve evidence, or what "immediately" meant when you had forty other cases in your queue. The company revised their triage system that week. By the time they finished, they had six severity tiers, clear escalation paths for each, and response-time requirements measured in minutes, not hours.

Not all content reviewers see is equal in urgency. Most policy violations can wait in a queue. Some require same-day action. A small percentage demand immediate response — threats to life, child safety emergencies, evidence of ongoing criminal activity. The difference between these categories is not just severity. It is time sensitivity. A piece of misinformation reviewed four hours from now causes the same harm as if reviewed immediately. A credible suicide threat reviewed four hours from now may be too late. Incident triage is the system that recognizes high-severity content the moment it arrives and routes it to people with the authority, training, and protocols to act within minutes.

## Defining the Severity Ladder

Most human review systems operate on a simple binary: violates policy or does not. Incident triage adds a second axis: how fast does this need action? The combination creates a severity ladder. At the bottom: content that violates policy but poses no immediate risk — spam, low-quality engagement bait, minor harassment. These go into the standard review queue. Mid-tier: serious policy violations that need same-day resolution — hate speech, graphic violence, sexual content involving adults. These get priority routing but not emergency treatment. Top tier: content that requires immediate action because delay increases harm — active threats, child exploitation material, content revealing ongoing criminal activity, imminent self-harm indicators. These trigger incident protocols.

The line between tiers is not subjective. It is defined by three questions. First: does delay increase harm? If waiting four hours means someone gets hurt, it is top-tier. Second: does this content require coordination with external parties? If law enforcement, mental health crisis teams, or platform legal need to be involved, it is likely top-tier. Third: does the reviewer have authority to act, or does this need executive decision-making? If the content involves a high-profile account, a government entity, or potential legal liability, it moves up the ladder regardless of content severity.

The ladder must be simple enough that a reviewer can assess severity in under thirty seconds. Complex rubrics fail under pressure. A well-designed severity system uses clear, observable signals. Specific location mentioned? Tier up. Timeline or countdown language? Tier up. Imagery showing weapons or preparation? Tier up. The reviewer is not making a threat assessment — they are pattern-matching to a checklist. The assessment happens after escalation, by people trained to do it.

## Escalation Paths and Contact Trees

When a reviewer identifies high-severity content, the next ten seconds determine whether the incident response works. They need to know exactly who to contact, through what channel, and what information to include. This is not the time for "check the wiki" or "ask your manager." The escalation path must be visible in the review interface itself — a button that says "escalate to incident team," not a Slack channel they have to remember or an email address they have to look up.

The contact tree has multiple branches because not all high-severity content needs the same response team. Imminent harm cases go to a dedicated incident coordinator who interfaces with crisis services and law enforcement. Child safety cases go to the specialized team that handles mandatory reporting and evidence preservation. Content involving high-profile accounts or potential PR crises goes to a leadership team that includes legal and communications. The reviewer does not choose the branch — the severity checklist does. When they click "escalate," the system routes based on the triage category they selected.

Each branch has primary and backup contacts available around the clock. If your platform operates globally, high-severity content does not wait for business hours in San Francisco. The incident coordinator role is staffed 24/7, either by rotating on-call shifts or by distributed teams across time zones. The backup contact is not just "if primary does not respond" — it is "if primary does not respond within five minutes." When someone's safety is at stake, you do not wait for a calendar reminder.

The contact tree includes external partners. If your platform has a relationship with crisis intervention organizations like the National Suicide Prevention Lifeline or local mental health services, those contacts are pre-loaded. If you have a law enforcement liaison, their contact information is in the system. The reviewer should never have to Google "how to report this to police" while staring at a case. They click escalate, the system notifies the internal incident coordinator, and the coordinator activates external resources if needed.

## Response Time Requirements by Tier

The word "immediately" is not a protocol. It is a feeling. A functioning incident triage system replaces feeling with time-bound requirements. Top-tier content has a five-minute escalation window. From the moment the reviewer clicks "escalate," the incident coordinator must acknowledge receipt within five minutes. Not resolve — acknowledge. The reviewer needs confirmation that the case is now in the hands of someone empowered to act. If five minutes pass without acknowledgment, the system alerts the backup contact.

Acknowledgment is not the same as resolution. The incident coordinator's first action is confirming they have the case, preserving the evidence, and assessing whether external parties need immediate notification. Resolution timelines vary by case type. A suicide threat may require outreach within fifteen minutes. A child safety case may require law enforcement contact within thirty minutes and evidence packaging within two hours. A credible violence threat may require platform-level action — account suspension, content removal, user notification — within ten minutes, with law enforcement notification in parallel.

Mid-tier content operates on a same-day resolution standard. A case flagged at 9 AM should have a decision by end of business. This does not mean it sits in a queue for eight hours. It means the system guarantees it will be reviewed and actioned within that window. Priority queues, dedicated reviewers, or time-based alerts ensure mid-tier cases do not age out.

Standard-tier content can wait longer, but not indefinitely. A multi-day backlog is a failure mode. Even low-severity content should see a decision within 48 hours. Users who report violations and hear nothing for a week stop reporting. The triage system is not just about catching emergencies — it is about maintaining trust across all severity levels.

## Documentation During Active Incidents

When a reviewer escalates a high-severity case, they are creating evidence. What they document in the next two minutes may be reviewed by law enforcement, legal teams, or external investigators. It may become part of a court record. Documentation during incidents is not "add a note if you have time." It is a required step before the case leaves the reviewer's hands.

The documentation checklist is short and factual. What content was reported? Include direct quotes or precise descriptions, not interpretations. When was it posted? Include timestamps with time zones. Who reported it? Capture reporter account details and the report reason they selected. What actions did the reviewer take before escalation? Note if they removed the content, suspended the account, or left it active pending incident team review. What severity tier was assigned and why? Note the specific checklist items that triggered escalation.

The reviewer does not conduct investigation or assess credibility. They document what they observed. "Content contains specific threat against named individual with date and location" is correct. "User is probably not serious but escalating out of caution" is not. Opinions, speculation, and hedging do not belong in incident documentation. The incident team will do threat assessment. The reviewer's job is preserving the facts.

Screenshots and evidence preservation happen automatically if the system is built correctly. The moment a reviewer opens a high-severity case, the platform captures a full snapshot — content text, associated images, account metadata, post history for the last 30 days. The reviewer should not have to manually screenshot or copy-paste. Manual processes fail under time pressure. Automated evidence capture ensures nothing is lost if content is deleted or accounts are closed during the incident window.

If the content is still live, the documentation notes whether it was removed as part of escalation. Some incidents require leaving content up temporarily so law enforcement can monitor account activity. Others require immediate takedown to prevent further harm. The incident coordinator decides, but the reviewer documents the state at time of escalation.

## Preserving Reviewer Safety During Triage

Incident triage does not mean reviewers are exposed to the worst content unfiltered. The opposite. A well-designed triage system uses automated classifiers and keyword filters to pre-screen content before it reaches human eyes. If a piece of content contains phrases associated with self-harm, graphic violence, or child exploitation, the system flags it as high-severity before any reviewer opens it. The reviewer knows what category they are about to see and can prepare accordingly.

Some platforms blur or redact content by default for high-severity cases. The reviewer sees a summary — "content flagged for graphic violence, contains weapon imagery and threat language, posted 14 minutes ago" — before seeing the content itself. They can choose to proceed, or they can escalate directly based on the summary and let the incident coordinator review the full content. Not every high-severity case requires every reviewer to see every detail.

The system tracks how many high-severity cases each reviewer sees per shift. Incident triage does not mean one person handles all the worst content. It means high-severity cases are distributed to reviewers with appropriate training, current wellness status, and bandwidth. If a reviewer handled three suicide cases in one day, the system routes the next one to someone else unless no one else is available. Triage should not concentrate exposure.

Reviewers who escalate high-severity cases get immediate support. After escalation, their next task is a cooldown period — reviewing standard-tier content or taking a break. They do not move from one crisis to the next. The triage system includes a built-in buffer. Some platforms use a "safe case" rule: after a top-tier escalation, the reviewer's next three cases are guaranteed to be low-severity. This is not coddling. It is operational design. A reviewer processing a trauma case cannot immediately shift to another without recovery time. Quality degrades, errors increase, and burnout accelerates.

## Auditing Triage Decisions and Escalation Accuracy

Incident triage systems get audited differently than standard review workflows. The question is not "did the reviewer make the right decision?" It is "did the system identify urgent content fast enough?" An audit looks at three metrics. First: what percentage of content later confirmed as top-tier was correctly escalated within the five-minute window? If high-severity content sat in a standard queue for thirty minutes because the reviewer missed the signals, the checklist needs revision. Second: what percentage of escalations were appropriate? If reviewers are escalating mid-tier content as top-tier out of caution, the triage system creates false alarm fatigue. Third: how long did it take from escalation to incident coordinator acknowledgment? If the five-minute window is consistently missed, the coordinator staffing model is broken.

False negatives — high-severity content that was not escalated — are investigated individually. If a credible threat was reviewed as a standard policy violation and not escalated, the audit asks why. Was the severity checklist incomplete? Did the reviewer lack training? Was the content ambiguous enough that the miss was reasonable? The answer determines whether the system needs changes or the reviewer needs retraining.

False positives — standard content escalated as high-severity — are also investigated, but with less urgency. Over-escalation is safer than under-escalation. A reviewer who escalates five cases and three turn out to be non-urgent is not penalized. A reviewer who misses one credible threat is. The triage system is biased toward escalation by design. Better to have the incident coordinator review three false alarms than to miss one real crisis.

Escalation accuracy is tracked per reviewer but used as a system metric, not a performance review metric. If one reviewer has a much higher false positive rate than peers, they may need checklist training. If every reviewer is escalating a particular content type that turns out to be non-urgent, the checklist is wrong, not the reviewers. Triage accuracy is a training and tooling problem, not an individual performance problem.

## Incident Coordination with External Authorities

When content requires law enforcement involvement, the incident coordinator handles that contact, not the reviewer. The reviewer escalates, the coordinator assesses, and the coordinator decides whether external notification is required. This division exists for legal and operational reasons. Law enforcement requests need to follow jurisdictional rules, legal process, and corporate counsel guidance. Reviewers are not trained to navigate those constraints. Coordinators are.

The coordinator role is staffed by people with crisis response training and familiarity with the legal framework in every region the platform operates. If content originates from a user in Germany, the coordinator knows which German authorities to contact and what information can be shared under GDPR. If content involves a user in California, the coordinator knows whether the platform has mandatory reporting obligations and what evidence preservation law enforcement can request.

The platform maintains formal relationships with law enforcement in major operating regions. These are not "we'll call 911 if something happens" relationships. They are pre-established contacts with cybercrime units, national security teams, and child protection agencies. When an incident occurs, the coordinator is calling a known contact, not explaining the platform's existence to a police dispatcher. Response time improves dramatically when the relationship exists before the emergency.

Some platforms provide law enforcement with a dedicated portal for requesting information related to escalated incidents. This keeps evidence chains clear and ensures requests are logged. The incident coordinator documents every external contact — who was called, what information was shared, what actions law enforcement took or requested. This documentation protects the platform, the user whose content was reported, and the reviewer who escalated the case.

## Post-Incident Debrief and Process Refinement

Every high-severity escalation is reviewed after resolution. The debrief is not about assigning blame. It is about identifying process gaps. The incident coordinator leads the debrief, with the reviewer who escalated the case and any other team members involved. The questions are standard. What went well? What slowed response? Was the severity checklist accurate for this case? Did the escalation path work? Was evidence preserved correctly? Did external coordination happen smoothly? What would we change next time?

If the incident revealed a gap — a contact who was unreachable, a documentation step that was unclear, a severity signal that was not on the checklist — that gap gets fixed within days, not months. Incident response systems that wait for quarterly reviews to update protocols will repeat the same failures. The debrief produces action items, those action items have owners, and changes are deployed immediately.

The debrief also checks in on the reviewer's well-being. Escalating a high-severity case is stressful even when the system works perfectly. The debrief includes a simple question: do you need support? The reviewer can request a follow-up with a counselor, additional time off, or a temporary shift to lower-severity work. This is not optional kindness. It is operational necessity. A reviewer who handles a traumatic case and receives no follow-up is more likely to quit, burn out, or make errors in future cases.

Patterns across incidents inform system-wide changes. If the platform sees a spike in self-harm content during a particular news cycle, the triage system adjusts — additional reviewers assigned to high-severity queues, proactive outreach to crisis organizations, updated guidance on response protocols. Incident triage is not static. It adapts to the platform's evolving content landscape and external events that drive user behavior.

The next subchapter examines how safety reviewer operations coordinate with product and policy teams — the feedback loops that turn front-line observations into platform-level changes, the standing meetings that keep cross-functional teams aligned, and the incident reporting structures that ensure leadership sees what reviewers are seeing.
