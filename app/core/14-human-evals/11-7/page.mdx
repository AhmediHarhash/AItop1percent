# 11.7 — Data Classification and Handling Requirements

What does it mean to say that a piece of data is sensitive? Every organization has an intuitive sense of what should be protected — customer names, medical records, financial transactions, trade secrets — but intuition does not translate into consistent handling policies until you classify data into defined tiers and attach specific controls to each tier. Data classification is the taxonomy that determines which reviewers can access which data, which security controls must be active during review, how long the data can be retained, and what happens when a handling requirement is violated.

Without classification, every review session is a negotiation. Product asks whether a new vendor can review customer support chats. Security asks whether the chats contain PII. Product says probably not. Security says maybe some do. Legal says we should assume they do. The conversation loops for three weeks while review work sits in a queue. With classification, the answer is deterministic. Customer support chats are classified as Tier 2, which means they may contain PII, which means reviewers must be GDPR-trained, sessions must use VDI, and logs must be retained for six years. The vendor either meets those requirements or they do not. The conversation takes one day.

## The Five-Tier Classification Model

Most organizations converge on a classification model with three to five tiers. A five-tier model provides enough granularity to handle the range of data types you encounter in AI review systems without creating so many categories that teams cannot remember which tier applies to which data. The five tiers are Public, Internal, Confidential, Regulated, and Restricted.

**Public** data is anything you could publish on your website without legal or reputational harm. Marketing content, public API documentation, anonymized product usage trends. Public data does not require special handling during review. Any reviewer, whether internal or external, can access it. Sessions do not require VDI. Logs do not require encryption. Retention policies follow general business record rules.

**Internal** data is anything that should not be shared outside the organization but does not contain personally identifiable information or trade secrets. Internal project roadmaps, draft product specifications, anonymized eval metrics for internal models. Internal data requires basic access controls. External reviewers can access it if they have signed a non-disclosure agreement. Sessions do not require VDI, but reviewers must authenticate. Logs are encrypted at rest. Retention follows business record rules unless a specific project requires longer retention for audit purposes.

**Confidential** data is anything that, if disclosed, would harm the organization or a customer. Customer names, email addresses, business transaction details, model performance data that reveals strategic direction. Confidential data requires strong access controls. Only vetted external reviewers can access it. Sessions require VDI or secure browser environments. Clipboard and peripheral access are disabled. Logs are encrypted at rest and in transit. Retention follows the longest applicable business contract or regulatory requirement — typically three to seven years.

**Regulated** data is anything subject to legal or regulatory protection. Personal data under GDPR, protected health information under HIPAA, financial records under SOX, payment card data under PCI-DSS, content that falls under the EU AI Act's high-risk system requirements. Regulated data requires compliance-specific controls. Reviewers must be trained in the relevant regulation. Sessions require VDI with region-locked access. Data must remain in compliant cloud regions. Logs must be tamper-evident and retained for the regulatory minimum — six years for HIPAA, seven years for SOX, indefinitely for certain GDPR right-to-erasure exclusions. Vendors must sign data processing agreements that include liability for regulatory violations.

**Restricted** data is anything so sensitive that even internal access is limited to named individuals. Trade secrets, unreleased product code, merger and acquisition details, patient records for high-profile individuals, content moderation cases under active legal investigation. Restricted data requires approval for every access. Reviewers are named individually, not assigned by skill tag. Sessions require VDI with session recording. Every access is logged and reviewed by a compliance officer. Retention is indefinite or until the legal matter is resolved. Restricted data is rarely seen in large-scale human review. When it appears, it is handled as a special case outside the normal review workflow.

## Assigning Classification to Review Data

Every dataset in your review system must have a classification label. The label is assigned when the data is ingested. The assignment is not automatic. A human — typically a data owner, a legal representative, or a compliance officer — reviews the data schema, examines sample records, and assigns the classification based on policy.

You document the classification decision. You record who classified the data, what date they classified it, what classification tier was assigned, and what reasoning justified the tier. If the data contains any personal identifiers — names, email addresses, IP addresses, user IDs that can be correlated to real people — it is at least Confidential and possibly Regulated depending on jurisdiction. If the data contains health information, financial information, or information about children, it is Regulated. If the data could be published without redaction, it is Public. If none of those conditions apply, it is Internal or Confidential depending on business sensitivity.

The classification can change over time. A dataset that starts as Confidential might be downgraded to Internal after anonymization. A dataset that starts as Internal might be upgraded to Regulated after legal review determines it contains information covered by the EU AI Act. When the classification changes, you update the label, re-evaluate access controls, and notify any active reviewers that handling requirements have changed.

## Mapping Classification to Technical Controls

Each classification tier maps to a set of technical controls. The controls are enforced by the review platform, not by reviewer discipline. A reviewer assigned to a Regulated dataset cannot opt out of VDI. A reviewer accessing Confidential data cannot enable clipboard access. The platform enforces the policy based on the data classification label attached to every task.

For Public data, no special controls are required. For Internal data, authentication and session encryption are required. For Confidential data, VDI or secure browser sessions are required, clipboard and peripheral access are disabled, and session timeouts are set to ten minutes of inactivity. For Regulated data, all Confidential controls apply, plus region-locked access, compliance training verification, tamper-evident logging, and retention enforcement. For Restricted data, all Regulated controls apply, plus session recording, individual access approval, and manual compliance review of every session.

You test the mappings during platform configuration. You create test datasets at each classification tier. You assign test reviewers to each tier. You verify that a reviewer accessing Public data does not trigger VDI requirements. You verify that a reviewer accessing Regulated data cannot bypass VDI. You attempt to access Restricted data with a reviewer account that lacks individual approval. The system should block the access and log the attempt.

## Reviewer Clearance and Training Requirements

Not every reviewer is cleared to access every classification tier. Clearance is tied to training, background checks, contractual agreements, and regulatory certifications. A reviewer who has completed GDPR training is cleared for Confidential and Regulated data in EU jurisdictions. A reviewer who has completed HIPAA training is cleared for Regulated data in US healthcare contexts. A reviewer who has signed an NDA is cleared for Internal and Confidential data. A reviewer who has none of these clearances is limited to Public data.

The clearance is recorded in the reviewer's profile. When the reviewer attempts to access a task, the platform checks the task's data classification and compares it to the reviewer's clearances. If the reviewer is cleared, the task is assigned. If the reviewer is not cleared, the task is skipped and the next reviewer in the queue is considered. The reviewer does not see a denial message. They simply never receive tasks they are not cleared for.

Clearances expire. GDPR training is valid for one year. HIPAA training is valid for one year. Background checks are valid for two years. When a clearance expires, the reviewer's profile is updated. The next time they log in, they are prompted to renew their training or certification. Until they renew, they cannot access tasks at the classification tier that required the expired clearance.

You audit clearances quarterly. You generate a report showing which reviewers have access to which classification tiers, which clearances authorize that access, and which clearances are within 30 days of expiration. You notify reviewers and vendors when clearances are about to expire. If a clearance expires and is not renewed within 30 days, the reviewer's access is suspended until they complete the renewal.

## Handling Mixed-Classification Datasets

Some datasets contain records at multiple classification tiers. A customer support chat transcript might include a user's email address, which makes it Confidential, but it might also include a user's health condition mentioned in the chat, which makes it Regulated under HIPAA. The dataset as a whole must be classified at the highest tier present. If any record is Regulated, the entire dataset is Regulated, and all reviewers must meet Regulated clearance and handling requirements.

This can be inefficient. You might have a dataset of 100,000 support chats where 2% mention health conditions. Classifying the entire dataset as Regulated forces you to apply HIPAA controls to 98,000 chats that do not need them. The alternative is to split the dataset. You run an automated scan or a preliminary human review to identify the 2,000 chats that mention health conditions. You move those chats to a Regulated dataset. The remaining 98,000 chats stay in a Confidential dataset. Now you can assign the Regulated subset to HIPAA-cleared reviewers and the Confidential subset to less expensive, non-HIPAA reviewers.

Splitting datasets requires care. The automated scan must be conservative. If it misses a health mention and leaves a Regulated record in the Confidential dataset, you have a compliance violation. You run the scan, then run a manual spot-check on a sample of records that the scan classified as Confidential. If the spot-check finds any Regulated content, you re-run the scan with stricter filters or you classify the entire dataset as Regulated and accept the cost.

## Data Minimization and Redaction

Data classification intersects with data minimization. GDPR and the EU AI Act both require that you collect and process only the minimum data necessary for the purpose. If you are reviewing model outputs for tone and helpfulness, you do not need to show the reviewer the user's email address, phone number, or account ID. You can redact those fields before sending the task to the reviewer. Redaction reduces the classification tier. A customer support chat that includes an email address is Confidential. The same chat with the email address redacted might be Internal.

Redaction must be irreversible. If you redact an email address by replacing it with a placeholder like USER_EMAIL, the original email must not be recoverable from the review system. You apply the redaction in the data ingestion pipeline, before the data reaches the review database. The unredacted data is stored separately, in a system that reviewers do not access. The review system sees only the redacted version.

You document what was redacted and why. If a regulator asks why a dataset is classified as Internal instead of Confidential, you explain that all PII was redacted before review. You provide the redaction policy, the redaction script, and sample records showing before and after. The regulator can verify that the redaction is sufficient to justify the lower classification.

## Cross-Border Data Transfer and Classification

Data classification affects where review can happen. If your data is classified as Regulated under GDPR, it must remain in the EU unless you have implemented Standard Contractual Clauses or another approved transfer mechanism. If your data is classified as Regulated under HIPAA, it must remain in HIPAA-compliant US regions. If your data is classified as Confidential but not subject to specific geographic restrictions, you can allow review from any region where you have contractual agreements with vetted vendors.

You enforce geographic restrictions at the VDI and network level. A reviewer in India cannot access a GDPR Regulated dataset unless the dataset has been transferred to a non-EU region under Standard Contractual Clauses and the reviewer is employed by a vendor that is a party to those clauses. The VDI gateway blocks connections from IP addresses outside the permitted regions. If a permitted reviewer travels to a non-permitted region and tries to log in, the session is denied.

You monitor for violations. If a reviewer's IP address suddenly changes from Germany to the United States mid-session, the session is terminated and an alert is triggered. Either the reviewer is using a VPN to bypass geographic restrictions, or their credentials were compromised and someone in a different region is accessing the system. Either scenario requires investigation.

## Incident Handling for Misclassification

When a dataset is misclassified, the consequences depend on the direction of the error. If a Confidential dataset was labeled as Internal, you exposed the data to reviewers who did not sign NDAs and to sessions that did not enforce VDI. You must treat this as a data breach. You identify every reviewer who accessed the misclassified data. You notify affected customers. You determine whether any data was exfiltrated. You upgrade the classification, revoke access from reviewers who no longer meet the new tier's requirements, and re-review any judgments made under insufficient controls.

If an Internal dataset was labeled as Confidential, you applied stricter controls than necessary. This is not a breach, but it is inefficient. You paid for VDI sessions and HIPAA-cleared reviewers when you did not need to. You identify the misclassification, downgrade the label, and update the handling requirements going forward. You do not need to re-review past judgments because the judgments were made under stricter controls than required. The data was over-protected, not under-protected.

You investigate the root cause of every misclassification. Was the classification policy unclear? Was the data owner untrained? Was the classification decision rushed? You update the policy, provide additional training, or slow down the intake process to ensure proper review. Misclassification is preventable. When it happens, it reveals a gap in process or knowledge. You close the gap before the next dataset arrives.

Data classification is not a static label. It is a living policy that evolves as the data changes, as regulations change, and as your understanding of the data deepens. Every quarter, you re-review the classification of your most sensitive datasets. You ask whether the data is still used for its original purpose. You ask whether redaction or anonymization could lower the classification tier. You ask whether new regulations have imposed additional handling requirements. Classification is the interface between legal risk, operational cost, and reviewer access. Get it right, and review is efficient and compliant. Get it wrong, and every review session is a potential breach waiting to be discovered during the next audit.

