# 12.7 — Financial Services Compliance: SOX and Beyond

Every system that touches financial reporting is a SOX control. This includes the human review platform that validates your AI model's outputs before they feed into revenue recognition, fraud detection, credit decisioning, or any other process that affects the accuracy of financial statements. If your model processes transactions that impact the numbers your CFO signs off on, and humans review those outputs as part of quality assurance, those reviews are part of your internal control framework under Sarbanes-Oxley. The external auditor will ask to see evidence that reviews happened, that reviewers were qualified, that exceptions were escalated, and that the system prevents unauthorized changes to review decisions. If you cannot produce that evidence, your controls are deficient, your financial statements are unreliable, and your executives face personal liability.

SOX compliance in human review infrastructure means designing systems that create auditable trails, enforce segregation of duties, restrict access to authorized personnel, prevent tampering with evidence, and produce the documentation that external auditors require to assess control effectiveness. It is not about AI. It is about proving to a third-party auditor that the numbers are right and that you have processes in place to catch errors before they become material misstatements.

## What Makes a Review Process SOX-Relevant

Not every human review workflow is SOX-relevant. A review process is relevant if the data or decisions it validates flow into systems that affect financial reporting. If your model classifies customer support tickets and humans review the accuracy of those classifications, that review is not SOX-relevant unless ticket volume drives revenue recognition. If your model detects fraudulent transactions and humans review flagged cases before blocking payment, that review is SOX-relevant because fraud losses affect financial statements. If your model generates contract summaries and humans verify accuracy before those summaries inform revenue forecasts, that review is SOX-relevant.

The determining factor is impact on financial statements. If an error in the review process could lead to materially misstated revenue, expenses, assets, or liabilities, the review process is a control, and it must be designed, documented, tested, and maintained under SOX Section 404 requirements.

Revenue recognition workflows are almost always SOX-relevant. If your model extracts contract terms to determine when revenue should be recognized, and humans review those extractions, the review process is a control over revenue accuracy. If the model misclassifies a multi-year contract as a one-time sale and the reviewer fails to catch the error, revenue is overstated, and the financial statements are wrong. The review process exists to prevent that error. The control is effective only if you can prove reviews happen consistently, reviewers are competent, and errors are caught and corrected.

Fraud detection workflows are SOX-relevant when fraud losses are material to the financial statements. If your model flags suspicious transactions and humans review the flags before blocking accounts, the review process controls the accuracy of fraud loss accruals. If reviewers are inconsistent, if high-risk cases are not escalated, or if there is no secondary review for edge cases, fraud losses may be understated, and the control is ineffective.

Credit decisioning workflows are SOX-relevant at financial institutions where loan loss reserves affect financial statements. If your model scores credit risk and humans review approvals or denials, the review process controls the accuracy of credit decisions that drive reserve calculations. If reviewers override model scores without documentation, if there is no audit trail of overrides, or if override decisions are not periodically tested for accuracy, the control fails.

Expense classification workflows become SOX-relevant when expense recognition affects earnings. If your model categorizes expenses and humans review classifications, errors in that review can misstate cost of goods sold, operating expenses, or capital expenditures. A misclassified capital expense recognized as an operating expense understates assets and overstates expenses in the current period. If the review process does not catch the error, the financial statements are materially wrong.

## Segregation of Duties and Access Controls

SOX requires segregation of incompatible duties to reduce the risk of fraud and error. In human review workflows, this means separating the roles of reviewer, approver, and system administrator. A person who reviews AI outputs should not also have the ability to modify the underlying data, override the model's decision without a secondary check, or alter review logs.

A reviewer can evaluate whether a model's classification is correct. They cannot change the source data the model processed. A senior reviewer can approve or reject another reviewer's decision. They cannot delete review records or modify audit logs. A system administrator can manage user accounts and access permissions. They cannot perform reviews or approve decisions. If one person holds multiple roles, the control is weak.

Segregation extends to access permissions. A reviewer working on fraud cases should not have access to credit decisioning cases unless their role requires it. A reviewer validating revenue recognition should not have write access to financial reporting systems. A contractor performing annotation should not have administrator privileges. The principle is that access is granted based on job function and restricted to the minimum necessary to perform that function.

Role-based access control enforces segregation. Define roles for reviewer, senior reviewer, quality auditor, and system administrator. Assign permissions to roles, not to individuals. Grant individuals the roles their job requires, and revoke roles when job function changes. If a reviewer is promoted to a management role, their reviewer permissions should be revoked if they no longer perform review work. If a contractor's engagement ends, their access is terminated immediately.

Access control logs are part of the evidence trail. External auditors will request reports showing who had access to the review system during the audit period, what permissions they held, when access was granted, and when it was revoked. If the report shows that a terminated employee retained access for three months after departure, the control is deficient. If the report shows that an administrator performed review tasks, segregation of duties has failed.

## Audit Trails and Change Logging

SOX requires maintaining evidence of control operation. For review workflows, this means logging every action that affects the review decision or the integrity of the review process. Who accessed the case, when, what decision they made, whether they changed a prior decision, who approved it, and whether any exceptions were escalated. The logs must be immutable, time-stamped, and retained for the period required by record retention policies — typically seven years for financial records.

Audit trails must capture reviewer identity. A log entry that says "review completed" without identifying who completed it is useless. The log must record the unique user ID, timestamp, case ID, the decision made, and any comments or justification provided. If the reviewer changed a decision after initial submission, the log must record both the original and revised decisions with timestamps and reasons for change.

Change logging must be tamper-proof. If reviewers or administrators can modify or delete log entries, the evidence is unreliable, and the control fails. Implement append-only logging where entries cannot be altered after creation. Store logs in a separate system with restricted access. Hash log entries to detect tampering. External auditors will test whether logs can be modified, and if they can, the control is ineffective.

Audit trails must also capture system-level events. If an administrator changed access permissions, upgraded the review platform, or modified the workflow configuration, those events must be logged. If a system failure caused review data to be lost or corrupted, the failure must be documented. If a batch of cases was reprocessed due to a model update, the reprocessing must be logged with justification.

The audit trail is the evidence that controls operated as designed. When the external auditor tests the effectiveness of the review process, they will select a sample of review cases and trace them through the system. They will verify that each case was reviewed by an authorized person, that decisions were made within the required timeframe, that exceptions were escalated, and that no unauthorized changes occurred. If the audit trail is incomplete, the auditor cannot verify control operation, and the control is deemed ineffective.

## Control Testing and Evidence Requirements

External auditors test controls to determine whether they are designed effectively and operating as intended. For review workflows, this means auditors will request evidence that reviews occurred, that reviewers were qualified, that decisions were consistent with policy, and that exceptions were handled appropriately.

The evidence package typically includes a population report showing all review cases during the audit period, access control reports showing who had permissions to perform reviews, training records showing that reviewers completed required training, a sample of review cases with complete audit trails, and documentation of escalated exceptions and their resolutions. If you cannot produce these artifacts, the control cannot be tested, and it fails by default.

Auditors test controls by selecting a sample of review cases and examining the documentation for each case. They verify that the reviewer was authorized, that the review was completed within the required timeframe, that the decision was supported by evidence, and that any overrides or exceptions were approved by a senior reviewer. They also test whether reviews were independent — that the reviewer did not have a conflict of interest or a financial incentive to make a particular decision.

A common audit finding is insufficient documentation of reviewer qualifications. If the control description states that reviews are performed by qualified personnel, the auditor will ask for evidence of qualifications. This means training records, certifications, performance evaluations, or other documentation showing that reviewers have the knowledge and experience to make accurate judgments. If no documentation exists, the control is deficient.

Another common finding is inconsistent control operation. If the control is designed to operate daily but audit evidence shows gaps where no reviews occurred, the control did not operate as designed. If the control requires secondary review of high-risk cases but the sample reveals cases that bypassed secondary review, the control is ineffective. Consistency is as important as design.

Control deficiencies are classified as deficiencies, significant deficiencies, or material weaknesses. A deficiency is a control gap that does not rise to significant or material levels. A significant deficiency is a gap important enough to merit attention by those charged with governance. A material weakness is a deficiency that creates a reasonable possibility that a material misstatement will not be prevented or detected on a timely basis. Material weaknesses must be disclosed in the company's annual report, and they often trigger stock price declines and loss of investor confidence.

## Data Integrity and Immutability Requirements

SOX requires that financial data be accurate and complete. For review workflows that support financial processes, this means ensuring that review decisions, annotations, and case data cannot be altered improperly. If a reviewer marks a transaction as fraudulent and that decision affects fraud loss accruals, the decision must be preserved in its original form. If the decision is later revised, both the original and revised decisions must be retained with timestamps and justification.

Data integrity controls include write-once storage for review decisions, version control for case data, checksums or hashes to detect tampering, and access restrictions that prevent unauthorized modification. If review data is stored in a database, the database must enforce referential integrity, prevent orphaned records, and log every update or delete operation. If review data is exported for analysis, the export must be validated to ensure it matches the source system.

Immutability is particularly important for review decisions that affect financial reporting. Once a reviewer submits a decision, that decision becomes part of the financial record. It can be overridden by a senior reviewer or corrected if an error is found, but the original decision must be preserved. If reviewers can edit their own decisions without logging the change, the audit trail is unreliable.

External auditors will test data integrity by selecting review cases and comparing the data in the review system to the data in downstream financial systems. If a fraud review marked a transaction as legitimate and the transaction was processed, the auditor verifies that the review decision matches the system record. If the records do not match, data integrity has failed, and the control is ineffective.

## Vendor Management and Third-Party Risk

If you use a third-party vendor to perform human reviews, that vendor becomes part of your SOX control environment. SOX Section 404 requires management to assess the effectiveness of internal controls, including controls operated by service organizations. This means you must evaluate the vendor's controls, obtain evidence of control effectiveness, and monitor the vendor's performance.

The primary evidence document is a SOC 2 Type II report. A SOC 2 report is an independent auditor's assessment of a service organization's controls related to security, availability, processing integrity, confidentiality, and privacy. A Type II report includes not only a description of controls but also testing of whether those controls operated effectively over a period of time — typically six to twelve months.

If the vendor does not have a SOC 2 report, you must perform your own control assessment. This means reviewing the vendor's policies, testing access controls, examining audit trails, and verifying that segregation of duties is enforced. Most organizations cannot perform this level of assessment, which is why SOC 2 reports are standard in vendor relationships involving SOX-relevant processes.

The SOC 2 report must cover the controls relevant to your review process. If the report covers data security but not review quality controls, it is insufficient. If the report is Type I — meaning controls were assessed at a point in time but not tested over a period — it provides less assurance than a Type II report. If the report is more than twelve months old, it may not reflect current operations.

Vendor monitoring does not end with obtaining a SOC 2 report. You must periodically review vendor performance, test whether the vendor's controls are operating as described, and assess whether the vendor's risk profile has changed. If the vendor suffers a data breach, experiences turnover of key personnel, or undergoes a merger or acquisition, you must reassess control effectiveness.

If the vendor's controls are defective, your controls are defective. SOX does not allow you to outsource accountability. If the external auditor finds that a vendor's review process is unreliable and your financial statements depend on that process, you have a control deficiency or material weakness.

## Documentation Requirements for Policies and Procedures

SOX requires that internal controls be documented. For review workflows, this means maintaining written policies and procedures that describe how reviews are performed, who is authorized to perform them, what criteria are used to make decisions, how exceptions are escalated, and how evidence is retained.

The documentation must be specific. A policy that says "reviews are performed by qualified personnel" is not sufficient. The policy must define what qualifications are required, how qualifications are verified, and what training reviewers must complete. A procedure that says "high-risk cases are escalated" must define what makes a case high-risk, who it is escalated to, what the escalation timeline is, and how escalation decisions are documented.

Policy and procedure documentation is tested during control walkthroughs. The auditor will ask to see the written procedures, then observe whether the process operates as documented. If the written procedure says reviews are completed within 24 hours but the system shows reviews taking three days, the control is not operating as designed. If the procedure requires secondary review of overrides but reviewers report that secondary review is optional, the control is not being followed.

Documentation must be version-controlled and periodically reviewed. If procedures change, the documentation must be updated, and reviewers must be trained on the new procedures. If the documentation is outdated, auditors will assume the control is unreliable. If reviewers are following undocumented procedures, auditors cannot assess whether the control is effective.

The documentation must also cover exception handling. Every control has exceptions — cases that do not fit the standard workflow. A review procedure for fraud detection might specify that cases flagged by multiple models are auto-escalated, but what happens if the escalation system is down? The procedure must document the fallback process. If exceptions are handled ad hoc without documentation, the control is weak.

## Continuous Monitoring and Remediation

SOX compliance is not a one-time assessment. It requires continuous monitoring of control effectiveness and timely remediation of deficiencies. For review workflows, this means tracking control operation metrics, testing controls periodically, identifying gaps, and implementing corrective actions before deficiencies become material weaknesses.

Monitoring metrics for review workflows include percentage of cases reviewed within the required timeframe, percentage of cases requiring secondary review, percentage of reviewer decisions overridden by senior reviewers, number of access control violations, and number of audit log anomalies. If metrics trend in the wrong direction — for example, if the percentage of overridden decisions increases significantly — it may indicate that reviewers are under-trained, that the model's performance has degraded, or that the decision criteria are unclear.

Internal audit or compliance teams should test review controls quarterly or semi-annually. Testing involves selecting a sample of review cases, verifying that controls operated as designed, and documenting any deficiencies. If deficiencies are found, management must determine the root cause, implement corrective actions, and retest the control to verify that the deficiency has been remediated.

Remediation timelines depend on deficiency severity. A material weakness must be remediated immediately. A significant deficiency should be remediated within ninety days. A deficiency should be remediated within six months or accepted as a residual risk. Remediation must be documented, tested, and reported to the audit committee.

If remediation is delayed or ineffective, deficiencies escalate. A deficiency that is not addressed becomes a significant deficiency. A significant deficiency that persists becomes a material weakness. Once a material weakness is identified, it must be disclosed in the company's annual report, and the company must explain what caused it and what is being done to fix it. Public disclosure of material weaknesses triggers regulatory scrutiny, investor concern, and potential litigation.

SOX compliance in human review infrastructure is about control design, operation, testing, and documentation. It is about proving to external auditors that the processes humans use to validate AI outputs are reliable, that decisions are made by qualified personnel, that evidence is preserved, that access is restricted, and that exceptions are handled appropriately. The standard is not perfection. It is demonstrable control effectiveness supported by evidence that can withstand independent audit.

The next regulatory framework operates at a different level of specificity: the EU AI Act's requirements for meaningful human oversight, which apply not just to financial accuracy or data privacy but to the fundamental question of whether humans can actually intervene when AI systems make high-risk decisions.

