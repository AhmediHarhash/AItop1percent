# 2.2 — Queue Routing: Getting Items to the Right Reviewers

The best review queue in the world is useless if items reach the wrong reviewers. Routing is the logic layer that matches pending items to eligible reviewers based on skills, capacity, context, and constraints. Perfect routing sends every item to the reviewer who can evaluate it most accurately and most efficiently. Real-world routing is a constant compromise between perfect assignment and practical constraints — reviewer availability, skill distribution, workload balance, and the cold reality that sometimes no ideal reviewer exists.

Most teams start with naive routing: all items go into one queue, all reviewers see all items, first-come-first-served. This works until week two, when a junior reviewer claims a complex medical case they lack expertise to evaluate, a non-Spanish-speaking reviewer claims a Spanish-language item and stalls, and your most experienced reviewer spends the day clearing routine items while critical escalations sit unclaimed. Naive routing treats reviewers as interchangeable. They are not. Routing quality determines review quality, reviewer satisfaction, and system throughput. A well-designed routing layer is invisible when it works and catastrophic when it fails.

## Skill-Based Routing: Matching Expertise to Complexity

Not all reviewers can evaluate all items. Some items require domain expertise — medical content needs reviewers with clinical knowledge, legal content needs reviewers who understand contract language, financial content needs reviewers who know regulatory definitions. Some items require technical expertise — reviewing code outputs needs engineering background, reviewing SQL queries needs database knowledge. Some items require language expertise — non-English content needs native or fluent speakers. Some items require credential-based access — reviewing protected health information needs HIPAA-trained reviewers, reviewing financial records needs reviewers cleared for PII access.

Skill-based routing tags each item with required skills and each reviewer with possessed skills. An item tagged medical-terminology-required only routes to reviewers tagged medical-terminology-certified. An item tagged Spanish-language only routes to reviewers tagged Spanish-fluent. An item tagged contains-PHI only routes to reviewers tagged HIPAA-cleared. This prevents misrouting at the expense of adding skill management overhead — someone must maintain skill tags, verify certifications, and update reviewer profiles when skills change.

Skill tags should be specific enough to prevent misrouting but broad enough to avoid reviewer starvation. If you tag skills too narrowly — cardiology-specific instead of medical — you will have items waiting for the one cardiology reviewer while ten general medical reviewers sit idle. If you tag skills too broadly — healthcare instead of medical — you will route clinical content to administrative reviewers who cannot evaluate it. The right granularity depends on your reviewer pool size and item diversity. A team of five reviewers needs two or three skill categories. A team of two hundred reviewers can support twenty skill categories without starvation risk.

Skill-based routing should degrade gracefully when no exact match exists. If an item requires Spanish-fluent medical reviewers and none are available, the system should escalate to a supervisor who can reassign the item, expand routing to Spanish-competent reviewers, or send the item to an external specialist. If your routing logic simply leaves the item pending indefinitely when no match exists, you have created a silent failure mode that will breach SLAs and hide problems until users complain.

Some skills are mutually exclusive. A reviewer who is junior-certified should not see items tagged senior-only. A reviewer who is medical-specialized should not see items tagged legal-only even if no legal reviewers are available — better to escalate than to route to someone who will make an uninformed guess. Implement negative skill constraints: items tagged senior-only explicitly exclude reviewers tagged junior-certified. This prevents the fallback logic from routing high-stakes items to unqualified reviewers during capacity crunches.

## Affinity Routing: Context Carries Over Between Related Items

Reviewers perform better when they see related items consecutively. A reviewer who just evaluated ten outputs from the same AI model has built context about that model's failure modes, output patterns, and edge cases. A reviewer who just evaluated five items from the same user has built context about that user's behavior, intent, and history. A reviewer who just evaluated three items in the same product category has built context about policy nuances, acceptable phrasing, and common errors. Affinity routing preserves that context by preferentially assigning related items to the same reviewer.

Affinity routing tags items with affinity keys — model ID, user ID, product category, content domain — and tracks which reviewers have recently reviewed items with the same keys. When a new item enters the queue, the routing logic checks if any reviewer has recently seen related items and prefers that reviewer if they have capacity. This increases review speed because the reviewer does not need to rebuild context. It increases review accuracy because the reviewer recognizes patterns across items. It improves consistency because the same reviewer applies the same judgment standards to related content.

Affinity routing must balance context benefits against workload concentration. If you route all items for a specific user to the same reviewer, that reviewer becomes overloaded while others sit idle. If you route all items from a specific model to the same reviewer, that reviewer may develop blind spots or biases that other reviewers would catch. Implement affinity with a decay function: prefer the same reviewer for the next hour or the next ten items, then reset affinity to allow other reviewers to participate. This preserves short-term context benefits without creating long-term concentration.

Affinity routing interacts poorly with skill-based routing when the affinity-preferred reviewer lacks the required skills. If a reviewer has been handling general content and a related item appears that requires medical expertise, affinity routing wants to send it to the same reviewer but skill routing wants to send it to a medical specialist. Your routing logic needs a tiebreaker rule: does skill override affinity, or does affinity override skill, or does the system escalate for manual assignment? The right answer depends on your domain — in high-risk categories like healthcare or legal, skill should always override affinity.

Affinity routing creates long-term reviewer specialization that may not be desirable. If you consistently route medical items to medical specialists, those specialists never develop breadth in other categories and your general reviewers never develop medical expertise. If you consistently route Spanish-language items to Spanish speakers, your English-only reviewers never learn to recognize when items should have been tagged Spanish. Some teams intentionally break affinity periodically — one day per week, all items route randomly regardless of affinity — to cross-train reviewers and prevent siloing. This reduces short-term efficiency but increases long-term resilience when specialists are unavailable.

## Load-Aware Routing: Balancing Work Across Reviewers

Load-aware routing tracks each reviewer's current workload and preferentially assigns new items to reviewers with capacity. Workload can be measured as items claimed, items in-progress, items completed in the past hour, or estimated time remaining on claimed items. The simplest load metric is claimed count: each reviewer has a claim limit, and the routing logic only assigns new items to reviewers below the limit. This prevents any single reviewer from hoarding the queue while others wait for work.

Claim limits should vary by reviewer skill and role. A senior reviewer may have a claim limit of twenty items because they handle complex cases that take longer. A junior reviewer may have a claim limit of ten items because they are slower and need more guidance. A part-time reviewer may have a claim limit of five items because they are only online for three hours per day. If you apply a single uniform claim limit, you will underutilize your most efficient reviewers and overload your least experienced ones.

Load-aware routing must account for item complexity, not just item count. A reviewer with ten simple items may have less workload than a reviewer with two complex items. Some teams assign weight to each item based on category, priority, or historical handle time, and route based on total weight rather than item count. A reviewer with a weight limit of one hundred points can claim ten items worth ten points each or two items worth fifty points each. This balances workload more accurately but requires accurate weight estimation. If your weight estimates are wrong, your load balancing will be wrong.

Load-aware routing should prefer reviewers who are online, active, and recently responsive. A reviewer who claimed an item ten minutes ago and submitted a judgment five minutes ago is actively working. A reviewer who claimed an item two hours ago and has not transitioned it to in-progress is likely interrupted or idle. Routing logic should deprioritize inactive reviewers even if their claimed count is below the limit. Some teams implement activity-based claim decay: if a reviewer does not transition a claimed item to in-progress within fifteen minutes, the claim automatically releases and the item returns to the queue for another reviewer.

Load-aware routing fails when all reviewers are at capacity. If every reviewer has reached their claim limit and new items continue arriving, the queue depth grows and SLAs breach. Your routing logic must detect this condition and trigger alerts, auto-escalate items to supervisors, or throttle upstream systems to slow item creation. If your routing logic silently allows the queue to grow without intervention, you will discover the problem only when users complain about delays.

## Geographic and Timezone Routing: Matching Items to Reviewer Availability

If your reviewers are distributed across time zones, routing must account for availability. An item that enters the queue at 2 AM in New York should route to reviewers in Europe or Asia who are online, not to New York reviewers who are asleep. An item tagged urgent should route to reviewers in active timezones first, then fall back to reviewers in off-hours if no one is available.

Timezone-aware routing tags each reviewer with their working hours and checks the current time before assigning items. A reviewer in London with working hours 9 AM to 5 PM GMT should not receive items at 3 AM GMT unless they are flagged critical and no other reviewers are available. This prevents items from sitting claimed-but-not-started for hours because the reviewer logged off after claiming them.

Some teams implement follow-the-sun routing for high-urgency items: items route first to reviewers in the timezone where it is currently business hours, and if those reviewers are at capacity, items route to the next timezone entering business hours. This ensures continuous coverage without requiring any single reviewer to work overnight. Follow-the-sun routing requires coordination across regional teams — consistent skill levels, consistent judgment standards, and consistent tooling — or you will create quality variance by timezone.

Geographic routing also matters for regulatory compliance. Some jurisdictions require that data stay within specific regions. An item containing European user data may be legally prohibited from routing to reviewers in the United States or Asia unless those reviewers are operating under specific data processing agreements. Your routing logic must enforce geographic constraints: items tagged EU-data-residency only route to reviewers tagged EU-based or EU-cleared. Violating data residency rules is not a performance issue, it is a legal issue. Your routing system must make geographic violations impossible, not just unlikely.

## Language Routing: Fluency Requirements and Fallback Strategies

Items in non-English languages must route to reviewers who are fluent in that language. A reviewer who does not speak Spanish cannot evaluate whether a Spanish AI output is accurate, appropriate, or policy-compliant. Language routing tags each item with detected or declared language and each reviewer with language fluency, then enforces the match.

Language detection should happen upstream before items enter the queue. If you rely on reviewers to self-report that they cannot read the language after claiming the item, you have wasted their time and delayed the item. Use automated language detection on item creation. If the language is ambiguous or mixed, tag the item as multilingual and route only to reviewers who handle multilingual content.

Language routing must handle partial fluency. A reviewer who is conversational in Spanish may be able to review simple customer support outputs but not legal or medical content in Spanish. Fluency tags should include proficiency levels: native, fluent, conversational. Complex items require native or fluent reviewers. Simple items may accept conversational reviewers. If your fluency tags are binary — speaks Spanish or does not — you will either over-restrict routing and create bottlenecks or under-restrict routing and send complex content to reviewers who cannot evaluate it accurately.

Language routing must degrade gracefully when no fluent reviewers are available. If an urgent item in Vietnamese enters the queue and no Vietnamese-fluent reviewers are online, the item should escalate to a supervisor who can make a fallback decision — translate the item and route to English reviewers, delay the item until Vietnamese reviewers are available, or send the item to an external language specialist. The worst outcome is the item sitting in the queue indefinitely because no routing rule applies.

Some teams use machine translation as a fallback: if no native reviewer is available, translate the item to English and route to English reviewers with a flag indicating the item was translated. This reduces delays but introduces risk — translation errors, cultural nuance loss, and policy misinterpretation. If you use translation fallback, it should be limited to low-risk categories and should always include a disclaimer that the reviewer is evaluating a translation, not the original.

## Credential-Based Routing: Legal and Regulatory Access Control

Some content requires reviewers with specific credentials or training. Protected health information requires HIPAA training and a signed BAA. Financial records may require SOX compliance training. Content involving minors may require background checks. Controlled unclassified information may require security clearances. Credential-based routing enforces these requirements at the queue level, making it impossible to assign items to reviewers who lack the necessary clearances.

Credential tags should be verified externally, not self-reported. A reviewer should not be able to tag themselves as HIPAA-cleared in the review system without that credential being validated by HR, compliance, or an external training provider. Credential verification should sync periodically — if a reviewer's HIPAA training expires, their credential tag should automatically revoke and they should stop receiving PHI-containing items. If your credential enforcement relies on manual updates, you will route sensitive content to reviewers whose clearances have lapsed.

Credential-based routing must be absolute. Unlike skill-based routing, which can degrade gracefully to less-specialized reviewers, credential-based routing cannot degrade. If an item contains PHI and no HIPAA-cleared reviewers are available, the item must not route to non-cleared reviewers even if they have medical expertise. The correct fallback is escalation, delay, or rejection — never credential violation. Your routing logic must treat credential mismatches as hard failures, not soft preferences.

Credential expiration creates operational risk. If half your reviewers have HIPAA training that expires in the same month and none of them renew on time, you will suddenly lose capacity for all PHI-related items. Your routing system should track credential expiration dates and alert operations teams weeks in advance. Some teams implement credential expiration buffers: reviewers whose credentials expire within thirty days stop receiving new items in that category, giving them time to renew without disrupting active work.

## The Cold-Start Problem for New Reviewers

When a new reviewer joins the team, they have no skills tagged, no affinity history, no workload history, and no performance data. Naive routing will send them no items because they do not match any skill filters. Overly permissive routing will send them complex items they are not ready to handle. The cold-start problem is how you ramp new reviewers from zero to productive without overwhelming them or compromising quality.

The most common solution is a training queue: new reviewers start in a restricted queue containing only simple, low-risk items tagged training-safe. They review items in the training queue until they demonstrate competency — measured by agreement rate with senior reviewers, handle time, or supervisor evaluation. Once they pass a competency threshold, their skill tags update and they begin receiving items from the main queue. The training queue prevents new reviewers from encountering complex cases before they are ready and prevents their early mistakes from affecting production decisions.

Some teams implement shadow reviewing for new reviewers: they review the same items that senior reviewers are reviewing, but their judgments are not used for production decisions. Shadow reviewing allows new reviewers to build skills without risk. After a period of shadow reviewing — one week, fifty items, 85 percent agreement with senior reviewers — the new reviewer graduates to independent reviewing. Shadow reviewing is safer than training queues but requires more senior reviewer time because every shadowed item is reviewed twice.

Cold-start routing should gradually expand the new reviewer's item scope. A new reviewer starts with simple items in one category, then adds a second category, then adds a complexity tier, then adds a language. This incremental expansion allows the reviewer to build confidence and allows supervisors to identify skill gaps early. If you assign new reviewers the full range of items immediately, they will struggle, make more errors, and burn out faster.

New reviewers need faster feedback loops than experienced reviewers. An experienced reviewer may receive feedback weekly. A new reviewer should receive feedback daily, or even per-item for the first week. Fast feedback prevents new reviewers from reinforcing incorrect patterns. Some teams route all new-reviewer items to secondary review automatically for the first two weeks. This catches errors immediately and provides teaching moments while the reviewer is still forming habits.

## Routing Rule Maintenance: The Invisible Operational Tax

Routing rules are not static. As your team grows, as your content evolves, as your policies change, your routing rules must evolve with them. A routing rule that worked perfectly in January may create bottlenecks in June when team composition changes or content volume shifts. Routing rule maintenance is an ongoing operational cost that most teams underestimate.

Skill tags must stay synchronized with reviewer training and turnover. When a reviewer completes HIPAA training, their credential tag must update immediately. When a reviewer leaves the team, their profile must deactivate immediately so items do not route to an account no one monitors. When a reviewer shifts roles from general to specialist, their skill tags must update to reflect the new scope. If skill tags drift out of sync with reality, your routing will send items to reviewers who cannot or should not handle them.

Routing rules must adapt to volume changes. If a new AI feature launches and generates ten times more items in one category, routing rules may need to expand the reviewer pool for that category, reduce affinity to spread load, or throttle upstream item creation. If a category of items drops to near-zero volume, routing rules may need to merge that category with a related one to avoid reviewer underutilization. Static routing rules assume stable volume. Real-world volume is not stable.

Routing logic should be auditable and version-controlled. When you change a routing rule, you should be able to see the old rule, the new rule, who changed it, when, and why. You should be able to roll back routing changes if they create unintended consequences. You should be able to analyze routing behavior over time to detect patterns — if 90 percent of escalations come from items routed by one rule, that rule may need refinement. If your routing logic is hard-coded or configured through a UI with no change history, you will struggle to debug routing problems and cannot learn from past mistakes.

Routing failures should be visible. If an item sits in pending state for more than a threshold duration because no reviewers match the routing criteria, that should trigger an alert. If a routing rule consistently sends items to reviewers who then escalate them, that should trigger a review of the rule. If a routing rule has not matched any items in thirty days, that may indicate the rule is obsolete or the skill tags are wrong. Routing observability is as important as queue observability — you cannot optimize what you cannot measure.

The routing layer is where your queue architecture meets operational reality. Routing rules encode your team's skills, your policies, your risk tolerance, and your capacity constraints. Poor routing creates delays, quality errors, and reviewer frustration. Excellent routing makes review feel effortless — items appear in front of the right person at the right time with the right context.

The next critical design decision after routing is priority: when multiple items are waiting for the same reviewer, which one should they see first, and how do you prevent priority systems from collapsing under pressure.

