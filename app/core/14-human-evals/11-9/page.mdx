# 11.9 — Vendor Access Controls and Contractual Requirements

In late 2025, a health tech company discovered that patient review data — excerpts from clinical notes that reviewers had evaluated for AI safety — had been accessed by employees of their third-party annotation vendor who had no business reason to see it. The access was not malicious. A vendor engineer was debugging a latency issue and opened a live session to observe the review interface. In doing so, he saw patient names, diagnoses, and treatment histories. The vendor had not violated the contract, because the contract never specified who within the vendor organization could access data, under what circumstances, or with what audit trail. The discovery triggered a HIPAA breach notification affecting 1,800 patients, a six-month regulatory investigation, and the termination of a vendor relationship that had taken two years to establish.

The failure was not in the vendor's security practices. It was in the customer's failure to define, enforce, and audit access controls as a contractual requirement. When you engage a vendor to participate in your review infrastructure — whether they host the platform, provide reviewers, or offer annotation tooling — you are delegating custody of sensitive data. That delegation does not transfer your liability. You remain responsible for ensuring the vendor's access controls meet the same standards you would enforce internally. If they do not, the failure is yours.

## The Principle of Least Privilege for Vendor Access

Not every vendor employee needs access to your review data. In most cases, only a small subset does — the specific individuals conducting reviews, the support engineer responding to a specific ticket, the compliance auditor verifying adherence to SLAs. Everyone else within the vendor organization should have zero access. The principle of least privilege applies to vendor relationships exactly as it does to internal systems: grant the minimum access required, to the minimum number of people, for the minimum duration necessary.

Your contract must define access tiers. Tier 1 might be annotators and reviewers who see live data as part of their work. Tier 2 might be vendor support staff who access data only when troubleshooting a specific issue, and only after customer approval. Tier 3 might be vendor compliance staff who see aggregated metrics and logs but never raw review data. Tier 4 is everyone else at the vendor, who have no access at all. Each tier has explicit access rights, explicit justifications, and explicit logging requirements.

The contract also defines the approval process for granting access. Tier 1 access might be pre-approved for named individuals after background checks and training. Tier 2 access requires case-by-case approval — your operations team receives a ticket, reviews the justification, and grants temporary access with a defined expiration. Tier 3 access is granted during scheduled audits or compliance reviews. The vendor cannot unilaterally grant access beyond what the contract allows. If they need to grant emergency access — a production incident requiring immediate troubleshooting — they must notify you within a defined timeframe and document the justification.

Some teams require the vendor to implement role-based access control that mirrors the customer's own internal controls. The vendor's IAM system enforces the same role definitions, the same approval workflows, the same audit logging. The vendor provides read-only access to their IAM audit logs so the customer can verify compliance. This creates a continuous compliance posture rather than a periodic audit-and-hope model.

## Background Checks and Clearance Requirements

If your review data includes regulated information — healthcare data under HIPAA, financial data under GLBA, classified or export-controlled data under ITAR or EAR — you cannot assume the vendor's hiring practices are sufficient. Your contract must specify the level of background screening required for anyone with access to your data.

For HIPAA data, this typically means a criminal background check, verification of identity, and workforce training on privacy obligations. For financial data, it may include credit checks and verification of employment history. For government contracts, it may require security clearances at a specific level. The vendor must perform these checks before granting access, maintain records of completion, and re-screen at defined intervals — annually for high-sensitivity roles, every three years for lower-sensitivity roles.

You also define what disqualifies a candidate. A criminal conviction related to fraud or data theft may be an automatic disqualification for access to financial data. A history of HIPAA violations may disqualify someone from accessing patient data. The contract specifies these criteria, and the vendor agrees to enforce them. If a vendor employee's background check reveals a disqualifying factor after they have already been granted access, the contract requires immediate revocation and notification to the customer.

Some customers require the vendor to provide a roster of all individuals with access, updated monthly, with each person's role, tier, background check status, and training completion date. This roster becomes part of the customer's audit trail. If a breach occurs, the customer can immediately identify who had access at the time and verify that each person met the contractual requirements.

## Data Minimization in Vendor Environments

The vendor should see only the data they need to perform their contracted function. If the vendor is providing annotation services, they need to see the text or image being annotated. They do not need to see user identifiers, session metadata, timestamps, or internal system logs. If the vendor is hosting the review platform, they may need to see metadata for system operations, but they do not need to see the content of reviews unless explicitly troubleshooting an issue.

Data minimization is enforced through technical controls. Before data reaches the vendor's environment, you redact or tokenize fields that are not required for the vendor's work. Patient names become pseudonymous identifiers. Email addresses become hashed tokens. Internal user IDs become opaque references. The vendor sees enough to perform their function but not enough to re-identify individuals or reconstruct sensitive contexts.

Some teams implement client-side encryption where the vendor never sees plaintext data. The customer encrypts sensitive fields before sending data to the vendor's platform. The vendor stores and processes encrypted data. Only the customer holds the decryption key. The review interface runs in the customer's controlled environment, decrypting data just-in-time for display. This model works when the vendor provides infrastructure but not human review services. If the vendor's employees are the reviewers, they need plaintext access, and encryption shifts to access control and logging.

Your contract defines what data is sent, in what form, and whether the vendor is permitted to retain copies. Some contracts prohibit the vendor from caching, logging, or backing up customer data beyond what is necessary for the immediate service. Others allow limited retention for operational purposes but require destruction within a defined timeframe. The key is that the vendor's data handling practices are not left to their discretion — they are contractually specified and auditable.

## Logging and Monitoring of Vendor Access

Every vendor access to your data must be logged with the same rigor you apply to internal access. The log should capture who accessed what data, when, from which IP address, using which credentials, for what stated purpose, and whether the access was successful. These logs are the foundation of your ability to detect misuse, investigate incidents, and demonstrate compliance.

Your contract requires the vendor to maintain access logs, to retain them for a defined period, and to provide them to you on demand. Some contracts require real-time log streaming — every access event is sent to the customer's SIEM or logging platform as it occurs. This allows the customer to monitor vendor access in real time, detect anomalies, and alert on suspicious patterns without waiting for periodic log exports.

Log retention requirements should match or exceed your own internal requirements. If you retain access logs for three years under GDPR or seven years under SOX, the vendor must do the same for logs covering your data. The contract specifies log format, completeness requirements, and the vendor's obligation to preserve logs during litigation holds or regulatory investigations.

You also define what triggers an alert. Access outside normal business hours, access from an unexpected geographic region, bulk data exports, repeated failed authentication attempts, or access by individuals not on the approved roster — each of these should generate an alert sent to your security operations team. The vendor's monitoring system can generate these alerts, or the vendor can stream logs to your system and let you define the alerting logic.

## Contractual Breach Notification and Incident Response

When a vendor experiences a security incident involving your data — unauthorized access, data exfiltration, accidental disclosure, ransomware, insider threat — they must notify you within a defined timeframe. The industry standard is 24 to 72 hours, but for highly sensitive data, you may require notification within hours. The contract specifies the notification timeline, the information that must be included, and the escalation process.

The notification must include what data was affected, how many records, which individuals or systems gained unauthorized access, when the incident occurred, when it was detected, what the root cause was, and what containment measures have been taken. Vague notifications — "we detected unusual activity and are investigating" — do not meet the contractual standard. You need enough detail to assess whether the incident triggers your own breach notification obligations, whether you need to notify regulators, and whether you need to revoke the vendor's access.

Your contract also defines the vendor's role in incident response. Are they required to preserve forensic evidence? Are they required to engage a third-party incident response firm? Are they required to provide you with access to their environment to conduct your own investigation? Are they required to remediate the root cause within a defined timeframe? Each of these is negotiable, but the negotiation must happen before the incident, not during it.

Some contracts include breach penalties. If the vendor's failure to follow contractual security requirements leads to a breach, they may be liable for notification costs, regulatory fines, customer damages, or contract termination. These penalties create economic incentives for the vendor to treat your data with the same care you would. Without them, the vendor's incentive is to minimize their own costs, which may conflict with your obligation to protect data.

## Right to Audit and Compliance Verification

You cannot rely on the vendor's self-assessment of their security practices. Your contract must include a right-to-audit provision that allows you to verify, through independent means, that the vendor is meeting their contractual obligations. This audit can take several forms.

First-party audits involve your own team visiting the vendor's facility, reviewing their access control systems, interviewing their staff, and examining their logs. This is the most thorough approach but also the most resource-intensive. It works best for high-value, high-risk vendor relationships where the data sensitivity justifies the effort.

Third-party audits involve an independent auditor conducting the review and providing an attestation to both you and the vendor. SOC 2 Type II audits are the most common. The vendor undergoes an annual audit of their security controls, and you receive the audit report. If the vendor serves multiple customers, the cost of the audit is amortized across all of them. You review the report to confirm that the controls relevant to your data are in place and effective.

Continuous compliance monitoring uses automated tools to verify security posture without manual audits. The vendor grants you read-only access to their IAM audit logs, their SIEM, their access control policies. You run automated scans to verify that access is limited to approved individuals, that logging is enabled, that encryption is configured correctly. This approach scales better than manual audits but requires the vendor to provide API access to their internal systems.

Your contract defines the audit frequency, the audit scope, the vendor's obligation to remediate findings, and the timeline for remediation. If an audit reveals that the vendor granted access to unapproved individuals, they must revoke that access within 48 hours and provide evidence of revocation. If the audit reveals missing logging, they must enable it and backfill logs if possible. If they fail to remediate, you have the right to suspend their access or terminate the contract.

## Data Sovereignty and Cross-Border Access Restrictions

If your data is subject to residency requirements — GDPR's restrictions on transferring EU data outside the EU, China's data localization laws, Russia's requirements for domestic data storage — your contract must ensure the vendor complies. This means specifying where data can be stored, where it can be processed, and who can access it.

For EU data under GDPR, the vendor must either process data within the EU, use Standard Contractual Clauses if processing outside the EU, or rely on an adequacy decision for the destination country. The contract specifies which mechanism applies, and the vendor agrees not to transfer data to non-approved countries. If the vendor uses subprocessors — other vendors they rely on to deliver the service — those subprocessors must meet the same requirements.

Some customers require geo-fencing at the network level. The vendor's systems are configured to reject access requests from IP addresses outside approved regions. If a vendor employee attempts to access customer data while traveling in a restricted country, the access is blocked. This prevents accidental or coerced access in jurisdictions with weak privacy protections or government surveillance obligations.

The contract also addresses government access requests. If the vendor receives a subpoena, warrant, or national security letter demanding access to your data, they must notify you before complying, unless legally prohibited. You then have the opportunity to challenge the request, negotiate a narrower scope, or ensure the request is lawful. This notification requirement is standard in US contracts but may be prohibited in some jurisdictions, which is why understanding the vendor's legal domicile is critical.

## Vendor Offboarding and Data Return or Destruction

When your contract with a vendor ends — whether due to expiration, termination for cause, or migration to a new vendor — you must ensure that all copies of your data in the vendor's possession are returned or destroyed. Without this, the vendor retains access indefinitely, creating a persistent security and compliance risk.

Your contract defines the offboarding process. The vendor must return all data in a specified format within a defined timeframe — typically 30 days after contract termination. If return is not feasible due to data volume or format, the vendor must destroy the data and provide a certification of destruction. The certification includes what was destroyed, when, using what method, and by whom. It is signed by an authorized representative of the vendor and provided to you for your records.

Destruction must cover all copies — production systems, backups, disaster recovery sites, development and test environments, logs. The vendor cannot claim they destroyed production data while retaining it in backups. The contract specifies that destruction includes all copies in all environments, and the certification must confirm this.

Some contracts allow a grace period where the vendor retains data for a limited time to support transition or to comply with their own legal obligations. If the vendor is required by law to retain certain data — audit logs, financial records, litigation holds — the contract specifies what is retained, for how long, and under what access controls. Once the grace period or legal obligation expires, the data must be destroyed.

You verify offboarding through post-termination audits. Sixty or ninety days after contract termination, you or a third-party auditor verify that the vendor's systems no longer contain your data. You review access logs to confirm that no access has occurred since termination. You inspect backup inventories to confirm that backups containing your data have been rotated out. This verification closes the loop and provides evidence that the vendor relationship has been fully unwound.

## Subprocessor and Fourth-Party Risk Management

Vendors rarely deliver services entirely in-house. They rely on cloud providers for infrastructure, SaaS tools for operations, and third-party specialists for specific capabilities. Each of these is a subprocessor — a fourth party who has potential access to your data. Your contract must address subprocessor risk.

The contract requires the vendor to disclose all subprocessors with access to your data. This disclosure includes the subprocessor's name, their role, the type of data they access, and where they are located. The vendor must update this list whenever they add or change a subprocessor, and they must provide you with advance notice — typically 30 days — so you can object if the subprocessor does not meet your requirements.

Each subprocessor must meet the same security and compliance standards as the primary vendor. If your contract requires SOC 2 Type II compliance, the subprocessor must also be SOC 2 compliant. If your contract prohibits data transfer outside the EU, the subprocessor must also be EU-based or covered by Standard Contractual Clauses. The vendor is responsible for ensuring subprocessor compliance, and they remain liable for subprocessor failures.

Some customers maintain an approved subprocessor list. Before engaging a new subprocessor, the vendor submits a request describing the subprocessor's role, their security posture, and their compliance certifications. The customer reviews and approves or rejects. If approved, the subprocessor is added to the contract as an amendment. If rejected, the vendor must find an alternative or forgo the subprocessor's services.

This level of control is rare outside highly regulated industries, but even in less strict environments, subprocessor transparency is critical. You cannot assess your risk if you do not know who has access to your data. The vendor relationship is only as secure as the weakest link in their supply chain. Contractual subprocessor requirements make that chain visible and auditable.

The vendor is not just a service provider. They are an extension of your security perimeter, and every access they have is an access you are responsible for. Contracts are where this responsibility is codified, and audit is where it is verified. The next subchapter covers the physical security requirements when review operations take place on-premise rather than in the cloud.

