# Chapter 3 — Reviewer Tooling and UX Design

The interface your reviewers use is not a minor implementation detail. It is the primary determinant of review quality, reviewer productivity, and workforce retention. A poorly designed review tool does not just slow people down—it introduces systematic errors, burns out experienced reviewers, and makes training new ones nearly impossible. This chapter covers everything that appears on a reviewer's screen: annotation surfaces, context displays, keyboard workflows, dashboards, decision trees, escape hatches, accessibility, and the increasingly critical domain of model-assisted review.

---

- 3.1 — The Reviewer Interface Is Your Review Quality
- 3.2 — Annotation Surfaces: Forms, Highlights, and Structured Inputs
- 3.3 — Context Display: Showing Reviewers What They Need
- 3.4 — Keyboard-First Design for High-Volume Review
- 3.5 — Decision Trees and Guided Workflows
- 3.6 — Undo, Skip, and Defer: Essential Escape Hatches
- 3.7 — Reviewer Dashboards: Performance, Progress, and Feedback
- 3.8 — Mobile and Remote Review Considerations
- 3.9 — Accessibility in Review Tooling
- 3.10 — Integrating External Tools and References
- 3.11 — Session Management and Fatigue Prevention
- 3.12 — Versioning and Change Management in Review Tools
- 3.13 — Model-Assisted Review: AI Draft Decisions and Evidence Highlighting
- 3.14 — Confidence Visualization and Human Override UX

---

*Great review tools disappear from the reviewer's attention, letting them focus entirely on the decision at hand. Bad review tools demand constant attention, leaving little cognitive capacity for the actual work.*
