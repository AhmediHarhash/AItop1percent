# 2.4 â€” Load Balancing Across Review Teams

The queue has 847 items. Three reviewers are working. One has 12 items assigned, one has 390, one has 445. The system sees three active reviewers with capacity and considers the work distributed. The reviewers see something different. The person with 445 items stopped caring about quality four hours ago. The person with 12 items finished their work in twenty minutes and has been idle since lunch. The system that created this distribution is technically correct and operationally catastrophic.

Uneven load destroys both quality and morale. A reviewer drowning in assignments rushes. A reviewer starved for work disengages. The distribution you allow determines the quality you get. Load balancing is not an optimization problem. It is a respect problem. The queue architecture that ignores reviewer experience produces work that looks reviewed but is not.

## Capacity Modeling Per Reviewer

Capacity is not uniform. One reviewer can evaluate 40 moderation cases per hour. Another can evaluate 15. The difference is not skill or effort. It is task complexity, decision confidence, and cognitive load. A new reviewer needs more time per case. A reviewer handling ambiguous edge cases needs more time. A reviewer working in a second language needs more time. A load balancing system that assumes uniform capacity assigns too much work to people who cannot absorb it and too little to people who can.

Model capacity at the individual level. Track historical throughput per reviewer per task type. A reviewer who averages 8 medical record reviews per hour has a capacity of 8, not the team average of 12. A reviewer who averages 50 content moderation decisions per hour has a capacity of 50. Capacity is measured, not assumed. The measurement window is the last 30 days, not the last shift. Short windows are volatile. Long windows miss performance changes.

Capacity is also dynamic. A reviewer who worked 6 hours today has less capacity than a reviewer who worked 2 hours. A reviewer who just finished 40 consecutive high-stakes cases has less capacity than a reviewer starting fresh. Fatigue reduces throughput and increases error rates. A load balancer that ignores current state overloads tired reviewers and underloads fresh ones. Real-time capacity must account for work already done today.

The system must also respect declared capacity. A reviewer who marks themselves as training-only has zero capacity for production work. A reviewer who is scheduled for 4 hours has capacity for 4 hours of work, not 8. A reviewer on partial duty due to injury or accommodation has reduced capacity. The load balancer that ignores these signals assigns work that cannot be completed and creates SLA breaches that were avoidable.

## Real-Time Load Awareness

The queue does not wait for shift handoff to rebalance. Load awareness must be real-time. When a reviewer finishes a case, the system evaluates current load across all active reviewers and assigns the next item to the reviewer with the lowest utilization. Utilization is current workload divided by capacity. A reviewer with 20 items assigned and a capacity of 40 items per shift has 50 percent utilization. A reviewer with 10 items assigned and a capacity of 15 items per shift has 67 percent utilization. The next item goes to the first reviewer.

Load awareness requires visibility into in-progress work. A reviewer who has 5 items assigned but has completed 4 of them has different availability than a reviewer who has 5 items assigned and has completed none. The system must track both assigned count and completed count. Assignment count alone is a lagging indicator. Completion velocity is the real signal. A reviewer completing items faster than their assignment rate has headroom. A reviewer completing items slower than their assignment rate is falling behind.

The system must also detect stalls. A reviewer who has had the same item open for 90 minutes without submission is stuck. The item may be ambiguous, the tooling may have failed, or the reviewer may have been pulled into a meeting. The load balancer must recognize stalls and route new work elsewhere. A stalled reviewer with 10 items assigned is not available for an 11th. The system that continues assigning to them creates a secondary backlog of in-progress work that appears active but is not moving.

Real-time awareness also means reacting to reviewer availability changes. A reviewer who logs off mid-shift transfers their remaining assigned work back to the queue. A reviewer who changes their status to unavailable stops receiving assignments. A reviewer who completes a training module and becomes certified for a new task type becomes eligible for new routing options. The load balancer must respond to these state changes within seconds, not at the next shift boundary.

## The Utilization Target

Full utilization is not the goal. A reviewer operating at 100 percent capacity has no buffer for unexpected complexity, no time for calibration discussion, no space for learning. A team operating at 100 percent capacity cannot absorb a surge, cannot handle a sick day, cannot onboard a new reviewer. The utilization target for sustainable high-quality review is 85 percent. The remaining 15 percent is resilience.

At 85 percent utilization, a reviewer has time to ask a question when uncertain. They have time to flag an edge case for discussion. They have time to participate in a calibration session without falling behind. The team operating at 85 percent can absorb a 10 percent volume spike without missing SLAs. The team operating at 100 percent cannot. The spike turns into a backlog, the backlog turns into pressure, and the pressure turns into errors.

Organizations push for higher utilization because idle reviewers feel like waste. This is a category error. The 15 percent buffer is not idle. It is invested in quality, learning, and system resilience. A reviewer who finishes their assigned work early and spends the remaining time reviewing difficult cases with a peer is not idle. A reviewer who uses buffer time to document a new edge case pattern is not idle. A reviewer who uses buffer time to mentor a new team member is not idle. The utilization target is not about maximizing throughput. It is about maximizing sustainable quality.

The system enforces the target through assignment throttling. When a reviewer reaches 85 percent utilization, they stop receiving new assignments until their current load drops. The throttle is per-reviewer, not per-team. A team average of 85 percent can hide individuals at 100 percent and others at 50 percent. The load balancer must enforce the target at the individual level. Every reviewer operates in the sustainable range or the quality promise is a lie.

## Handling Skill Scarcity

Not every reviewer can review every case. Only three people on the team are certified to review protected health information. Only two people are certified for legal holds. Only one person speaks Mandarin fluently enough to review tone in Chinese-language outputs. Skill scarcity creates routing constraints. The load balancer that ignores these constraints assigns work that cannot be completed correctly.

Skill scarcity also creates utilization imbalance. The three PHI-certified reviewers handle all PHI cases. If PHI cases are 30 percent of volume, those three reviewers are permanently overloaded while the rest of the team has spare capacity. The imbalance is structural, not transient. The load balancer must recognize it and respond.

The first response is cross-training. Every reviewer who can be certified for constrained skills should be. Cross-training does not mean training everyone on everything. It means expanding the pool for high-demand, low-supply skills. If only three people can review PHI, train three more. If only two people can review legal holds, train two more. The training investment pays for itself in routing flexibility. A team with six PHI-certified reviewers can balance load. A team with three cannot.

The second response is task shedding. If PHI cases exceed the capacity of certified reviewers, the organization must reduce PHI case volume, increase reviewer capacity, or accept SLA misses. There is no fourth option. The load balancer cannot assign PHI cases to uncertified reviewers. The system that tries creates compliance risk that outweighs the SLA benefit. Skill scarcity is a hard constraint. Treat it as one.

The third response is priority-based routing. If certified reviewers are overloaded, the highest-priority cases within their skill domain go first. A high-severity PHI case preempts a low-severity one. The load balancer must support priority within skill-constrained queues. A single FIFO queue for all PHI cases misallocates scarce capacity. The urgent case waits behind 40 routine ones because the system does not differentiate.

## Cross-Training to Increase Routing Flexibility

Cross-training is not just skill expansion. It is load balancing insurance. A team where every reviewer can handle every task type has maximum routing flexibility. A team where every reviewer is specialized has minimum flexibility. The tradeoff is expertise versus resilience. Maximum specialization produces deep expertise but creates single points of failure. Maximum generalization produces flexibility but risks shallow expertise. The right balance depends on volume, complexity, and turnover.

For high-volume, high-consistency tasks, cross-training everyone is correct. Content moderation, output quality checks, and data labeling benefit from broad skill distribution. The cases are similar enough that every reviewer can build competence. The volume is high enough that specialization does not improve quality. Cross-training the entire team eliminates routing constraints and prevents overload.

For low-volume, high-complexity tasks, selective cross-training is correct. Legal review, medical chart evaluation, and security incident assessment require deep expertise. Training everyone dilutes focus and increases error rates. Instead, train a small pool deeply and maintain that pool through deliberate practice. The pool must be large enough to handle peak load without overload. If peak PHI volume is 120 cases per day and each certified reviewer can handle 30, the team needs at least four certified reviewers. Three is insufficient. Five provides buffer.

Cross-training must be continuous. A reviewer trained six months ago but who has not reviewed a PHI case since is no longer proficient. Skills decay without use. The load balancer must track recency of practice and route maintenance volume to trained-but-idle reviewers. A reviewer certified for legal review who has not done one in 60 days receives the next legal case even if they are not the lowest-utilization reviewer. The assignment is not load balancing. It is skill maintenance. Both matter.

## Load Shedding When Overwhelmed

When volume exceeds capacity, the system must shed load. Load shedding is the controlled failure mode. It is better than uncontrolled failure, where every case is late, every reviewer is overwhelmed, and quality collapses. Load shedding chooses what to drop and what to protect. The choice is policy, not an algorithm.

The first form of load shedding is admission control. When the queue depth exceeds a threshold, the system stops accepting new low-priority cases. High-priority cases continue to flow. Low-priority cases are rejected with a clear signal: the system is over capacity, retry later. Admission control prevents the queue from growing unbounded. It also prevents the reviewer experience from degrading. A reviewer working a manageable queue produces quality. A reviewer working an infinite queue produces exhaustion.

The second form is SLA-based triage. Cases that cannot meet their SLA are removed from the active queue and moved to a backlog queue. The backlog is explicitly labeled as late. The distinction matters for reporting and accountability. An SLA miss for a case that was triaged out is different from an SLA miss for a case that was actively worked but finished late. The first is a capacity decision. The second is an execution failure.

The third form is delegation to automation. When human review is overwhelmed, lower-risk cases are routed to automated checks instead. The automation is less accurate but faster. The tradeoff is explicit: lower quality in exchange for capacity. The cases routed to automation are logged. The decision is reversible. When capacity recovers, the organization can choose to re-review the automated-only cases or accept the quality tradeoff as permanent.

Load shedding requires executive visibility. The decision to reject cases, miss SLAs, or route work to automation is not a reviewer decision or a load balancer decision. It is a business decision. The system must surface the load shedding event immediately to leadership. The alert says: we are over capacity, here is what we are shedding, here is the impact. Leadership decides whether to accept the shedding, add capacity, or reduce volume at the source.

## The Fairness Perception Problem

Load balancing is not just a throughput optimization. It is a perceived fairness signal. A reviewer who consistently receives harder cases than their peers perceives unfairness. A reviewer who consistently receives more cases than their peers perceives unfairness. Perception drives engagement. Unfair load distribution creates disengagement even when the distribution is technically optimal.

Perceived fairness requires visible equity. Reviewers must see that load is distributed evenly. A dashboard showing current utilization per reviewer makes distribution transparent. A reviewer who sees their utilization at 82 percent and their peers at 79 percent and 85 percent perceives fairness. A reviewer who sees their utilization at 95 percent and their peers at 60 percent perceives unfairness. Transparency does not fix imbalance, but it exposes it. Exposure creates accountability.

Fairness also requires rotation of undesirable work. Every team has cases no one wants to review. Graphic violence, child exploitation, or deeply ambiguous edge cases that require painful judgment calls. If the same reviewer always gets these cases, they burn out. The load balancer must rotate undesirable work evenly. The rotation is tracked and visible. A reviewer who handled 40 graphic cases this week receives fewer next week. The distribution is not random. It is managed.

Fairness requires accounting for hidden work. A reviewer who also trains new team members does less case review but more total work. A reviewer who participates in weekly calibration sessions has less available time than one who does not. The load balancer must account for non-case work when calculating capacity. A reviewer credited with 4 hours of non-case work per week has 4 fewer hours for case review. The system that ignores this overloads the people doing the organizational work that keeps quality high.

## Timezone Handoffs

Review does not stop at 5pm. A global review operation runs 24 hours. Load balancing across timezones introduces handoff complexity. A case assigned to a US-based reviewer at 4pm may not be started before end of shift. The case sits in their queue overnight. The SLA clock keeps running. The next morning, the case is 16 hours older and possibly breaching SLA. Timezone handoffs require explicit queue management.

The first strategy is shift-aware assignment. Cases arriving within 2 hours of shift end are not assigned to the current shift. They are held for the next shift or assigned to an overlapping timezone. A case arriving at 4pm US Eastern is assigned to a US Pacific reviewer with 3 hours left in their shift or held for the EMEA shift starting in 3 hours. The assignment decision prevents the overnight stall.

The second strategy is queue transfer at shift end. Any case that was assigned but not started is automatically transferred back to the global queue at shift end. The transfer is automatic, not manual. A reviewer who logs off with 8 assigned cases releases all 8 back to the queue. The next shift picks them up. The system that requires manual transfer creates overnight abandonment. Reviewers forget. Cases stall. SLAs are missed.

The third strategy is follow-the-sun routing. Urgent cases are routed to the timezone where reviewers are currently active. A high-priority case arriving at 10pm US Eastern is routed to the APAC shift, not held for US morning. The routing decision prioritizes SLA over reviewer continuity. Continuity matters for complex multi-stage reviews. SLA matters for time-sensitive decisions. The routing policy must specify which cases allow follow-the-sun and which require same-reviewer continuation.

Timezone handoffs also require communication infrastructure. A case partially reviewed by one shift must transfer context to the next. The first reviewer leaves notes: what they checked, what they found, what remains uncertain. The notes are structured, not freeform. The second reviewer reads the notes before continuing. The handoff is explicit. The system that transfers cases without context forces the second reviewer to duplicate work or skip steps. Both waste capacity.

Your review queue determines whether load is shared or hoarded, whether quality is protected or sacrificed to throughput, and whether reviewers stay engaged or burn out. Next, we examine batch versus stream processing models, and when each architecture is correct.
