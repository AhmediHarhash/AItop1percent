# 2.8 — Multi-Stage Review Pipelines

Complex decisions require multiple review stages. The temptation is to route every difficult case straight to your most experienced reviewer. That does not scale. What scales is a pipeline where tier-1 reviewers handle the straightforward majority, tier-2 reviewers handle the ambiguous cases that tier-1 escalates, and domain experts handle only the 2-5 percent of items that genuinely require specialized judgment. The architecture challenge is designing promotion criteria that move items between stages without creating bottlenecks, duplication, or confusion about who owns what.

A multi-stage pipeline is not just a fancy queue. It is a deliberate system for allocating human judgment according to difficulty. Get the promotion thresholds right and your experts spend their time on genuinely hard problems. Get them wrong and your experts drown in routine work while tier-1 reviewers sit idle.

## Tier-1, Tier-2, and Expert Stage Design

The three-tier model is the most common pattern. Tier-1 reviewers are trained on the task and can handle clear-cut cases with high confidence. They work through high volume, see repetitive patterns, and become fast. Tier-2 reviewers have deeper domain knowledge or more training. They handle cases where the judgment is genuinely ambiguous or where tier-1 explicitly marked uncertainty. Expert reviewers are specialists — clinicians for medical content, lawyers for legal interpretations, native speakers for culturally sensitive translation. They handle only the cases that earlier tiers cannot resolve with confidence.

The boundaries between tiers matter. Tier-1 should have explicit promotion criteria: "If you encounter X, escalate to tier-2." Not vague criteria like "escalate if uncertain." Specific criteria. "If the document references experimental treatment, escalate." "If the query contains a financial instrument you do not recognize, escalate." "If the tone judgment requires cultural context outside your training, escalate." Tier-1 reviewers need decision rules, not feelings.

Tier-2 receives escalations from tier-1 and also receives cases the routing system flags as high-complexity upfront. They work slower, think harder, and document their reasoning. They also send a small percentage to experts when they encounter edge cases. Experts receive only items that both tier-1 and tier-2 could not confidently resolve, plus a random sample for quality control. If your experts are reviewing more than 10 percent of total volume, your tier-1 and tier-2 criteria are too conservative.

## Promotion Criteria Between Stages

Promotion is the mechanism that moves an item from one stage to the next. The simplest form is explicit escalation: the tier-1 reviewer clicks an "Escalate to tier-2" button and writes a brief note explaining why. The item leaves tier-1 and enters the tier-2 queue. This works, but it has a flaw: tier-1 reviewers under time pressure will escalate too liberally to protect themselves. If escalation is free and mistakes are costly, they escalate everything borderline.

The fix is escalation feedback. When a tier-2 reviewer receives an escalation, they mark whether the escalation was justified. If tier-1 escalated a case that tier-2 resolves in under 30 seconds with no new information, that escalation was unnecessary. Track unnecessary escalation rates per reviewer. Not to punish, but to retrain. If a reviewer escalates 40 percent of their queue and half of those escalations are unnecessary, that reviewer needs clearer decision criteria or more training on the patterns they are escalating.

Some systems use confidence scoring instead of explicit escalation. The reviewer labels the item and also marks their confidence: high, medium, or low. Items with low confidence automatically promote to tier-2. Items with medium confidence promote if they also meet other criteria, such as high business impact or regulatory sensitivity. Items with high confidence stay in tier-1 unless random sampling pulls them for quality checks. This removes the escalation decision from the reviewer and makes promotion deterministic.

Automatic promotion based on item attributes is the third pattern. The system knows that certain types of cases are harder. Legal contracts over 50 pages always route to tier-2. Medical device classifications always route to experts. Customer support queries mentioning suicide or self-harm bypass all tiers and route to specialized crisis reviewers. These rules live in the routing logic, not in reviewer decisions. The advantage is consistency. The disadvantage is rigidity: you cannot adapt the rule mid-shift without redeploying code.

## The Latency Cost of Multi-Stage Pipelines

Every additional stage adds latency. A single-stage queue processes an item once. A two-stage queue processes it once in tier-1, promotes it, then processes it again in tier-2. The total time is the sum of tier-1 wait time, tier-1 review time, tier-2 wait time, and tier-2 review time. If your tier-2 queue is understaffed, items sit in tier-2 for hours after spending minutes in tier-1. The user waiting for a response does not care that 90 percent of the latency was queue wait time in a stage they never heard of.

Latency-sensitive workflows require tight SLAs on promotion. If an item escalates to tier-2, it must enter the tier-2 queue immediately and be prioritized appropriately. Some systems give escalated items higher priority than new items entering tier-2 directly, on the theory that an escalation represents urgency. Other systems treat all tier-2 items equally to avoid starvation of the direct-entry queue. The choice depends on your business. If tier-1 escalates only true emergencies, prioritize escalations. If tier-1 escalates liberally, do not.

You can measure pipeline latency by tracking time-to-completion from the moment an item enters tier-1 to the moment it exits the final stage. Break this into stage durations: tier-1 wait, tier-1 review, promotion delay, tier-2 wait, tier-2 review. If 70 percent of latency is tier-2 wait time, the bottleneck is tier-2 capacity, not tier-1 speed. Add tier-2 reviewers or tighten tier-1 escalation criteria.

## Parallel vs Sequential Stages

Most multi-stage pipelines are sequential: tier-1 completes, then tier-2 begins. But some decisions benefit from parallel review. Two reviewers see the same item simultaneously, label independently, and the system reconciles their judgments. If they agree, the label is final. If they disagree, a third reviewer breaks the tie. Parallel review doubles review cost but eliminates bias from seeing the prior reviewer's label.

Parallel stages make sense when the correctness risk is very high and the decision is subjective enough that two qualified reviewers might legitimately disagree. Medical diagnosis support, legal risk classification, and content moderation for graphic violence are common parallel-review domains. The cost is justified by the risk reduction. Sequential review makes sense when the decision is more objective or when tier-1 genuinely handles the easy majority and only ambiguous cases escalate.

Hybrid pipelines combine both. Tier-1 is sequential: one reviewer sees it, and if they escalate, tier-2 sees it. But the final expert stage uses parallel review: two experts see the item independently, and disagreement triggers a third expert. This balances cost and accuracy. You pay for parallel review only on the hardest 5 percent of cases.

## Stage-Specific Tooling

Tier-1 reviewers and expert reviewers do not need the same interface. Tier-1 reviewers benefit from speed optimizations: keyboard shortcuts, auto-advancing to the next item, minimal documentation fields. They see hundreds of items per day. Every extra click costs minutes over a shift. Their tool should assume they are moving fast and should not interrupt them with confirmation dialogs or multi-step workflows.

Expert reviewers need the opposite. They see a few items per day, spend 20 minutes per item, and write detailed justifications for their decisions. Their tool should show more context: previous review history, related items the same user submitted, external reference materials. Experts also benefit from free-text reasoning fields where they explain their logic. Tier-1 reviewers rarely write essays. Experts often do.

Tier-2 sits in between. They see moderate volume, work at moderate speed, and need moderate context. Their tool should show why tier-1 escalated the item and what tier-1's initial judgment was, if any. This prevents tier-2 from re-doing work tier-1 already completed. If tier-1 already verified that a document is in English and correctly formatted, tier-2 does not need to verify that again. They focus only on the ambiguous judgment that triggered escalation.

Stage-specific tooling also means stage-specific training and onboarding. Do not train tier-1 reviewers on expert-level edge cases they will never see. Do not train experts on tier-1 volume optimization tactics. Each stage has its own skill requirements and its own interface. Treat them as separate jobs, not one job at three difficulty levels.

## Inter-Stage Communication

When tier-1 escalates to tier-2, what information should travel with the item? The minimum is the item itself: the model output, the user query, the context. But that forces tier-2 to start from scratch. Better: tier-1 also passes their preliminary judgment and their reason for escalation. "Labeled as safe, but escalating because the query mentions a prescription drug I am not trained to evaluate." Now tier-2 knows what to focus on.

Some systems let tier-2 send feedback to tier-1. Not punitive feedback, but clarifying feedback. "You escalated this because you were unsure if the tone was sarcastic. In our guidelines, sarcasm in product reviews is allowed unless it targets a person. This was product sarcasm, so tier-1 could have labeled it safe." Tier-1 learns from that feedback and escalates fewer similar cases next time. This creates a feedback loop where tier-1 gets better over time, reducing the tier-2 load.

Inter-stage communication also includes routing notes visible to managers but not to reviewers. If an item escalates three times in a row—tier-1 to tier-2, tier-2 to expert, expert back to tier-2 for clarification—the system should flag this as a potential process failure. Either the guidelines are unclear, the item is genuinely unprecedented, or the reviewers are misunderstanding each other. Managers see these patterns and intervene.

Communication also flows backward. If an expert reviews an item and discovers that tier-1 misunderstood the guidelines, the expert can annotate the item with a teaching note: "This was escalated as ambiguous, but the guideline clearly states X. Tier-1 should label this pattern as Y in the future." These teaching moments accumulate in a knowledge base that informs future training.

## The Duplication Problem

Multi-stage pipelines risk wasted work. Tier-1 spends five minutes reviewing an item, escalates it, and tier-2 spends another five minutes reviewing the same aspects tier-1 already covered. The total review cost is ten minutes, but only five minutes of net new judgment happened. This is the duplication problem.

The fix is partial completion. Tier-1 marks which aspects of the item they confidently evaluated and which aspects they escalated. If the task is to label content for safety, toxicity, and factual accuracy, tier-1 might label safety as clearly safe and toxicity as clearly non-toxic, but escalate the factual accuracy judgment because it requires domain expertise. Tier-2 sees the tier-1 safety and toxicity labels, accepts them, and focuses only on factual accuracy. Total review time: five minutes in tier-1, three minutes in tier-2, eight minutes total instead of ten.

Partial completion requires decomposable tasks. Not all judgments decompose cleanly. If the task is "rate the overall quality of this summary," you cannot easily separate that into sub-judgments that tier-1 completes and tier-2 refines. But if the task is "check grammar, check accuracy, check completeness," each of those is a separate judgment. Tier-1 can confidently complete two and escalate one.

Some systems skip duplication prevention and accept the cost. If review time is cheap and the risk of tier-2 missing something tier-1 saw is high, full re-review is safer. The trade-off depends on your error tolerance and your cost budget. High-stakes domains often re-review everything. High-volume domains optimize to avoid duplication.

## When to Flatten Pipelines

Not every domain benefits from multiple stages. If 95 percent of items are straightforward and the remaining 5 percent are genuinely expert-level with no middle ground, a two-tier system works better than three. Tier-1 handles the easy majority, experts handle the hard minority, and you skip the tier-2 layer entirely. Tier-1 reviewers escalate directly to experts using explicit criteria.

Flattening also makes sense when your tier-1 reviewers are already highly trained. If you are reviewing medical imaging and every reviewer has a radiology background, the concept of "tier-1" versus "tier-2" may be artificial. They are all qualified. The difference is just seniority or case load, not capability. In that scenario, route by case complexity, not reviewer tier. Complex cases go to anyone available with the right subspecialty. Simple cases go to anyone available. No formal tiers.

Flat pipelines are also faster. Fewer stages mean lower latency, simpler routing logic, and less inter-stage communication overhead. If your SLA is tight and your reviewers are competent, flatten the pipeline and invest in better training so that every reviewer can handle a wider range of cases. The staging model makes sense when there is a genuine skill gap between tiers. If the skill gap is small, the staging overhead outweighs the benefit.

Some systems start with a flat pipeline and add stages only when volume forces specialization. When you have 50 reviewers and 10,000 items per day, you discover that 30 of your reviewers spend 80 percent of their time on routine cases and 20 reviewers spend all their time on hard cases. At that point, formalize the tiers: the 30 become tier-1, the 20 become tier-2. But before you hit that scale, a flat pipeline with smart routing works fine.

## Monitoring Stage Efficiency

Every multi-stage pipeline generates metrics you must track. Escalation rate: what percentage of tier-1 items escalate to tier-2? If that number rises above 15 percent, either your tier-1 reviewers need retraining or your routing logic is sending too many hard cases to tier-1. Unnecessary escalation rate: what percentage of tier-2 items were escalated unnecessarily? If that number is high, tier-1 reviewers are escalating out of caution, and you need tighter escalation criteria.

Stage latency: how long does an item spend in each stage? Break this into wait time and review time. If tier-2 items wait for hours but are reviewed in minutes, the bottleneck is tier-2 staffing, not tier-2 speed. If tier-2 items are reviewed slowly, the bottleneck is reviewer skill or case complexity. Adjust training or routing.

Promotion accuracy: when tier-1 escalates an item, does tier-2 agree the escalation was justified? Track agreement rates. Low agreement means tier-1 reviewers are misunderstanding escalation criteria. High agreement means the criteria are working. Over time, escalation agreement should improve as tier-1 reviewers learn from feedback.

Expert utilization: what percentage of expert time is spent on cases that genuinely require expert judgment versus cases that tier-2 could have resolved? If experts spend 30 percent of their time on tier-2-level cases, your tier-2 escalation criteria are too loose. Tighten them, or train tier-2 to handle more edge cases.

Multi-stage pipelines are powerful tools for scaling human judgment without sacrificing quality. The next challenge is handling the items that cannot be processed at all—the dead letters, poison pills, and orphaned tasks that accumulate in every system and must not be allowed to disappear. That is the subject of the next subchapter: handling queue failures and dead letters.
