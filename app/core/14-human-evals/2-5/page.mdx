# 2.5 â€” Batch vs Stream: Two Models for Queue Processing

Review work arrives in two forms. Batch review is scheduled, planned, and cognitively optimized for deep focus. Stream review is continuous, reactive, and optimized for latency. Most organizations run both models simultaneously without recognizing the distinction. They assign batch-like work to stream queues and wonder why reviewers burn out. They assign stream-like work to batch queues and wonder why SLAs are missed. The processing model you choose determines the quality you get, the speed you achieve, and the reviewer experience you create.

## When Batch Wins

Batch review is correct when the decision is complex, when calibration matters more than latency, and when the work benefits from cognitive focus. A weekly audit of 200 randomly sampled cases is batch work. The cases do not need to be reviewed immediately. They need to be reviewed carefully, with time to think, discuss edge cases, and refine judgment. Batch work is scheduled into dedicated review sessions. A reviewer blocks 4 hours on Wednesday afternoon, opens the batch, and works through it without interruption.

Batch review produces higher-quality decisions. The reviewer enters a flow state. They see patterns across the batch. They notice that 6 of the 200 cases have the same edge case and realize the pattern needs a policy update. They flag the pattern for discussion. The insight only emerges because the reviewer saw the cases together. A stream reviewer sees one case per hour mixed with 40 other case types and never sees the pattern. The batch structure enables learning.

Batch review also protects focus. A reviewer working a batch is not interrupted by new assignments. The queue does not ping them every 3 minutes with a new case. They complete the batch, then move to the next one. The uninterrupted work time produces better decisions and less cognitive fatigue. A reviewer who completes 50 cases in a 3-hour batch session is less exhausted than a reviewer who completes 50 cases across an 8-hour stream shift. The difference is context switching.

Batch review is also correct for calibration-sensitive work. A team reviewing medical chart quality works in batches of 20 charts per reviewer per week. Every Friday, the team meets to discuss edge cases from their batches. The discussion calibrates judgment. A reviewer who scored a chart as high-quality hears why a peer scored it as low-quality. The conversation refines their mental model. Calibration requires shared context. Batch review creates that context. Stream review does not.

## When Stream Wins

Stream review is correct when latency matters, when the decision is relatively simple, and when the work is high-volume. Content moderation for user-generated posts is stream work. A post reported for violating policy must be reviewed within 15 minutes or the user perceives the system as broken. The decision is typically straightforward: the post either violates policy or it does not. The volume is high. A single reviewer might evaluate 60 posts per hour.

Stream review optimizes for throughput and responsiveness. Cases are assigned as soon as they arrive. A reviewer finishes one case and immediately receives the next. The queue is always full. The reviewer never waits for work. The system maximizes utilization. A stream reviewer operating at 85 percent utilization completes 51 cases per hour with a 5-minute average latency. A batch reviewer working the same cases in 4-hour blocks completes them with a 2-hour average latency. The batch has higher quality but misses the latency requirement.

Stream review is also correct when cases are independent. A moderation decision on one post does not inform the decision on the next post. Each case is evaluated in isolation. The lack of cross-case learning is not a deficiency. It is the nature of the work. Stream assignment does not create missed insight because there is no cross-case insight to miss.

Stream review is required for user-blocking decisions. A user appealing a ban cannot wait 3 days for the next batch review cycle. The appeal must be reviewed within hours. The reviewer who handles the appeal is pulled from the stream queue. They complete the appeal review, then return to the stream. The interruption is acceptable because the alternative is unacceptable latency.

## Hybrid Models

Most review operations need both models. Routine moderation runs as stream. Weekly quality audits run as batch. The hybrid system allows each type of work to use the processing model that fits its requirements. The challenge is managing the transition. A reviewer working a stream queue cannot simultaneously work a batch. The two models require different cognitive modes. Switching between them within a single shift creates the worst of both: the fatigue of stream and the latency of batch.

The correct hybrid assigns reviewers to one model per shift. A reviewer scheduled for stream works stream for the entire shift. A reviewer scheduled for batch works batch for the entire shift. The schedule rotates weekly or daily depending on team size and workload. A team of 12 reviewers might run 9 on stream and 3 on batch. The ratio adjusts to match workload. A week with high batch volume shifts to 6 stream and 6 batch. The shift assignment is visible and planned. A reviewer knows at the start of their shift which mode they are working.

Some organizations run a third model: priority stream. Priority stream is stream processing for high-urgency cases. A case flagged as high-severity enters the priority stream queue. A dedicated reviewer monitors the priority queue and handles cases immediately. The priority reviewer is not assigned routine stream cases. Their only job is to respond to urgent work. The model works when urgent volume is low enough that one dedicated reviewer can handle it without overload. If urgent volume exceeds one person's capacity, the organization must staff multiple priority reviewers or reclassify what counts as urgent.

Hybrid models require separate queue infrastructure. A batch queue does not ping reviewers in real-time. It presents a list of cases to be completed by end of shift. A stream queue does ping reviewers in real-time. It assigns one case at a time. A priority queue pings immediately and overrides current work. The infrastructure must support all three. A single unified queue that tries to serve all models produces confusion. The reviewer does not know which case is urgent, which can wait, and which is part of a batch to be completed as a set.

## The Context-Switching Cost of Stream

Stream review creates relentless context switching. A reviewer completes a moderation case, switches to a quality audit case, switches to a user appeal, switches to a labeling task. Each switch costs cognitive energy. The reviewer must reload the evaluation criteria, reload the policy, reload the mental model of what good looks like. The cost per switch is small. The cumulative cost over 8 hours is large.

Research on knowledge work consistently shows that context switching reduces both speed and accuracy. A developer switching between three projects completes less work than a developer focused on one. A reviewer switching between five case types completes less work than a reviewer focused on two. The stream model imposes continuous context switching by design. The cost is inherent. The question is how to minimize it.

The first strategy is batching within stream. Instead of assigning one case at a time, assign 5 cases of the same type. The reviewer completes all 5 before switching to a different case type. The micro-batch reduces switching frequency from every 3 minutes to every 15 minutes. The reviewer builds momentum within the case type. The quality improves. The throughput improves. The cognitive load decreases.

The second strategy is case type affinity. A reviewer who handles a moderation case is preferentially assigned the next moderation case. The affinity is not strict. If no moderation cases are available, the reviewer receives a different case type. But when possible, the system keeps the reviewer in the same context. The affinity reduces switching without creating strict specialization. The reviewer still handles multiple case types per shift but in longer runs of the same type.

The third strategy is rotation with recovery. A reviewer works stream for 90 minutes, then takes a 10-minute break, then resumes. The break is not optional. It is scheduled. The system stops assigning cases 10 minutes before the break. The reviewer finishes their current case and steps away. The break allows cognitive recovery. The reviewer returns with restored focus. The 10-minute investment produces higher quality for the next 90 minutes. The system that eliminates breaks to maximize utilization reduces both quality and throughput.

## Batch Assignment Strategies

Batch work requires assignment planning. A batch of 200 cases must be distributed across 8 reviewers. The distribution strategy affects both completion time and quality. The simplest strategy is equal division: 25 cases per reviewer. The strategy is fair but ignores capacity differences. A fast reviewer finishes 25 cases in 90 minutes and waits. A slow reviewer finishes 25 cases in 4 hours and rushes the last 5 to meet the deadline. Equal division is not equitable.

A better strategy is capacity-proportional assignment. A reviewer with a capacity of 40 cases per shift receives 40 cases. A reviewer with a capacity of 20 cases per shift receives 20 cases. The batch is fully assigned, and every reviewer works at their sustainable rate. The strategy requires accurate capacity measurement. If capacity estimates are wrong, the distribution is wrong. A reviewer assigned 40 cases based on historical data who is currently slower due to fatigue or distraction falls behind. The system must allow in-batch reassignment. A reviewer who completes their share early can pull additional cases from the batch. A reviewer who is behind can release cases back for redistribution.

A third strategy is skill-matched assignment. A batch of medical record reviews is distributed based on clinical expertise. Cardiology cases go to the reviewer with cardiology training. Oncology cases go to the oncology-trained reviewer. The matching improves quality. It also creates utilization imbalance. The reviewer with the most common specialty receives the most cases. The system must track specialty distribution in the batch and adjust assignments to prevent overload.

Batch assignment also requires start-time coordination. If the batch is due by end of day Friday and one reviewer starts Monday while another starts Thursday, the Thursday reviewer has 8 hours to complete work that should take 16 hours. The batch must either be assigned at the start of the batch period with a clear deadline, or assigned dynamically as reviewers become available. The first approach is simpler but less flexible. The second approach is more complex but adapts to reviewer availability.

## Reviewer Preference and Productivity Differences

Some reviewers prefer batch work. They like the focus, the flow state, and the ability to see patterns. Some reviewers prefer stream work. They like the variety, the pace, and the immediate feedback. The preference is not a proxy for skill. It is a cognitive and temperamental difference. A review operation that ignores preference assigns reviewers to work modes that drain rather than energize them.

The system should track reviewer preference and honor it when possible. A reviewer who prefers batch is assigned batch shifts 70 percent of the time. A reviewer who prefers stream is assigned stream shifts 70 percent of the time. The remaining 30 percent is cross-training and flexibility. Honoring preference is not indulgence. It is productivity optimization. A reviewer working their preferred mode produces higher quality and higher throughput than the same reviewer forced into the opposite mode.

Productivity differences between batch and stream are measurable. Some reviewers are 20 percent faster in batch. Some are 20 percent faster in stream. The difference is real and consistent. The system must measure productivity per mode and use the data for assignment planning. A reviewer who completes 30 cases per hour in stream but 40 cases per hour in batch should be assigned batch work whenever batch volume is available. The assignment is not favoritism. It is capacity optimization.

Preference and productivity must also be revisited. A reviewer who preferred batch six months ago may prefer stream now. A reviewer whose productivity was higher in stream may have developed batch skills that shift their productivity profile. The system should prompt reviewers quarterly to update their preference and should recalculate productivity statistics every 60 days. The static assumption produces stale assignments.

## Reporting and Visibility

Batch and stream work require different reporting. A stream reviewer's performance is measured in cases per hour, average latency, and accuracy. A batch reviewer's performance is measured in batch completion rate, time to complete batch, and accuracy. The metrics are not interchangeable. A batch reviewer who completes a 50-case batch in 4 hours with 98 percent accuracy is high-performing. If those same 50 cases were measured as stream work with a 5-minute average latency, the reviewer would appear slow. The reporting system must recognize the work mode and apply the correct metrics.

Visibility also differs. A stream reviewer sees their current case and their position in the queue. A batch reviewer sees the full batch, their progress through the batch, and how their progress compares to the batch deadline. The batch view creates different motivation. The reviewer knows that finishing early allows them to move to other work or take a longer break. The stream reviewer knows that finishing one case immediately brings the next case. The batch creates closure. The stream creates continuity. Both are correct for their respective modes.

The system must also report mode utilization. What percentage of reviewer time is spent in batch versus stream? A team that is 90 percent stream and 10 percent batch may need to shift resources if batch work is undercapitalized. A team that is 50/50 may need to specialize further if context switching is reducing productivity. The utilization report surfaces the balance and allows intentional adjustment.

Your choice between batch and stream determines whether reviewers can focus or must context-switch, whether calibration is possible or impossible, and whether latency targets can be met without burning out your team. Next, we examine queue depth and backlog management, and how to prevent the backlog from becoming permanent debt.
