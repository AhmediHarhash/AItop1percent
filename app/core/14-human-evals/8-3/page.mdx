# 8.3 — Escalation Paths for Unresolved Disagreements

In August 2025, a healthcare analytics company running clinical note evaluation had a problem. Reviewers were escalating 140 cases per week to the adjudication team. The adjudicators resolved most within 48 hours, but 22 cases per week remained unresolved after adjudication. These were outputs where even the senior reviewer could not make a confident determination. The edge cases were genuinely ambiguous, required clinical expertise the adjudicator lacked, or revealed gaps in the rubric that no individual reviewer could fix. These 22 cases per week sat in limbo. No label. No resolution. No path forward. After six weeks, the backlog reached 130 unresolved cases, and the eval pipeline effectively had a growing blind spot.

The company had majority vote for simple cases and expert adjudication for complex cases, but they had no escalation path for the cases that defeated adjudication. They assumed adjudicators could resolve everything. They were wrong. Not every disagreement can be settled by one person reviewing the output more carefully. Some disagreements require collaboration, domain expertise the adjudicator does not have, or changes to the rubric itself. Without a defined escalation path, these cases accumulate and create operational and data quality problems.

## When Disagreement Cannot Be Resolved at the Reviewer Level

Most disagreements are resolvable by the adjudicator. The primary reviewers missed something, misread the guideline, or interpreted an ambiguous case differently. The adjudicator sees the issue, applies the rubric correctly, and issues a final label. These cases move through the system cleanly.

But some disagreements are not reviewer error. They are system gaps. The rubric does not cover this scenario. The output is genuinely borderline and reasonable experts disagree. The task requires knowledge outside the adjudicator's expertise. The reviewers provided conflicting rationales and both rationales are logically sound. In these cases, asking the adjudicator to make a unilateral decision produces either arbitrary labels or decision paralysis. Neither is acceptable.

Escalation is necessary when the adjudicator cannot resolve the disagreement with confidence. This does not mean the adjudicator is unqualified — it means the case is legitimately unresolvable within the current system. Recognizing when a case needs escalation is a skill. Adjudicators who are afraid to escalate make forced decisions that create bad ground truth. Adjudicators who escalate too often create bottlenecks and erode trust in their judgment. The balance is knowing when you have the information to decide and when you need help.

## Escalation Criteria: What Qualifies for Further Review

Escalation should not be subjective. Define explicit criteria. A case escalates if the adjudicator meets one or more of the following conditions: they cannot determine which interpretation of the rubric is correct after consulting guidelines and examples; the case reveals an ambiguity or gap in the rubric that affects labeling; the case requires domain expertise the adjudicator does not have; the disagreement stems from a novel failure mode not covered in training; or the reviewers provided detailed conflicting rationales and both are defensible.

These criteria prevent arbitrary escalation. An adjudicator cannot escalate simply because the case is difficult or time-consuming. Difficulty is the job. But if the adjudicator has applied the rubric as written and still cannot make a confident call, escalation is appropriate. If the adjudicator realizes the rubric does not define how to handle this scenario, escalation is appropriate. If the case requires interpreting a legal clause and the adjudicator is not a lawyer, escalation is appropriate.

A logistics company defined escalation criteria for route safety evaluation. Adjudicators could escalate if the disagreement involved interpreting local traffic regulations they were unfamiliar with, if the case required knowledge of seasonal weather patterns not documented in the rubric, or if the reviewers disagreed on whether a route met accessibility standards and both provided plausible justifications. These criteria were specific to the task. They gave adjudicators clear permission to escalate rather than guess. Escalation rates were 8 percent of adjudicated cases, which was manageable and appropriate given the complexity of the task.

## Who Receives Escalations: The Second-Tier Review Team

Escalations need an owner. In most systems, this is a small group of senior domain experts, rubric authors, or team leads who have authority to make final decisions, update guidelines, or convene group discussions. This group is not the adjudicator pool — it is a tier above. The adjudicators handle disagreements that fall within the rubric. The escalation team handles disagreements that reveal problems with the rubric or require expertise beyond what adjudicators have.

The escalation team should be small enough to make decisions quickly and large enough to cover the necessary expertise. For most systems, this is two to five people. A larger team introduces coordination overhead. A smaller team creates single points of failure. If the system serves multiple domains — legal, medical, technical — the escalation team should include representatives from each domain so that escalated cases can be routed to the right expert.

A financial services company had a three-person escalation team for investment summary review: a senior financial analyst, a compliance officer, and the original author of the evaluation rubric. Adjudicators escalated cases that involved ambiguous regulatory language, novel financial instruments not covered in the rubric, or disagreements about risk disclosure adequacy. The escalation team reviewed each case together, discussed the rationale, made a final determination, and documented whether the rubric needed updates. Most escalations were resolved within 48 hours. Rubric updates happened monthly based on patterns that emerged from escalated cases.

The escalation team is also responsible for feedback. When they resolve a case, they communicate the decision back to the adjudicator and, if relevant, to the primary reviewers. This feedback loop is critical. If adjudicators escalate cases and never hear the resolution, they do not learn. If primary reviewers never see how escalated cases were ultimately labeled, they do not improve calibration. The escalation team closes the loop by explaining why a case was labeled a certain way and, when appropriate, updating training materials or guidelines to prevent similar escalations in the future.

## Turnaround Time Requirements: Preventing Escalation Backlog

Escalations that sit unresolved for weeks create three problems. First, they delay ground truth generation, which delays model iteration. Second, they create uncertainty in the reviewer pool about whether the rubric is stable. Third, they signal that escalation is where cases go to die, which discourages adjudicators from escalating when they should. Turnaround time for escalated cases must be fast enough that the pipeline does not stall.

A reasonable target is 48 to 72 hours for most escalations. Cases that require rubric changes or cross-functional discussion may take longer, but the escalation team should acknowledge the case within 24 hours and provide a timeline. If escalations routinely take more than a week to resolve, the escalation team is undersized, the escalation criteria are too loose, or the rubric is fundamentally underspecified and needs a larger revision.

The healthcare analytics company that started with a 130-case backlog implemented a 48-hour SLA for escalations. The escalation team reviewed all new escalations twice per week in a standing 90-minute session. Cases that required domain expertise from outside the team were routed to clinical advisors within 24 hours with a request for resolution within one week. Cases that revealed rubric gaps were tagged for inclusion in the next monthly rubric update. The backlog cleared in five weeks and did not recur. Adjudicators gained confidence that escalating was not abandoning a case — it was routing it to the people who could fix the underlying issue.

Tracking escalation volume and resolution time is essential. If escalation volume is increasing over time, either the rubric is degrading in quality, the task is getting harder, or the reviewer pool is poorly calibrated. If resolution time is increasing, the escalation team is overloaded or the escalated cases are becoming more complex. Both trends are warning signs that require operational intervention.

## Escalation Patterns as a Rubric Improvement Signal

Escalations are not just individual cases to resolve — they are data. Patterns in escalations reveal where the rubric is weak. If 40 percent of escalations involve the same criterion, that criterion needs rewriting. If escalations cluster around a specific output type, that type needs more examples in the guideline. If escalations spike after a model update, the new model is producing failure modes the rubric was not designed to handle.

A content moderation platform tracked escalation patterns monthly. In February 2025, 35 percent of escalations involved determining whether satirical content crossed into hate speech. The rubric defined hate speech clearly but did not address satire. Adjudicators escalated because they could not confidently apply the hate speech definition to satirical content. The escalation team added a section to the rubric on satire, defined three key indicators that distinguish satirical criticism from hate speech, and provided five annotated examples. Escalations on satire dropped to 6 percent the following month. The pattern in escalations diagnosed the problem. The rubric revision fixed it.

Some escalations cannot be resolved with rubric updates because the disagreement is philosophical or value-based. What counts as respectful tone in professional communication? Where is the line between summarization and editorialization? How much risk is acceptable in a route recommendation? These questions do not have objective answers. They require organizational judgment. When escalations reveal these philosophical disagreements, the escalation team's job is not to resolve the disagreement — it is to document the organization's stance and encode it in the rubric so reviewers have a clear directive.

## Preventing Escalation Bottlenecks

The escalation team is a scarce resource. If too many cases escalate, the team becomes a bottleneck and the entire evaluation pipeline slows. Preventing bottlenecks requires upstream investment. Better rubrics reduce escalations. Better adjudicator training reduces escalations. Better escalation criteria reduce unnecessary escalations. All three require continuous attention.

One pattern that creates unnecessary escalations is adjudicators using escalation as a fallback for hard decisions. If the adjudicator is unsure and escalation is easy, they escalate rather than making a call. This inflates escalation volume and trains adjudicators to avoid difficult decisions. The fix is clarifying that escalation is for unresolvable cases, not merely difficult ones. Adjudicators are hired to make difficult decisions within the rubric. Escalation is for cases where the rubric does not provide the tools to make that decision.

Another pattern is systemic underspecification. If 25 percent of adjudicated cases escalate, the rubric is not production-ready. The problem is not the adjudicators — it is the rubric. Pause new case review and invest two weeks in rubric improvement. Analyze the escalated cases. Identify the five most common reasons for escalation. Rewrite the rubric to address those reasons. Retrain adjudicators on the updated rubric. Resume review. Escalation rates should drop by half within a month. If they do not, repeat the process.

The escalation path is not a sign of failure. It is a sign of maturity. Systems that pretend every disagreement can be resolved by one adjudicator are lying to themselves. Systems that acknowledge the need for escalation and build a structured path to handle it create better ground truth and more defensible decisions.

The next subchapter examines the adjudicator role itself: who should do it, how to select them, and how to keep them calibrated over time.

