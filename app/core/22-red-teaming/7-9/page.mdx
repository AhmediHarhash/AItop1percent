# 7.9 — Token Exhaustion and Billing Abuse: Economic Exploitation

Most teams think token limits exist to prevent performance degradation. They are wrong. Token limits exist because context windows cost money, and attackers know it. In December 2025, an e-commerce AI assistant burned through $23,000 in four days because a single user discovered that the system would stuff the entire product catalog into context if asked to "compare all available products with detailed specifications and reviews." The catalog contained 14,000 products. Each query consumed 280,000 tokens of context. The attacker scripted 800 requests. The system had a 1-million-token context window and no per-user token budget. By the time engineering traced the cost spike, the user had consumed 224 million tokens at $0.10 per million tokens input.

Token exhaustion is economic exploitation disguised as legitimate use. The attacker does not break authentication, does not inject malicious code, does not exfiltrate data. They simply force your system to spend tokens until your budget is gone.

## Token Economics as Attack Surface

Every model interaction has a token budget: input tokens plus output tokens. GPT-5.1 with a 128,000-token context window costs roughly $1.00 per million input tokens and $3.00 per million output tokens as of early 2026. Claude Opus 4.5 costs $2.00 per million input tokens and $6.00 per million output tokens. Gemini 2.5 Pro costs $0.50 per million input tokens and $1.50 per million output tokens. These are not abstract numbers. They are your unit economics.

An attacker who can force 100,000 input tokens per query and 10,000 output tokens per query costs you $0.13 per request on GPT-5.1. If they script 1,000 requests per hour, that is $130 per hour or $3,120 per day. A sustained attack for a week costs you $21,840. If your product charges $20 per month per user, the attacker just offset 1,092 paying customers.

The attack surface is anywhere your system allows unbounded token consumption. Systems that load entire documents into context, systems that allow arbitrary retrieval scope, systems that concatenate unlimited conversation history, systems that generate lengthy outputs without caps, systems that allow users to upload arbitrarily large files for processing. Each of these is a token budget vulnerability.

## Context Window Exhaustion

Modern models support context windows from 128,000 tokens up to 1 million tokens or more. Teams treat these as feature capabilities rather than cost liabilities. The attacker treats them as billing maximization opportunities.

A legal document analysis tool allows users to upload contracts for review. The system loads the entire contract into context along with relevant case law and regulatory text. A typical contract is 8,000 tokens. The attacker uploads a 400-page contract with dense legal language: 120,000 tokens. The system also retrieves 50,000 tokens of case law. Total input: 170,000 tokens. The model generates a 15,000-token analysis. Total cost per query: $0.23. The attacker uploads 500 documents in a day. Cost: $115.

A research assistant allows users to query a knowledge base of scientific papers. When the user asks a question, the system retrieves up to 200 relevant papers and loads their abstracts into context. Each abstract is 300 tokens. The attacker asks "What is known about protein folding?" which matches 200 papers. The system loads 60,000 tokens of abstracts plus 5,000 tokens of conversation history. The model generates a 12,000-token synthesis. Total cost: $0.11. The attacker scripts this query 2,000 times per day with slight variations. Cost: $220 per day.

A customer support chatbot maintains full conversation history in context. After 50 turns, the context contains 35,000 tokens. The attacker intentionally extends the conversation to 200 turns by asking trivial follow-up questions. The context grows to 140,000 tokens. Every subsequent response costs 14x more than the first response. The attacker runs 50 such conversations simultaneously.

Defense requires context budget management at every layer. Do not load entire documents into context. Load only the relevant sections. Do not retrieve 200 documents. Retrieve 10, or retrieve 200 but only load summaries into context, not full text. Do not maintain unlimited conversation history. After 20 turns, summarize the conversation into 2,000 tokens and drop the original turns.

Implement per-user context budgets. Free users get 32,000 tokens of context per query. Paid users get 128,000 tokens. Enterprise users negotiate custom limits. When a user exceeds their context budget, truncate intelligently. Drop the least relevant retrieved documents, summarize older conversation turns, remove redundant content. Never hard-fail. Degrade gracefully.

## Output Length Manipulation

Input tokens are expensive. Output tokens are 3x more expensive. Attackers maximize output length to maximize cost. The simplest attack: append "provide a comprehensive, detailed, thorough response with complete explanations for every point" to every query. Many models interpret this as an instruction to generate maximally long outputs.

A code explanation tool typically generates 800-token responses explaining a function. The attacker appends "explain in extreme detail with full background on every concept, including historical context and alternative approaches." The model generates 8,000 tokens. The output cost increases 10x. A financial analysis tool typically generates 1,200-token reports. The attacker asks for "a comprehensive report with full methodology, detailed assumptions, sensitivity analysis, and risk assessment for every scenario." The model generates 18,000 tokens.

The attack works because models are trained to be helpful and comply with user instructions for thoroughness. The defense is not to ignore user preferences but to enforce hard output limits. Set max tokens per response based on user tier. Free users: 2,000 tokens. Paid users: 8,000 tokens. Enterprise: 32,000 tokens. If the model exceeds the limit, truncate and offer continuation only if the user explicitly requests it.

Monitor output length distributions. Your median response is 600 tokens. Your 95th percentile is 2,400 tokens. A user consistently generating 15,000-token responses is either legitimate and should be on a higher tier, or malicious and should be flagged. Investigate when users hit max tokens repeatedly. Are they genuine power users or cost attackers?

## Billing Tier Exploitation

Many AI providers offer tiered pricing: free tier with rate limits, pay-as-you-go with higher limits, enterprise with negotiated rates. Attackers exploit tier boundaries to maximize damage at minimum personal cost.

The free tier attack: create 500 free accounts using temporary email addresses. Each account gets 1,000 free queries per month. Script all 500 accounts to execute maximum-cost queries simultaneously. Total cost to the provider: 500,000 expensive queries. Cost to the attacker: zero dollars and thirty minutes of scripting time.

The pay-as-you-go attack: use a stolen credit card to create a paid account. Execute maximum-cost queries until the card is flagged or declined. Before that happens, consume $5,000 worth of tokens. The attacker pays nothing. The provider absorbs the chargeback.

The trial abuse attack: many providers offer $100 in free credits for new signups. The attacker creates 200 accounts using different email addresses and VPN-rotated IP addresses. Each account gets $100 in credits. The attacker scripts maximum-cost queries until credits are exhausted. Total cost to the provider: $20,000. Cost to the attacker: zero.

Defense requires fraud detection at signup and usage anomaly detection at runtime. New accounts that immediately begin executing maximum-cost queries are suspicious. New accounts from known VPN or datacenter IPs are suspicious. Accounts that hit their spending cap within 6 hours of creation are suspicious. Accounts that exhaust free credits in a single day are suspicious.

Implement progressive trust. New accounts get conservative limits for the first 7 days. Email verification required before access. Phone verification required before paid tier access. Credit card pre-authorization required before high-limit access. Accounts that demonstrate normal usage patterns for 30 days graduate to higher trust tiers with fewer restrictions.

## Credit Card Fraud Through AI

Stolen credit cards are used to create paid accounts, consume expensive AI services, then charge back the transaction. The attacker gets access to a powerful AI system at no cost. The provider loses both the service cost and the chargeback fee.

In October 2025, a video generation service lost $78,000 in a single weekend to stolen credit card fraud. The attackers created 340 accounts using stolen card details, generated 12,000 high-resolution videos at $6.50 per video, then initiated chargebacks on Monday morning. The service provider had no fraud detection, no spending velocity limits, and no delay between account creation and full service access. By the time the chargebacks appeared, the attackers were gone.

Defense requires treating new paid accounts with suspicion until they prove legitimacy. Implement spending velocity limits: a new account should not be able to spend $500 in the first hour. Delay high-cost feature access for new accounts: wait 24 hours after successful payment before enabling video generation, bulk API access, or enterprise-tier models. Monitor for chargeback patterns: if an account receives a chargeback, flag all accounts with similar signup patterns, IP addresses, or usage profiles.

Use fraud detection services. Check credit cards against known fraud databases before accepting payment. Require 3D Secure verification for high-value transactions. Flag transactions from high-risk countries or known VPN exit nodes. None of these are perfect, but they raise the cost of fraud enough to deter casual attackers.

## Testing Billing Security

Red teams test token and billing vulnerabilities by simulating economic attacks. The test suite includes:

**Maximum context consumption**: Submit queries designed to load the maximum possible context. Measure input tokens per query. If a single query can consume 500,000 tokens, you have a context budget problem.

**Maximum output generation**: Submit prompts designed to trigger the longest possible outputs. Measure output tokens per response. If a single response can generate 30,000 tokens, you need output caps.

**Free tier exploitation**: Create 50 free accounts and script maximum-cost queries within free tier limits. Measure total cost to the provider. If 50 accounts can generate $500 in costs, your free tier is too generous.

**Trial credit exhaustion**: Create 20 trial accounts and exhaust credits as fast as possible using maximum-cost queries. Measure time to exhaustion and total cost. If a trial account can burn through $100 in credits in under 6 hours, you need usage velocity limits.

**Stolen card simulation**: Create a new paid account with a test credit card, execute maximum-cost queries, then simulate a chargeback. Measure financial exposure. If the system allows more than $200 in charges within the first 24 hours of account creation, you need progressive trust limits.

## Token Budgets and Enforcement

Every user, every session, every API key should have a token budget. Not just a rate limit on requests but a hard cap on total tokens consumed per day or per month. Free users: 500,000 tokens per month. Paid users: 10 million tokens per month. Enterprise users: negotiated limits.

Enforce budgets at the API gateway layer, not the application layer. When a user reaches 80% of their token budget, send a warning. When they reach 100%, either hard-stop their requests or downgrade them to a cheaper, smaller-context model. Do not allow token budget overruns unless you have explicit billing for overages.

Track token consumption in real-time. Use a streaming aggregation system to maintain running totals per user. Expose token usage dashboards so users can see how much of their budget they have consumed. Alert when token consumption velocity spikes: a user who typically consumes 50,000 tokens per day suddenly consuming 2 million tokens in 6 hours is either experiencing a legitimate spike or under attack.

## Economic Defense Patterns

Economic attacks succeed because teams optimize for functionality and user experience without considering adversarial economics. The fix is not to degrade the product for legitimate users. The fix is to make abuse unprofitable.

Tiered access controls: Free users get limited context, limited output, and limited queries. Paid users get more. Enterprise users get the most. This is not user-hostile. This is sustainable economics. A free user who needs 500,000-token context windows should become a paid user.

Graceful degradation: When a user exceeds their budget, do not fail hard. Reduce context size, shorten outputs, queue requests, or switch to cheaper models. Maintain functionality while protecting costs.

Fraud detection as a first-class system component: Treat fraud detection with the same rigor as authentication. Anomaly detection on signup, on spending, on usage patterns. Machine learning models that flag suspicious accounts. Human review for high-risk transactions.

Progressive trust: New accounts start with conservative limits. As they demonstrate legitimate usage over days and weeks, limits increase. This prevents zero-day account abuse while allowing legitimate users to scale naturally.

Token budgets, output caps, context limits, progressive trust, fraud detection, graceful degradation. These are not optional features. They are the minimum viable defense against economic exploitation. Every token an attacker cannot force you to generate is a dollar that stays in your budget. The battle is not technical. It is economic. And the team that understands this wins.

---

The next escalation of tool abuse is recursive loops — attackers who force agents to spawn agents, tools to trigger tools, and execution to continue until resources are exhausted.
