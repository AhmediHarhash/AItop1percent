# 6.8 — Multi-Tenant Isolation Testing: Session Collision and Cache Poisoning

Why do companies pay enterprise prices for single-tenant deployments when shared infrastructure costs a fraction as much? Because they have seen what happens when multi-tenancy fails. In October 2025, a HR platform serving 340 enterprise customers discovered that cache poisoning allowed one customer's employees to retrieve another customer's performance reviews, salary data, and termination records. The bug had existed for four months. The platform used a shared Redis cache with keys derived from query text but not tenant ID. When Customer A queried "show me performance reviews for January 2025," the cache stored the response under a key that did not include the customer identifier. When Customer B queried the same text, they received Customer A's data. The company issued breach notifications to 140,000 employees across 34 customers. Twelve customers terminated their contracts within 60 days. The financial impact exceeded $40 million. The company now offers only single-tenant deployments.

Multi-tenant isolation is binary. It either works perfectly, or it fails catastrophically. There is no middle ground. A single leaked document, a single cross-customer query response, a single cache entry that bleeds data across tenants is enough to destroy trust and trigger contract breaches. Testing multi-tenant isolation is not a launch checklist item. It is continuous operational discipline. If you cannot prove isolation through systematic testing, you do not have isolation. You have risk waiting to materialize.

## The Multi-Tenant Isolation Challenge

Shared infrastructure is designed for efficiency, not isolation. When 500 customers use the same model instance, the same vector database, the same application servers, the economics are compelling. Infrastructure cost per customer drops by 80 to 95 percent compared to single-tenant deployments. But efficiency requires sharing — shared memory, shared caches, shared indexes, shared queues. Every shared resource is a potential isolation boundary failure. The challenge is maintaining isolation despite sharing. This is hard. It is also mandatory.

Isolation must hold at every layer. Application code, caching layers, vector databases, model serving infrastructure, logging, monitoring — each layer must enforce tenant boundaries. A failure at any single layer breaks isolation for the entire system. Example: The application correctly namespaces all queries by tenant, the vector database correctly filters results by tenant, but the monitoring system logs all queries to a shared index without tenant filtering. A bug in the log analysis tool exposes one customer's queries to another. Isolation is a system property, not a component property. Testing must cover the whole stack.

Tenant ID validation is the first line of defense. Every request must include a verified tenant identifier. The identifier must be cryptographically validated — derived from an authenticated session token, not from user-supplied input. The identifier must be propagated to every downstream service, every cache key, every database query, every log entry. If tenant ID propagation fails at any layer, that layer becomes an isolation vulnerability. Testing must verify that tenant IDs are present, validated, and used in every context where isolation matters.

## Session Collision Attack Vectors

Predictable session IDs enable cross-tenant access. If session IDs are generated using sequential counters, low-entropy timestamps, or tenant-specific patterns, an attacker can guess valid session IDs for other tenants. Example: A session ID generated as "tenant-789-sequence-12345" reveals the tenant ID and the sequence number. An attacker registered as Tenant 790 can guess that Tenant 789's next session ID will be "tenant-789-sequence-12346" and attempt to use it. If the system does not validate that the session belongs to the authenticated tenant, the attacker gains access. Testing requires attempting to use guessed session IDs from a different tenant's context and verifying that all attempts are rejected.

Session ID reuse across tenants is a catastrophic design flaw. Some systems generate a single session ID when a user authenticates and reuse it across all services. If the session ID does not include tenant context, and a user belongs to multiple tenants, their session ID might be valid in contexts where they should not have access. Example: A consultant who works with Customer A and Customer B uses the same session ID in both tenants' portals. A bug in tenant validation allows the consultant to access Customer A's data while authenticated to Customer B's tenant. Testing requires multi-tenant users who attempt cross-tenant actions using the same session credentials.

Session hijacking through cache timing attacks exploits predictable cache behavior. An attacker measures response times to infer whether their query hit a cached result. If the cache is shared across tenants and keyed without tenant ID, the attacker can prime the cache with their own data and observe when other tenants hit that cache entry. This does not directly leak data, but it leaks information about other tenants' behavior — query patterns, document access, usage timing. Testing for this requires controlled cache poisoning experiments: Tenant A populates the cache with a known query, Tenant B issues the same query, and response times are measured to detect cache hits.

## Cache Poisoning Across Tenants

Shared cache keys without tenant namespacing are the root cause of most multi-tenant cache poisoning. A cache key derived only from query text — "cache-key-what-is-the-revenue-for-q3-2025" — does not distinguish between tenants. When Customer A asks "what is the revenue for Q3 2025," the response is cached. When Customer B asks the same question, they receive Customer A's revenue figure. The fix is trivial: include tenant ID in every cache key — "cache-key-tenant-789-what-is-the-revenue-for-q3-2025". The failure mode is common because developers assume query text uniquely identifies intent. It does not.

Prompt prefix caching without tenant isolation creates cross-tenant leakage in model serving. Some systems cache the model's internal state after processing a shared prompt prefix to reduce latency. Example: The system prompt is identical for all tenants, so the model's state after processing it is cached and reused. But if tenant-specific instructions are appended to the shared prefix, and the cache does not account for this, one tenant's state influences another's. Testing requires issuing tenant-specific queries that should produce different results and verifying that cached state does not cause convergence toward a shared result.

Time-of-check-to-time-of-use bugs enable cache poisoning. The system validates tenant ID when the request is received, caches the result, but does not revalidate tenant ID when serving from cache. An attacker can exploit this by making a legitimate request that passes validation, then modifying the cache key externally to poison the cache for other tenants. This requires infrastructure access — Redis write access, cache invalidation API access — but is viable in environments where customers have partial infrastructure control, such as self-hosted deployments or platforms with customer-accessible APIs.

## Embedding Index Isolation Testing

Shared vector indexes with query-time filtering are vulnerable to filter bypass. Most vector databases support metadata filtering: retrieve only documents where tenant ID equals X. But the filtering happens after the vector search. The search retrieves the top-k most similar vectors across all tenants, then filters by tenant. If the filtering logic has a bug, or if the attacker can manipulate the metadata, cross-tenant documents leak. Testing requires injecting canary documents for Tenant A, querying as Tenant B, and verifying that Tenant A's canaries never appear in results, even if they are semantically similar to Tenant B's query.

Embedding collisions reveal cross-tenant document existence. Even if query-time filtering works perfectly, the attacker can infer that another tenant has a document on a specific topic by observing embedding space proximity. Example: Tenant A uploads a highly unusual document — a technical specification for a proprietary algorithm. Tenant B, who knows Tenant A is a customer, issues a query for that algorithm. The vector search retrieves results from Tenant B's documents, but the proximity scores or the distribution of results suggests that a closer match exists outside the filtered set. The attacker infers that Tenant A has a document on that topic. This is metadata leakage, not content leakage, but it still violates confidentiality.

Separate indexes per tenant eliminate vector-level leakage. Instead of a single shared index with tenant filtering, each tenant gets a dedicated index. Queries against Tenant A's index can never retrieve Tenant B's documents, regardless of filtering bugs or metadata manipulation. The cost is higher infrastructure overhead — each index requires memory, storage, and indexing time — but the isolation guarantee is architectural. For high-security environments, this is the only acceptable approach. Testing confirms that queries to one tenant's index never return data from another tenant's index, even under infrastructure failures or misconfigurations.

## Prompt Template Isolation

Shared prompt templates with tenant-specific variables can leak cross-tenant data if variable substitution fails. Example: A prompt template says "You are an assistant for tenant name placeholder. Answer questions about their documents." The system substitutes the tenant name dynamically. If substitution fails and the placeholder remains, or if it substitutes the wrong tenant's name, the model's behavior changes in ways that leak information. Testing requires deliberately breaking variable substitution — null tenant IDs, mismatched session tokens, SQL injection in tenant name fields — and verifying that the model never references the wrong tenant.

Dynamic prompt construction from tenant-specific data must namespace all retrievals. If the system builds a prompt by retrieving the tenant's branding guidelines, tone preferences, or custom instructions, the retrieval query must include tenant ID. If it does not, the system might pull another tenant's customizations. Testing requires tenants with highly distinct prompt customizations — Tenant A uses formal tone, Tenant B uses casual tone — and verifying that responses always match the correct tenant's style, even under load or cache invalidation.

## Testing Methodology for Isolation

Cross-tenant canary injection is the gold standard. For each tenant in the test set, inject a unique, high-entropy canary string into multiple documents, prompts, and queries. Example: Tenant A's canaries are "canary-a-1f8e3c72," "canary-a-9d4b6a18," "canary-a-5c2f7e44." Tenant B's canaries are completely distinct. Issue queries, retrieve documents, and scan all responses for canaries that do not belong to the requesting tenant. Any cross-tenant canary match is proof of isolation failure. This technique works across all layers — caches, vector indexes, model outputs, logs.

Adversarial cross-tenant queries test filter robustness. Tenant B crafts queries designed to match Tenant A's known documents. Example: Tenant A uploaded a document titled "Project Phoenix Technical Specification." Tenant B queries "what is Project Phoenix" or "show me technical specifications for Phoenix." If the system returns any information from Tenant A's document, isolation failed. Repeat across 500 to 1,000 adversarial queries covering different document types, topics, and query structures. Zero leakage is the only acceptable outcome.

Load-based isolation testing identifies concurrency bugs. Spin up 100 simultaneous tenants, each issuing queries concurrently. Measure whether isolation holds under high load. Many isolation bugs only manifest when infrastructure is under memory pressure, cache thrashing, or race conditions. Example: Tenant ID validation works correctly at 10 requests per second but fails at 500 requests per second due to a race condition in session token parsing. Load testing must exceed production peak load by at least 2x to surface these issues.

Infrastructure failure testing verifies isolation during degraded states. Deliberately fail components — kill cache nodes, simulate database connection loss, induce memory pressure on model servers — and verify that isolation holds. Some systems maintain isolation during normal operation but fail open during outages, reverting to a shared default state or skipping tenant filters to preserve availability. This is unacceptable. Isolation must hold even during failures. If the choice is between availability without isolation or unavailability with isolation, unavailability is the correct choice for regulated industries.

## Automation and Continuous Testing

Isolation testing must be automated and run continuously. Build a test harness that creates multiple test tenants, injects canaries, issues cross-tenant queries, and verifies that no canaries leak. Run this harness on every deployment, every configuration change, and on a weekly schedule even without code changes. Infrastructure drift, dependency updates, and cache configuration changes can break isolation without touching application code. Continuous testing catches drift before it reaches production.

Regression tests for every historical isolation failure prevent recurrence. When an isolation bug is found, add a test case that reproduces it to the automated suite. This ensures the specific failure mode never happens again. Over time, the test suite becomes a catalog of every isolation vulnerability the system has ever had. This is valuable organizational knowledge. New engineers learn the threat model by reading the test suite. Security reviews reference it to identify coverage gaps.

Production monitoring for isolation violations complements testing. Log tenant IDs for every request and every downstream service call. Monitor for anomalies: queries that reference multiple tenant IDs, cache keys that omit tenant ID, database queries without tenant filters. Alert when anomalies are detected. Testing catches bugs before deployment. Monitoring catches bugs that testing missed and detects attacks in progress. Both are necessary.

Multi-tenant isolation is not a feature. It is a contract. Customers trust you to keep their data separate from competitors, separate from other customers, separate from everyone who is not explicitly authorized. Break that contract once and the relationship is over. Testing is not about finding bugs. Testing is about proving the contract holds. If you cannot prove it, do not offer multi-tenancy.

The next step is tenant penetration testing — actively attempting to break into other tenants' data through application-layer attacks and infrastructure exploitation.

