# 6.6 — RAG Content Extraction: Attacking the Knowledge Base

Most teams assume RAG systems are safe because users never access documents directly. They query the model, the model retrieves context, and the model synthesizes a response. The source documents stay hidden in the vector database, never exposed. This assumption is dangerously wrong. In January 2026, a legal services company discovered that their RAG-powered contract assistant had leaked entire proprietary agreements to competitors. The attack did not exploit a database vulnerability or an API bug. It exploited the model itself. By asking targeted questions over multiple sessions, attackers reconstructed 83 complete contracts from fragments returned in model responses. The company had designed careful access controls for direct document access. They had not considered that RAG itself is an extraction interface.

RAG systems expose knowledge bases through the model's synthesis process. Every retrieved chunk, every citation, every reference is a piece of the underlying document. Ask enough questions, collect enough fragments, and you reconstruct the source. The model is not leaking data — it is functioning exactly as designed. The vulnerability is architectural. If your RAG knowledge base contains confidential documents, competitive intelligence, or regulated data, you are running an extraction API disguised as a chat interface. Testing whether documents can be reconstructed is not optional. It is baseline operational security.

## How RAG Enables Extraction

Retrieval responses contain document fragments verbatim. When a user asks a question, the RAG system retrieves the top-k most relevant chunks and passes them to the model. The model synthesizes an answer using those chunks. In many implementations, the answer includes direct quotes, paraphrases, or summaries of the retrieved text. Each response is a window into the knowledge base. A user cannot see the full document, but they can see parts of it. Enough parts, assembled across enough queries, reveal the whole.

Targeted queries extract specific sections. An attacker who knows the structure of a document type — legal contracts, financial reports, technical specifications — can craft queries that target each section sequentially. Example: A contract typically has preamble, definitions, obligations, warranties, termination, and dispute resolution sections. The attacker asks six questions, one per section. "What are the defined terms in the agreement between Company A and Company B?" "What are the obligations of Company A?" "What are the termination conditions?" Each response returns fragments from the corresponding section. Combine the fragments and you have the contract.

Citation metadata leaks document structure. Many RAG implementations include citations in responses: "According to section 3.2 of Document ID 4729..." or "As stated in the Q3 2025 financial report, page 18..." These citations reveal document identifiers, section numbers, page counts, and titles. Even if the model paraphrases instead of quoting directly, the citation tells the attacker which document was used and where to focus future queries. Metadata is not neutral — it is a map. Attackers use it to navigate the knowledge base systematically.

Iterative refinement reconstructs full documents. The attacker starts with broad queries to identify relevant documents, then narrows to specific sections, then drills into details. Example: Query 1: "What financial reports are available for Q3 2025?" Response reveals document IDs and summaries. Query 2: "What was the revenue figure in the Q3 2025 report?" Response reveals revenue details. Query 3: "What were the operating expenses in the Q3 2025 report?" Response reveals expense details. Over 20 to 40 queries, the attacker reconstructs the entire report. No single query exposes the full document, but the aggregate does.

## Access Control Bypass Through RAG

RAG systems often bypass document-level access controls. A user who is forbidden from downloading a contract can still query it through the RAG interface. The access control logic says "this user cannot read the file," but the RAG system says "this user can ask questions, and I will retrieve from all available documents to answer them." The two systems do not communicate. The result is privilege escalation. A user with question-asking access gains effective read access through extraction.

Row-level security in vector databases is rarely enforced. Most vector databases do not support fine-grained access control at the chunk level. When a user queries the RAG system, retrieval happens across the entire knowledge base, not just the subset the user is authorized to access. Some teams implement filtering in application code — retrieve all chunks, then filter by user permissions before passing to the model — but this is fragile. If the filtering logic has a bug, the model sees unauthorized chunks. If the filtering logic is bypassed through a different query path, unauthorized data leaks. Access control that depends on application code outside the database is always at risk.

Multi-tenant RAG systems are particularly vulnerable. When multiple customers share a knowledge base, isolation depends on query-time filtering. Customer A's query should only retrieve Customer A's documents. But if the filtering logic fails, Customer A can extract Customer B's data by asking questions that happen to match Customer B's content. Testing for this requires cross-tenant queries: log in as Customer A, ask questions that should only match Customer B's documents, and verify that no Customer B content appears in responses. If it does, isolation is broken.

Shared embeddings create cross-customer leakage. Some multi-tenant systems embed all customers' documents into a single vector space to reduce infrastructure cost. At query time, they filter by tenant ID. But embeddings themselves can leak information. If Customer A's query returns semantically similar results from Customer B's documents before filtering, the model might reference those results in synthesis. Even if the final response is filtered, the model has already been influenced by unauthorized data. True isolation requires separate vector indexes per tenant, not just query-time filtering.

## Extraction Testing Methodology

Document reconstruction testing measures how much of a document can be recovered through queries. Select ten representative documents from the knowledge base — contracts, reports, internal memos, technical specs. Assign each to a red teamer who has query access but not direct download access. Give them 50 queries per document and one hour of effort. Measure how much of each document they successfully reconstruct. If they recover more than 30 percent of any document, extraction is viable. If they recover more than 60 percent, extraction is trivial. Production-ready RAG systems should make reconstruction expensive enough that attackers give up before reaching useful thresholds.

Targeted section extraction tests whether specific high-value information can be extracted efficiently. Instead of reconstructing entire documents, attackers target the most sensitive sections: pricing terms in contracts, revenue figures in financial reports, vulnerability details in security assessments. Measure how many queries it takes to extract these sections. If a red teamer can extract the pricing page of a contract in under five queries, confidential pricing is effectively public to anyone with query access.

Cross-tenant leakage testing verifies isolation in multi-tenant systems. Create two test tenants with distinct document sets. Log in as Tenant A and craft queries designed to match Tenant B's content. Example: If Tenant B has uploaded a document about "Project Nightingale," Tenant A queries "What is Project Nightingale?" If the response contains information from Tenant B's documents, isolation has failed. Repeat across 100 cross-tenant queries covering different document types, topics, and query patterns. Zero leakage is the only acceptable result.

Citation and metadata extraction evaluates how much structural information leaks. Query the RAG system with generic questions and collect all citations, document IDs, section references, and page numbers from responses. Analyze whether this metadata reveals confidential information: document titles that expose unannounced projects, section numbers that reveal document length and structure, timestamps that reveal when documents were created. Even if content is not leaked, metadata can be sensitive.

## Defense Strategies

Chunk-level access control enforces permissions at retrieval time. Instead of filtering after retrieval, tag each chunk with authorization metadata and enforce permissions during the vector search itself. Only chunks the user is authorized to access are retrieved. The model never sees unauthorized data, so it cannot synthesize responses based on it. This requires vector databases that support metadata filtering at query time — Pinecone, Weaviate, and Qdrant all support this as of 2026. It also requires rigorous tagging during ingestion. If even one chunk is mis-tagged, it leaks.

Rate limiting per user per document prevents bulk extraction. Even if a user is authorized to query a document, limit how many questions they can ask about it within a time window. Example: 20 queries per document per day. This does not prevent extraction, but it slows it down. An attacker who needs 50 queries to reconstruct a document now needs three days instead of one hour. The delay increases the chance of detection and makes bulk extraction of hundreds of documents infeasible.

Response filtering detects and redacts sensitive patterns in model outputs. Before returning a response to the user, scan it for PII, financial figures, legal terms, or proprietary terminology. If detected, redact the sensitive information or reject the response entirely. This is a defense-in-depth layer — it assumes that chunks were retrieved correctly and access control worked, but catches cases where the model synthesizes sensitive information in unexpected ways. Filtering is not perfect, but it stops low-effort extraction.

Audit logging and anomaly detection catch extraction in progress. Log every query, every retrieved chunk, and every citation. Monitor for patterns consistent with extraction: the same user querying the same document repeatedly, sequential queries targeting different sections of a document, bulk queries across many documents in a short time. Alert when thresholds are crossed. Extraction is rarely a single query — it is a campaign. Monitoring detects campaigns before they complete.

## When RAG is the Wrong Architecture

If document confidentiality is a hard requirement, RAG may not be viable. Retrieval-augmented generation inherently exposes portions of the knowledge base through responses. If even partial exposure is unacceptable — classified government documents, trade secrets under NDA, patient records under HIPAA — RAG creates unacceptable risk. Alternatives include fine-tuning on sanitized summaries instead of full documents, using the model to route users to access-controlled document downloads instead of answering directly, or abandoning LLM-based synthesis entirely in favor of traditional search with strict access controls.

If multi-tenancy requires perfect isolation, shared vector databases are too risky. Even with query-time filtering, bugs happen. A misconfigured filter, a race condition during ingestion, or a privilege escalation vulnerability in the application layer can leak one customer's data to another. The only architecture that guarantees isolation is separate vector indexes per tenant, deployed in separate infrastructure. This increases cost and operational complexity, but it eliminates an entire class of leakage risk. For regulated industries or high-value enterprise contracts, the cost is justified.

If the knowledge base changes frequently, access control gets out of sync. Documents are added, updated, and deleted daily. Permissions change as employees join, leave, or switch roles. Keeping chunk-level authorization metadata in sync with source-of-truth access controls is a hard engineering problem. If the lag between a permission change and the RAG system reflecting it exceeds one hour, there is a window where authorized users lose access or unauthorized users gain it. Some teams solve this by rebuilding the entire vector index nightly. This works for small knowledge bases but does not scale to millions of documents.

## Operational Implications

Treat RAG as a read interface, not a synthesis-only interface. If a user can query a document through RAG, they can extract it. Design access controls accordingly. Do not assume that synthesis obscures the source material. It does not. A user who can ask unlimited questions can reconstruct the source, whether or not they can download it directly. The permission model for RAG access should match the permission model for document access. If a user should not read a document, they should not be able to query it either.

Document what is in the knowledge base and who can access it. This sounds obvious but is often skipped. Teams dump entire file systems into vector databases without cataloging what they contain. Six months later, someone asks "can customer support agents query internal financial reports through the RAG system?" and no one knows. Inventory the knowledge base. Tag documents by sensitivity level. Map user roles to authorized document sets. Audit the mapping quarterly. RAG is not a black box — it is infrastructure, and infrastructure requires operational discipline.

Test extraction continuously, not just at launch. Attackers refine techniques over time. A RAG system that resisted extraction in January 2026 may be trivially exploitable by June 2026 as new prompting techniques emerge. Automate extraction testing. Run it monthly. Track how many queries it takes to reconstruct high-value documents. If the number drops, defenses are degrading. If the number rises, defenses are improving. Continuous testing is the only way to know.

RAG systems are powerful, flexible, and useful. They are also extraction interfaces. Design them as such. The teams that succeed are the ones who treat RAG as a security surface from day one and build defenses accordingly. The teams that fail are the ones who assume the model's synthesis process hides the source data. It does not.

The next layer is cross-user data leakage — when one user's context bleeds into another's.

