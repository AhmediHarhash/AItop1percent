# 7.7 â€” Resource Exhaustion Through Tool Abuse

The AI agent offered a simple feature: analyze this document and summarize key points. The document upload limit was 50MB. A user uploaded a 48MB PDF. The AI accepted it, called an OCR tool to extract text, then called a vector embedding tool to chunk and process it. The OCR took four minutes and consumed 16GB of memory. The embedding took another six minutes and generated 240,000 vectors. Then the AI crashed. The user uploaded another document. Same process. Another crash. After five uploads, the system was unresponsive. The attacker spent nothing. The company burned through compute quotas and storage limits. The cost: fourteen thousand dollars in three hours.

This is resource exhaustion through tool abuse. The attacker does not break into the system. They do not steal data. They do not need elevated privileges. They just trigger expensive operations, repeatedly, until something runs out. Compute. Memory. Storage. API quotas. Rate limits. Database connections. The tool does what it was designed to do. The attacker abuses the design by calling it at scale or with pathological inputs.

## Resource Consumption Vectors

Every tool consumes resources. A database query consumes CPU, memory, and I/O. A file upload consumes storage and bandwidth. An API call consumes quota. An image generation request consumes GPU time. A report generation tool consumes compute and network.

In traditional applications, resource consumption is controlled through input validation and rate limiting. Upload size limits prevent storage exhaustion. Query timeouts prevent runaway database operations. API rate limits prevent quota exhaustion. These controls are hardcoded into the application logic.

In AI systems, the AI is the application logic. The AI decides which tools to call, with what parameters, in what sequence. If the AI can be manipulated into making expensive tool calls, resource controls must be built into the tools themselves or enforced at the policy layer. If they are not, the attacker manipulates the AI into triggering exhaustion.

The simplest resource exhaustion attack is the large input. The attacker provides input at or near the maximum allowed size. The tool processes it. Processing large inputs is expensive. If the attacker repeats this many times, they consume resources faster than they are replenished.

The second vector is the complex operation. Some operations are cheap for small inputs and expensive for large inputs. A search query across ten records is instant. A search query across ten million records takes seconds or minutes. An attacker triggers the expensive variant.

The third vector is the expensive sequence. Individual tool calls may be cheap, but chaining them together amplifies cost. The attacker triggers sequences that maximize resource consumption per request.

The fourth vector is the parallel attack. The attacker makes many requests simultaneously. Each request is within limits. The aggregate exceeds capacity. The system slows, queues grow, timeouts occur, and service degrades.

## Compute Exhaustion Attacks

Compute exhaustion happens when the attacker triggers CPU or GPU-intensive operations. The tool performs computation. Computation takes time and resources. The attacker makes the tool compute things that are expensive relative to the value delivered.

A code analysis AI in late 2025 allowed users to upload code files for security scanning. The scanner used static analysis tools that were CPU-intensive. A small file took seconds. A large file took minutes. An attacker uploaded the maximum allowed file size, 10MB, filled with deeply nested code structures designed to maximize analysis time. Each file took twelve minutes to scan. The attacker uploaded twenty files in parallel. The scanner consumed all available CPU for four hours. Legitimate users could not get scans. The attacker paid nothing. The company paid for the compute.

Another compute exhaustion vector is the algorithmic complexity attack. The attacker provides input that triggers worst-case performance in the tool's algorithm. A search tool with quadratic complexity on certain inputs. A parser with exponential backtracking on adversarial patterns. A rendering tool that recursively processes deeply nested structures.

A document processing AI in early 2026 parsed XML files. The parser had a vulnerability to XML entity expansion attacks. An attacker uploaded an XML file with a small number of entities defined recursively. When expanded, the file ballooned from 1KB to 3GB in memory. The parser consumed all available memory and crashed. The attacker repeated the upload. Each attempt consumed memory, triggered an out-of-memory error, and restarted the service. The service spent more time crashing and restarting than processing legitimate requests.

## Storage Filling Attacks

Storage exhaustion happens when the attacker fills disk, database, or object storage. The tool writes data. The attacker makes the tool write large amounts of data or makes many requests that each write small amounts.

The simplest storage attack is the large upload. The attacker uploads files at or near the size limit. Each upload consumes storage. The attacker repeats until storage is full. If the system does not enforce per-user storage quotas, the attacker can fill shared storage.

A collaboration AI in late 2025 allowed users to upload documents for team sharing. The upload limit was 100MB per file. The storage limit was 1TB per team. The attacker created a free team account, uploaded ten 100MB files per hour, and filled the team's quota in four days. The service had no global rate limit on uploads. The attacker created additional free accounts and repeated. After two weeks, the platform's free tier storage was 80 percent full. The company had to provision additional storage, upgrade their infrastructure, and implement stricter quotas.

Another storage vector is the persistent write. The tool writes data that is not cleaned up. Logs, temporary files, cached results, generated reports. Each write is small. Over time, they accumulate. If the system does not garbage-collect, the attacker can slowly fill storage by triggering writes.

An analytics AI in early 2026 generated PDF reports on demand. Each report was saved to cloud storage for future retrieval. The reports were never deleted. An attacker requested hundreds of reports, each 5MB. The reports accumulated. After three months, the storage contained 40,000 reports, consuming 200GB. The storage cost exceeded the revenue from the user's subscription.

## API Quota Exhaustion

Many AI tools call external APIs. Cloud services, data providers, payment processors, third-party SaaS tools. These APIs have rate limits and quota limits. Exceeding the limit results in throttling, errors, or additional charges. An attacker can exhaust quotas by triggering API calls through the AI's tools.

A translation AI in late 2025 used a third-party translation API. The API charged per character translated. The AI allowed users to translate documents. An attacker uploaded large documents filled with text. Each translation consumed thousands of API credits. The attacker uploaded documents continuously. The API bill for the month was sixty thousand dollars, twelve times the normal amount. The company had not implemented per-user API quota limits. The attacker consumed the quota for all users.

Another quota exhaustion vector is the expensive API call. Not all API calls cost the same. A simple lookup is cheap. A complex computation, a bulk export, or a premium feature is expensive. If the AI can be tricked into calling the expensive variant, the attacker amplifies cost.

A mapping AI in early 2026 used a geocoding API. The API had a free tier for simple address lookups and a paid tier for batch geocoding and route optimization. The AI had access to both. An attacker asked the AI to optimize delivery routes for large datasets. The AI called the paid route optimization API. Each call cost five dollars. The attacker made fifty requests. The bill was two hundred fifty dollars. The attacker's account was free tier. The company absorbed the cost.

## Rate Limit Manipulation

Rate limits protect APIs and services from overload. They cap the number of requests per second, per minute, or per hour. In AI systems, the rate limit is often applied to the user, but the tool calls are made by the AI's service account. If the AI's service account has higher limits than individual users, an attacker can manipulate the AI into making tool calls that exceed the user's limits but not the AI's limits.

The attack is to trigger many tool calls in quick succession. Each call is legitimate. The rate is not. The AI makes the calls because each individual request seems reasonable. The aggregate violates rate limits, but the AI's service account absorbs the violation, not the user.

A customer data platform in late 2025 had an AI assistant that could query customer records. The database had a rate limit of 100 queries per minute per service account. The AI's service account had a limit of 1,000 queries per minute because it served many users. An attacker crafted prompts that caused the AI to make multiple queries per request. "Show me details for accounts A, B, C, D, E" triggered five queries. The attacker made ten such requests in one minute. Fifty queries. Well under the AI's limit. But the attacker was one user. Fifty queries in one minute from one user was abusive. No rate limit caught it because the limit was on the AI's service account, not the user.

Another rate limit attack is the distributed trigger. The attacker uses multiple accounts or sessions to trigger tool calls. Each session stays under the per-session limit. The aggregate exceeds capacity. This is a distributed denial of service attack, but instead of targeting the frontend, it targets the backend tools.

## Cascading Resource Failures

Resource exhaustion in one component can cascade to others. The attacker exhausts storage. The system starts failing writes. Failed writes generate errors. Errors are logged. Logs fill disk. Disk full crashes the logging service. No logs means no observability. Engineers cannot diagnose the problem. The system degrades further.

A data pipeline AI in early 2026 processed uploaded files. The files were stored in object storage, queued for processing, then processed by workers. An attacker uploaded thousands of files. The object storage filled. The queue backed up. Workers could not retrieve files from storage because the storage service was slow. Workers timed out. Timeout errors filled the error queue. The error queue consumed memory. Memory exhaustion crashed the workers. With no workers, the queue grew indefinitely. The entire pipeline collapsed. The root cause was the attacker filling object storage. The failure spread to every component.

Cascading failures are why resource exhaustion attacks are dangerous beyond their direct cost. The attacker spends a small amount to trigger the initial exhaustion. The system's own resource dependencies amplify the damage. The result is total service degradation.

## Testing for Exhaustion Vulnerabilities

Testing for resource exhaustion means attempting to consume resources at scale and observing whether the system limits or allows it. You need to map which tools consume which resources, then trigger those tools repeatedly or with pathological inputs.

Start by identifying expensive tools. Which tools perform computation? Which tools write data? Which tools call external APIs? Which tools have high memory usage? These are your targets.

Next, determine the limits. What is the maximum input size? What is the rate limit per user? What is the API quota? What is the storage quota? These are the boundaries. Your goal is to test whether they are enforced.

Then trigger expensive operations. Upload the largest allowed file. Make the most complex query. Request the most expensive API operation. Observe the resource consumption. Time. Memory. CPU. Storage. API credits. If one request consumes significant resources, calculate how many requests it would take to exhaust capacity.

Repeat the operation. Make the same expensive request multiple times. Observe whether rate limiting stops you. If not, observe how many repetitions it takes before the system slows or fails.

Test parallel requests. Make many expensive requests simultaneously. Observe whether the system queues them, throttles them, or processes them all and exhausts resources.

Test cascading effects. Fill storage and observe whether other components fail. Exhaust API quotas and observe whether the system handles the quota errors gracefully or crashes.

A media processing platform in late 2025 tested their AI agent for resource exhaustion vulnerabilities. They uploaded maximum-sized video files and measured processing time. Each file took eleven minutes and consumed 8GB of memory. They calculated that ten parallel uploads would exhaust available memory. They tested it. The system crashed. They implemented per-user concurrency limits and memory-based queuing. They re-tested. The system queued requests and processed them sequentially. No crash. They tested large uploads with malformed video codecs designed to trigger expensive decoding. The decoder consumed 40GB of memory and ran for thirty minutes before hitting a timeout. They implemented stricter input validation and codec allowlists. The malformed uploads were rejected before decoding.

## Defense and Rate Limiting

The defense against resource exhaustion is multi-layered. Input validation, rate limiting, quotas, timeouts, and monitoring.

Input validation limits the size and complexity of inputs. File size limits. Query complexity limits. Maximum nesting depth. These prevent pathological inputs from triggering expensive operations.

Rate limiting caps the number of requests or tool calls per user per time period. The limit should be per user, not per AI service account. If the AI makes tool calls on behalf of a user, those calls count against the user's quota.

Quotas cap total resource consumption per user. Storage quotas. API call quotas. Compute quotas. Once the user reaches their quota, further requests are denied or queued until the quota resets.

Timeouts prevent runaway operations. Every tool call has a maximum execution time. If the operation exceeds the timeout, it is killed. This prevents a single expensive operation from consuming resources indefinitely.

Monitoring tracks resource usage in real-time. Disk usage, memory usage, API quota consumption, queue depth. When usage exceeds thresholds, alerts fire. Engineers investigate before exhaustion occurs.

A SaaS platform in early 2026 implemented comprehensive resource controls for their AI agent. They set per-user rate limits: ten tool calls per minute, one hundred per hour. They set storage quotas: 1GB per free user, 10GB per paid user. They set API quotas: five hundred external API calls per day per user. They implemented timeouts: ten seconds for database queries, sixty seconds for report generation, five minutes for file processing. They monitored resource usage per user and globally. When a user exceeded 80 percent of any quota, the AI warned them. When they exceeded 100 percent, further requests were queued or denied. After deployment, resource exhaustion attacks stopped. Attackers tried. The rate limits blocked them. The quotas capped their consumption. The system remained stable.

Resource exhaustion is not a sophisticated attack. It does not require deep technical knowledge or zero-day vulnerabilities. It requires only the ability to trigger expensive operations and the persistence to repeat. But it is effective. It disrupts service. It inflates costs. It degrades performance for all users. The defense is to treat every tool call as a potential resource liability and enforce limits at every layer. Validate inputs. Limit rates. Cap quotas. Timeout operations. Monitor consumption. Make exhaustion expensive for the attacker and cheap to detect and block.

---

Next, we examine the economic dimension of tool abuse: cost amplification attacks, where attackers trigger operations specifically designed to maximize financial cost to the defender.