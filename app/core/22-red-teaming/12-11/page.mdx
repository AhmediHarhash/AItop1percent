# 12.11 — The Red Team Maturity Model

Why do organizations need a maturity model for red teaming? Because capability does not appear overnight. Security testing evolves through predictable stages—from ad-hoc attempts at breaking things to sophisticated, intelligence-driven, continuous adversarial operations integrated into every aspect of development and deployment. Understanding which stage you are at helps you plan investments, set realistic goals, and measure progress. Skipping stages rarely works. Trying to operate at Level 4 maturity with Level 2 infrastructure and processes creates frustration, wasted effort, and false confidence.

The Red Team Maturity Model has five levels. Each level builds on the previous one. Each level requires different skills, different tools, different organizational support. Moving from one level to the next typically takes six months to two years depending on organizational size, existing security capability, and investment. Most organizations in 2026 operate somewhere between Level 2 and Level 3. Very few have reached Level 5. The goal is not necessarily to reach the highest level—it is to reach the level that matches your system's risk profile and operational needs.

## Why a Maturity Model

Maturity models provide a common language for discussing capability. When engineering says "we do red teaming" and security says "we need better red teaming," they might be talking past each other. Engineering might mean Level 1—we occasionally try to break things. Security might mean Level 4—we have continuous, automated adversarial testing integrated into CI/CD. A maturity model makes the gap visible and concrete.

Assessment becomes objective. Instead of debating whether red teaming is "good enough," you evaluate against defined criteria. Do you have documented red team methodologies? Do you run tests on a regular schedule? Do you have automated testing infrastructure? Do you integrate findings into sprint planning? The maturity model provides checkboxes. You either meet the criteria or you do not.

Progression becomes plannable. If you are at Level 2 and need to reach Level 3, the maturity model shows what gaps to close. You need automation infrastructure. You need to integrate testing into development workflows. You need to build repeatable test suites. Knowing the gaps helps you plan hiring, tooling investments, and process changes. The model turns "improve red teaming" from a vague aspiration into a specific roadmap.

## Level 1 — Ad-Hoc Testing

Level 1 is where every organization starts. Security testing happens sporadically, driven by individual initiative rather than organizational process. Someone on the team tries to break the system before launch. Maybe a security-minded engineer spends a Friday afternoon testing prompt injections. Maybe the team hires a consultant for a one-time security review. Testing happens, but it is not systematic, not documented, not repeatable.

Characteristics of Level 1: No dedicated red team. No formal testing schedule. No standardized methodology. Findings are reported informally—Slack messages, email, verbal conversations. No tracking system for vulnerabilities. Remediation happens if someone has time and remembers. No metrics on coverage or effectiveness. Security testing is an afterthought, not a planned activity.

Level 1 is better than nothing. Occasionally someone finds a critical vulnerability. But coverage is unpredictable. You might thoroughly test prompt injection while never testing data extraction. You might test the chatbot while ignoring the API. Repeat testing rarely happens—if you test the same system six months later, you probably will not remember what you tested before or what you found. Organizational knowledge does not accumulate.

Moving beyond Level 1 requires commitment to regular testing and basic documentation. You do not need sophisticated tools or large teams. You need to schedule testing—monthly, quarterly, before major releases—and write down what you find. That transition from ad-hoc to periodic is the shift to Level 2.

## Level 2 — Periodic Formal Testing

Level 2 introduces structure. Red teaming happens on a defined schedule with documented methodologies. The organization treats security testing as a planned activity rather than an optional extra. Testing might still be infrequent—once per quarter, once per major release—but it is predictable and follows consistent processes.

Characteristics of Level 2: Defined testing schedule. Documented test methodologies covering major attack classes—prompt injection, jailbreaks, data extraction, safety bypass. Findings tracked in a proper system—JIRA, GitHub Issues, a dedicated security tool. Formal triage process for vulnerabilities. Assigned owners for remediation. Basic metrics on findings per test cycle and remediation timelines.

Coverage improves significantly at Level 2 because testing is systematic. You test the same attack classes each cycle, which means you catch regressions when changes break previously effective defenses. You track findings over time, which shows whether vulnerability counts are trending up or down. You have evidence of testing for audits, compliance, and leadership reporting.

The limitation of Level 2 is frequency. Testing quarterly means vulnerabilities introduced in February might not be discovered until May. Testing only before releases means ongoing development happens without continuous security feedback. Teams deploying frequently—weekly or daily—find that quarterly red teaming provides insufficient coverage. That tension drives the transition to Level 3.

Moving from Level 2 to Level 3 requires automation infrastructure and integration into development workflows. You cannot run comprehensive manual tests weekly—the labor cost is prohibitive. You need automated testing that runs continuously or on every major code change.

## Level 3 — Continuous Automated Testing

Level 3 integrates red teaming into continuous delivery pipelines. Automated test suites run on every commit, every pull request, or every deployment. Security testing becomes part of the development feedback loop rather than a separate periodic activity. Engineers get security feedback within hours or days instead of weeks or months.

Characteristics of Level 3: Automated adversarial test suites covering core attack classes. Tests run automatically in CI/CD pipelines. Results integrated into developer workflows—failing security tests block merges or deployments. Regression suites ensure that fixed vulnerabilities stay fixed. Test coverage metrics tracked over time. Automated and manual testing combined—automation handles regression and known attack patterns, manual testing explores novel attacks.

The shift to Level 3 dramatically improves security responsiveness. A code change that introduces a prompt injection vulnerability gets flagged within hours. A model update that degrades safety behavior triggers alerts before production deployment. Engineers develop intuition about secure patterns because they receive immediate feedback when they introduce vulnerabilities.

Building Level 3 capability requires significant investment. You need testing infrastructure—compute for running adversarial tests, storage for test cases and results, orchestration for running tests across different system components. You need engineering effort to build and maintain test suites. You need process changes to integrate security testing into development workflows without blocking productivity. The investment is substantial but justified for systems with high deployment frequency or significant risk.

The limitation of Level 3 is that automated testing only catches known attack patterns. Automation runs the tests you design. Novel attacks that your test suites do not cover will not be detected. That gap drives the transition to Level 4.

## Level 4 — Integrated Red Team Operations

Level 4 treats red teaming as a core organizational capability, not a separate security function. Red teams work directly with engineering, product, and operations. They participate in design reviews, launch planning, incident response. Red teaming insights inform architectural decisions, defensive roadmaps, and feature prioritization. Security testing is not something that happens to the product—it is part of how the product is built.

Characteristics of Level 4: Dedicated red team with specialized AI security expertise. Red team involvement in feature design before implementation. Adversarial threat modeling for new systems and major changes. Continuous exploratory testing alongside automated regression testing. Red team findings integrated into engineering roadmaps with clear prioritization. Security metrics included in team OKRs and performance reviews. Formal collaboration with external researchers through bug bounties and research partnerships.

The integration at Level 4 creates cultural change. Security becomes everyone's responsibility, not just the security team's job. Engineers think adversarially during design. Product managers consider attack scenarios when scoping features. Operations teams monitor for adversarial activity, not just system health. Red team expertise spreads through the organization via training, documentation, and direct collaboration.

Building Level 4 capability requires organizational commitment beyond tooling and process. Leadership must prioritize security visibly and consistently. Headcount must be allocated to red team roles. Engineering teams must have time to address findings, not just deliver features. Incentive structures must reward secure design, not just shipping fast. These cultural and organizational changes take longer than technical changes—often one to two years.

The limitation of Level 4 is that it is reactive to the current threat landscape. You test against known attacks, model current adversaries, defend against documented techniques. Novel threat classes, zero-day attack techniques, and adversary innovation can still surprise you. That awareness drives the transition to Level 5.

## Level 5 — Proactive Threat Anticipation

Level 5 organizations do not just defend against current threats—they anticipate future ones. They invest in research to discover attack classes before adversaries do. They develop defenses for theoretical vulnerabilities before exploitation occurs in the wild. They contribute to the broader security community by publishing research, sharing threat intelligence, and advancing the state of the art in AI security.

Characteristics of Level 5: Internal research teams studying adversarial AI. Partnerships with academic institutions on security research. Threat modeling that includes future capabilities and adversary evolution. Investment in defensive techniques that address theoretical rather than observed attacks. Active participation in industry security initiatives and standards development. Publication of security research and defensive techniques. Proactive disclosure of vulnerabilities discovered in own systems to build community trust.

Level 5 organizations shape the threat landscape instead of just responding to it. When they discover a new attack class, they develop defenses, publish findings, and help the industry prepare before widespread exploitation occurs. They think in terms of adversary capability trajectories—if attackers can do X today, what will they be able to do in 12 months, and how do we defend against that future state now?

Building Level 5 capability requires resources that only the largest or highest-risk organizations can justify. You need research headcount, publication time, academic partnerships, and leadership willing to invest in security beyond immediate business needs. Most organizations will never reach Level 5, and that is fine. Level 4 maturity provides excellent security for the vast majority of AI systems. Level 5 is for organizations whose systems are critical infrastructure, face nation-state adversaries, or have mission-critical requirements for security leadership.

## Assessing Your Current Level

Honest self-assessment is harder than it sounds. Organizations tend to overestimate their maturity—equating aspirations with reality, giving themselves credit for partial implementations, or conflating one component at a higher maturity level with overall organizational maturity.

Assessment criteria should be specific and evidence-based. For each maturity level, ask: Do we have the infrastructure? Do we have the processes? Do we have the skills? Do we have the organizational support? All four must be true to claim that maturity level. Having automated testing infrastructure but no processes for acting on results does not equal Level 3. Having a red team but no integration with engineering workflows does not equal Level 4.

Partial credit indicates where to focus next. If you have Level 2 processes but no automation, you know that building test automation is the path to Level 3. If you have Level 3 automation but red team findings are not integrated into engineering planning, you know that organizational integration is the path to Level 4. Assessment reveals gaps, and gaps become roadmaps.

External validation helps calibrate self-assessment. Third-party security reviews, compliance audits, or maturity assessments from consultants provide outside perspectives. They catch blind spots, challenge assumptions, and compare your capability against industry benchmarks. If your self-assessment says Level 3 but an external review says Level 2, believe the external review and investigate the gap.

## Planning Maturity Progression

Maturity progression should be deliberate, not rushed. Jumping from Level 1 to Level 4 in six months creates fragile capability—processes without cultural support, tools without expertise, automation without understanding. Sustainable maturity progression happens one level at a time with consolidation periods between advances.

Investment scales with maturity level. Moving from Level 1 to Level 2 requires primarily time and discipline—scheduling testing, documenting methods, tracking findings. The cost is low. Moving from Level 2 to Level 3 requires engineering effort and infrastructure—building automation, integrating into CI/CD, maintaining test suites. The cost is moderate. Moving from Level 3 to Level 4 requires organizational change—headcount, process redesign, cultural shifts. The cost is high. Moving from Level 4 to Level 5 requires strategic investment in research and community leadership. The cost is very high.

Align maturity targets with risk. A low-risk internal tool might only need Level 2. A customer-facing AI product with moderate risk probably needs Level 3. A high-stakes system handling sensitive data or making critical decisions likely needs Level 4. Systems that are potential targets for sophisticated adversaries or that set industry standards might justify Level 5. Over-investing in maturity relative to risk wastes resources. Under-investing creates vulnerabilities.

Celebrate progress at each level. Moving from ad-hoc testing to periodic formal testing is real improvement. Building continuous automated testing is significant achievement. Integrating red team operations into product development transforms security culture. Each level provides value. Reaching Level 5 is not the only definition of success—reaching the maturity level appropriate for your system's risk profile is success.

The Red Team Maturity Model provides a framework for understanding where you are, where you need to be, and how to get there. It turns security improvement from an abstract goal into concrete stages with clear criteria. It helps you plan investments, measure progress, and communicate capability to leadership and stakeholders. Most importantly, it acknowledges that red teaming is not a binary—you either have it or you do not. It is a spectrum of capability that grows over time with deliberate effort and organizational commitment.

We have covered the operational foundations of continuous red teaming—automation, integration, bug bounties, community engagement, threat intelligence, and maturity progression. Next, we turn to how red teaming intersects with enterprise governance and compliance in Chapter 13.
