# 13.8 â€” Vendor Red Teaming Requirements: What to Ask Providers

Your vendors are part of your attack surface. Every AI provider, infrastructure platform, and data service you rely on represents a potential vulnerability in your security posture. In late 2025, a healthcare company discovered their compliance-certified AI vendor had never performed adversarial testing on their API layer. When the healthcare team's security team ran basic injection attacks during a routine audit, they found they could exfiltrate model responses containing other customers' PII. The vendor's SOC 2 certification covered their infrastructure security but said nothing about AI-specific attack resistance. The healthcare company had assumed vendor compliance meant vendor security. It did not.

The gap between general security certifications and AI-specific security practices is massive. A vendor can pass every traditional security audit while remaining completely vulnerable to prompt injection, jailbreaking, data extraction, and model manipulation attacks. You cannot rely on standard compliance frameworks to tell you whether a vendor's AI systems are secure against adversarial techniques. You need to ask different questions, demand different evidence, and verify different capabilities. Vendor red teaming requirements are how you turn that uncertainty into contractual obligation.

## Why Vendor Security Matters

When you integrate an AI vendor's API, you are trusting them with three critical security responsibilities. First, they must protect their model from attacks that could compromise your data. If their system is vulnerable to prompt injection that leaks context across customers, your sensitive prompts become visible to other users. Second, they must protect their infrastructure from attacks that could degrade or manipulate your service. If an attacker can poison their model or corrupt their vector database, your application receives compromised responses without knowing it. Third, they must protect your users from attacks that exploit the vendor's system to harm your business. If their content filtering fails under adversarial pressure, your brand takes the reputation damage.

You do not control their infrastructure, their training data, their model architecture, or their security practices. You can only influence what they commit to contractually and verify what they demonstrate through testing. That makes vendor security requirements fundamentally different from internal security requirements. Internally, you can mandate red teaming, allocate resources, and enforce practices. With vendors, you can only require evidence, set contractual standards, and maintain the right to audit. The leverage you have is selection and contract negotiation. The risk you carry is operational dependency.

Most vendor security questionnaires focus on general IT security: data encryption, access controls, incident response procedures, compliance certifications. These matter, but they do not address AI-specific attack vectors. A vendor can have perfect infrastructure security while running models that leak training data, hallucinate credentials, or accept jailbreak prompts that bypass all safety filters. The questions you ask must be tailored to the adversarial risks specific to AI systems.

## Red Teaming Questionnaire for Vendors

When evaluating a vendor, your questionnaire should cover four domains: adversarial testing practices, attack resistance capabilities, incident response maturity, and transparency commitments. Start with adversarial testing practices. Ask whether the vendor conducts regular red teaming exercises on their models and APIs. Ask how often, using what methodologies, and with what scope. Ask whether they employ external red teamers or only internal security staff. Ask whether they test for prompt injection, jailbreaking, data extraction, context hijacking, and model manipulation attacks. Ask whether they publish summaries of findings and mitigations. A vendor who has never performed adversarial testing on their AI systems is not ready for enterprise use, regardless of how impressive their feature set looks.

Ask for evidence. Do not accept "yes, we do red teaming" as sufficient. Ask for documentation: red teaming reports, remediation timelines, test coverage metrics, attack scenarios tested. Ask for the names and qualifications of the people performing the testing. Ask whether they use automated adversarial tooling or only manual testing. Ask whether they test in production-like environments or only in isolated sandboxes. Ask whether they test multi-turn attacks, tool-calling exploits, and retrieval manipulation scenarios. The depth of their answer reveals the depth of their practice.

Ask about attack resistance capabilities. Ask whether their API includes rate limiting, input validation, content filtering, and anomaly detection. Ask how they handle prompt injection attempts. Ask whether they log and alert on adversarial patterns. Ask whether they offer customer-configurable controls for blocking or flagging suspicious queries. Ask whether their retrieval systems validate sources, sanitize outputs, and limit data exposure. A vendor who cannot articulate specific technical defenses against known attack classes is operating without adequate protection.

Ask about incident response maturity. Ask what happens when they discover a new vulnerability. Ask how quickly they patch, how they communicate with customers, and whether they provide post-incident analysis. Ask whether they have a security disclosure program that accepts external reports. Ask whether they have ever had a security incident involving their AI systems and how they handled it. A vendor who has never experienced or disclosed an AI security incident may simply have never looked hard enough. A vendor who has experienced incidents and demonstrates mature response processes is often more trustworthy than one claiming perfect security.

Ask about transparency commitments. Ask whether they will share red teaming results under NDA. Ask whether they will commit to regular security updates. Ask whether they will notify you within a defined timeframe if they discover a vulnerability that could affect your data or users. Ask whether they will allow you to perform your own adversarial testing against their APIs, within reasonable usage limits. A vendor who resists transparency is a vendor hiding risk.

## Evaluating Vendor Responses

When you receive responses, evaluate them for specificity, realism, and accountability. Vague answers are red flags. "We take security very seriously" is not an answer to "how often do you red team your models." "We follow industry best practices" is not an answer to "what prompt injection defenses do you implement." "We are SOC 2 compliant" is not an answer to "how do you test for jailbreaking attacks." Push for specifics. If the vendor cannot or will not provide them, that is signal.

Evaluate the realism of their claims. If a vendor claims they have never found a vulnerability in their models, they either have not tested thoroughly or they are lying. Every complex AI system has vulnerabilities. The question is whether the vendor finds them before attackers do. A vendor who admits to discovering and patching vulnerabilities regularly is demonstrating competence, not weakness. A vendor who claims perfect security is demonstrating either inexperience or dishonesty.

Evaluate their accountability mechanisms. Do they commit to SLAs around security response times? Do they offer financial penalties for breaches caused by their negligence? Do they provide contractual rights to audit their security practices? Do they indemnify you against damages caused by their security failures? Vendors who are confident in their security practices are willing to back that confidence with accountability. Vendors who resist accountability are vendors who know their practices are weak.

Compare responses across vendors. If one vendor provides detailed red teaming reports and another provides only a one-page security overview, you have learned something important about their relative maturity. If one vendor commits to quarterly adversarial testing and another has no defined cadence, you have learned something about their operational discipline. Use the variation in responses to inform your selection and your negotiation leverage.

## Contractual Requirements

Translate your findings into contractual requirements. Your contract should include four categories of commitments: ongoing security practices, transparency obligations, incident response procedures, and termination rights. Under ongoing security practices, require the vendor to conduct adversarial testing at defined intervals. Require them to remediate high-severity findings within defined timeframes. Require them to maintain specific defenses against known attack classes. Make these requirements auditable. Reserve the right to request evidence of compliance.

Under transparency obligations, require the vendor to notify you of any security vulnerability that could affect your data or users within a specific timeframe, typically 24 to 72 hours. Require them to provide incident post-mortems. Require them to share summary findings from their red teaming exercises, even if under NDA. Transparency is your early warning system. Without it, you are blind to risks accumulating in your vendor's infrastructure.

Under incident response procedures, define what constitutes a security incident, how the vendor must respond, and what information they must provide. Define escalation paths, communication channels, and coordination responsibilities. Define whether you have the right to pause or terminate service during an active incident. A vendor who resists these definitions is a vendor who has not thought through their incident response process.

Under termination rights, preserve the right to terminate the contract without penalty if the vendor fails to meet security commitments, fails to remediate vulnerabilities within agreed timeframes, or suffers a breach that compromises your data or users. This right is your ultimate leverage. A vendor who knows you can walk away is a vendor with incentive to maintain their security posture.

## Ongoing Verification

Vendor commitments mean nothing without ongoing verification. Establish a cadence for reviewing vendor security practices. Quarterly is typical for high-risk vendors. Annually may suffice for lower-risk services. During reviews, request updated evidence of adversarial testing. Request logs of security incidents and remediations. Request updates to their defenses and capabilities. Request confirmation that they remain compliant with contractual commitments.

Perform your own adversarial testing against vendor APIs. You are entitled to test the security of systems you depend on, as long as you do so within usage limits and do not attempt to access other customers' data. Run prompt injection tests. Run jailbreak attempts. Run data extraction scenarios. Run tool-calling exploits. Document what you find. If you discover vulnerabilities, report them to the vendor under responsible disclosure principles and track their response. A vendor who responds quickly and transparently to your findings is a vendor worth keeping. A vendor who dismisses, delays, or retaliates is a vendor to replace.

Monitor public disclosures. If the vendor suffers a public security incident, evaluate their response. If they patch a vulnerability, verify that the patch is effective. If they change their security practices, assess whether the change improves or degrades your risk profile. Vendor security is not static. It evolves based on the vendor's investment, their threat landscape, and their operational maturity. Your verification cadence keeps you informed of that evolution.

## When Vendors Fall Short

When a vendor fails to meet security requirements, you have four options: negotiate improvement, accept the risk, mitigate the risk, or terminate the relationship. Negotiate improvement first. If the vendor is responsive and capable, they may be willing to invest in better security practices in exchange for your continued business or expanded contract. Set clear expectations, define success criteria, and establish a timeline. Some vendors will rise to the challenge. Others will not.

If the vendor cannot or will not improve, decide whether the risk is acceptable. Sometimes the vendor provides unique value that justifies elevated risk. Sometimes the data you send them is low-sensitivity and the risk is tolerable. If you accept the risk, document the decision, ensure senior leadership is informed, and ensure your risk register reflects the exposure. Do not accept risk silently.

If you cannot accept the risk but cannot immediately replace the vendor, mitigate. Add additional layers of filtering or validation on your side. Limit the data you send to the vendor. Implement monitoring that detects anomalous vendor behavior. Deploy fallback mechanisms that reduce dependency. Mitigation does not eliminate vendor risk, but it reduces your exposure while you plan a transition.

If the vendor is unresponsive, dishonest, or incapable of meeting basic security standards, terminate. The short-term disruption of replacing a vendor is preferable to the long-term risk of a security incident caused by their negligence. Your termination rights exist for this purpose. Use them when necessary.

## Alternative Mitigations

If you must continue using a vendor with inadequate security practices, deploy defense in depth on your side. First, sanitize inputs before sending them to the vendor. Strip PII, remove sensitive context, validate that queries do not contain adversarial patterns. If the vendor's API accepts malicious prompts, at least ensure those prompts do not contain your users' private data.

Second, validate outputs before using them. Treat vendor responses as untrusted. Check for hallucinations, check for policy violations, check for data leakage patterns. If the vendor's model is compromised, your output validation is your last line of defense. Third, monitor vendor behavior for anomalies. Track response times, error rates, content patterns, and API behavior. If the vendor's system starts behaving differently, you want to know immediately.

Fourth, limit blast radius. Do not route all your traffic through a single vendor. Do not make your entire product dependent on a single vendor API. Maintain the ability to failover to alternative providers or degrade functionality gracefully. A diversified vendor strategy reduces the impact of any single vendor's failure.

## Building Vendor Security Programs

At organizational scale, vendor security becomes a program, not a one-time questionnaire. Establish a vendor risk tier system. Tier one vendors handle sensitive data, serve critical functionality, or have broad access to your systems. They require the most rigorous evaluation, the strongest contractual requirements, and the most frequent verification. Tier two vendors handle moderate-risk data or serve non-critical functionality. They require standard evaluation and periodic verification. Tier three vendors handle only public data or provide non-sensitive services. They require basic evaluation and minimal ongoing oversight.

Standardize your evaluation process. Build a questionnaire template, a scoring rubric, and a decision framework. Train your procurement and engineering teams to apply them consistently. Build a repository of vendor security assessments so you can compare vendors over time and share findings across teams. Centralize vendor security reviews so that each vendor is evaluated once, not separately by every team that wants to use them.

Establish an ongoing vendor monitoring program. Assign ownership for each vendor relationship. Define review cadences. Track vendor security incidents, remediations, and compliance status. Build dashboards that show vendor risk exposure across your organization. Escalate when vendors fall out of compliance. This operational discipline is what separates vendor security theater from vendor security practice.

By treating vendor security as a core component of your adversarial testing program, you extend your red teaming beyond the boundaries of your own infrastructure. You cannot secure what you do not control, but you can demand evidence, enforce accountability, and maintain the right to verify. Vendor red teaming requirements are how you make that demand real.

---

The vendors you depend on are part of your attack surface. But vendors are not isolated risks. They exist within a broader AI supply chain that includes model providers, infrastructure platforms, data sources, and open-source dependencies. Next, we examine how to red team the entire supply chain.
