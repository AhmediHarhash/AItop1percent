# Chapter 3 — Extended Thinking, Long-Context, and Multimodal Prompting

Modern models process millions of tokens, handle images and audio, and support extended reasoning chains. This creates new architectural possibilities and new failure modes: lost-in-the-middle errors, multimodal fusion bugs, cost explosions from careless context usage.

---

## What This Chapter Covers

- **3.1** — Extended Thinking: When and How to Use Chain-of-Thought Budgets
- **3.2** — Designing Prompts for 100K–1M+ Token Context Windows
- **3.3** — Long-Context Prompt Architecture: Placement, Ordering, and Attention
- **3.4** — Needle-in-a-Haystack and Lost-in-the-Middle Mitigation
- **3.5** — Document-Grounded Prompting for Long Inputs
- **3.6** — Multi-Document Synthesis Prompts
- **3.7** — Vision and Image Prompting: Layout, Annotation, and Multi-Image
- **3.8** — Audio and Voice Prompt Design
- **3.9** — Multimodal Fusion: Combining Text, Image, and Structured Data
- **3.10** — PDF, Table, and Chart Comprehension Prompts
- **3.11** — Video and Temporal Sequence Prompting
- **3.12** — When Long Context Beats RAG (and Vice Versa)
- **3.13** — Cost and Latency of Long-Context and Multimodal Prompts

---

*Context windows are capabilities, not excuses to be lazy.*
