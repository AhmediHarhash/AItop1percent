# 1.10 â€” Mapping Dimensions to Your Risk Tier

In February 2025, two AI startups launched products within days of each other. The first, a consumer app with thirty-five employees, built an AI assistant that suggested weekend activities based on weather, user preferences, and local events. The second, a healthcare company with ninety employees, built an AI that recommended medication dosage adjustments for patients with chronic kidney disease. Both teams allocated roughly 40 percent of their engineering resources to quality assurance. Both used similar testing frameworks and evaluation methodologies. The consumer app launched successfully and reached 120,000 users in its first month. The healthcare app launched to a pilot group of forty patients, killed a patient within six weeks due to a drug interaction the AI failed to flag, and shut down permanently after regulatory investigation. The teams had committed identical resources to quality, but they had fundamentally different quality requirements driven by their risk tiers. The consumer app needed to be useful and engaging. The healthcare app needed to be safe and correct. The difference was not rhetorical. It was the difference between success and catastrophic failure.

## Risk Tiers Shape Quality Priorities

Every AI product operates in a risk tier determined by the consequences of failure, as we established in Section 1. Low-risk products like entertainment recommendations or creative writing assistants cause minimal harm when they fail. High-risk products like medical diagnosis, autonomous vehicles, or financial trading systems cause severe harm or even death when they fail. These risk tiers directly determine which quality dimensions must dominate your quality strategy. You cannot optimize all dimensions equally with finite resources. You must make tradeoffs. The art of quality management is making the right tradeoffs for your specific risk tier.

Low-risk products should optimize for usefulness and speed while maintaining baseline safety. Users tolerate occasional errors in activity recommendations because the cost of a bad suggestion is a wasted afternoon, not a lost life. They do not tolerate slow responses or irrelevant suggestions because those failures make the product unusable even when technically correct. The activity recommendation app measured success primarily through engagement metrics and response latency. Safety evaluation focused on ensuring the app did not recommend dangerous activities or expose personal data, but correctness was secondary. If the app suggested a museum that was closed or a restaurant that was fully booked, users shrugged and tried the next suggestion. The app's quality profile emphasized usefulness at 60 percent of quality effort, speed at 25 percent, and safety at 15 percent, with minimal investment in correctness or fairness beyond legal compliance.

High-risk products must optimize for safety and correctness while treating speed as secondary. The medication dosage app's fatal failure occurred because the team allocated their quality resources like a consumer app. They spent significant effort optimizing response time and user experience. They tuned the model to provide useful suggestions that clinicians would accept. But they under-invested in safety evaluation, particularly in detecting dangerous drug interactions across complex medication regimens. The patient who died was taking seven medications. The AI recommended increasing the dose of one without recognizing that the increase would interact dangerously with another drug in the regimen. This failure would have been caught by comprehensive safety testing that simulated complex multi-drug scenarios, but that testing was not prioritized because the team was focused on usefulness and adoption.

The mismatch between risk tier and quality investment is not always as dramatic as life and death. But it is always consequential. A customer service chatbot that prioritizes speed over correctness might respond quickly with wrong information, frustrating users and increasing support costs. A legal research tool that prioritizes usefulness over correctness might surface irrelevant cases prominently, wasting attorney time. A content moderation system that prioritizes throughput over safety might miss hate speech in its rush to process high volumes. Every misalignment between risk tier and quality dimension priorities creates failures that could have been prevented with appropriate resource allocation.

## Dimension Weighting by Risk Tier

Create an explicit quality dimension map that allocates your quality effort across correctness, safety, usefulness, reliability, and fairness based on your risk tier. This map should be a formal document reviewed and approved by leadership, not an informal understanding. The activity recommendation app's map allocated effort as follows: usefulness 60 percent, speed and reliability 25 percent, safety 10 percent, correctness 5 percent, fairness 0 percent beyond legal minimums. The medication dosage app should have allocated: safety 50 percent, correctness 35 percent, reliability 10 percent, usefulness 5 percent, fairness 0 percent specific to their use case. These numbers are not universal. They depend on your specific product, user base, regulatory environment, and competitive context. But they must be explicit and they must drive resource allocation.

Use this dimension map to prioritize testing effort, evaluation dataset construction, metric selection, and team hiring. If safety dominates your map at 50 percent, then 50 percent of your quality engineering time should focus on safety testing, 50 percent of your evaluation data should cover safety scenarios, 50 percent of your quality metrics should measure safety dimensions, and you should hire safety specialists rather than generalist quality engineers. The medication dosage app failed this allocation. Their safety investment was approximately 15 percent despite operating in a domain where safety should have been 50 percent or higher. This misallocation was not malicious. It resulted from following standard practices borrowed from lower-risk AI products without adapting to their risk tier.

The dimension map must be living documentation that guides concrete decisions. When a product manager proposes a feature that would improve usefulness but might degrade safety, the dimension map provides the framework for evaluation. If you are in a high-risk tier where safety is weighted at 50 percent and usefulness at 5 percent, the answer is clear: prioritize safety. If you are in a low-risk tier with reversed weights, the calculus differs. Without an explicit map, these decisions become political rather than principled, with the loudest voice or highest-ranking executive determining priorities rather than risk-appropriate analysis.

## Low-Risk Products: Optimize for Delight

Low-risk products compete primarily on user experience, not on avoiding catastrophic failures. Users choose these products because they are useful, fast, and enjoyable, not because they are maximally safe or correct. Your quality strategy should reflect this competitive reality. Invest heavily in usefulness metrics: relevance, personalization, variety, and surprise. Measure whether users engage with suggestions, return to the product daily, and recommend it to friends. These metrics correlate with business success in low-risk domains.

Speed and reliability dominate user satisfaction in low-risk products more than correctness does. The activity recommendation app discovered through user research that a response time over three seconds caused 40 percent of users to abandon the interaction, regardless of recommendation quality. A fast mediocre suggestion beat a slow perfect suggestion in user satisfaction and retention. This insight drove the team to optimize inference latency aggressively, even when optimization reduced accuracy slightly. They cached common queries, used smaller faster models for simple requests, and set strict latency SLAs. This speed-first approach would be inappropriate for the medication dosage app, where a fast wrong answer is worse than a slow right answer, but it was optimal for activity recommendations.

Safety in low-risk products focuses on preventing rare but severe harms, not on optimizing average-case safety. The activity recommendation app needed to ensure it never suggested illegal activities, never exposed user location data, and never recommended genuinely dangerous activities like swimming in prohibited areas. These safety checks were implemented as hard constraints and red team tested extensively. But the team did not invest in nuanced safety evaluation for edge cases like suggesting outdoor activities to users with mobility limitations. That level of safety granularity exceeded the risk tier requirements and would have consumed resources better spent on usefulness.

Low-risk products also benefit from rapid iteration cycles that would be inappropriate for high-risk products. The activity recommendation app deployed new model versions weekly, testing them on small user populations before full rollout. Each deployment included A/B tests measuring engagement and retention. Failures were rolled back within hours. This velocity was possible because failures had low consequences. A bad recommendation annoyed users but did not harm them. The same velocity in the medication dosage app would have been reckless, exposing patients to inadequately tested dosing algorithms. Risk tier determines not just what you optimize but how fast you can move.

## Medium-Risk Products: Balance Across Dimensions

Medium-risk products like educational AI, professional productivity tools, or customer service automation require more balanced quality profiles. These products cause real harm when they fail, professional embarrassment, wasted time, damaged customer relationships, but not catastrophic harm like injury or death. The quality dimension map for medium-risk products typically spreads effort more evenly: correctness 30 percent, usefulness 25 percent, reliability 20 percent, safety 15 percent, fairness 10 percent. These products cannot afford to neglect any dimension.

An AI-powered legal research assistant launched in mid-2025 illustrates this balance. The product helped attorneys find relevant case law and statutes. Correctness mattered because citing wrong cases would damage attorney credibility and harm client cases. Safety mattered because suggesting inappropriate legal strategies could lead to malpractice. Usefulness mattered because attorneys would only adopt a tool that saved time and improved their work. Reliability mattered because missed searches or system downtime during critical case preparation caused professional harm. Fairness mattered because biased legal research could perpetuate discrimination. The team built evaluation frameworks that tested all five dimensions and set quality gates that required passing thresholds on each before deployment.

Medium-risk products often face the hardest quality tradeoffs because no single dimension can be neglected, but resources remain finite. The legal research assistant team struggled with the tension between usefulness and correctness. Highly precise search results that returned only definitively relevant cases were less useful than slightly less precise results that included potentially relevant edge cases. Attorneys wanted comprehensive results they could filter themselves, not conservative results that might miss important precedents. The team resolved this tension by offering confidence scores with search results, allowing attorneys to choose their own precision-recall tradeoff while ensuring the system communicated its uncertainty honestly.

Balancing dimensions also means accepting that you cannot achieve excellence in all areas simultaneously. The legal research assistant achieved good but not exceptional performance across all dimensions rather than exceptional performance in some and poor performance in others. This balanced adequacy was appropriate for the medium-risk tier. Users needed the product to be reliably good across all quality dimensions, not spectacularly good at usefulness but dangerously bad at safety. The dimension map enforced this balance by preventing over-investment in any single dimension at the expense of others.

## High-Risk Products: Safety and Correctness Dominate

High-risk products in healthcare, finance, transportation, critical infrastructure, and legal adjudication must treat safety and correctness as overriding concerns. All other quality dimensions are secondary. The medication dosage app should have allocated at least 85 percent of quality effort to safety and correctness combined, leaving only 15 percent for usefulness, speed, and fairness. This allocation feels extreme but reflects the reality that a single safety failure can kill users and destroy the company.

Design your quality process for high-risk products around formal verification, redundant checking, and conservative decision boundaries. The medication dosage app used standard ML evaluation methods: holdout test sets, accuracy metrics, and human review of sample outputs. This approach is adequate for low-risk products but insufficient for high-risk ones. High-risk products need adversarial testing that actively searches for failure modes, formal safety specifications that define prohibited outputs, automated checking systems that verify safety constraints before any output reaches users, human-in-the-loop architectures where AI suggestions require expert approval, and conservative confidence thresholds where the system refuses to make recommendations unless certainty exceeds demanding levels.

A successful high-risk AI launched in early 2025 demonstrates this approach. The product provided diagnostic support for radiologists reading chest X-rays. The team allocated 55 percent of quality effort to safety and 35 percent to correctness. Safety evaluation included red team exercises where clinicians attempted to fool the system, adversarial datasets containing images designed to trigger misdiagnosis, and formal specifications prohibiting the system from diagnosing conditions outside its training distribution. Correctness evaluation used prospective clinical studies comparing AI-assisted diagnosis to unassisted diagnosis, with sample sizes sufficient for statistical significance on rare conditions. The system was designed to operate only as decision support, never as autonomous diagnosis, ensuring human oversight on every case. This conservative architecture was slower and more expensive than autonomous operation, but it was appropriate to the risk tier.

High-risk products also require different organizational structures. The chest X-ray diagnostic system had a dedicated safety team reporting directly to the CEO, independent of the product and engineering teams. This safety team had veto authority over deployments and could halt production if safety metrics degraded. The organizational separation prevented conflicts of interest where product teams might downplay safety concerns to meet shipping deadlines. This governance overhead would be excessive for low-risk products but was essential for high-risk ones.

## Regulatory Alignment by Risk Tier

Regulatory requirements increasingly map to risk tiers. The EU AI Act, enforced since 2026, classifies AI systems into minimal, limited, high, and unacceptable risk categories with corresponding requirements. High-risk systems in healthcare, transportation, law enforcement, and critical infrastructure face mandatory conformity assessments, quality management systems, human oversight requirements, and transparency obligations. Medium-risk systems face lighter transparency requirements. Low-risk systems face minimal obligations. Your quality dimension map must align with these regulatory tiers to ensure compliance.

If your product is classified as high-risk under the EU AI Act or similar regulations, safety and correctness are not just business priorities but legal requirements with enforcement mechanisms. The medication dosage app would have been classified as high-risk, requiring conformity assessment before market deployment. Had the team understood this classification, they would have been forced to invest appropriately in safety evaluation before launch, likely preventing the fatal failure. Regulatory classification provides an external forcing function that aligns quality investment with risk tier when internal incentives might under-invest.

Map your product to relevant regulatory frameworks early in development, not as a compliance afterthought. Identify which risk tier your product falls into under the EU AI Act, FDA regulations for medical devices, financial services regulations, or other applicable frameworks. Use that regulatory classification to guide your quality dimension map. If regulators classify your product as high-risk, allocate quality resources accordingly regardless of your internal risk assessment. Regulatory classification reflects societal judgment about appropriate safety standards that you should respect.

Regulatory requirements also evolve as AI capabilities and risks become better understood. The medication dosage app launched before the EU AI Act was fully enforced. By late 2025, similar products faced much stricter requirements. Your dimension map must be updated as regulations change, ensuring that you maintain compliance even as standards tighten. Build regulatory monitoring into your quality process, reviewing relevant frameworks quarterly and updating dimension weights when requirements change.

## Building Your Dimension Priority Map

Construct your quality dimension map through structured risk assessment, not intuition. Begin by identifying your product's risk tier using the framework from Section 1. What is the worst plausible outcome if your AI makes a serious mistake. For the activity recommendation app, the answer was wasted time and mild disappointment. For the medication app, the answer was patient death. This worst-case analysis determines your baseline risk tier.

Next, assess each quality dimension's relationship to that worst-case outcome. For the medication app, safety failures directly cause the worst-case outcome, so safety must be heavily weighted. Correctness failures also lead to harm, though less immediately, so correctness must also be weighted heavily. Usefulness failures make the product less likely to be adopted but do not directly cause patient harm, so usefulness can be weighted lightly. Speed failures annoy users but do not cause medical harm, so speed can be weighted minimally. This causal analysis from quality dimensions to risk outcomes generates your priority weights.

Validate your dimension map against real failure scenarios. Conduct tabletop exercises where you simulate quality failures in each dimension and assess their impact. If a safety failure in your simulation causes unacceptable harm but safety is weighted at only 15 percent in your map, your map is wrong. If a usefulness failure has minimal impact but usefulness is weighted at 40 percent, you are over-investing. Adjust your map iteratively until simulated failures produce impacts that align with your resource allocation.

Involve diverse stakeholders in map construction. Engineers understand technical tradeoffs. Product managers understand user needs. Legal counsel understands regulatory requirements. Domain experts understand failure modes. Safety specialists understand risk mitigation. Each perspective contributes to a more accurate dimension map. The medication dosage app's map was created by the product team alone, missing critical input from medical safety experts who could have identified the drug interaction risks that ultimately killed a patient.

## Organizational Alignment on Priorities

Quality dimension maps fail when they exist only as documents without organizational buy-in. The medication dosage app had a risk assessment document that identified safety as critical, but the team's actual resource allocation did not reflect that priority because leadership incentivized fast deployment and high adoption rates. The quality map must be reflected in roadmaps, sprint planning, performance reviews, and funding decisions.

Establish quality gates that enforce dimension priorities. For high-risk products, require passing safety and correctness thresholds before any feature ships, even if that delays deployment. For low-risk products, require meeting usefulness and speed targets while allowing some correctness variance. These gates make priorities concrete and enforceable. The chest X-ray diagnostic system used a four-stage quality gate: automated safety checks must pass with zero violations, correctness metrics must exceed 95 percent on all demographic segments, clinical experts must review and approve a random sample of 100 cases, and an external medical review board must certify the release. This multi-stage gate reflected the product's high-risk tier and safety-dominant quality map.

Train your entire team on the quality dimension map and the reasoning behind it. Engineers should understand why safety receives 50 percent of quality investment while speed receives 5 percent. Product managers should understand why feature requests that improve usefulness might be rejected if they increase safety risk. Sales teams should understand what quality promises they can make based on where the company has invested. This shared understanding prevents the misalignment where different functions optimize for different unstated quality priorities.

Performance incentives must align with dimension priorities. If your map allocates 50 percent to safety but engineers are rewarded primarily for shipping features quickly, they will prioritize speed over safety regardless of what the map says. Align bonuses, promotions, and recognition with the quality dimensions your map prioritizes. The medication dosage app rewarded engineers for user adoption and feature velocity, creating incentives that directly conflicted with the safety-first approach their risk tier required.

## Dynamic Adjustment as Products Evolve

Quality dimension maps should evolve as products mature and expand. A product might launch as low-risk and later enter higher-risk domains. The activity recommendation app began suggesting activities to individuals, a low-risk use case. In 2026, they added features for school field trip planning, a medium-risk use case where safety became more important because the system was recommending activities for children under institutional care. The team updated their quality map to increase safety weighting from 10 percent to 30 percent, added safety checks for age-appropriate activities, and implemented liability review processes. This dynamic adjustment prevented the common failure where quality practices appropriate to an initial low-risk use case persist inappropriately as the product enters higher-risk domains.

Monitor for scope creep that changes your risk tier without triggering quality adaptation. The medication dosage app originally planned to serve only one class of medications for one condition. During development, the scope expanded to multiple drug classes and comorbid conditions without corresponding increases in safety testing. This scope expansion raised the risk tier from high to very high, but quality investment did not scale. Implement governance processes that require risk reassessment whenever product scope changes significantly. If reassessment identifies a higher risk tier, pause feature development and invest in quality infrastructure before proceeding.

User population changes also affect risk tier. A B2B tool used by trained professionals has different risk characteristics than the same tool deployed to consumers. The legal research assistant was initially designed for attorneys who could critically evaluate search results. When the company considered a consumer version for people representing themselves in court, the risk tier jumped because untrained users were more likely to misinterpret results. This use case expansion would have required substantial increases in correctness and safety investment to prevent harm from misuse.

## Cross-Functional Quality Ownership

Quality dimension maps only work when all functions contribute to quality, not just engineering and QA. Product management must make roadmap tradeoffs that respect dimension priorities. Design must create interfaces that support high-priority dimensions. Marketing must make promises aligned with actual quality capabilities. Sales must sell use cases appropriate to the product's risk tier. The medication dosage app's failure involved cross-functional breakdown. Engineering under-tested safety. Product pushed for fast deployment. Sales sold to patients with complex medication regimens the system was not designed for. No single function was solely responsible, but the combination was lethal.

Establish cross-functional quality reviews at key product milestones: scoping, design approval, pre-launch, and post-launch. These reviews should assess whether all functions are aligned with the quality dimension map. Does the roadmap allocate engineering time consistent with dimension priorities. Does the design support the most critical dimensions. Do marketing materials promise what the system can deliver in its actual quality tier. These reviews catch misalignment before it causes failures.

Create shared quality dashboards visible to all functions. When marketing, sales, product, and engineering all see the same real-time quality metrics weighted by dimension priorities, alignment becomes easier. The chest X-ray diagnostic system's quality dashboard showed safety metrics most prominently, with correctness second, and usefulness metrics smaller and lower on the page. This visual hierarchy reinforced that safety mattered most, correctness second, and usefulness was tertiary. Every function that viewed the dashboard absorbed this priority ordering.

## The Cost of Misalignment

Misaligning quality investment with risk tier has severe consequences. Under-investing in quality for high-risk products causes catastrophic failures like the medication dosage app's patient death. Over-investing in quality for low-risk products creates products that are safe but uncompetitive because resources were diverted from usefulness and speed. The activity recommendation app competed against consumer products optimized ruthlessly for engagement and delight. If they had invested 50 percent of resources in safety appropriate to a high-risk product, they would have shipped a safe but boring product that users abandoned for more engaging alternatives.

Right-sizing quality investment to risk tier maximizes both safety and business outcomes. You achieve adequate safety for your risk tier without over-investing in safety beyond what that tier requires, freeing resources for the dimensions that drive competitive advantage in your market. This optimization is not about minimizing quality. It is about directing quality investment to the dimensions that matter most for your specific product, users, and regulatory context.

Calculate the cost of misalignment explicitly. The medication dosage app's under-investment in safety cost one life, destroyed a company valued at approximately 15 million euros, and created regulatory scrutiny that harmed the entire medical AI industry. The activity recommendation app's appropriate quality allocation enabled them to reach product-market fit in four months and achieve profitability within a year. These outcomes were not luck. They resulted from aligning quality investment with risk tier.

## Communicating Risk Tier to Stakeholders

Your quality dimension map communicates your risk tier to internal and external stakeholders. When investors, board members, or customers see that you allocate 85 percent of quality effort to safety and correctness, they understand you are building a high-risk product with appropriate safeguards. When they see 60 percent allocated to usefulness and speed, they understand you are building a low-risk product optimized for user experience. This transparency sets accurate expectations and builds trust.

Use your dimension map in sales conversations to explain what you have optimized for and what tradeoffs you have made. The legal research assistant sales team showed their balanced dimension map to prospective customers, explaining that the product achieved good performance across all quality dimensions rather than excellent performance in some and poor in others. This honesty helped customers understand what they were buying and reduced post-sale disappointment when the product did not excel in every possible dimension.

Share dimension maps with regulators when seeking approval for high-risk systems. Demonstrating that you have allocated quality resources proportional to risk shows regulatory sophistication and risk awareness. The chest X-ray diagnostic system's FDA submission included their dimension map showing 90 percent combined investment in safety and correctness. This allocation demonstrated to reviewers that the team understood the risks and had invested accordingly.

With the anatomy of quality established through understanding its dimensions, metrics, contracts, and risk-tier mapping, Chapter 2 takes each dimension and examines it in depth, starting with the most fundamental: correctness and how to measure whether your AI is actually right.
