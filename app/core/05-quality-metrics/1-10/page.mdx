# 1.10 â€” Mapping Dimensions to Your Risk Tier

In February 2025, two AI startups launched products within days of each other. The first, a consumer app with thirty-five employees, built an AI assistant that suggested weekend activities based on weather, user preferences, and local events. The second, a healthcare company with ninety employees, built an AI that recommended medication dosage adjustments for patients with chronic kidney disease. Both teams allocated roughly 40 percent of their engineering resources to quality assurance. Both used similar testing frameworks and evaluation methodologies. The consumer app launched successfully and reached 120,000 users in its first month. The healthcare app launched to a pilot group of forty patients, killed a patient within six weeks due to a drug interaction the AI failed to flag, and shut down permanently after regulatory investigation. The teams had committed identical resources to quality, but they had fundamentally different quality requirements driven by their risk tiers. The consumer app needed to be useful and engaging. The healthcare app needed to be safe and correct. The difference was not rhetorical. It was the difference between success and catastrophic failure.

## Risk Tiers Shape Quality Priorities

Every AI product operates in a risk tier determined by the consequences of failure, as we established in Section 1. Low-risk products like entertainment recommendations or creative writing assistants cause minimal harm when they fail. High-risk products like medical diagnosis, autonomous vehicles, or financial trading systems cause severe harm or even death when they fail. These risk tiers directly determine which quality dimensions must dominate your quality strategy. You cannot optimize all dimensions equally with finite resources. You must make tradeoffs. The art of quality management is making the right tradeoffs for your specific risk tier.

Low-risk products should optimize for usefulness and speed while maintaining baseline safety. Users tolerate occasional errors in activity recommendations because the cost of a bad suggestion is a wasted afternoon, not a lost life. They do not tolerate slow responses or irrelevant suggestions because those failures make the product unusable even when technically correct. The activity recommendation app measured success primarily through engagement metrics and response latency. Safety evaluation focused on ensuring the app did not recommend dangerous activities or expose personal data, but correctness was secondary. If the app suggested a museum that was closed or a restaurant that was fully booked, users shrugged and tried the next suggestion. The app's quality profile emphasized usefulness at 60 percent of quality effort, speed at 25 percent, and safety at 15 percent, with minimal investment in correctness or fairness beyond legal compliance.

High-risk products must optimize for safety and correctness while treating speed as secondary. The medication dosage app's fatal failure occurred because the team allocated their quality resources like a consumer app. They spent significant effort optimizing response time and user experience. They tuned the model to provide useful suggestions that clinicians would accept. But they under-invested in safety evaluation, particularly in detecting dangerous drug interactions across complex medication regimens. The patient who died was taking seven medications. The AI recommended increasing the dose of one without recognizing that the increase would interact dangerously with another drug in the regimen. This failure would have been caught by comprehensive safety testing that simulated complex multi-drug scenarios, but that testing was not prioritized because the team was focused on usefulness and adoption.

## Dimension Weighting by Risk Tier

Create an explicit quality dimension map that allocates your quality effort across correctness, safety, usefulness, reliability, and fairness based on your risk tier. This map should be a formal document reviewed and approved by leadership, not an informal understanding. The activity recommendation app's map allocated effort as follows: usefulness 60 percent, speed and reliability 25 percent, safety 10 percent, correctness 5 percent, fairness 0 percent beyond legal minimums. The medication dosage app should have allocated: safety 50 percent, correctness 35 percent, reliability 10 percent, usefulness 5 percent, fairness 0 percent specific to their use case. These numbers are not universal. They depend on your specific product, user base, regulatory environment, and competitive context. But they must be explicit and they must drive resource allocation.

Use this dimension map to prioritize testing effort, evaluation dataset construction, metric selection, and team hiring. If safety dominates your map at 50 percent, then 50 percent of your quality engineering time should focus on safety testing, 50 percent of your evaluation data should cover safety scenarios, 50 percent of your quality metrics should measure safety dimensions, and you should hire safety specialists rather than generalist quality engineers. The medication dosage app failed this allocation. Their safety investment was approximately 15 percent despite operating in a domain where safety should have been 50 percent or higher. This misallocation was not malicious. It resulted from following standard practices borrowed from lower-risk AI products without adapting to their risk tier.

## Low-Risk Products: Optimize for Delight

Low-risk products compete primarily on user experience, not on avoiding catastrophic failures. Users choose these products because they are useful, fast, and enjoyable, not because they are maximally safe or correct. Your quality strategy should reflect this competitive reality. Invest heavily in usefulness metrics: relevance, personalization, variety, and surprise. Measure whether users engage with suggestions, return to the product daily, and recommend it to friends. These metrics correlate with business success in low-risk domains.

Speed and reliability dominate user satisfaction in low-risk products more than correctness does. The activity recommendation app discovered through user research that a response time over three seconds caused 40 percent of users to abandon the interaction, regardless of recommendation quality. A fast mediocre suggestion beat a slow perfect suggestion in user satisfaction and retention. This insight drove the team to optimize inference latency aggressively, even when optimization reduced accuracy slightly. They cached common queries, used smaller faster models for simple requests, and set strict latency SLAs. This speed-first approach would be inappropriate for the medication dosage app, where a fast wrong answer is worse than a slow right answer, but it was optimal for activity recommendations.

Safety in low-risk products focuses on preventing rare but severe harms, not on optimizing average-case safety. The activity recommendation app needed to ensure it never suggested illegal activities, never exposed user location data, and never recommended genuinely dangerous activities like swimming in prohibited areas. These safety checks were implemented as hard constraints and red team tested extensively. But the team did not invest in nuanced safety evaluation for edge cases like suggesting outdoor activities to users with mobility limitations. That level of safety granularity exceeded the risk tier requirements and would have consumed resources better spent on usefulness.

## Medium-Risk Products: Balance Across Dimensions

Medium-risk products like educational AI, professional productivity tools, or customer service automation require more balanced quality profiles. These products cause real harm when they fail, professional embarrassment, wasted time, damaged customer relationships, but not catastrophic harm like injury or death. The quality dimension map for medium-risk products typically spreads effort more evenly: correctness 30 percent, usefulness 25 percent, reliability 20 percent, safety 15 percent, fairness 10 percent. These products cannot afford to neglect any dimension.

An AI-powered legal research assistant launched in mid-2025 illustrates this balance. The product helped attorneys find relevant case law and statutes. Correctness mattered because citing wrong cases would damage attorney credibility and harm client cases. Safety mattered because suggesting inappropriate legal strategies could lead to malpractice. Usefulness mattered because attorneys would only adopt a tool that saved time and improved their work. Reliability mattered because missed searches or system downtime during critical case preparation caused professional harm. Fairness mattered because biased legal research could perpetuate discrimination. The team built evaluation frameworks that tested all five dimensions and set quality gates that required passing thresholds on each before deployment.

Medium-risk products often face the hardest quality tradeoffs because no single dimension can be neglected, but resources remain finite. The legal research assistant team struggled with the tension between usefulness and correctness. Highly precise search results that returned only definitively relevant cases were less useful than slightly less precise results that included potentially relevant edge cases. Attorneys wanted comprehensive results they could filter themselves, not conservative results that might miss important precedents. The team resolved this tension by offering confidence scores with search results, allowing attorneys to choose their own precision-recall tradeoff while ensuring the system communicated its uncertainty honestly.

## High-Risk Products: Safety and Correctness Dominate

High-risk products in healthcare, finance, transportation, critical infrastructure, and legal adjudication must treat safety and correctness as overriding concerns. All other quality dimensions are secondary. The medication dosage app should have allocated at least 85 percent of quality effort to safety and correctness combined, leaving only 15 percent for usefulness, speed, and fairness. This allocation feels extreme but reflects the reality that a single safety failure can kill users and destroy the company.

Design your quality process for high-risk products around formal verification, redundant checking, and conservative decision boundaries. The medication dosage app used standard ML evaluation methods: holdout test sets, accuracy metrics, and human review of sample outputs. This approach is adequate for low-risk products but insufficient for high-risk ones. High-risk products need adversarial testing that actively searches for failure modes, formal safety specifications that define prohibited outputs, automated checking systems that verify safety constraints before any output reaches users, human-in-the-loop architectures where AI suggestions require expert approval, and conservative confidence thresholds where the system refuses to make recommendations unless certainty exceeds demanding levels.

A successful high-risk AI launched in early 2025 demonstrates this approach. The product provided diagnostic support for radiologists reading chest X-rays. The team allocated 55 percent of quality effort to safety and 35 percent to correctness. Safety evaluation included red team exercises where clinicians attempted to fool the system, adversarial datasets containing images designed to trigger misdiagnosis, and formal specifications prohibiting the system from diagnosing conditions outside its training distribution. Correctness evaluation used prospective clinical studies comparing AI-assisted diagnosis to unassisted diagnosis, with sample sizes sufficient for statistical significance on rare conditions. The system was designed to operate only as decision support, never as autonomous diagnosis, ensuring human oversight on every case. This conservative architecture was slower and more expensive than autonomous operation, but it was appropriate to the risk tier.

## Regulatory Alignment by Risk Tier

Regulatory requirements increasingly map to risk tiers. The EU AI Act, enforced since 2026, classifies AI systems into minimal, limited, high, and unacceptable risk categories with corresponding requirements. High-risk systems in healthcare, transportation, law enforcement, and critical infrastructure face mandatory conformity assessments, quality management systems, human oversight requirements, and transparency obligations. Medium-risk systems face lighter transparency requirements. Low-risk systems face minimal obligations. Your quality dimension map must align with these regulatory tiers to ensure compliance.

If your product is classified as high-risk under the EU AI Act or similar regulations, safety and correctness are not just business priorities but legal requirements with enforcement mechanisms. The medication dosage app would have been classified as high-risk, requiring conformity assessment before market deployment. Had the team understood this classification, they would have been forced to invest appropriately in safety evaluation before launch, likely preventing the fatal failure. Regulatory classification provides an external forcing function that aligns quality investment with risk tier when internal incentives might under-invest.

Map your product to relevant regulatory frameworks early in development, not as a compliance afterthought. Identify which risk tier your product falls into under the EU AI Act, FDA regulations for medical devices, financial services regulations, or other applicable frameworks. Use that regulatory classification to guide your quality dimension map. If regulators classify your product as high-risk, allocate quality resources accordingly regardless of your internal risk assessment. Regulatory classification reflects societal judgment about appropriate safety standards that you should respect.

## Building Your Dimension Priority Map

Construct your quality dimension map through structured risk assessment, not intuition. Begin by identifying your product's risk tier using the framework from Section 1. What is the worst plausible outcome if your AI makes a serious mistake. For the activity recommendation app, the answer was wasted time and mild disappointment. For the medication app, the answer was patient death. This worst-case analysis determines your baseline risk tier.

Next, assess each quality dimension's relationship to that worst-case outcome. For the medication app, safety failures directly cause the worst-case outcome, so safety must be heavily weighted. Correctness failures also lead to harm, though less immediately, so correctness must also be weighted heavily. Usefulness failures make the product less likely to be adopted but do not directly cause patient harm, so usefulness can be weighted lightly. Speed failures annoy users but do not cause medical harm, so speed can be weighted minimally. This causal analysis from quality dimensions to risk outcomes generates your priority weights.

Validate your dimension map against real failure scenarios. Conduct tabletop exercises where you simulate quality failures in each dimension and assess their impact. If a safety failure in your simulation causes unacceptable harm but safety is weighted at only 15 percent in your map, your map is wrong. If a usefulness failure has minimal impact but usefulness is weighted at 40 percent, you are over-investing. Adjust your map iteratively until simulated failures produce impacts that align with your resource allocation.

## Organizational Alignment on Priorities

Quality dimension maps fail when they exist only as documents without organizational buy-in. The medication dosage app had a risk assessment document that identified safety as critical, but the team's actual resource allocation did not reflect that priority because leadership incentivized fast deployment and high adoption rates. The quality map must be reflected in roadmaps, sprint planning, performance reviews, and funding decisions.

Establish quality gates that enforce dimension priorities. For high-risk products, require passing safety and correctness thresholds before any feature ships, even if that delays deployment. For low-risk products, require meeting usefulness and speed targets while allowing some correctness variance. These gates make priorities concrete and enforceable. The chest X-ray diagnostic system used a four-stage quality gate: automated safety checks must pass with zero violations, correctness metrics must exceed 95 percent on all demographic segments, clinical experts must review and approve a random sample of 100 cases, and an external medical review board must certify the release. This multi-stage gate reflected the product's high-risk tier and safety-dominant quality map.

Train your entire team on the quality dimension map and the reasoning behind it. Engineers should understand why safety receives 50 percent of quality investment while speed receives 5 percent. Product managers should understand why feature requests that improve usefulness might be rejected if they increase safety risk. Sales teams should understand what quality promises they can make based on where the company has invested. This shared understanding prevents the misalignment where different functions optimize for different unstated quality priorities.

## Dynamic Adjustment as Products Evolve

Quality dimension maps should evolve as products mature and expand. A product might launch as low-risk and later enter higher-risk domains. The activity recommendation app began suggesting activities to individuals, a low-risk use case. In 2026, they added features for school field trip planning, a medium-risk use case where safety became more important because the system was recommending activities for children under institutional care. The team updated their quality map to increase safety weighting from 10 percent to 30 percent, added safety checks for age-appropriate activities, and implemented liability review processes. This dynamic adjustment prevented the common failure where quality practices appropriate to an initial low-risk use case persist inappropriately as the product enters higher-risk domains.

Monitor for scope creep that changes your risk tier without triggering quality adaptation. The medication dosage app originally planned to serve only one class of medications for one condition. During development, the scope expanded to multiple drug classes and comorbid conditions without corresponding increases in safety testing. This scope expansion raised the risk tier from high to very high, but quality investment did not scale. Implement governance processes that require risk reassessment whenever product scope changes significantly. If reassessment identifies a higher risk tier, pause feature development and invest in quality infrastructure before proceeding.

## Cross-Functional Quality Ownership

Quality dimension maps only work when all functions contribute to quality, not just engineering and QA. Product management must make roadmap tradeoffs that respect dimension priorities. Design must create interfaces that support high-priority dimensions. Marketing must make promises aligned with actual quality capabilities. Sales must sell use cases appropriate to the product's risk tier. The medication dosage app's failure involved cross-functional breakdown. Engineering under-tested safety. Product pushed for fast deployment. Sales sold to patients with complex medication regimens the system was not designed for. No single function was solely responsible, but the combination was lethal.

Establish cross-functional quality reviews at key product milestones: scoping, design approval, pre-launch, and post-launch. These reviews should assess whether all functions are aligned with the quality dimension map. Does the roadmap allocate engineering time consistent with dimension priorities. Does the design support the most critical dimensions. Do marketing materials promise what the system can deliver in its actual quality tier. These reviews catch misalignment before it causes failures.

## The Cost of Misalignment

Misaligning quality investment with risk tier has severe consequences. Under-investing in quality for high-risk products causes catastrophic failures like the medication dosage app's patient death. Over-investing in quality for low-risk products creates products that are safe but uncompetitive because resources were diverted from usefulness and speed. The activity recommendation app competed against consumer products optimized ruthlessly for engagement and delight. If they had invested 50 percent of resources in safety appropriate to a high-risk product, they would have shipped a safe but boring product that users abandoned for more engaging alternatives.

Right-sizing quality investment to risk tier maximizes both safety and business outcomes. You achieve adequate safety for your risk tier without over-investing in safety beyond what that tier requires, freeing resources for the dimensions that drive competitive advantage in your market. This optimization is not about minimizing quality. It is about directing quality investment to the dimensions that matter most for your specific product, users, and regulatory context.

With the anatomy of quality established through understanding its dimensions, metrics, contracts, and risk-tier mapping, Chapter 2 takes each dimension and examines it in depth, starting with the most fundamental: correctness and how to measure whether your AI is actually right.
