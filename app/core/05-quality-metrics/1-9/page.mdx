# 1.9 â€” Quality as a Contract Between Product and User

In March 2025, a healthcare AI company with 180 employees launched a clinical documentation assistant that promised to reduce physician charting time by forty percent while maintaining perfect accuracy on diagnostic codes and treatment recommendations. The marketing site displayed this promise prominently. Sales conversations emphasized the accuracy guarantee. Pilot customers signed contracts with service level agreements specifying 99.5 percent coding accuracy. The product launched to twelve hospital systems in April. By June, the average coding accuracy measured in production was 94.7 percent. Not catastrophically bad by industry standards, but nowhere near the promised 99.5 percent. Hospitals began withholding payment. Three threatened legal action. Two cancelled their contracts entirely. The company's head of product insisted the issue was a misunderstanding: the 99.5 percent figure was an aspirational goal, not a guarantee, and 94.7 percent was actually excellent compared to competitors. The customers disagreed. They had entered into a contract, implicit and explicit, about what quality meant. The company had broken that contract. No amount of arguing about industry benchmarks could rebuild the trust that breach had destroyed.

## The Contractual Nature of Quality

Quality is not an internal property of your AI system. It is a promise you make to users about what they can expect when they use your product. This promise exists whether or not you explicitly articulate it. Every feature description, every marketing claim, every demo, every sales conversation, and every user interface element communicates implicit promises about performance, reliability, and outcomes. When your landing page shows an AI writing assistant and the example output is eloquent prose, you have promised eloquence. When your medical AI is marketed for diagnostic support and you show a case study where it caught a rare disease, you have promised diagnostic capability. When your pricing page describes your service as "enterprise-grade," you have promised reliability and support quality that matches that tier. These promises aggregate into a quality contract that users rely on when they choose your product.

The healthcare documentation company's failure was not primarily technical. Their 94.7 percent accuracy was a genuine achievement requiring sophisticated NLP and medical knowledge. Their failure was contractual. They created expectations they could not meet, then acted surprised when customers enforced those expectations. This pattern is endemic in AI products because the technology's capabilities are probabilistic and context-dependent, but marketing and sales demand clear, confident claims. The gap between what the technology can reliably deliver and what customers are told to expect creates a contractual mismatch that manifests as a quality failure.

Understanding quality as a contract reframes your entire approach to building and deploying AI systems. You cannot simply build the best system you can and hope it satisfies users. You must understand what you have promised, ensure those promises are achievable, measure whether you are fulfilling them, and communicate honestly when circumstances change. The contract is bilateral: users promise to use your product for appropriate purposes within specified constraints, and you promise to deliver defined levels of performance, safety, and reliability. When either party violates the contract, the relationship breaks down.

## Implicit Contracts and User Expectations

Most quality contracts are never written down. They exist in the user's mental model of how the product should behave. These implicit contracts are formed by prior experience, industry norms, analogical reasoning, and cultural expectations. When a user encounters a chatbot, they bring expectations formed by every previous chatbot interaction, every conversation with humans, and every cultural script about how helpful assistants should behave. If your chatbot violates these expectations, users will experience it as a quality failure even if your chatbot performs exactly as you designed it. The user's expectations define the contract, not your internal specifications.

Understanding implicit contracts requires ethnographic insight into your users' mental models. The healthcare company discovered through post-mortem interviews that hospital billing departments expected AI coding assistants to match or exceed human expert performance because that was the standard for previous automation tools in their workflow. When human coders achieved 96 to 98 percent accuracy, an AI assistant producing 94.7 percent accuracy felt like a regression, not an improvement. The company's comparison point was other AI systems in research papers, where 94.7 percent was state of the art. The users' comparison point was the human experts they were replacing, where 94.7 percent was below par. Both perspectives were valid, but only the users' perspective mattered for the quality contract.

Map these implicit expectations before you make explicit promises. Conduct user interviews that explore not just what users want but what they assume. Ask questions like: what accuracy rate would make you trust this system? What happens when the system makes a mistake? How often can it fail before you stop using it? What other tools have you used for this task and how did they perform? Users often cannot articulate their expectations clearly, but they can describe their experiences with similar tools and their reactions to hypothetical failure scenarios. These descriptions reveal the implicit contracts you need to satisfy.

Pay special attention to expectations formed by analogies. Users understand new AI products by comparing them to familiar tools. If your AI assistant is analogous to a human assistant, users expect it to handle edge cases gracefully, understand context, and communicate proactively about limitations. If your AI tool is analogous to a database query, users expect it to be precise and deterministic. If the analogy users make differs from the analogy you intend, the implicit contracts will diverge, creating quality failures when the product behaves according to your mental model rather than theirs.

## Explicit Contracts and Service Level Agreements

Explicit quality contracts formalize promises in SLAs, product documentation, and contractual terms. The healthcare company's 99.5 percent accuracy SLA was an explicit contract. These formal commitments are legally and commercially binding. Breaking them has direct business consequences: withheld payments, contract cancellations, legal liability, and reputational damage. Yet teams often write SLAs without deep understanding of whether their system can reliably meet them. The healthcare company set 99.5 percent accuracy as their SLA target because it sounded good and beat competitor claims, not because they had evidence their system could sustain that performance across diverse hospital environments, EHR systems, medical specialties, and documentation styles.

Write SLAs based on empirical evidence from production-like conditions, not laboratory benchmarks. Your evaluation dataset is curated, cleaned, and optimized for model performance. Production data is messy, adversarial, and full of edge cases. The gap between evaluation performance and production performance is usually ten to twenty percentage points for complex AI systems. If your model achieves 98 percent accuracy on your evaluation set, expect 88 to 92 percent in production. Set your SLA below the lower bound of that range, not at the evaluation benchmark. This conservative approach frustrates sales teams who want aggressive SLAs to win deals, but it prevents the contract violations that destroy customer relationships.

Structure SLAs to include measurement methodology, not just target numbers. The healthcare company's 99.5 percent accuracy SLA did not specify what accuracy meant. Was it per-encounter accuracy, per-code accuracy, or per-patient accuracy? Was it measured on all encounters or only on encounters where the AI was confident enough to make a recommendation? Were edge cases included or excluded? These specification ambiguities allowed the company to claim they were meeting the SLA using certain measurement methods while customers measured and found violations. Precise SLAs specify both the target metric and the exact procedure for measuring it, including data selection, calculation methods, and audit procedures. This precision eliminates ambiguity and creates accountability.

Consider probabilistic SLAs that acknowledge the statistical nature of AI systems. Instead of promising 99.5 percent accuracy unconditionally, promise that 95 percent of monthly measurements will exceed 94 percent accuracy, with individual measurements allowed to vary. This framing is more honest about system behavior and gives you flexibility to handle temporary performance degradation without contract violation. It also aligns customer expectations with the reality that AI performance varies over time and across contexts.

## The Asymmetry of Trust

Quality contracts have a brutal asymmetry: broken contracts destroy trust much faster than good quality builds it. The healthcare company had performed well for eight weeks before accuracy began degrading. Those eight weeks of good performance created moderate trust and satisfaction. The four weeks of broken accuracy promises destroyed all accumulated trust and created active distrust that extended beyond accuracy to other product claims. Customers began questioning everything: if the accuracy guarantee was wrong, what about the security claims, the uptime promises, the data privacy policies? One broken promise made all promises suspect.

This asymmetry is not irrational user behavior. It reflects Bayesian updating about your reliability as a partner. When you meet quality expectations, users learn that you are competent. When you break quality promises, users learn that you either cannot deliver what you promise or choose not to. Both interpretations are damaging. The first suggests technical incompetence. The second suggests dishonesty. Either way, trust collapses. Rebuilding that trust requires not just fixing the immediate problem but demonstrating sustained reliability over a much longer period than the period of good performance before the breach. One research study of SaaS customer trust found that recovering from a single major quality incident required an average of seven months of incident-free performance.

Design your quality contracts with this asymmetry in mind. Conservative promises that you consistently exceed build more trust than aggressive promises that you occasionally meet. The healthcare company would have been better served by promising 95 percent accuracy and delivering 96 to 97 percent than by promising 99.5 percent and delivering 94.7 percent. Users reward consistent over-delivery more than they reward high promises. This principle conflicts with sales incentives that reward winning deals through aggressive commitments, but it serves long-term customer relationships and retention.

The trust asymmetry also means that you must invest disproportionately in preventing contract violations compared to achieving contract compliance. A system that meets its SLA 99 percent of the time but violates it 1 percent of the time may still damage customer relationships if those violations are severe or if they create doubt about your competence. Build margin into your quality targets: if your SLA is 95 percent accuracy, design your system to achieve 97 percent, giving you buffer for natural variation and unexpected degradation.

## Dimensionality of Contracts

Quality contracts span all the dimensions we have discussed: correctness, safety, usefulness, reliability, and fairness. Most AI products emphasize one or two dimensions in their marketing and contracts while leaving others implicit. The healthcare company emphasized correctness in their contract but left reliability implicit. When their system's accuracy degraded over time as clinical documentation patterns shifted, users experienced this as a contract violation even though the contract said nothing about temporal stability. Users expected that a medical AI sold for continuous use would maintain its performance, not degrade. That expectation was part of the implicit contract.

Audit your product's promises across all quality dimensions. Review your marketing site, sales materials, demo scripts, documentation, and actual product interface. For each dimension, identify what promises you are making implicitly or explicitly. Then assess whether you can reliably deliver on those promises in production conditions. Common gaps include: promising high accuracy but delivering poor reliability, promising usefulness but neglecting safety, promising speed but providing inconsistent latency, or promising broad capability but delivering narrow competence. Every gap is a potential contract violation waiting to happen.

Make implicit promises explicit when they matter to users. If temporal stability is critical for your use case, add it to your SLA. If fairness across demographic groups matters, specify fairness metrics in your contract. If safety matters, define what safe means and how you will measure it. This explicitness protects both you and your users. You gain clarity about what you must deliver. Users gain clarity about what they can expect. Ambiguity favors neither party when conflicts arise.

The dimensionality of contracts also requires you to communicate tradeoffs honestly. If you optimize for speed, you may sacrifice some accuracy. If you prioritize safety, you may reduce usefulness by refusing to answer certain queries. Users need to understand these tradeoffs to calibrate their expectations appropriately. A content moderation system that promises high recall might have lower precision, meaning it flags more false positives. If users understand this tradeoff, they can plan for manual review processes. If they do not, they will experience the false positives as contract violations.

## Measuring Contract Compliance

You cannot manage a contract you do not measure. The healthcare company did not implement production accuracy monitoring until after customers complained. They had evaluation pipelines for development but no continuous measurement in production. This is backwards. Contract compliance must be measured continuously in production with the same rigor you apply to development metrics. Instrument your production system to collect ground truth data, calculate SLA metrics in real time, and alert when you approach or breach contract thresholds. This monitoring should be automated, not manual, because manual measurement is slow and introduces bias.

The measurement methodology must match the contract specification. If your SLA promises 99.5 percent accuracy measured per encounter, your production monitoring must calculate per-encounter accuracy using the same methodology. If your SLA promises 500 millisecond p95 latency, you must measure p95 latency in production. Mismatches between contract language and measurement methodology create disputes. The healthcare company measured accuracy by sampling random encounters monthly. Customers measured accuracy by reviewing all encounters where clinicians edited AI suggestions. These different methodologies produced different numbers and created conflict about whether the SLA was met.

Build dashboards that show SLA compliance as the primary metric, not internal quality metrics that correlate with SLAs. Your team should see the same numbers your customers see. This alignment prevents the disconnect where your internal metrics look good while customers are experiencing SLA violations. Share these dashboards with customers when appropriate. Some enterprise contracts include provisions for customer access to SLA compliance dashboards. This transparency builds trust by demonstrating that you measure and care about the same things they do.

Establish early warning systems that alert before you violate contracts, not after. If your SLA promises 95 percent accuracy and your current production performance is 95.3 percent with a declining trend, you should receive alerts warning that you are approaching violation threshold. This early warning gives you time to investigate and remediate before customers are affected. Set multiple alert thresholds: warning when you are within 2 percentage points of violation, urgent when you are within 1 percentage point, and critical when you have violated. This graduated alerting ensures appropriate response urgency.

## The Renegotiation Process

Quality contracts must evolve as products and user needs change. The healthcare company discovered that achieving 99.5 percent accuracy would require model improvements costing approximately 800,000 euros and taking six months. Rather than silently failing to meet their SLA, they should have initiated contract renegotiation. Renegotiation is not contract violation. It is honest communication about changed circumstances and collaborative problem-solving. Customers often accept revised terms if the alternative is explained clearly and they are offered compensating value.

Initiate renegotiation before you breach the contract, not after. The healthcare company waited until three customers threatened legal action. By then, renegotiation felt like desperation rather than professional adjustment. If you detect that you will miss an SLA in the future based on current trends, contact customers immediately, explain the situation with full transparency, propose solutions which might include revised SLA terms or compensating features, and give customers the choice to accept new terms or exit the contract. This proactive approach preserves trust even when you cannot meet original commitments.

Document renegotiated terms with the same precision as original contracts. Verbal agreements about relaxed SLAs or changed measurement methodologies create future disputes. Write down what changed, why it changed, what the new terms are, and how long those terms will last. Both parties should sign or acknowledge the updated agreement. This formality might feel excessive for minor adjustments, but it prevents the slow contract drift where informal allowances become permanent expectations that later cause conflict.

When renegotiating, offer compensating value for reduced commitments. If you need to lower an accuracy SLA from 99.5 percent to 96 percent, offer enhanced customer support, additional training, or price reductions to compensate for the reduced performance guarantee. This compensation acknowledges that you are asking customers to accept less than originally promised and shows good faith in maintaining a fair exchange of value.

## Quality Contracts in Low-Stakes Products

The contractual framing applies even when there are no formal SLAs. Consumer AI products and free tools create implicit quality contracts through their interfaces and claims. When ChatGPT generates a response, it implicitly promises that the response is relevant to your query, reasonably accurate, and not harmful. Users rely on these implicit promises even though they signed no contract and pay nothing. Breaking these promises damages the product's reputation and user retention just as surely as breaking explicit SLAs damages B2B relationships.

Free and consumer products often have lower quality standards than enterprise products, but they still have standards that users expect. A free AI writing assistant can produce worse prose than a paid enterprise tool, but it cannot produce offensive content or corrupt user documents. A free chatbot can be slower than a paid service, but it cannot give actively dangerous advice. These boundary conditions define the minimum quality contract. Violating them creates user harm and reputational damage regardless of pricing tier.

Map your minimum quality contract for consumer products using user research and incident analysis. What failures cause users to stop using the product immediately? What failures cause users to warn others not to use it? What failures create safety risks or legal liability? These critical failures define your contract boundaries. You may not promise high performance, but you must promise not to cross these boundaries. Instrument your product to detect boundary violations and respond immediately when they occur.

Consumer products also create implicit contracts through comparative claims. If your marketing says "more accurate than competing tools," you have promised superior accuracy even without specifying a numeric threshold. If your app store description says "lightning fast," you have promised low latency even without defining milliseconds. These comparative and qualitative claims create contractual obligations that users will enforce through churn, negative reviews, and reputation damage when violated.

## Fairness as a Contractual Dimension

Fairness promises are increasingly part of quality contracts, especially in regulated domains. The EU AI Act, enforced since 2026, requires certain AI systems to meet fairness standards for demographic groups. If your product is marketed for use in hiring, lending, healthcare, or law enforcement in EU markets, you have both legal and implicit contractual obligations around fairness. Users expect that your system will not discriminate based on protected characteristics. This expectation exists whether or not you explicitly promise fairness.

Define what fairness means for your product and make that definition part of your quality contract. Fairness is multidimensional: equal error rates across groups, equal opportunity, demographic parity, individual fairness, and procedural fairness are distinct concepts that can conflict. Choose the fairness definition appropriate to your use case, document it in your policies and contracts, measure it in production, and include it in SLAs when relevant. A hiring AI might promise equal false positive rates across demographic groups. A lending AI might promise equal opportunity for qualified applicants. These specific promises are enforceable and measurable, unlike vague claims about being "fair and unbiased."

Monitor fairness metrics with the same rigor as accuracy metrics. Fairness can degrade over time as data distributions shift or as user populations change. The healthcare documentation system might maintain equal accuracy across demographic groups initially but develop disparities as certain hospitals adopt it faster than others. Continuous monitoring detects these shifts before they become contract violations or regulatory violations.

Communicate fairness commitments clearly to users and customers. Many AI products include fairness claims in marketing but do not explain what those claims mean or how they are measured. This vagueness creates implicit contracts that are hard to fulfill and verify. Be specific: state which fairness definition you use, which demographic groups you measure, what thresholds you maintain, and how often you audit. This transparency sets accurate expectations and demonstrates accountability.

## The Cost of Over-Promising

The temptation to over-promise is intense in competitive markets. Sales teams want the strongest possible claims to win deals. Marketing teams want differentiation that stands out. Product teams want to demonstrate ambition and vision. But over-promising creates quality contracts you cannot fulfill, and the cost of contract violations exceeds the benefit of won deals. The healthcare company won twelve hospital contracts with their aggressive accuracy promises. They lost five of those contracts and spent an estimated 1.2 million euros in legal fees, remediation work, and discounts to retain the others. They would have been financially better off winning eight contracts with honest promises than winning twelve with inflated ones.

Institute contractual review processes that involve engineering and quality teams, not just sales and marketing. Before any SLA is offered, engineering must confirm that production systems can reliably meet it with margin for error. Before any marketing claim is published, quality teams must review it for accuracy and achievability. This review creates friction that slows sales processes, but it prevents the much larger friction of contract disputes and customer attrition. Frame this review not as bureaucracy but as risk management that protects customer relationships and company reputation.

Document the evidence basis for every contractual claim. When you promise 99 percent uptime, document the historical uptime data, infrastructure redundancy, and incident response processes that support that promise. When you promise 95 percent accuracy, document the evaluation results, production monitoring data, and quality assurance processes that validate that claim. This documentation serves two purposes: it forces you to verify that promises are achievable, and it provides evidence to customers that you have done due diligence rather than making aspirational claims.

## Recovery from Contract Violations

When you violate a quality contract, recovery requires acknowledgment, remediation, and recommitment. The healthcare company eventually executed this sequence successfully with their remaining customers. They acknowledged the violation clearly without excuses or blame-shifting. They explained what went wrong in technical terms customers could understand. They described their remediation plan with specific timelines and milestones. They offered financial compensation for the violation period. And they recommitted to the contract with strengthened monitoring and escalation procedures. This full sequence took four months and significant cost, but it retained seven of their twelve original customers.

Do not minimize contract violations or ask customers to accept degraded quality as the new normal. Some product teams respond to SLA misses by arguing that the SLA was unrealistic or that competitors do not meet it either. This argument further damages trust by suggesting you are not taking the contract seriously. Users do not care about your competitors' performance or your internal assessment of what is realistic. They care about the promise you made and whether you are honoring it. Acknowledge the breach, fix it, or renegotiate the terms. Those are the only responses that preserve relationships.

Build post-incident processes that treat contract violations as critical events requiring executive attention, root cause analysis, and systematic remediation. The healthcare company now escalates any SLA miss of more than two percentage points to their executive team within 24 hours. This escalation ensures that contract violations are addressed with urgency and resources rather than being normalized as acceptable variance. High-visibility processes prevent contract drift where small violations accumulate into large breaches.

Communicate recovery progress transparently to affected customers. Weekly updates on what you are doing to fix the problem, what progress you have made, and when you expect full resolution demonstrate accountability and rebuild trust. Customers can tolerate temporary failures if they trust you are working diligently to resolve them. Silent periods where customers hear nothing about your recovery efforts suggest indifference or incompetence.

## Learning from Contract Violations

Every contract violation teaches you something about the gap between your internal understanding of the product and your customers' needs and expectations. The healthcare company learned that hospitals expected temporal stability they had not promised or measured. This insight led them to add temporal stability metrics to their evaluation framework and to include performance stability clauses in future contracts. Contract violations are painful feedback about misalignments that your normal product development processes missed.

Conduct thorough post-mortems on contract violations that examine not just the technical failure but the contractual and communication failures. How did the gap between promise and delivery emerge? What assumptions did you make that proved false? What did you fail to measure that you should have measured? What expectations did customers have that you did not anticipate? These questions reveal systemic problems in how you design, evaluate, and position your products.

Share learnings from contract violations across your organization. The sales team needs to know what promises proved unrealistic so they can adjust their pitches. The marketing team needs to know what claims created unrealistic expectations so they can revise materials. The engineering team needs to know what performance requirements customers actually need so they can prioritize appropriately. Contract violations are expensive educational opportunities that should inform everyone who touches product positioning and delivery.

Quality is not an internal metric to optimize. It is a promise to users that defines your relationship with them. Breaking that promise destroys trust asymmetrically and rapidly. Keeping that promise, especially when it requires saying no to aggressive marketing claims or renegotiating when circumstances change, builds the trust that sustains long-term customer relationships. With this contractual understanding, we can now examine how different product risk tiers require different quality dimension priorities and resource allocations.
