# 8.12 â€” Data Routing Policy: Which Requests Are Allowed to Leave Your Infrastructure

In March 2025, a human resources software company discovered that their AI-powered performance review assistant had sent 18,000 employee performance reviews containing salary data, manager feedback, and termination discussions to the Claude Opus API over a six-month period. The discovery happened during a SOC 2 Type II audit when the auditor asked for the data flow diagram showing how employee data moved through the system. The engineering team had assumed that because Claude's enterprise API had a zero data retention policy, sending employee reviews was acceptable. The auditor disagreed. SOC 2 requires documented data classification and routing policies that specify which data types are allowed to leave controlled infrastructure. The company had neither. The audit failed. The company spent $280,000 on remediation, including building a data classification layer, migrating sensitive queries to self-hosted Llama 4 Maverick, and re-auditing four months later. The root cause was not technical failure. It was the absence of a data routing policy that classified requests by sensitivity and enforced routing rules before queries reached external APIs.

Data routing policy is the set of rules that determines which requests go to external model APIs and which requests must stay on self-hosted infrastructure. The policy is based on data classification, not task type or model capability. A product question from a logged-out user can go to any provider. A customer support query containing account numbers and transaction history cannot. The distinction is not about whether the external provider is trustworthy. It is about regulatory requirements, contractual obligations, and risk tolerance. GDPR, HIPAA, PCI-DSS, and SOC 2 all impose constraints on where sensitive data can be processed and who can access it. Data routing policy is how you operationalize those constraints in an AI system.

## Building a Data Sensitivity Taxonomy

The foundation of data routing policy is a **data sensitivity taxonomy** that classifies information into tiers based on regulatory requirements, business risk, and contractual obligations. The most common taxonomy has five tiers: public data, internal data, confidential data, regulated data, and restricted data. Each tier has different routing rules, retention policies, and access controls.

**Public data** is information that is already public or intended for public release. Marketing copy, product documentation, publicly available research papers, and anonymized aggregate statistics fall into this tier. Public data can be routed to any model provider without restriction. There is no compliance risk because the data is not protected by regulation or contract. The routing decision is based purely on cost, latency, and model capability.

**Internal data** is information that is not public but is not subject to regulatory protection. Internal project plans, engineering design docs, competitive analysis, and non-sensitive employee communications fall into this tier. Internal data can generally be routed to external APIs if the provider has an enterprise contract with zero data retention and no training on customer data. You verify the contract terms, confirm that the provider's DPA meets your requirements, and route the request. The risk is low because the data is not regulated, but you still enforce contractual protections to prevent unauthorized access or retention.

**Confidential data** is proprietary business information that would cause competitive harm if disclosed. Trade secrets, unreleased product designs, customer lists, pricing strategies, and M&A discussions fall into this tier. Confidential data typically cannot be routed to external APIs unless the provider has specific contractual protections for trade secrets and a strong legal track record. Most companies route confidential data to self-hosted models or to API providers with private deployment options where the model runs in your VPC and no data leaves your infrastructure. The routing decision is driven by IP protection, not regulation.

**Regulated data** is information subject to specific legal protections. PII under GDPR, PHI under HIPAA, payment card data under PCI-DSS, and financial records under SOX fall into this tier. Regulated data has strict routing rules defined by the regulation. HIPAA requires a Business Associate Agreement with any third party that processes PHI. GDPR requires data residency in the EU for EU citizen data unless the provider has Standard Contractual Clauses or adequacy decisions. PCI-DSS prohibits sending unencrypted cardholder data to third parties unless they are PCI-compliant service providers. You cannot route regulated data based on convenience or cost. You route based on compliance requirements, and you document the legal basis for every routing decision.

**Restricted data** is the most sensitive tier, typically used for data that combines multiple regulatory requirements or carries extreme business risk. Executive communications during litigation, merger negotiation details, and highly sensitive medical records fall into this tier. Restricted data is never routed to external APIs. It stays on self-hosted models running in controlled infrastructure with dedicated access logs, encryption at rest and in transit, and role-based access control. The routing rule is absolute: restricted data does not leave your infrastructure, period.

Your taxonomy may have different tier names or different numbers of tiers, but the principle is the same. You classify data by sensitivity, and you enforce routing rules that match regulatory and business requirements. The taxonomy is not a theoretical exercise. It is a reference document that your classification system uses to make routing decisions in production.

## Implementing Request-Level Routing Based on Data Classification

Request-level routing means inspecting each query before it reaches a model and deciding where to send it based on the data it contains. You cannot rely on task type or user role to determine sensitivity. A customer support query might be public data if it is a general product question, or it might be regulated data if it contains account details. A document summarization request might be internal data if summarizing a project plan, or it might be confidential data if summarizing a patent application. The only way to route correctly is to classify the request content itself.

The **classifier** is a lightweight component that sits in the request path before the routing layer. It receives the user query, any attached documents, and any context from the application. It analyzes the content to identify sensitive data types: PII, PHI, payment card numbers, social security numbers, trade secrets, or other protected categories. Based on what it finds, it assigns the request to a sensitivity tier and passes the tier label to the routing layer. The routing layer then sends the request to the appropriate model based on policy.

Classification can be rule-based, ML-based, or hybrid. **Rule-based classification** uses regex and keyword matching to detect patterns like email addresses, phone numbers, credit card numbers, and medical terms. It is fast, deterministic, and easy to audit, but it has high false positive and false negative rates. A query containing the string "patient diagnosis" might be flagged as PHI even if it is a general question about diagnostic procedures, not a specific patient record. A query containing "John Smith, age 45, diabetes" might not match your regex if it is phrased slightly differently.

**ML-based classification** uses a fine-tuned model to detect sensitive data based on context and semantics, not just keywords. It can distinguish between a general question about medical conditions and a query containing actual patient information. It has lower false positive rates than rule-based systems, but it is slower, harder to audit, and requires training data. You also face the bootstrapping problem: you need a model to classify data before routing to a model, which means the classifier itself must run on infrastructure you control.

**Hybrid classification** combines rules and ML. Fast regex checks catch obvious patterns like credit card numbers and social security numbers. An ML model handles ambiguous cases where context is required to determine sensitivity. The hybrid approach balances speed, accuracy, and auditability. Most production systems use hybrid classification because pure rule-based systems are too noisy and pure ML systems are too slow for the request critical path.

The classifier outputs a sensitivity tier and a confidence score. High confidence classifications route immediately. Low confidence classifications trigger a secondary review, either by a human or by a more expensive classifier model. If the classifier cannot determine sensitivity within the latency budget, the request defaults to the most restrictive routing policy: self-hosted only. Defaulting to restrictive is safer than defaulting to permissive. You may over-route some non-sensitive queries to self-hosted models, increasing cost slightly, but you will never accidentally route sensitive data to an external API.

## Policy Enforcement Architecture

Policy enforcement happens in the **routing gateway**, a service that sits between your application and all model providers. Every request flows through the gateway. The gateway receives the request, calls the classifier, retrieves the routing policy for the returned sensitivity tier, selects the appropriate model provider, and forwards the request. The gateway is the single point of enforcement for data routing rules, which means it is also a single point of failure. It must be highly available, low latency, and thoroughly tested.

The routing policy is stored as configuration, not code. A policy file or database table maps sensitivity tiers to allowed providers, required infrastructure, and fallback behavior. For example:

- Public data: OpenAI GPT-5, Anthropic Claude Opus 4.5, Google Gemini 3 Ultra
- Internal data: Anthropic Claude Opus 4.5 with enterprise DPA, Google Gemini 3 Ultra with zero retention
- Confidential data: self-hosted Llama 4 Maverick on internal GPU cluster
- Regulated data: self-hosted Qwen 3 Supernova with audit logging and data residency in EU region
- Restricted data: self-hosted Mistral Large 3 on airgapped infrastructure, no external network access

The policy is versioned and auditable. Every change to the policy is logged with timestamp, author, and justification. Changes require approval from Legal, Security, and the AI Platform team. You do not allow individual engineers to modify routing policy in production without review. Policy changes are deployed through the same CI/CD pipeline as code changes, with the same testing and rollback mechanisms.

**Overrides** are temporary exceptions to the routing policy, typically used during incident response or migrations. A PCI audit is failing because payment card queries are routed to an external API. You add an override that forces all payment card queries to self-hosted models for the next 90 days while you fix the underlying policy bug. Overrides are time-limited, require executive approval, and trigger alerts when they are active. They are not a permanent workaround. They are a safety valve for emergencies.

**Audit logging** captures every routing decision: the request ID, the user, the query content hash, the classification result, the sensitivity tier, the selected provider, the timestamp, and the policy version. Logs are immutable and retained for the duration required by your compliance frameworks. SOC 2 typically requires 12 months. HIPAA requires six years. GDPR requires logs only as long as necessary to demonstrate compliance, but in practice that means at least 12 months. You cannot prove compliance without audit logs, and you cannot pass an audit if the logs are incomplete or tampered with.

The gateway also enforces **rate limiting and quotas** per sensitivity tier. Regulated data queries are limited to a lower rate than public data queries because they consume more expensive self-hosted infrastructure. If a user or service suddenly sends a burst of regulated data queries, the gateway throttles the traffic and alerts the security team. Unusual access patterns to sensitive data are a leading indicator of compromise or insider threat.

## The PII Redaction Approach

An alternative to routing sensitive data to self-hosted models is **PII redaction**, where you strip sensitive data from the query before sending it to an external API, then re-inject the sensitive data into the response after it returns. For example, a customer support query says: "My account number is 4532-8821-5543 and I need help with my recent transaction." You redact the account number, send the query as "My account number is REDACTED_ACCOUNT and I need help with my recent transaction" to Claude Opus API, receive a response, and replace REDACTED_ACCOUNT with the original account number before returning the response to the user.

Redaction works well for structured PII like account numbers, phone numbers, and email addresses. It works poorly for unstructured sensitive data like medical histories, legal discussions, or trade secrets, where redaction destroys the context the model needs to generate a useful response. If a user asks "Can you review this patent application and suggest improvements," redacting the patent content makes the query unanswerable.

Redaction also introduces **re-injection risk**. If the model's response references the redacted data in a different context, re-injection can produce semantically incorrect or misleading text. For example, you redact a dollar amount from a financial query, the model's response uses a different dollar amount in its explanation, and re-injection replaces the wrong amount with the redacted value. The response is now factually incorrect, and the user receives bad advice.

Despite these limitations, redaction is valuable for queries where sensitive data is peripheral to the task. A content moderation query might contain a user's email address in the metadata, but the email address is not relevant to the moderation decision. You redact the email, send the content to an external model, and re-inject on response. The moderation quality is unaffected, and you avoid routing PII to an external API.

Redaction is implemented as a preprocessing step in the routing gateway. The classifier identifies sensitive entities, the redactor replaces them with placeholders, and the gateway stores a mapping from placeholders to original values. After the model responds, the re-injector uses the mapping to restore original values. The mapping is stored in memory only, never persisted to disk, and is deleted immediately after re-injection. If re-injection fails, the response is rejected and the user receives an error, not a response with placeholders still visible.

## Compliance-Driven Routing

Compliance frameworks impose specific requirements on where data can be processed and who can access it. GDPR requires that personal data of EU citizens be processed in the EU or in jurisdictions with adequacy decisions, unless you have Standard Contractual Clauses with the processor. HIPAA requires a Business Associate Agreement with any third party that processes PHI. SOC 2 requires that service providers have their own SOC 2 attestation or undergo equivalent security review. PCI-DSS requires that payment card data be processed only by PCI-compliant entities.

These requirements translate directly into routing rules. If you serve EU users and use external model APIs, you must verify that the provider has EU data residency options and SCCs in place, or you must route EU user data to self-hosted models in EU regions. If you process PHI, you must verify that the provider has signed a BAA and has HIPAA-compliant infrastructure, or you must route PHI to self-hosted models. If you handle payment card data, you must verify that the provider is PCI-compliant, or you must route card data to self-hosted models in PCI-compliant infrastructure.

**Data residency** is enforced by routing geography-tagged requests to region-specific model deployments. A request from a user in Germany is tagged with EU residency requirement. The routing gateway checks the policy, sees that EU data must stay in EU, and routes to either a self-hosted model in your Frankfurt data center or to an API provider's EU endpoint. You do not route EU requests to a US-based API even if it is cheaper or faster. Compliance overrides optimization.

Data residency requirements also affect model provider selection. As of early 2026, OpenAI offers EU data residency for GPT-5 through Azure OpenAI Service in EU regions. Anthropic offers EU residency for Claude Opus 4.5 through AWS Bedrock in EU regions. Google offers EU residency for Gemini 3 through Vertex AI in EU regions. If you use a provider that does not offer EU residency, you cannot route EU user data to that provider, regardless of model capability.

BAA requirements work similarly. As of early 2026, Anthropic and Google both offer HIPAA-compliant BAAs for their enterprise API tiers. OpenAI offers BAAs through Azure OpenAI Service. If your provider does not offer a BAA, you cannot route PHI to that provider. You route to a provider with a BAA or to self-hosted infrastructure.

## The Hybrid Architecture in Practice

The most common production architecture for compliance-driven routing is **hybrid**: self-hosted models for sensitive data, external APIs for everything else. A healthcare platform runs self-hosted Llama 4 Maverick 70B on H100 GPUs for queries containing PHI and routes all other queries to Claude Opus 4.5 API. A financial services firm runs self-hosted Qwen 3 Supernova 32B for queries containing account numbers or transaction details and routes general queries to GPT-5 API. A legal tech company runs self-hosted Mistral Large 3 for queries containing attorney-client privileged communications and routes legal research queries to Gemini 3 Ultra API.

The hybrid architecture requires a robust classification system to distinguish sensitive from non-sensitive queries, a routing gateway to enforce policy, and operational capability to run self-hosted infrastructure. It also requires cost modeling to ensure that the self-hosted infrastructure is cheaper than routing everything to API. If only five percent of your queries contain sensitive data, running dedicated GPU infrastructure for that five percent may cost more than routing everything to a provider with a BAA. You make the decision based on total cost of ownership, not just inference cost.

Hybrid architecture also creates **two different SLAs**. Self-hosted models have latency and availability characteristics that differ from API models. If your self-hosted infrastructure has p95 latency of 3.2 seconds and your API provider has p95 of 1.4 seconds, sensitive queries will be noticeably slower than non-sensitive queries. Users may perceive this as a quality difference even though both queries succeed. You either accept the latency gap or invest in faster self-hosted infrastructure to close it.

The operational burden is also higher. API providers handle model updates, scaling, and incident response. Self-hosted infrastructure requires your team to monitor GPU utilization, debug inference failures, apply model updates, and respond to outages. If your team is small or lacks ML infrastructure experience, the operational cost of hybrid architecture may outweigh the compliance benefits. In that case, you route everything to a compliant API provider and pay the premium for managed service.

## Policy Testing and Validation

Data routing policy is not self-verifying. You must test that the policy is correctly implemented, that the classifier correctly assigns sensitivity tiers, and that the routing gateway enforces the policy without exceptions. Testing happens in three phases: unit testing, integration testing, and production validation.

**Unit testing** verifies that the classifier correctly identifies sensitive data patterns. You build a test suite of queries with known sensitivity labels: queries containing PII, queries containing PHI, queries containing trade secrets, and queries with no sensitive data. You run each query through the classifier and verify that it assigns the correct tier. You measure precision and recall: the percentage of sensitive queries correctly flagged, and the percentage of non-sensitive queries incorrectly flagged. You tune the classifier until precision exceeds 95 percent and recall exceeds 98 percent. Lower recall means you leak sensitive data to external APIs. Lower precision means you over-route non-sensitive data to expensive self-hosted infrastructure.

**Integration testing** verifies that the routing gateway enforces policy correctly. You send test requests with different sensitivity tiers and verify that they route to the expected providers. You test override behavior, fallback behavior, and error handling. You test that audit logs are complete and tamper-proof. You test that rate limiting and quotas work as configured. Integration tests run in a staging environment that mirrors production architecture but uses test data and test API keys.

**Production validation** uses audit logs to verify that real user queries are routed correctly. You sample 1,000 production requests per day, manually review the classification and routing decisions, and measure error rate. You look for false negatives: sensitive queries routed to external APIs. You also look for false positives: non-sensitive queries routed to self-hosted models, increasing cost. You track error trends over time. If the false negative rate increases, you tune the classifier or tighten the policy. If the false positive rate increases, you investigate whether the classifier is degrading or whether the query distribution has shifted.

Production validation also includes compliance audits. Quarterly or annually, you pull a random sample of 10,000 requests, classify them manually by sensitivity tier, and compare the manual classification to the automated classification. Discrepancies are investigated and used to improve the classifier. This is the same process that external auditors use during SOC 2 or HIPAA audits. If you cannot pass your own internal audit, you will not pass an external audit.

You also test **policy violation scenarios**. What happens if an engineer accidentally routes PHI to an external API by hardcoding a provider in application code, bypassing the gateway? The audit logs should capture the violation. The security monitoring system should alert. The incident response team should investigate and remediate. You run tabletop exercises where you simulate policy violations and verify that detection and response work as designed.

Data routing policy is the operationalization of compliance in AI systems. It translates legal requirements and business risk into technical controls that execute on every request. Without it, you are gambling that your team never accidentally routes sensitive data to the wrong provider. With it, you have defense in depth, audit trails, and the ability to prove compliance to regulators, auditors, and customers. The difference is not philosophical. It is the difference between passing an audit and failing it, between maintaining customer trust and losing it, and between operating legally and operating in violation of regulation.

The principles of data sensitivity classification, request-level routing, and policy enforcement are not optional. They are foundational to responsible AI deployment in regulated industries, and they apply regardless of which models you use or where you run them.
