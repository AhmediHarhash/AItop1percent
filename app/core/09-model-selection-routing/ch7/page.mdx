# Chapter 7 — Fine-Tuning vs Prompting vs RAG: The Adaptation Decision

Every team that deploys AI eventually faces the same question: should we prompt better, add retrieval, or fine-tune? The answer is never obvious, and getting it wrong wastes months. Teams that fine-tune when prompting would suffice burn engineering time and create maintenance burdens. Teams that keep prompting when they should fine-tune pay frontier-model prices for behavior a tuned small model could handle at a fraction of the cost. Teams that skip RAG when the model needs external knowledge watch hallucination rates climb until users stop trusting the product.

This chapter covers the adaptation decision in full. When prompting is enough. When RAG adds the knowledge the model lacks. When fine-tuning locks in behavior, style, or cost savings. Hybrid approaches. The decision checklist. The pitfalls. The full adaptation stack.

---

- **7.1** — The Three Adaptation Strategies: When Each One Wins
- **7.2** — Prompting-First: Why This Is Always Your Starting Point
- **7.3** — RAG for Knowledge: When the Model Needs Facts It Does Not Have
- **7.4** — Fine-Tuning for Behavior: When You Need Consistent Style, Format, or Tone
- **7.5** — Fine-Tuning for Cost: Replacing Frontier Prompting with a Tuned Smaller Model
- **7.6** — Hybrid Approaches: Fine-Tuned Models with RAG and Structured Prompts
- **7.7** — The Fine-Tuning Decision Checklist: Data Requirements, Cost, and Maintenance Burden
- **7.8** — Fine-Tuning Pitfalls: Overfitting, Catastrophic Forgetting, and Eval Drift
- **7.9** — When to Distill Instead of Fine-Tune: Synthetic Data from Frontier Models
- **7.10** — Continuous Fine-Tuning: Updating Models as Your Data and Requirements Change
- **7.11** — The Adaptation Stack: Layering Prompting, RAG, and Fine-Tuning Together

---

*Prompting is where you start. RAG is where you add knowledge. Fine-tuning is where you lock in behavior. The best systems layer all three — but only when each layer earns its place.*
