# 6.7 â€” Classifier Plus Generator: Routing and Acting as Separate Concerns

In mid-2025, a customer support platform serving a large telecommunications provider began experiencing cost overruns that puzzled the finance team. Their AI-powered support system was processing approximately 180,000 queries per day, routing every single request through Claude Opus 4 to first categorize the issue, then generate the response. The monthly model costs had climbed to $340,000, well above the budgeted $180,000. When the engineering team audited the request logs, they discovered that 68% of queries were simple account questions that could be handled by a much cheaper model, but every request paid the full Opus routing tax before being answered. The architecture treated categorization and generation as a single monolithic step, using the most expensive model for both. By the time they split these concerns and introduced a lightweight classifier, they had burned through an additional $1.2 million in unnecessary inference costs. The root cause was not understanding that routing and acting are fundamentally different operations with different performance requirements and different cost structures.

## The Traffic Cop Principle

Your classifier is not trying to solve the user's problem. It is only trying to send the request to the right place. This distinction changes everything about how you build and evaluate it. A classifier that routes queries to specialized generators needs to be fast, cheap, and accurate enough to avoid catastrophic misrouting, but it does not need to be sophisticated enough to actually generate the final response. You are building a traffic cop, not a problem solver.

This separation of concerns allows you to use radically different models for routing versus generation. Your classifier might be a fine-tuned GPT-5-nano model that costs 0.02 dollars per million tokens and responds in 200 milliseconds, while your generators might be Claude Opus 4.5 for complex reasoning, Gemini 3 Deep Think for analytical queries, and GPT-5.1 for creative content. The classifier sees every request, but the expensive generators only see the requests they are designed to handle. The cost savings compound quickly at scale.

The traffic cop principle also means your classifier can be wrong in specific, tolerable ways. If your classifier occasionally sends a billing question to the technical support generator instead of the billing generator, and both generators are competent enough to handle the misrouted query reasonably well, the error cost is low. The catastrophic errors are sending a complex legal question to a simple FAQ generator, or routing a sensitive compliance query to a model without appropriate safety guardrails. Your classifier optimization focuses on eliminating these high-cost errors, not achieving perfect classification accuracy across all categories.

## Classifier Model Options

You have three primary approaches to building the routing classifier: fine-tuned small models, embedding-based classifiers, and rule-based pre-filters. Each has distinct trade-offs in accuracy, cost, latency, and maintenance burden. Most production systems use a combination of all three in a cascading architecture.

**Rule-based pre-filters** run first and catch the obvious cases. These are simple pattern matching rules that route requests without calling any model at all. If the query contains the exact phrase "reset my password" or "cancel my subscription," you route it immediately to the appropriate specialized generator. Rule-based routing costs almost nothing, adds fewer than 10 milliseconds of latency, and handles 20 to 40 percent of queries in most customer support systems. The limitation is that rules are brittle and require constant maintenance as users find new ways to phrase common requests. You are not trying to handle all queries with rules. You are trying to short-circuit the most common, most unambiguous requests before paying for model inference.

**Embedding-based classifiers** use a small embedding model to convert the query into a vector, then use nearest-neighbor search or a simple logistic regression model to classify it. You generate embeddings for a labeled training set of queries, train a lightweight classifier on those embeddings, and deploy it alongside a fast vector search index. At inference time, you embed the incoming query, run it through the classifier, and get a category prediction in 50 to 150 milliseconds. Embedding-based classifiers are fast, cheap, and surprisingly accurate for well-separated categories. The training loop is straightforward: collect queries, label them with the correct routing destination, generate embeddings, train the classifier, evaluate on a holdout set, deploy. The main limitation is that embedding models compress semantic meaning, so queries that are semantically similar but require different handling can get misclassified. A question about how to use a feature and a complaint about that feature not working might embed similarly but need different generators.

**Fine-tuned small models** give you the highest accuracy for complex routing decisions. You take a small, fast model like GPT-5-nano, Llama 4 Scout, or Gemini 3 Flash, fine-tune it on thousands of labeled query-to-category examples, and deploy it as your classifier. Fine-tuned models can learn nuanced distinctions that embeddings miss, handle multi-intent queries more reliably, and adapt to domain-specific language patterns. The cost per inference is still a fraction of your large generator models, typically 0.01 to 0.05 dollars per thousand queries, and latency stays under 300 milliseconds with proper optimization. The downside is training overhead. You need a labeled dataset of at least 2,000 to 5,000 examples per category, you need to retrain periodically as query patterns shift, and you need infrastructure to version, deploy, and monitor the fine-tuned model.

Most production systems use all three in sequence. Rules catch 20 to 40 percent of queries instantly. Embedding classifiers catch another 30 to 50 percent with high confidence. Fine-tuned models handle the remaining ambiguous cases. This cascade minimizes cost and latency while maintaining high routing accuracy.

## The Classifier Training Loop

Building the initial classifier is straightforward. Maintaining it as your system evolves is where most teams fail. Query patterns shift, new categories get added, generator capabilities change, and your classifier silently degrades if you do not have a systematic retraining process.

Your training data comes from production query logs, labeled with the correct routing destination. In the early days, you manually label a seed dataset of 500 to 2,000 examples per category. This seed dataset gets you to a working classifier quickly, but it is not representative of real production distribution. The queries you imagine during training are not the queries users actually send. You launch the classifier, route queries based on its predictions, and immediately start collecting ground truth labels from downstream signals.

The downstream signals are how you know if the classifier made the right decision. If a query gets routed to the billing generator, and the user rates the response as helpful and does not escalate to a human agent, the routing was likely correct. If the query gets routed to technical support, and the generator produces a low-confidence response that the user ignores, then escalates to an agent who transfers them to billing, the routing was wrong. You label that query with the correct category and add it to your training set. This feedback loop runs continuously, labeling thousands of queries per day with real production outcomes.

You retrain the classifier weekly or biweekly, depending on how fast your query distribution shifts. Each retraining cycle pulls the latest labeled queries from production, adds them to the training set, rebalances class weights to handle category skew, trains a new model, evaluates it on a held-out test set, and deploys it if it outperforms the current production model. You track classifier accuracy overall, but more importantly, you track accuracy per category and cost-weighted accuracy. Misclassifying a high-value enterprise support query is more expensive than misclassifying a simple FAQ question, so your evaluation metrics weight categories by their downstream cost impact.

The training loop also adapts to new categories. When you add a new specialized generator, you add a new category to the classifier. You seed it with a small labeled dataset, deploy the updated classifier with conservative routing thresholds for the new category, and let production data refine the boundary over the next few retraining cycles. The classifier learns the new category from real user queries, not from your initial guesses about what that category should contain.

## How Classifier Accuracy Affects Overall System Quality

A classifier with 95 percent accuracy sounds excellent until you calculate the compound error rate across your entire system. If your classifier misroutes 5 percent of queries, and each misrouted query has a 60 percent chance of producing a low-quality response from the wrong generator, then 3 percent of all user interactions fail due to routing errors alone. At 200,000 queries per day, that is 6,000 failed interactions daily. If 10 percent of those failures escalate to human agents, you just created 600 unnecessary escalations per day, costing you approximately $12,000 in agent time.

The impact of classifier errors is not uniform across categories. Misrouting a billing question to the technical support generator might produce a mediocre but passable response, because most large generators have seen enough billing-related content in their training data to fake competence. Misrouting a compliance question to a creative content generator might produce a response that violates regulatory requirements, exposing you to legal risk. You cannot optimize for overall accuracy. You must optimize for category-specific precision and recall, with different error tolerance thresholds for different routing decisions.

Some categories are ambiguous by nature, not because your classifier is weak. A query like "I was charged twice, is this a bug or a billing issue?" legitimately spans both technical support and billing. Forcing the classifier to pick one category guarantees that 40 to 50 percent of these multi-intent queries get misrouted. The better architecture is multi-label classification, where the classifier can assign multiple categories to a single query and route it to multiple generators in parallel or in sequence.

Classifier confidence scores tell you when to trust the routing decision and when to escalate. If your classifier predicts the billing category with 97 percent confidence, route it directly. If it predicts billing with 62 percent confidence and technical support with 38 percent confidence, the query is ambiguous. You have three options: route it to both generators and let the user choose which response is more helpful, route it to a general-purpose generator that can handle both, or route it to a human agent immediately. The confidence threshold for automatic routing is a tunable parameter. Lowering it increases automation rate but also increases misrouting errors. Raising it decreases errors but sends more queries to expensive fallback paths.

The other factor is generator robustness to misrouted queries. If your technical support generator is a narrow, fine-tuned model that only knows how to answer hardware troubleshooting questions, it will fail catastrophically on a misrouted billing query. If your technical support generator is GPT-5.1 with a technical support system prompt, it will handle the misrouted billing query reasonably well, even though it is not optimal. Building robust generators that degrade gracefully on out-of-scope queries reduces the cost of classifier errors and lets you run the classifier with lower confidence thresholds.

## Multi-Label Classification for Spanning Queries

Traditional single-label classification assumes every query belongs to exactly one category. This assumption breaks immediately in real-world systems. Users ask hybrid questions, combine multiple intents in a single message, or phrase requests in ways that genuinely require multiple types of expertise.

Multi-label classification allows the classifier to assign multiple categories to a single query, each with its own confidence score. A query like "Can you pull my invoice from last month and explain why the charge is higher than usual?" needs both data retrieval from the billing system and explanatory reasoning about pricing changes. The classifier assigns both the billing category and the analysis category, each with high confidence. Your routing logic then decides whether to call both generators in sequence, call them in parallel and merge the outputs, or route to a single generalist generator that can handle both aspects.

The routing decision depends on whether the categories are complementary or conflicting. Complementary categories work together: billing data retrieval feeds into pricing analysis, legal precedent search feeds into contract drafting, product documentation lookup feeds into technical troubleshooting. You route these queries through a multi-stage pipeline where each generator handles its assigned aspect and passes context to the next. Conflicting categories represent genuine ambiguity: the query could be interpreted as either a refund request or a feature complaint, and the appropriate response depends on which interpretation is correct. You route these queries to a disambiguation step, either by asking the user a clarifying question or by sending the query to a generalist generator that can handle both interpretations.

Multi-label classification also handles queries that belong to zero categories with high confidence. If every category score is below your confidence threshold, the query is out-of-distribution. It might be gibberish, it might be a novel request type you have not seen before, or it might be an adversarial input. Instead of guessing, you route it to a fallback handler: a generalist model, a human agent, or a polite error message asking the user to rephrase.

Training a multi-label classifier requires different labeling and evaluation approaches than single-label. Each training example gets tagged with all applicable categories, not just the primary one. A query about canceling a subscription due to billing errors gets labeled with both billing and account management. Your evaluation metrics shift from simple accuracy to per-category precision and recall, and you track how often the classifier correctly identifies all relevant categories versus missing one. The F1 score becomes more important than raw accuracy, because false negatives (missing a relevant category) and false positives (adding an irrelevant category) have different downstream costs.

## Fallback Handling When the Classifier Is Uncertain

Routing confidence below threshold is not a failure signal. It is information. It tells you the query does not fit cleanly into your predefined categories, and forcing a decision will likely produce a bad outcome. Your fallback strategy determines whether low-confidence routing becomes a minor inconvenience or a major quality problem.

The simplest fallback is routing to a generalist model. If your specialized generators are fine-tuned models or narrow prompt-engineered variants, and your fallback is Claude Opus 4.5 or GPT-5.2, the generalist often produces a better response than a misrouted specialist. The cost per query is higher, but the failure rate is lower. You tune your confidence threshold to balance cost and quality: higher thresholds send more queries to the expensive generalist, lower thresholds send more queries to cheaper specialists with higher misrouting risk. Most production systems settle on thresholds between 0.70 and 0.85, where the classifier routes 60 to 80 percent of queries to specialists and sends the rest to the generalist.

The second fallback option is human escalation. If your system includes human agents as a backstop, you can route low-confidence queries directly to an agent without attempting automated response generation. This makes sense for high-stakes domains like healthcare, legal advice, or financial services, where a wrong answer has serious consequences. The cost per escalation is high, typically 5 to 15 dollars in agent time, but the risk of a bad automated response is higher. You set a very conservative confidence threshold, route only the most confident queries to automated generators, and send everything else to humans.

The third option is disambiguation. Instead of guessing which generator to use, you ask the user a clarifying question. "It looks like your question is about billing. Are you asking about a specific charge, or do you need help with payment methods?" The user picks the correct category, and you route accordingly. Disambiguation adds one extra interaction turn, which increases friction, but it eliminates misrouting errors entirely. This works well for non-urgent queries where users are willing to answer a quick follow-up question, and it works poorly for time-sensitive support requests where users expect an immediate answer.

You can also combine fallback strategies in a decision tree. Confidence above 0.85 routes to the predicted specialist. Confidence between 0.70 and 0.85 routes to the generalist. Confidence between 0.50 and 0.70 triggers disambiguation. Confidence below 0.50 escalates to a human. This tiered approach optimizes for cost, quality, and user experience across different uncertainty levels.

The failure mode to avoid is silent misrouting. If your classifier picks a category with low confidence and you route the query anyway without flagging the uncertainty, the user gets a bad response and has no idea why. You have no signal that routing was the problem, so you cannot fix it. Every routing decision should be logged with the confidence score, and low-confidence decisions should be flagged for review. If you notice that a specific category consistently has low-confidence routing, it is a signal that the category is poorly defined, the training data is insufficient, or the generator behind that category is not actually handling the queries it receives.

## Cost Savings from Classifier-Based Routing

The cost case for classifier-based routing is straightforward. If you have a workload where 40 percent of queries can be handled by a small, cheap model, and the other 60 percent require a large, expensive model, routing saves you approximately 30 to 50 percent on inference costs compared to sending everything to the expensive model. The exact savings depend on the price ratio between your classifier, your cheap generators, and your expensive generators.

A typical architecture in early 2026 might use GPT-5-nano as the classifier at 0.02 dollars per million input tokens, Llama 4 Scout as the cheap generator at 0.10 dollars per million tokens, and Claude Opus 4.5 as the expensive generator at 15 dollars per million tokens. If your average query is 200 tokens and your average response is 800 tokens, each classifier call costs 0.000004 dollars, each cheap generation costs 0.0001 dollars, and each expensive generation costs 0.015 dollars. Without routing, sending all queries to Opus costs 0.015 dollars each. With routing, 40 percent cost 0.0001 dollars plus the classifier overhead, and 60 percent cost 0.015 dollars plus the classifier overhead. Total cost per query drops from 0.015 dollars to 0.0091 dollars, a 39 percent reduction. At 200,000 queries per day, that is $1,800 saved daily, or $54,000 per month.

The savings scale non-linearly as you add more specialized generators. If you can route 20 percent of queries to a rule-based system with zero model cost, 30 percent to a cheap small model, 35 percent to a mid-tier model like Gemini 3 Pro at 2.50 dollars per million tokens, and only 15 percent to the most expensive model, your blended cost per query drops to 0.0043 dollars, a 71 percent reduction. The more granular your routing categories, the better you can match query complexity to model cost.

The cost savings are not just in model inference. Classifier-based routing also reduces latency for simple queries, which improves user experience and reduces infrastructure load. A query that routes to Llama 4 Scout and gets a response in 400 milliseconds does not tie up a connection waiting for Claude Opus 4.5 to finish thinking for 2.3 seconds. Lower latency means higher throughput on the same infrastructure, which defers the need for additional server capacity.

The investment required to realize these savings is modest. Building the initial classifier takes one to two weeks of engineering time to collect training data, train the model, and integrate it into your routing logic. Maintaining the classifier requires ongoing labeling effort, typically handled by automated feedback loops after the first few months, and periodic retraining runs that take a few hours of compute time per week. For any system processing more than 10,000 queries per day, the cost savings pay back the engineering investment within the first month.

The hidden cost is monitoring and debugging. With a single monolithic model, debugging is simple: if the response is bad, the model is at fault. With classifier-based routing, bad responses can come from classifier errors, generator errors, or both. You need logging and observability infrastructure to trace each query through the routing decision, see which generator handled it, and correlate quality metrics with routing accuracy. This observability overhead is not optional. Without it, you cannot tell whether a quality regression is due to a degraded classifier or a degraded generator, and you will waste days investigating the wrong component.

Classifier-based routing is not a premature optimization. It is a fundamental architectural pattern for any production AI system with diverse query types and cost constraints. You start with a simple two-category classifier on day one: simple queries route to a cheap model, complex queries route to an expensive model. As your system matures, you add more categories, more specialized generators, and more sophisticated fallback logic. The complexity grows gradually, and the cost savings compound over time. The alternative is paying for the most expensive model on every query forever, which is professional negligence at scale.

The next challenge is coordinating multiple model providers in the same system, each with different APIs, different capabilities, and different failure modes. Multi-provider architectures unlock flexibility and cost optimization, but they introduce operational complexity that can overwhelm teams unprepared for the integration burden.

