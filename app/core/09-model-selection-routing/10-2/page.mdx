# 10.2 â€” The Model Approval Process: Who Signs Off and What They Review

In June 2025, a legal technology company deployed Claude Opus 4.5 to replace GPT-5 in their contract analysis pipeline. The engineering team had run comprehensive evaluations showing a twelve percent improvement in clause extraction accuracy and a nine percent reduction in false positives on liability terms. They verified the change in staging, ran their safety tests, confirmed the cost impact was acceptable, and deployed to production on a Friday afternoon. On Monday morning, their legal counsel discovered the change when reviewing a compliance report. Legal had not been consulted. They immediately flagged a problem: the company's contract with Anthropic had different data retention terms than their OpenAI contract, and the change meant customer contract data was now being sent to a provider whose agreement had not been reviewed for compliance with their enterprise customer commitments. The specific issue was that Anthropic's standard terms at the time allowed thirty-day retention for abuse monitoring, while their customer contracts guaranteed zero retention. The company had to roll back the model change, renegotiate their Anthropic contract to match their customer commitments, and delay the deployment by six weeks. The engineering team had done everything right from a technical perspective. They had failed to include the right stakeholders in the approval process.

Most model changes require input from multiple functions. Engineering validates technical performance. Product confirms alignment with user needs. Security assesses data handling risk. Legal reviews contractual and regulatory implications. Compliance verifies that required controls are in place. Domain experts confirm that the model is appropriate for the task. When any of these stakeholders is excluded from the approval process, you create blind spots that lead to failed deployments, compliance violations, or business risk. The model approval process is the mechanism that ensures all relevant perspectives are considered before a change goes to production. It is not a bureaucratic hurdle. It is a structured way to surface risks and constraints that engineering alone cannot identify.

## Who Is Involved and Why

The **engineering lead** or the engineer proposing the change is responsible for demonstrating that the model meets technical requirements. They provide the evaluation results showing that the model performs at or above the required thresholds for the task. They document the testing that has been completed, including functional testing, edge case coverage, and load testing if applicable. They explain the rationale for the change: why this model is being proposed, what problem it solves, and what alternatives were considered. They also provide the operational details: expected request volume, latency requirements, cost impact, and any infrastructure changes required to support the new model. The engineering lead is the primary author of the approval request. They assemble the evidence and make the case for the change.

The **product owner** reviews the change from a user and business perspective. They confirm that the model change aligns with the product roadmap and user needs. They verify that the success criteria being measured in the evaluation match the outcomes that matter to users. They assess whether any user-facing behavior will change as a result of the model switch and whether those changes are acceptable. For example, if the new model produces slightly longer responses or uses different phrasing, product needs to confirm that this does not degrade the user experience. The product owner also considers the timing of the change. Is this the right moment to introduce a new model, or are there other product changes in flight that would make this riskier? Product has veto authority if they believe the change will harm user experience or business objectives, even if the technical metrics look good.

The **security team** reviews data handling and provider risk. They verify that the new model provider meets the organization's security requirements. This includes assessing the provider's data retention policies, their encryption standards, their access controls, their incident response capabilities, and their compliance certifications. Security also reviews what data will be sent to the model. If the task involves sensitive information like personal data, financial records, or proprietary business information, security must confirm that the provider's terms and safeguards are appropriate for that data sensitivity level. For high-risk use cases, security may require additional controls like data masking, encryption beyond what the provider offers, or contractual commitments that go beyond the provider's standard terms. Security has veto authority if the provider does not meet security requirements or if the data handling introduces unacceptable risk.

The **legal team** reviews contractual terms and regulatory compliance. They examine the provider's terms of service, data processing agreement, and any amendments or custom terms that have been negotiated. They verify that the terms are compatible with the organization's obligations to customers, partners, and regulators. They assess whether the model change introduces any new legal risks, such as increased liability exposure, intellectual property concerns, or regulatory compliance gaps. For regulated use cases, legal works closely with compliance to ensure the model change does not violate any applicable laws or industry standards. Legal also reviews any public-facing commitments the organization has made about how AI is used, ensuring the model change does not contradict those commitments. Legal has veto authority if the terms are unacceptable or if the change creates legal risk that cannot be mitigated.

The **compliance team** reviews risk tiering and required controls. They verify that the model has been assigned the correct risk tier based on the task it will perform and the potential impact of errors. They confirm that the evaluation and safety testing completed by engineering meets the standards required for that risk tier. They check that any required controls, such as human review, output validation, or logging, are in place and operational. For high-risk systems subject to regulations like the EU AI Act, compliance ensures that the required documentation, testing, and oversight mechanisms are in place before deployment. Compliance also maintains the audit trail, ensuring that the approval decision and its rationale are recorded in a way that will satisfy auditors and regulators. Compliance has veto authority if the required controls are not in place or if the risk assessment is inadequate.

The **domain expert** reviews the appropriateness of the model for the specific use case. This is someone with deep knowledge of the domain in which the task operates. For medical applications, this might be a physician or clinical informatics specialist. For legal applications, this might be an attorney or legal analyst. For financial applications, this might be a risk manager or compliance officer from the business unit. The domain expert evaluates whether the task definition accurately reflects the real-world problem, whether the success criteria measure what actually matters, and whether the model's behavior is appropriate given the domain context. They catch issues that engineering and product might miss because they lack domain-specific knowledge. For example, a domain expert might identify that a model's high accuracy on a benchmark does not translate to reliable performance on the specific edge cases that occur in production, or that the model's output style is inappropriate for the audience that will consume it. The domain expert has veto authority if they believe the model is not suitable for the task, even if it passes technical evaluations.

## What They Review

Each stakeholder reviews a specific set of artifacts and criteria. The approval request should package all of this information in a structured format so reviewers can quickly find what they need. The best approach is a pull request that modifies the model registry and includes a detailed description with links to supporting documentation. The pull request description serves as the approval request. It includes a summary of the change, the rationale, and sections that address each reviewer's concerns.

Engineering reviews the **evaluation results**. They need to see the metrics, the test set characteristics, the performance thresholds, and the comparison to the current model or baseline. They look for evidence that the evaluation was rigorous and that the results are reliable. They check whether edge cases and failure modes were tested. They verify that the evaluation methodology is appropriate for the task and that the test data is representative of production traffic. They also review the operational details: the expected cost per request, the latency percentiles, the rate limits, and any infrastructure dependencies. Engineering wants to confirm that the model will work reliably in production and that it will not introduce operational problems like excessive costs or unacceptable latency.

Product reviews the **success criteria and user impact**. They need to see how the model change will affect user-facing behavior and business outcomes. They look at the success criteria to confirm they align with product goals. They review any changes in output quality, response time, or user experience. If the model change will be visible to users, product needs to understand how it will be communicated and whether any user education or support changes are required. Product also considers the business impact: will this change improve conversion rates, reduce support burden, increase user satisfaction, or achieve other business objectives? They want evidence that the change will deliver value, not just technical improvement.

Security reviews the **data handling and provider security posture**. They need to see what data will be sent to the model, how it will be transmitted, how long it will be retained, who will have access to it, and how it will be protected. They review the provider's security documentation, certifications, and contractual commitments. For providers the organization has not used before, security may conduct a vendor security assessment that includes reviewing the provider's security policies, interviewing their security team, and potentially conducting a security audit. Security wants to confirm that the provider can be trusted with the data and that the data handling meets the organization's security standards.

Legal reviews the **contractual terms and regulatory implications**. They need to see the provider's terms of service, data processing agreement, and any negotiated amendments. They look for terms that create risk: unlimited liability, broad indemnification obligations, unfavorable data retention policies, or restrictions on how outputs can be used. They also assess regulatory compliance. For use cases subject to GDPR, HIPAA, SOX, or other regulations, legal verifies that the provider's terms and practices are compliant. They check whether the provider has the required certifications, whether data will be processed in approved jurisdictions, and whether the contractual terms include the necessary compliance commitments. Legal wants to ensure the organization is not taking on unacceptable legal or regulatory risk.

Compliance reviews the **risk tier and required controls**. They need to see the risk assessment for the task, the controls that are required for that risk tier, and evidence that those controls are in place. They review the evaluation results to confirm the testing was appropriate for the risk level. For high-risk systems, compliance may require additional documentation, such as a risk mitigation plan, a monitoring and incident response plan, or a bias and fairness assessment. Compliance also ensures the approval decision is documented in a way that satisfies audit requirements. They want a clear record of who approved the change, what evidence they reviewed, and what conditions or constraints were attached to the approval.

The domain expert reviews the **task definition and model appropriateness**. They need to see the task description, the input and output specifications, the success criteria, and examples of the model's outputs. They evaluate whether the task accurately reflects the real-world problem and whether the model's behavior is appropriate for the domain context. They look for issues that technical metrics might not capture, such as outputs that are technically correct but practically useless, or outputs that are accurate on average but unreliable on the specific cases that matter most. The domain expert brings the perspective of someone who deeply understands the problem space and can assess whether the technical solution is actually solving the right problem in the right way.

## The Approval Workflow

The workflow begins when an engineer submits an **approval request**. This is typically a pull request that adds a new model to the registry or modifies the approved use cases for an existing model. The pull request description includes the rationale for the change, links to evaluation results, a summary of the testing completed, the cost analysis, the data handling details, and any other information reviewers need. The pull request is tagged with the risk tier of the change, which determines the approval requirements.

The workflow routes the request to the appropriate reviewers based on the risk tier. For a **low-risk change**, such as upgrading from GPT-5.1 to GPT-5.2 for an existing non-regulated task, the required reviewers might be the engineering lead and product owner. The workflow notifies them, they review the pull request, and they approve by adding their approval in the pull request review interface. Once both have approved, the pull request can merge and the change deploys. The entire process might take a few hours to a day. Low-risk changes benefit from a streamlined process that does not create unnecessary delays.

For a **medium-risk change**, such as introducing a new model family for an existing use case or expanding an approved model to a new task, the required reviewers might include engineering, product, and security. Security reviews the provider's data handling and security posture. If the provider is already approved for other tasks, this review may be quick. If the provider is new, security may need a few days to complete their assessment. The workflow allows reviewers to work in parallel. Engineering, product, and security can review simultaneously. If any reviewer raises concerns or requests changes, those are discussed in the pull request comments. The engineer addresses the feedback, updates the request, and the reviewers re-review. Once all required approvals are collected, the change can proceed.

For a **high-risk change**, such as introducing a new model for a regulated use case or deploying a model that will make decisions with significant user or business impact, the required reviewers include engineering, product, security, legal, compliance, and a domain expert. The workflow routes the request to all of them in parallel. Each reviewer has specific criteria they are responsible for, as described above. Legal may need time to review contracts, negotiate terms, or consult with external counsel. Compliance may need time to complete a risk assessment or prepare documentation for regulators. The domain expert may need time to review outputs and provide feedback. The workflow tracks the status of each review and blocks merge until all approvals are recorded. High-risk changes may take days or weeks to approve, depending on the complexity and the findings from each review. This is appropriate. High-risk decisions should not be rushed.

The workflow also supports **conditional approvals**. A reviewer might approve the change contingent on certain conditions being met. For example, security might approve the use of a new provider contingent on negotiating a custom data processing agreement that includes specific retention and access controls. Legal might approve contingent on adding a disclosure to the user interface that explains how AI is being used. Compliance might approve contingent on implementing a human review step for outputs above a certain risk threshold. These conditions are recorded in the pull request comments and tracked as follow-up tasks. The change cannot fully deploy until the conditions are satisfied and verified. Conditional approvals allow the workflow to move forward while ensuring that important safeguards are not forgotten.

## Fast-Track Approvals for Low-Risk Changes

Not every model change requires a full review by six stakeholders. A well-designed approval process scales with risk. For low-risk changes that follow established patterns, the process should be fast and lightweight. A **fast-track approval** applies when the change meets specific criteria that indicate low risk. These criteria might include: the model is from a provider already approved for similar tasks, the model family is already in use for this task and the change is just a version upgrade, the evaluation results show equal or better performance across all success criteria, the cost impact is within acceptable bounds, and the data handling is identical to the current model.

When a change qualifies for fast-track approval, the workflow requires fewer reviewers and shorter review times. The typical fast-track approval might only require the engineering lead and product owner. Engineering confirms the technical evaluation is solid and the operational impact is acceptable. Product confirms the change aligns with product goals and does not degrade user experience. Both reviewers are expected to respond within one business day. If they do not raise concerns, the change proceeds. This allows low-risk improvements to deploy quickly without bureaucratic overhead.

The criteria for fast-track approval must be explicit and enforced by the workflow. You cannot leave it to the discretion of the engineer to decide whether their change is low-risk. Engineers are biased toward speed and may underestimate risk. Instead, the workflow evaluates the pull request against the fast-track criteria automatically. If the criteria are met, the pull request is tagged as fast-track and routed to the reduced reviewer set. If the criteria are not met, the pull request is tagged as standard or high-risk and routed to the full reviewer set. This ensures that the process is consistent and that risk assessments are not ad-hoc.

Some organizations implement a **pre-approved model list** for certain use cases. For example, all GPT-family models from OpenAI might be pre-approved for summarization tasks, and all Claude models from Anthropic might be pre-approved for content generation tasks. When a model is on the pre-approved list for a use case, switching between models on that list is automatically fast-tracked. The pre-approved list is reviewed and updated periodically by the governance team to reflect changes in provider terms, model capabilities, and organizational risk tolerance. This approach reduces approval overhead for routine model changes while maintaining oversight for new or higher-risk decisions.

## The Approval Record

Every approval must be documented in a way that satisfies audit and compliance requirements. The **approval record** includes who approved the change, when they approved it, what evidence they reviewed, and any conditions or constraints attached to the approval. The best approval record is the pull request history. The pull request itself serves as the approval request. The pull request description contains the evidence and rationale. The pull request reviews and comments contain the stakeholder feedback and approval decisions. The merge timestamp and commit hash record when the approval was finalized and the change was deployed. The git log provides a complete audit trail that can be reviewed at any time.

For organizations that need additional structure, the approval record can be supplemented with entries in a governance database. When a pull request modifying the model registry is merged, a webhook triggers an update to the governance database that records the model, the task, the approval date, the approving stakeholders, links to the evaluation results, and any conditions attached to the approval. This database can be queried to generate compliance reports, such as a list of all model approvals in the past year or all approvals that involved legal review. The database is a derived view, not the source of truth. The source of truth is the model registry and the pull request history. The database makes reporting easier but does not replace the primary audit trail.

The approval record must also capture the rationale. Why was this model chosen? What problem does it solve? What alternatives were considered and why were they rejected? This rationale is recorded in the pull request description and discussion. When someone reviews the approval decision six months later, they should be able to understand the context and reasoning without having to track down the original participants and ask them to recall what they were thinking. The rationale is not just historical documentation. It is decision documentation that informs future choices. If you are considering switching to a different model again, you can review the previous approval to understand what criteria were important and what trade-offs were made.

Some organizations require a formal sign-off document in addition to the pull request approval. This might be a PDF that summarizes the change, lists the approving stakeholders, includes their signatures or electronic approval timestamps, and is stored in a compliance archive. This is more common in highly regulated industries where auditors expect to see formal approval artifacts. The sign-off document is generated automatically from the pull request data at the time of merge. It is not filled out manually. Manual sign-off documents are error-prone and difficult to keep synchronized with actual system state. Automated generation ensures the sign-off document accurately reflects the pull request approval.

## Common Failure Modes

The model approval process can fail in several predictable ways. One common failure mode is **rubber-stamp approvals**, where reviewers approve changes without actually reviewing the evidence. This happens when the approval process is perceived as bureaucratic rather than valuable, when reviewers are overloaded and do not have time for thorough review, or when there is social pressure to approve quickly and not block progress. Rubber-stamp approvals defeat the purpose of the process. They create the appearance of governance without the substance. The solution is to make the approval process valuable to reviewers by ensuring they have the information they need, that their input is respected, and that their concerns are addressed. It also helps to limit the volume of approval requests by using fast-track approvals for low-risk changes and only requiring full review for changes that genuinely need it.

Another failure mode is **bottleneck reviewers**, where one person or team becomes a constraint on all approvals. This often happens with legal or compliance teams that are understaffed relative to the volume of approval requests. Every model change waits in a queue for legal review, and legal cannot keep up. The backlog grows, engineers become frustrated, and they start looking for ways to bypass the process. The solution is to scale the review capacity by cross-training additional reviewers, delegating approval authority for low-risk changes, or implementing pre-approved model lists that reduce the number of requests requiring full review. It is also important to provide reviewers with the tools and information they need to review efficiently. If legal has to hunt for contract terms or ask engineers to explain data handling, reviews take longer. If the approval request includes all of this information upfront, reviews are faster.

A third failure mode is **approval processes that are too slow**, leading to engineers bypassing them. If every model change requires a two-week approval process, engineers will find ways to deploy changes without approval and seek forgiveness later. The solution is to make the approval process fast for low-risk changes and reserve the rigorous review for high-risk changes. Fast-track approvals should complete in one day. Standard approvals should complete in three to five days. High-risk approvals may take longer, but they should have clear timelines and escalation paths if reviews are delayed. The process should also support emergency approvals for urgent changes, with a streamlined review that can complete in hours followed by a post-deployment review to confirm the change was appropriate.

A fourth failure mode is **lack of clarity about who approves what**. If the approval workflow does not clearly specify which stakeholders are required for which types of changes, engineers waste time figuring out who to ask and reviewers waste time reviewing changes that are not in their domain. The solution is to document the approval matrix: for each risk tier, specify which stakeholders are required, what criteria they review, and what authority they have. This matrix should be built into the approval workflow so that the system automatically routes requests to the right reviewers. Engineers should not have to guess who needs to approve their change. The workflow should tell them.

## Balancing Rigor with Velocity

The fundamental tension in the approval process is between rigor and velocity. Rigor ensures that changes are thoroughly vetted and risks are identified before deployment. Velocity ensures that the organization can move fast, iterate quickly, and respond to changing requirements. Too much rigor creates bureaucracy that slows progress and frustrates engineers. Too little rigor creates risk that leads to compliance failures, security incidents, or business harm. The goal is to calibrate the process so that rigor scales with risk. Low-risk changes move fast with lightweight approvals. High-risk changes move slower with thorough review. The process is a dial, not a switch.

This calibration requires ongoing adjustment. As your organization grows, as your use cases become more complex, and as regulatory requirements evolve, you will need to revisit the approval process and refine it. You should collect feedback from engineers and reviewers about what is working and what is not. You should measure approval cycle times and identify bottlenecks. You should track approval decisions and look for patterns in what gets approved, what gets rejected, and what gets conditionally approved. This data informs process improvements. If fast-track approvals are rarely used, you may need to expand the fast-track criteria. If high-risk approvals are taking too long, you may need to add review capacity or streamline the review process. The approval process is not static. It evolves as the organization learns.

The ultimate measure of a good approval process is whether it prevents bad decisions without blocking good ones. You want a process that catches the model change that will violate a customer contract, introduces unacceptable security risk, or fails to meet regulatory requirements. You also want a process that allows the model upgrade that improves performance, reduces cost, or enables a new product feature to deploy quickly. The process should add value, not just overhead. When engineers see the approval process as a valuable safeguard that helps them avoid mistakes, they engage with it constructively. When they see it as bureaucratic box-checking, they resent it and look for ways around it. The design of the process, the tools that support it, and the culture around it all contribute to whether it is seen as helpful or obstructive.

Once models are approved and deployed, the next challenge is managing the ongoing relationship with model providers, including monitoring their reliability, tracking their changes, and handling incidents when they occur.

