# 3.6 — Rule-Based Routing: Heuristic Dispatchers for Predictable Workloads

In early 2024, a customer support platform serving 200,000 monthly users routed every query to GPT-4, their only production model. Monthly inference costs hit $67,000. In July 2024, the team added GPT-4-mini to their stack and realized they could save money by routing simple queries to the cheaper model. The engineering lead spent a weekend writing a router: if the query was under thirty tokens, route to mini; if it contained the word "refund" or "cancel," route to GPT-4; if the user was on a free plan, route to mini; if the user was on an enterprise plan, route to GPT-4. The router was sixty lines of Python with a series of if-statements. It deployed on Monday. Within a week, costs dropped by thirty-eight percent with no measurable quality degradation. The team celebrated and moved on. Six months later, in January 2025, the router had grown to 340 lines and twenty-seven rules. The team had added rules for new features, new user tiers, new keywords, and edge cases discovered in production. The router still worked, but it had become fragile: adding a new rule sometimes broke existing rules because conditions overlapped in unexpected ways. A query containing both "refund" and the free-tier user flag would hit two conflicting rules, and the router's precedence logic—first match wins—meant the outcome depended on rule order. The team had started to lose track of which rules fired for which queries. But costs remained low, quality remained acceptable, and nobody had time to rewrite the router. This is rule-based routing at its best and worst: simple, effective, and easy to start, but brittle and hard to maintain as complexity grows.

Rule-based routing uses explicit, hand-coded conditions to decide which model handles each query. Each rule is a Boolean expression: if condition X is true, route to model Y. Rules can be based on any feature you can compute before model invocation: query length, keyword presence, user attributes, session metadata, time of day. Rule-based routing is the simplest routing architecture to implement, the easiest to understand, and the most predictable. You write the rules, you deploy them, and you know exactly what will happen for any given query. There are no training phases, no labeled datasets, no model retraining. The logic is transparent and debuggable. When rule-based routing works, it works well. When it fails, it fails loudly, and you know why.

## What Rules Look Like: Task Type, User Tier, Content Type, Input Length, Time of Day

Rules can be organized along several dimensions. Task type rules dispatch based on the kind of work the query requires. Classification tasks—sentiment analysis, intent detection, category labeling—go to a small, fast model fine-tuned for classification. Generation tasks—writing emails, drafting summaries, creating content—go to a larger, more capable generalist model. Code-related queries—debugging help, code generation, code review—go to a model optimized for code, like GPT-5 with code-specific fine-tuning or Claude Opus 4.5 with extended code context. If your system handles a well-defined taxonomy of task types and you can reliably infer task type from the query, task-type rules are highly effective.

User tier rules dispatch based on who is asking. Free users get the cheapest model. Paying users get the mid-tier model. Enterprise customers get the frontier model. Premium users who pay extra for priority support get the frontier model with longer context windows and higher rate limits. This is a business decision as much as a technical one: you provision model capacity based on user value, and you use routing to enforce the tiers. User tier rules are simple to implement—user tier is a field in your user database, and you look it up at request time—and they align cost with revenue.

Content type rules dispatch based on what the query is about. Code questions go to the coding model. Legal questions go to a model fine-tuned on legal text. Medical questions go to a model trained on clinical data. Product support questions go to a model that has been fine-tuned on your product documentation. Content type rules require a way to detect content type from the query, which can be as simple as keyword matching—if the query contains "function," "class," or "syntax," it is a code question—or as sophisticated as running a small classifier to predict content type before routing.

Input length rules dispatch based on how much text the user sent. Queries under fifty tokens go to a fast, cheap model. Queries over 5,000 tokens go to a model with a large context window. Input length is trivial to compute, and it correlates with both cost and task complexity: longer inputs often signal more complex tasks that need stronger models, and longer inputs cost more to process, so you want to avoid sending short queries to expensive models with large context windows. The customer support platform used a simple length rule: under thirty tokens to mini, over thirty tokens to GPT-4. This rule alone saved twenty-two percent of costs because sixty percent of support queries were under thirty tokens and were adequately handled by mini.

Time-of-day rules dispatch based on when the query arrives. Batch jobs that run overnight can use cheaper, slower models because latency is not a concern. Interactive queries during business hours use faster models. Queries that arrive during peak traffic hours go to a model with higher throughput provisioning. Queries during low-traffic hours go to a model that scales down to save cost. Time-of-day rules require integration with your scheduling or traffic management system, but they are conceptually simple: if the current time is between 2 AM and 6 AM, route to the batch model.

Rules can be combined with AND and OR logic. A single query might match multiple rules, and you need a precedence strategy: first match wins, last match wins, highest-priority rule wins, most specific rule wins. The customer support platform used first-match-wins, which meant rule order mattered. They documented the order in comments and enforced it with unit tests, but as the rule count grew, the interactions became harder to reason about.

## When Rule-Based Routing Works Well: Predictable, Stable Query Distributions

Rule-based routing excels when your query distribution is predictable and stable. If ninety percent of your queries fall into a few well-defined categories, and those categories map cleanly to model capabilities, you can write five to ten rules that handle most traffic accurately. If your user base is segmented into clear tiers with different needs, you can write tier-based rules that align cost and quality with willingness to pay. If your task types are unambiguous—every query is either a classification task or a generation task, never both—you can write task-type rules that dispatch cleanly.

Rule-based routing works well when you can compute rule conditions cheaply and quickly. Keyword matching, string length, user database lookups, and time checks are all fast and deterministic. If your rules depend on expensive computations—running a separate model to classify the query, parsing complex JSON payloads, querying external APIs—the latency cost of evaluating rules can exceed the latency savings from routing to a faster model.

Rule-based routing works well when your team is small and the rule set is small. If you have three models and ten rules, you can keep the entire routing logic in your head. You can debug by inspection. You can onboard new engineers in an afternoon. If you have ten models and eighty rules, the logic becomes opaque, and you need tooling—rule analyzers, decision trees, simulation environments—to understand what the router will do.

Rule-based routing works well when decision boundaries are sharp and features are discrete. If "contains the word refund" is a reliable signal that the query needs the strong model, write a rule. If "contains words that are semantically related to refund" is the real boundary, a rule is not expressive enough, and you need a classifier or an embedding-based router.

The customer support platform had a stable query distribution: sixty percent simple FAQs, thirty percent account issues, ten percent complex product questions. Three models: GPT-4 for complex, GPT-4-mini for simple, and a fine-tuned GPT-5-mini for account issues. Ten rules covering task type, user tier, and input length. The rules handled ninety-two percent of queries correctly. This is the ideal case for rule-based routing: small rule set, clear categories, fast conditions, stable traffic.

## When Rule-Based Routing Fails: Ambiguity, Nuance, and Rule Explosion

Rule-based routing fails when queries are ambiguous and cannot be cleanly categorized with simple conditions. Consider a query like "How do I change my settings?" This could be a simple FAQ—route to mini—or a complex troubleshooting question if the user's settings are corrupted—route to GPT-4. The word "settings" is not enough information to decide. You could add more rules: if the query contains "settings" and is under twenty tokens, route to mini; if it contains "settings" and "not working," route to GPT-4. But now you are writing rules for every combination of keywords and edge cases, and the rule count explodes.

Rule-based routing fails when the decision depends on semantic meaning rather than surface features. A query like "Why does this keep happening?" is short and contains no special keywords, so a length-based rule would route it to mini. But the query is likely a follow-up to a previous issue, which means it is complex and needs context from the conversation history, which means it should go to a model with long context and strong reasoning. A rule cannot capture this without access to session state, and once you add session state to your rule conditions, you are no longer writing simple heuristics—you are building a stateful decision engine, which is more complex than a classifier.

Rule-based routing fails when the number of rules grows so large that the rule set becomes unmaintainable. This is the rule explosion problem. You start with ten rules. You discover an edge case, so you add an eleventh rule. The eleventh rule conflicts with the fourth rule, so you reorder them. You add a new model, so you add five more rules to route to it. You launch a new feature, so you add rules for the new query types the feature generates. A year later, you have sixty rules, and nobody on the team understands the full rule set. Adding a new rule requires testing against all existing rules to avoid unintended interactions. The rule file is a thousand lines of nested if-statements. You cannot refactor it without risking regressions. This is where rule-based routing breaks down.

The customer support platform hit this wall in month nine. They had twenty-seven rules, and the rule file had become the most feared part of the codebase. Engineers avoided touching it. When a new model was added, the lead engineer spent three days auditing the rules, writing tests, and carefully inserting five new rules in the right precedence order. The team knew they needed to replace the rule-based router, but they had no time to do it, so the rule set kept growing.

## Preventing Rule Explosion: Consolidation, Hierarchical Rules, and Migration Plans

You can delay rule explosion by consolidating rules. Instead of writing separate rules for every keyword, write one rule that checks a keyword list. Instead of writing separate rules for every user tier, write one rule that looks up tier priority from a config file. Instead of writing separate rules for every model, write rules that assign a complexity score to the query and a capability score to each model, and route to the model whose capability score meets or exceeds the query's complexity score. This is still rule-based—you are not training a model—but you are factoring out common logic and reducing duplication.

You can delay rule explosion by using hierarchical rules. Top-level rules handle broad categories: if the query is a code question, route to the code model. If the query is not a code question, evaluate second-level rules: if the user is enterprise tier, route to GPT-4; if the user is free tier, evaluate third-level rules based on input length. Hierarchical rules make precedence explicit and reduce the number of possible interactions between rules. The customer support platform refactored their twenty-seven flat rules into a three-level hierarchy and cut the effective rule count to fourteen top-level rules plus a few second-level rules per branch. This made the router easier to understand, but it did not solve the fundamental problem: rule-based routing does not scale to complex decision boundaries.

Eventually, you need a migration plan. Rule-based routing is a starting point, not an end state. When the rule set becomes too large or too fragile, migrate to classifier-based routing or embedding-based routing. The migration path is to run both routers in parallel: deploy the new router in shadow mode, log its decisions, compare them to the rule-based router's decisions, and measure cost and quality. When the new router performs as well as or better than the rule-based router, cut over. Keep the rule-based router as a fallback for high-confidence cases—this is the hybrid architecture—and use the new router for ambiguous cases.

The customer support platform began this migration in month ten. They trained a classifier on 4,000 labeled queries, deployed it in shadow mode, and ran an A/B test. The classifier matched the rule-based router's quality and saved an additional twelve percent of cost by routing more accurately. They cut over in month eleven, retired fifteen of the twenty-seven rules, and kept twelve high-confidence rules as a pre-filter. The hybrid router has been stable for six months with no rule additions.

## Rule-Based Routing as the Foundation for Hybrid and Classifier-Based Systems

Rule-based routing is not obsolete. It is the foundation. You start with rules because they are fast to implement, easy to debug, and require no training data. You learn which rules work and which do not. You discover edge cases. You collect production data. Then you evolve. You add a classifier to handle ambiguous queries. You add an embedding-based router to handle semantic similarity. You keep the rules for clear-cut cases where determinism and transparency matter.

Every routing system in production today started as rules. The question is not whether to use rules, but when to stop adding rules and start learning from data. If you can handle your workload with ten rules, stop there. If you need fifty rules, you have already passed the point where a classifier would be simpler and more accurate. If you find yourself debugging rule interactions or writing rules with five levels of nested conditions, you are past the point of diminishing returns.

Rule-based routing teaches you what features matter. When you write a rule that checks input length, you learn that length is predictive of task complexity. When you write a rule that checks for the word "refund," you learn that certain keywords signal high-stakes queries. These insights inform the feature engineering for your classifier. The rules you wrote are the features the classifier will learn.

Rule-based routing is also the fallback when other routers fail. If your classifier is not confident, fall back to a rule. If your embedding-based router cannot find a similar query in your index, fall back to a rule. If your production router crashes, fall back to a hard-coded rule that routes everything to the safe default model. Rules are the safety net.

## Operational Simplicity: Why Rules Persist in Production

Rule-based routing persists in production because it is operationally simple. There is no model to train, no dataset to collect, no retraining pipeline to maintain. There is no model serving infrastructure: the rules run in the same process as your application, with no external dependencies. There is no model versioning or A/B testing of model updates. There is no risk of the router degrading over time as query distributions shift, because the rules are deterministic and do not drift.

Rule-based routing is easy to test. You write unit tests that assert: if the query is X, the router returns model Y. You write integration tests that replay production traffic through the router and verify that the decisions match expectations. You write property-based tests that generate random queries and verify that the router always returns a valid model name. All of this is standard software testing. There are no holdout sets, no precision-recall curves, no calibration checks.

Rule-based routing is easy to monitor. You log which rule fired for each query. You count how many queries hit each rule. You track the distribution of routing decisions: what percentage of traffic goes to each model. If the distribution shifts suddenly, you investigate. If a rule stops firing, you delete it. If a rule fires too often, you split it into more granular rules. This is operational monitoring, not ML monitoring.

Rule-based routing is easy to explain to stakeholders. You can show the rule file to your product manager, your finance team, your executive sponsor. They can read the rules and understand the logic. They can ask "Why did this query go to the expensive model?" and you can point to the exact rule that made the decision. This transparency is valuable for compliance, for cost attribution, and for trust.

## When to Evolve Beyond Rules: Traffic Volume, Cost Pressure, and Quality Demands

You outgrow rule-based routing when traffic volume makes manual rule maintenance unsustainable. If you are handling 10,000 queries per month and have ten rules, you can manage by hand. If you are handling 10 million queries per month, you cannot afford to manually tune rules every time the query distribution shifts. You need a router that adapts automatically, which means a classifier or an embedding-based router.

You outgrow rule-based routing when cost pressure demands more precision. If you are spending $10,000 per month on models and a rule-based router saves you $4,000, you are satisfied. If you are spending $500,000 per month and a rule-based router saves you $150,000 but a classifier could save you $300,000, the incremental $150,000 justifies the engineering cost of building the classifier.

You outgrow rule-based routing when quality demands exceed what simple heuristics can deliver. If your users complain that simple queries are getting routed to slow models and complex queries are getting routed to weak models, and you cannot fix it by adding more rules without creating rule conflicts, you need a smarter router.

You outgrow rule-based routing when your team has ML expertise and infrastructure to support learned routers. If you have data scientists who can train classifiers, MLOps engineers who can deploy models, and monitoring tools to track classifier performance, the operational cost of a classifier-based router is low. If you do not have that expertise, rule-based routing is the rational choice until you build the capability.

The customer support platform outgrew rules because they hit all four triggers: traffic grew from 200,000 to 800,000 queries per month, model costs grew from $67,000 to $240,000 per month, users complained about misrouting, and the team hired a machine learning engineer. The migration to a hybrid classifier-based router was overdue, and it paid off immediately.

Rule-based routing is not a failure. It is a phase. Every production system starts simple and grows in complexity as needed. Rules are the right starting point for nearly every routing problem. The mistake is not starting with rules—the mistake is staying with rules too long, adding rule after rule until the system collapses under its own weight. Know when to evolve, and evolve deliberately.

Next, we turn to embedding-based routing, where queries and models are represented as vectors in a shared semantic space and routing becomes a similarity search problem.
