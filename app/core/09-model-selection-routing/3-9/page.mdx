# 3.9 — Cost-Aware Routing: Budget Constraints and Spend-Per-Query Limits

In mid-2025, a customer support platform serving mid-market SaaS companies hit a $340,000 monthly model API bill despite budgeting only $180,000. The finance team escalated to the CEO. The engineering team investigated and found that 73% of the spend came from routing every single customer inquiry through GPT-5.1 Turbo at $15 per million input tokens and $60 per million output tokens. The queries included simple questions like "how do I reset my password" and "what are your business hours" — questions that GPT-5 Mini could answer perfectly at one-twentieth the cost. The company had no cost controls in the routing layer. Every query, regardless of complexity or business value, went to the most expensive model. When the bill spiked due to a traffic surge from a product launch, there was no mechanism to throttle spend or shift to cheaper models. The root cause was not the model choice itself but the absence of cost-aware routing. They were making selection decisions based solely on capability, ignoring the economic dimension. Cost-aware routing treats budget as a first-class constraint in the routing decision, ensuring that every dollar spent on inference delivers proportional value.

## The Per-Query Cost Limit Strategy

The simplest form of cost-aware routing is the per-query cost ceiling. You define a maximum acceptable cost for each query and route to the most capable model that fits within that limit. For a customer support use case, you might set a $0.02 cost cap per query. Given current 2026 pricing, that eliminates GPT-5 and GPT-5.1 for all but the shortest queries, but allows GPT-5, Claude Sonnet 4.5, and all smaller models. The routing logic evaluates candidate models in descending order of capability and selects the first one whose estimated cost falls below the cap. Cost estimation requires knowing the expected input and output token counts, which you can predict using historical data for similar queries or heuristics based on query length and task type.

This approach works well when queries have uniform business value. If every customer support ticket is worth roughly the same to the business, a uniform cost cap makes sense. But in practice, business value varies dramatically. A query from a enterprise customer paying $50,000 per year deserves more spend than a query from a free-tier user. A query that could result in a sale or prevent churn has higher value than a routine information request. Uniform cost caps ignore this variation and either overspend on low-value queries or underspend on high-value ones. The next step is value-based cost allocation.

Value-based allocation ties cost limits to the business value of the query. You classify queries by value tier and assign different cost caps to each tier. Tier one might be enterprise customers, high-intent sales leads, and escalated support cases with a $0.10 per query cap. Tier two might be standard customers with a $0.02 cap. Tier three might be free users and informational queries with a $0.005 cap. The routing layer looks up the user segment and query type, retrieves the corresponding cost cap, and selects the model accordingly. This ensures that high-value interactions get the best models and low-value interactions get cost-efficient models. It requires instrumentation to identify value signals at query time — user account type, subscription tier, query intent, escalation status — and it requires a policy decision about how much to spend on each segment.

## Budget Tracking and Dynamic Routing

Per-query cost caps prevent individual queries from becoming too expensive, but they do not prevent aggregate spending from exceeding the monthly budget. If traffic spikes or if routing decisions skew toward expensive models, you can still blow through your budget by mid-month. Dynamic budget-aware routing tracks cumulative spend against a time-based budget and adjusts routing thresholds as the budget depletes. You start the month with a $200,000 budget. The routing layer tracks real-time spend. If you are on track to exhaust the budget by day 20, the router starts shifting more queries to cheaper models. If you are under budget by day 20, the router can afford to route more queries to premium models.

The simplest implementation uses a spend rate target. If your monthly budget is $200,000, your daily target is roughly $6,700. At the end of each day, you compare actual spend to target. If actual spend is 20% over target, you reduce the per-query cost caps by 20% for the next day. If actual spend is 20% under target, you increase the caps by 20%. This feedback loop smooths spending over the month and prevents the cliff at month-end where you have to route everything to the cheapest models because the budget is exhausted. Users experience consistent quality throughout the month rather than a sharp drop in the final week.

A more sophisticated approach uses predictive budget pacing. You forecast remaining traffic for the month based on historical patterns and current trends. You calculate the remaining budget. You divide remaining budget by forecasted remaining queries to get the target cost per query for the rest of the month. You adjust routing thresholds to hit that target. If you have $80,000 left and expect 5 million queries, your target is $0.016 per query. You route to models that meet quality bars while staying under that cost. This approach is smoother than day-by-day corrections because it looks ahead rather than reacting to yesterday's spend.

Both approaches require real-time cost tracking. You need to log the input and output token counts for every query and multiply by the per-token price of the model used. You sum these costs in a rolling time window — last 24 hours, last 7 days, month-to-date — and expose them to the routing layer. The routing layer queries this cost tracker before making each routing decision. If the tracker reports that you are over budget, the router applies stricter cost caps. This tight feedback loop is what enables budget-aware routing. Without it, you are flying blind and the budget becomes a post-hoc report rather than a real-time constraint.

## Feature-Level and User-Level Budget Allocation

Global budgets are blunt instruments. They treat all product features and all users as equally important. In practice, some features generate revenue and some do not. Some users are paying customers and some are in free trials. Allocating the entire budget globally means low-value features and users consume budget that could go to high-value ones. The solution is budget partitioning. You divide your monthly budget across features, user segments, or both, and enforce per-partition caps.

Feature-level budgeting assigns a budget to each product surface. The chatbot feature gets $80,000 per month. The code generation feature gets $60,000. The content moderation feature gets $30,000. The onboarding assistant gets $20,000. Each feature has its own routing layer with its own cost tracking and its own thresholds. The chatbot can route to GPT-5 because it has a large budget and high user engagement. The onboarding assistant routes to Llama 4 405B because it has a smaller budget and is used infrequently. The content moderation feature routes to Claude Haiku 4 because it processes millions of items and needs to stay cheap. This allocation reflects the business value of each feature. You are explicitly deciding how much to spend on each capability.

User-level budgeting assigns a budget to each user segment. Enterprise customers get $5 per month per seat. Professional customers get $1 per month per seat. Free users get $0.10 per month per seat. The routing layer checks the user's segment and remaining budget before each query. If the user has budget remaining, the router selects the model based on standard routing logic. If the user has exhausted their budget, the router falls back to the cheapest model or returns a rate-limit error. This prevents free users from consuming resources meant for paying customers. It also creates an economic incentive for users to upgrade to higher tiers if they need more capable models.

Combined feature-and-user budgeting is the most sophisticated approach. You allocate budget to feature-segment pairs. The chatbot feature for enterprise users gets $50,000. The chatbot for free users gets $10,000. The code generation feature for professional users gets $40,000. The code generation feature for free users gets $5,000. This fine-grained allocation ensures that high-value interactions get the resources they need while low-value interactions stay within tight constraints. It requires careful policy design and ongoing adjustment as product usage patterns change, but it gives you precise control over where inference spend goes.

## The Budget Exhaustion Problem

The risk with budget-aware routing is the cliff effect. If you exhaust your budget on day 25 of the month, you have to route all remaining queries to the cheapest models for the final five days. Quality drops sharply. Users notice. Support tickets increase. Sentiment drops. You saved money but damaged the user experience. The damage is worse if it happens at a high-traffic time like month-end close for a financial application or holiday shopping for a retail application. Budget exhaustion at the worst possible moment creates the worst possible impression.

The solution is budget smoothing. Instead of spending freely until the budget is gone, you pace spending to ensure consistent quality throughout the budget period. The predictive pacing approach described earlier does this by adjusting cost caps based on forecasted remaining traffic. Another approach is the reserve budget. You set aside 10% to 20% of your monthly budget as a reserve and do not touch it unless you are in the final days of the month and under the target spend rate. This reserve acts as a buffer against traffic spikes and routing inefficiencies. If you finish the month under budget, you roll the reserve into next month's allocation. If you finish over budget, you draw down the reserve.

A third approach is tiered degradation. You define three or four quality tiers and shift routing thresholds gradually as the budget depletes. At 50% of budget remaining with 50% of the month remaining, you are on pace — no change. At 60% of budget consumed with 50% of the month elapsed, you are 10% over pace — shift 10% of queries from tier one models to tier two models. At 80% of budget consumed with 60% of the month elapsed, you are significantly over pace — shift 30% of queries to cheaper tiers. At 95% of budget consumed, you shift everything except the highest-value queries to the cheapest tier. This graceful degradation prevents the cliff and spreads the quality reduction over time and across query types, making it less noticeable to users.

Budget smoothing is not optional. If you implement cost-aware routing without smoothing, you will create a recurring quality collapse at the end of every budget period. Users will learn that your product is unreliable at month-end or quarter-end. That reputational damage is more expensive than the inference cost you saved.

## Setting Cost Budgets That Balance Quality and Spend

The hardest part of cost-aware routing is setting the budget in the first place. If you set it too low, you force the router to use cheap models that produce unacceptable quality. If you set it too high, you overspend and either blow through your funding or price yourself out of the market. The right budget is the one that delivers the minimum acceptable quality at the lowest cost, which is a product decision, not an engineering decision.

Start with a quality baseline. Run your evaluation suite against each candidate model and measure task success rate, output quality scores, and error rates. Identify the minimum acceptable performance threshold for each task type. For customer support, you might require 90% resolution rate and 4.0 out of 5.0 quality score. For code generation, you might require 85% correctness and 3.8 quality. For content moderation, you might require 95% precision and 92% recall. These thresholds define what acceptable quality means.

Next, calculate the cost to deliver that quality with each model. For a customer support query, GPT-5 delivers 94% resolution and 4.5 quality at $0.08 per query. GPT-5.1 delivers 92% resolution and 4.3 quality at $0.04 per query. GPT-5 delivers 90% resolution and 4.0 quality at $0.015 per query. GPT-5 Mini delivers 85% resolution and 3.7 quality at $0.003 per query. Claude Sonnet 4.5 delivers 91% resolution and 4.2 quality at $0.025 per query. Llama 4 405B delivers 88% resolution and 3.9 quality at $0.008 per query. Given your 90% resolution and 4.0 quality threshold, GPT-5 is the cheapest model that meets the bar, at $0.015 per query.

Now multiply by expected query volume. If you expect 10 million queries per month, the budget is $150,000 per month using GPT-5 for all queries. If that is more than you can afford, you have three options. First, lower the quality threshold and use a cheaper model. Second, reduce query volume by optimizing product design to reduce unnecessary queries. Third, implement tiered routing so only high-value queries use GPT-5 and low-value queries use Llama 4 or GPT-5 Mini. If 30% of queries are high-value and 70% are low-value, and you route high-value queries to GPT-5 at $0.015 and low-value queries to Llama 4 at $0.008, the blended cost is 0.3 times $0.015 plus 0.7 times $0.008, which is $0.0101 per query or $101,000 per month. You saved $49,000 per month by accepting slightly lower quality on low-value queries.

This analysis gives you a cost-quality frontier. You plot each routing strategy on a graph with cost on the x-axis and quality on the y-axis. You identify the strategies that are on the efficient frontier — the ones that deliver the best quality for a given cost. Strategies below the frontier are strictly worse. The budget decision is choosing a point on the frontier that your business can afford and your product can tolerate. That point changes as model pricing changes, as model capabilities improve, and as your product's quality requirements evolve. You revisit it quarterly or whenever a major model release or pricing change occurs.

## Real-Time Cost Tracking Integration

Cost-aware routing depends on accurate, low-latency cost data. The routing layer needs to know how much you have spent so far today, this week, this month. It needs to know the per-query cost of each candidate model for the current input. It needs this data in under 10 milliseconds so it does not add perceptible latency to the query path. This requires a real-time cost tracking system integrated directly into the routing layer.

The cost tracker is a service that ingests token usage logs from every inference call, calculates the cost using current per-token pricing, and aggregates it in a time-series database. The database stores per-minute, per-hour, and per-day spend totals partitioned by feature, user segment, and model. The routing layer queries this database at decision time. The query is a fast key-value lookup: give me the current day's spend for feature X and user segment Y. The response comes back in single-digit milliseconds. The router compares the result to the daily budget target and adjusts cost caps accordingly.

Cost estimation for candidate models requires predicting token usage before the query runs. You cannot know the exact output length in advance, but you can estimate it. Use historical data: for queries of similar length and task type, what is the median output token count? Use prompt engineering constraints: if your prompt instructs the model to limit the response to 500 tokens, estimate 500 tokens. Use conservative padding: estimate the 90th percentile output length rather than the median to avoid underestimating cost. Multiply estimated input tokens by the model's input price and estimated output tokens by the output price. Sum them. That is your cost estimate. If it exceeds the cost cap, do not route to that model.

Cost tracking and estimation introduce a small amount of latency and a small risk of estimation error. The latency is acceptable if you keep it under 10 milliseconds. The estimation error is acceptable if you pad conservatively and reconcile actual costs afterward. The alternative — routing without cost awareness — is unacceptable because it leads to uncontrolled spending and budget exhaustion.

## Cost-Aware Routing as a Defense Against Runaway Spending

Cost-aware routing is not just an optimization. It is a safety mechanism that prevents catastrophic spending from traffic spikes, prompt injection attacks, and misconfigured systems. In late 2025, a legal research platform experienced a prompt injection attack where a malicious user crafted a query that caused the model to generate a 15,000-token output full of hallucinated case law. The query was repeated 200,000 times in an hour using a script. The platform was routing all queries to GPT-5 at $60 per million output tokens. The 15,000-token outputs cost $0.90 each. The attack generated $180,000 in inference costs in one hour before the team noticed and shut down the API. The platform had no cost caps and no anomaly detection on spend.

If they had implemented per-query cost caps of $0.10, the router would have blocked or downgraded the expensive queries after the first few. If they had implemented budget-based rate limiting, the system would have throttled requests after detecting abnormal spend rates. Cost-aware routing with real-time monitoring would have limited the damage to a few thousand dollars instead of nearly $200,000. This is the defensive value of cost-aware routing. It ensures that even if something goes wrong — a traffic spike, an attack, a runaway prompt — the financial damage is bounded.

Traffic spikes have the same effect. A product launch, a viral social media post, or a press mention can cause query volume to increase by 10x or 100x in a matter of hours. Without cost-aware routing, you route every query to your default model and your bill explodes. With cost-aware routing, the system detects the elevated spend rate and shifts more queries to cheaper models, keeping total spend within the budget envelope. You preserve the user experience for high-value users while degrading gracefully for the surge of new users. When traffic returns to normal, the system shifts back to higher-quality models. This dynamic response to traffic variability is only possible with real-time cost tracking and budget-aware routing.

Misconfigured systems also cause runaway spending. A developer changes a prompt and accidentally removes a length constraint. The model starts generating 10,000-token responses instead of 500-token responses. The cost per query increases by 20x. Without cost-aware routing, this misconfiguration can run for days before someone notices the bill. With cost-aware routing, the system detects the cost increase immediately and either blocks the expensive queries or alerts the team. The financial exposure is limited to hours instead of days.

Cost-aware routing treats inference spend as a constrained resource and enforces limits at decision time. It turns cost from a billing surprise into a production constraint that the system respects and optimizes for. Every production routing system should have cost-aware routing as a foundational layer. It is not a nice-to-have feature. It is a requirement for operating inference workloads at scale in 2026, where model pricing varies widely and traffic is unpredictable. The teams that implement it avoid budget crises and deliver consistent quality within their economic constraints. The teams that skip it eventually face a budget crisis that forces a painful migration to cheaper models or a product shutdown.

The next subchapter covers latency-aware routing, where response time becomes the binding constraint and the routing layer selects models to meet SLA targets.
