# 2.8 â€” Structured Output Reliability: JSON Mode, Function Calling, and Schema Adherence by Model

In mid-2025, a financial services company built a transaction monitoring system that processed bank transaction descriptions and extracted structured data: merchant name, category, amount, date, and location. The team chose a high-quality language model known for excellent general reasoning. They wrote prompts that instructed the model to return valid JSON with specific field names and types. Early tests on fifty sample transactions showed perfect schema adherence. They deployed to production processing 400,000 transactions per day across twelve banks.

Within seventy-two hours, downstream systems began failing. The data pipeline expected valid JSON but received malformed output in three percent of cases. The model sometimes returned markdown-wrapped JSON instead of raw JSON. It occasionally invented extra fields not in the schema. It sometimes returned null for required fields without marking them as nullable. It returned the string "unknown" in numeric amount fields. It returned dates in inconsistent formats, sometimes ISO-8601, sometimes month-day-year, sometimes spelled out. Each malformed output crashed the parser. The team added error handling and retry logic, but retries produced different malformed outputs. The failure rate stabilized at two to four percent depending on input complexity. The system worked most of the time but failed unpredictably and cost significantly more due to retries.

The root cause was conflating generation quality with structured output reliability. The model could understand instructions and reason about transactions. It could not reliably produce syntactically valid JSON that adhered to a strict schema. The team had assumed that a smart model would follow format instructions. They learned that intelligence and format compliance are orthogonal capabilities. A model can be brilliant at reasoning and terrible at schema adherence. Structured output reliability is a distinct dimension that must be evaluated separately, with different models performing dramatically differently even when general quality is comparable.

## The Structured Output Landscape in 2026

Structured output capability in January 2026 varies widely across providers and models. OpenAI offers three mechanisms: JSON mode, which guarantees syntactically valid JSON but does not enforce schema; structured outputs with schema enforcement, which validates against a provided JSON Schema and retries internally until the output conforms; and function calling, which is a specialized form of structured output where the model generates function names and arguments conforming to declared schemas. Anthropic provides tool use, a function calling mechanism where the model decides whether to call a tool and generates arguments, and JSON mode, which encourages JSON output but does not guarantee validity. Google offers function calling with schema validation and a structured output mode for Gemini models that enforces schema adherence. Open-weight models support grammar-constrained generation through libraries like llama.cpp and guidance, which use token masking to prevent the model from generating tokens that violate the grammar.

These mechanisms differ in reliability, flexibility, and cost. OpenAI's structured outputs with schema enforcement achieve near-perfect adherence for schemas of moderate complexity. The system retries internally until the output validates, then returns the valid result. The cost is increased latency and token consumption due to retries. JSON mode guarantees valid JSON syntax but allows any structure, so the model might return a valid JSON object that does not match your expected fields. Function calling works well for simple function argument schemas but struggles with deeply nested or highly optional structures.

Anthropic's tool use is highly reliable for function calling scenarios where the model chooses among a small set of tools. Schema adherence for complex nested structures is less reliable than OpenAI's structured outputs. JSON mode is a prompt-based approach that improves JSON output rates but does not guarantee validity. Google's function calling is robust for API-style use cases with clear function signatures. Structured output mode in Gemini 3 shows strong adherence but has seen less production battle-testing than OpenAI's implementation.

Open-weight models using grammar-constrained generation achieve perfect syntactic validity because the generation process cannot produce invalid tokens. The constraint is applied at the token level, masking any token that would violate the grammar. This works well for simple JSON schemas but becomes computationally expensive for complex schemas with many optional fields or large vocabularies. Latency can increase significantly compared to unconstrained generation.

## Schema Complexity and Adherence Rates

Schema adherence rates vary dramatically by schema complexity. A simple flat object with three required string fields achieves near-perfect adherence across all capable models. A nested object with arrays of objects, optional fields, union types, and strict format requirements shows adherence rates ranging from sixty percent to ninety-nine percent depending on model and enforcement mechanism.

Define schema complexity tiers. Tier one is flat objects with one to five fields, all required, all primitive types. Example: merchant name string, amount number, date string. Adherence rate for tier-one schemas exceeds ninety-nine percent on all production models with JSON mode or structured output support. Tier two is shallow nested objects with up to three levels of nesting, some optional fields, arrays of primitives. Example: a transaction object containing a merchant object with name and category, an array of tags, and optional metadata. Adherence rate for tier-two schemas ranges from ninety-five to ninety-nine percent on flagship models with structured output enforcement, and eighty to ninety-five percent on models using prompt-based JSON mode.

Tier three is deep nested objects with four or more levels of nesting, arrays of objects, union types, conditional fields based on other field values. Example: a legal contract extraction schema with nested parties, each containing nested addresses and contact methods, arrays of clauses with nested subclauses, optional amendment sections that appear only if contract type is amendment. Adherence rate for tier-three schemas ranges from eighty-five to ninety-eight percent on OpenAI structured outputs, seventy to ninety percent on Anthropic tool use, and fifty to eighty percent on prompt-based approaches without enforcement.

The dimensions of schema complexity that stress models are depth of nesting, number of optional fields, presence of union types, format constraints on string fields, and conditional logic. Each dimension compounds difficulty. A schema with five levels of nesting, twenty optional fields, three union types, and date format constraints will fail more often than a schema with two levels, five required fields, and no format constraints.

## Evaluating Structured Output Reliability

Build a structured output test suite that covers your schema complexity tier. Generate one hundred to five hundred test cases representing the distribution of inputs you expect in production. For each test case, define the expected output structure. Run each test case through candidate models using their structured output mechanisms. Parse the output and validate against the schema. Measure schema validation rate: the percentage of outputs that parse successfully and match the schema. Measure field completeness: the percentage of expected fields that are present and non-null. Measure type correctness: the percentage of fields that have the correct type, not a string when a number is expected. Measure format correctness: the percentage of string fields that match format requirements like ISO-8601 dates or email addresses.

Also measure edge case handling. Edge cases include null values, empty arrays, special characters in strings, very large numbers, very long strings, and unusual but valid inputs. A model that achieves ninety-eight percent adherence on typical inputs but drops to seventy percent on edge cases is not reliable. Production systems encounter edge cases constantly. Your evaluation must include them.

Run the test suite at least three times per model to account for sampling variation. Structured output reliability is probabilistic. A model might succeed on the first attempt and fail on the second attempt with the same input. Measure mean adherence rate and standard deviation. A model with ninety-seven percent mean adherence and one percent standard deviation is more reliable than a model with ninety-eight percent mean adherence and four percent standard deviation. The latter is unpredictable.

Track failure modes. When the model fails to adhere to the schema, how does it fail? Does it return syntactically invalid JSON? Does it return valid JSON with missing fields? Does it return valid JSON with incorrect types? Does it hallucinate extra fields? Each failure mode requires different error handling. Syntactically invalid JSON can be caught immediately by the parser. Missing fields might be tolerable if you provide defaults. Incorrect types require type coercion. Hallucinated extra fields might be ignored or might indicate the model misunderstood the task.

## Retry Strategies When Structured Output Fails

When the model returns output that does not conform to the schema, you have three options: fail the request, retry with the same prompt, or retry with an enhanced prompt that includes the previous failed output and instructs the model to fix it. Failing the request is appropriate for non-critical tasks where partial failure is acceptable. Retrying with the same prompt works if the failure was due to sampling randomness and the model has a high probability of success on subsequent attempts. Retrying with an enhanced prompt works if the failure was due to a specific misunderstanding that can be corrected with feedback.

OpenAI structured outputs with schema enforcement retry internally, so you do not implement retry logic yourself. The API returns only valid outputs or an error if the system cannot produce a valid output within a retry limit. Anthropic tool use and Google function calling do not retry internally. You must implement retry logic. A typical retry strategy is to attempt up to three times. If the first attempt fails validation, parse the error, construct a new prompt that includes the failed output and the validation error, and retry. If the second attempt fails, repeat. If the third attempt fails, fall back to a human review queue or a default output.

Enhanced retry prompts improve success rates by ten to thirty percentage points on models that understand feedback. The enhanced prompt format is: original instruction, followed by the schema, followed by the failed output, followed by the validation error message, followed by an instruction to correct the output. Example structure in prose: you previously generated the following output, which failed validation because the date field is not in ISO-8601 format. Please generate a corrected version that adheres to the schema.

Retries cost tokens and latency. Each retry consumes input tokens for the prompt and output tokens for the attempt. If your average request costs 5,000 input tokens and 500 output tokens, and you retry twice, you consume 15,000 input tokens and 1,500 output tokens. If your schema validation rate is ninety percent, ten percent of requests incur retry cost. If the validation rate is seventy percent, thirty percent of requests incur retry cost, and some percentage of those will fail after three attempts. The cost multiplier for retries can range from 1.1 times to 2 times depending on validation rate and retry limit.

Latency also multiplies. Each retry adds one round-trip to the model. If a single request takes 1,200 milliseconds and you retry twice, the request takes 3,600 milliseconds. If your latency budget is 2,000 milliseconds, retries are not viable. You must choose a model with higher adherence or simplify the schema.

## Constrained Decoding vs Post-Processing Validation

Constrained decoding enforces schema adherence during generation by masking invalid tokens. The model cannot generate a token that would violate the grammar. This guarantees syntactic validity but requires integrating a constraint engine into the generation process. Libraries like llama.cpp with grammar support, guidance, and outlines provide constrained decoding for open-weight models. The constraint is expressed as a formal grammar, typically a variant of Backus-Naur Form or JSON Schema.

Constrained decoding is computationally expensive. The constraint engine evaluates every candidate token at every generation step to determine whether it would violate the grammar. For simple grammars this adds minimal overhead. For complex grammars with many optional branches and large vocabularies, the overhead can double or triple generation time. The trade-off is perfect validity at the cost of latency.

Post-processing validation checks the output after generation. The model generates freely, then you parse and validate. If the output is invalid, you retry or fail. Post-processing is computationally cheap but introduces retry loops. The choice between constrained decoding and post-processing depends on latency tolerance and retry budget. If you can afford the latency increase of constrained decoding, you eliminate retries and achieve deterministic validity. If you cannot afford the latency increase, you use post-processing and accept occasional retries.

Hybrid approaches combine lightweight constraints during generation with post-processing validation. For example, you might use JSON mode to encourage valid JSON syntax, reducing the syntactic error rate from fifteen percent to two percent, then validate schema adherence post-processing. This reduces retry rate without incurring the full cost of constrained decoding.

## Function Calling and Tool Use Patterns

Function calling is structured output in the context of tool use. The model decides whether to call a function, which function to call, and what arguments to pass. The arguments must conform to the function's schema. Function calling is a harder problem than general structured output because the model must perform two tasks: deciding whether to call a function, and generating valid arguments.

Evaluate function calling separately from general JSON output. Build a test suite where the model must choose among multiple functions or choose not to call any function. Measure decision accuracy: does the model call the correct function for the task? Measure argument validity: do the generated arguments conform to the function schema? Measure argument correctness: are the argument values semantically correct for the task, not just syntactically valid?

A model might achieve high argument validity but low argument correctness. Example: the function signature for send email includes to, subject, and body. The model generates a valid JSON object with all three fields as strings, achieving perfect argument validity. But it puts the recipient's name in the subject field and the subject in the body field, achieving zero percent argument correctness. Validity measures syntax. Correctness measures semantics.

Function calling reliability varies by the number of functions and the complexity of their signatures. A tool set with two functions and simple flat argument schemas achieves near-perfect reliability. A tool set with twenty functions, some with overlapping purposes and complex nested argument schemas, shows significantly lower reliability. The model confuses similar functions. It hallucinates arguments not in the schema. It omits required arguments.

If your application uses function calling extensively, choose models optimized for tool use. As of January 2026, OpenAI GPT-5.2, Anthropic Claude Opus 4.5, and Google Gemini 3 Pro all show strong function calling performance. Open-weight models lag in function calling reliability compared to their performance on general reasoning tasks. Function calling requires both understanding when to call a tool and generating structured arguments, a combination that benefits from specialized training.

## Structured Output for Extraction and Data Pipelines

Extraction tasks and data pipelines are the most common use cases for structured output. You process unstructured text, emails, documents, logs, or user input, and you extract entities, relationships, or events into structured records for downstream systems. Downstream systems expect clean, valid, consistently formatted data. They cannot tolerate malformed JSON or missing fields.

Structured output reliability often matters more than generation quality for these tasks. A model that extracts ninety-eight percent of entities accurately but produces invalid JSON four percent of the time is less valuable than a model that extracts ninety-five percent of entities accurately but produces valid JSON ninety-nine point nine percent of the time. The four percent invalid JSON crashes the pipeline. The three percent missed entities degrade quality but do not break the system.

Prioritize schema adherence over extraction recall in pipeline applications. Choose models with strong structured output enforcement even if their reasoning quality is slightly lower. Use OpenAI structured outputs or grammar-constrained generation for mission-critical pipelines. Accept the higher cost and latency to eliminate pipeline failures.

Also design schemas to be forgiving. Avoid deeply nested structures if possible. Use flat or shallow schemas. Make fields optional unless they are truly required by downstream systems. Use union types sparingly. Prefer string types with post-processing validation over strict format constraints in the schema. A model can return a date as a string in any format, and you normalize it in post-processing. This is more reliable than requiring the model to produce ISO-8601 format directly.

## The Structured Output Evaluation Matrix

Organize models by structured output tier. Tier one is no structured output support. The model generates free text. You parse it with heuristics. Reliability is low, typically fifty to seventy percent depending on prompt quality and input variability. Tier two is prompt-based JSON encouragement. The model is instructed to return JSON but has no enforcement. Reliability is seventy to ninety percent for simple schemas, lower for complex schemas. Tier three is JSON mode with syntax guarantees but no schema enforcement. Reliability for syntactic validity is ninety-eight to one hundred percent, but schema adherence is seventy-five to ninety-five percent. Tier four is structured outputs with schema enforcement or grammar-constrained generation. Reliability for both syntactic validity and schema adherence is ninety-five to one hundred percent for schemas of moderate complexity.

Map your schema complexity to the required tier. If you have a tier-one simple flat schema and can tolerate ninety percent reliability, a tier-two prompt-based approach works. If you have a tier-two schema with nesting and optional fields and require ninety-eight percent reliability, you need tier-four enforcement. If you have a tier-three complex schema and require near-perfect reliability, you need tier-four enforcement and may need to simplify the schema.

Also consider the failure cost. If a structured output failure costs pennies in retry tokens, you can tolerate lower reliability. If a structured output failure crashes a pipeline processing millions of records and requires manual intervention costing hundreds of dollars, you need maximum reliability regardless of cost.

Structured output reliability is a hard requirement for data-intensive production systems. It is not a nice-to-have. It is the difference between a system that runs and a system that fails unpredictably. Evaluate it rigorously. Test it on real schemas and real input distributions. Measure validation rates, field completeness, type correctness, and edge case handling. Choose models and mechanisms that meet your reliability threshold, then optimize for cost and quality within that subset.

With structured output reliability evaluated, you now have a complete picture of the operational constraints: cost per task, latency budget, context window requirements, and schema adherence. The next dimension is reasoning capability, where you assess whether the model can actually solve the problem, the subject of the next chapter.
