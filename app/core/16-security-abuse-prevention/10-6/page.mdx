# 10.6 — LLMjacking: Compute Theft and API Resale

In November 2025, Pillar Security documented the first attributed LLMjacking operation: Operation Bizarre Bazaar. Over ninety-one thousand attack sessions targeted AI infrastructure across dozens of organizations. The stolen compute wasn't used to train models or run internal experiments. It was packaged and sold on criminal marketplaces at a forty to sixty percent discount compared to legitimate API providers. Buyers could access GPT-5, Claude Opus 4.5, and Gemini 3 Pro through a simple web interface, paying with cryptocurrency, no questions asked. The sellers had zero infrastructure costs. They were reselling access to compute they'd stolen from companies that had already paid for it.

LLMjacking is the industrial-scale theft of AI compute resources for profit. Unlike other attacks where the goal is disruption or data exfiltration, LLMjacking operators want your infrastructure to keep running. They need it operational so they can resell it to their customers. The longer they remain undetected, the more money they make. The victim organization pays for the compute twice: once to the cloud provider for the stolen usage, and again to investigate and remediate the breach.

This is the business model that will define AI security incidents in 2026 and beyond. The attacker who steals a database can sell it once. The attacker who steals access to your AI infrastructure can sell it continuously until you discover and revoke their access. The economics are so favorable that LLMjacking has become the primary motivation for targeting AI systems, surpassing data theft and model extraction in observed attack volume.

## What LLMjacking Is

LLMjacking is unauthorized use of AI compute resources with the intent to resell that compute to third parties. The attacker gains access to your model deployments, your API keys, your inference infrastructure — whatever allows them to generate predictions or completions. They then build a proxy service that accepts requests from their customers and forwards them to your infrastructure. The requests appear to come from your compromised credentials, so your logging shows normal usage patterns. The attacker's customers get access to expensive models at a fraction of the retail price. The attacker pockets the difference. You pay the bill.

The attack chain typically has three components. First, the initial compromise: the attacker obtains credentials or access to your AI infrastructure through phishing, exposed secrets, insider access, or supply chain compromise. Second, the proxy infrastructure: the attacker builds a service that mimics the API of major model providers but routes all requests through your compromised access. Third, the marketplace: the attacker lists their proxy service on criminal forums or dedicated platforms where buyers can purchase access using cryptocurrency or other hard-to-trace payment methods.

The sophistication of these operations varies. Low-end LLMjacking operations are simple Python scripts that forward OpenAI API calls through a stolen key. High-end operations, like Bizarre Bazaar, built full web platforms with user accounts, usage dashboards, rate limiting, and customer support. They accepted payment in multiple cryptocurrencies. They offered service level guarantees. They marketed themselves as privacy-focused alternatives to mainstream AI services, attracting users who wanted to avoid content moderation or usage tracking. The platform operators never disclosed that the underlying compute was stolen.

## The Criminal Marketplace Economy

The economics of LLMjacking are simple and brutal. A legitimate GPT-5 API call costs approximately three cents per thousand input tokens and twelve cents per thousand output tokens as of early 2026. An attacker reselling stolen access charges forty to sixty percent of that — roughly one cent for input tokens and five cents for output tokens. The margin is pure profit because the attacker has no infrastructure costs. They're not running servers. They're not paying for model access. They're forwarding requests through your compromised credentials and pocketing the difference between what their customer pays and zero.

From the buyer's perspective, the value proposition is compelling if you ignore the legal and ethical problems. They get access to frontier models at a steep discount. They can submit queries that would violate the terms of service of legitimate providers — no content moderation, no usage monitoring, no compliance checks. If the stolen access gets burned, they lose their account on the criminal marketplace, but they were already operating pseudonymously with cryptocurrency, so they simply create a new account and resume usage.

The Bizarre Bazaar operation demonstrated the scale this can reach. Over a three-month period before detection, the marketplace processed an estimated eight million API requests across multiple compromised accounts. The operators generated approximately two hundred fifty thousand dollars in revenue. The victim organizations paid over six hundred thousand dollars in actual compute costs to their cloud providers. The gap between revenue and costs exists because the criminals underpriced to gain market share and because some of the requests were lower cost than average. But the fundamental asymmetry remains: the attacker captures value without bearing costs, and the victim bears costs without capturing value.

## Attack Vectors: Credential Theft and Key Exposure

The initial compromise for LLMjacking operations follows predictable patterns. The most common vector is exposed API keys in public repositories, CI/CD logs, or client-side code. A developer commits code to GitHub with a hardcoded API key in the source. Automated scanning tools operated by attackers detect the key within minutes. The attacker tests the key, confirms it works, and adds it to their rotation. By the time the developer realizes the mistake and rotates the key, the attacker has already used it to process thousands of requests.

Phishing operations target employees with access to model deployment credentials. The attacker sends a fake security alert, a fake API documentation update, or a fake meeting invite with a malicious link. The employee enters their credentials on a phishing page. The attacker immediately tests the credentials against known AI service endpoints. If they work, the credentials go into production for the resale operation within hours. The employee might not realize they were compromised until anomalous usage triggers billing alerts days or weeks later.

Supply chain compromise provides another entry point. Third-party packages, especially those that wrap AI APIs or provide SDK functionality, can be trojaned to exfiltrate credentials. The attacker publishes a malicious version of a popular package or compromises an existing maintainer account. Organizations that auto-update dependencies pull the malicious version. The package reads environment variables containing API keys and transmits them to attacker-controlled infrastructure. The attacker waits a few days before using the keys to avoid immediate correlation between the package update and the suspicious usage.

Insider access, whether from malicious employees or from attackers who have gained persistent access through other means, represents the highest-risk vector because it's the hardest to detect. An attacker with access to your secrets management system, your environment configuration, or your deployment manifests can rotate through credentials as they're rotated, maintaining persistent access for months. They're not relying on a single stolen key that gets revoked — they have access to the process that generates new keys.

## Proxy Injection and Traffic Obfuscation

Once the attacker has credentials, they need to use them without triggering abuse detection. The simplest approach is direct forwarding: accept a request, forward it to the victim's infrastructure using stolen credentials, return the response. This works but creates detectable patterns. All requests appear to come from the same compromised account. Traffic volume spikes. Geographic anomalies appear if the attacker's customers are in different regions than the victim's normal users.

More sophisticated operations use proxy injection to blend malicious traffic with legitimate traffic. The attacker compromises multiple accounts across multiple organizations. They spread their resale traffic across all of these accounts, keeping each one below suspicious volume thresholds. An individual account might show a twenty percent increase in usage — noticeable if you're looking, but not immediately alarming. Across ten compromised accounts, the attacker can process significant volume while keeping each account below the detection threshold.

Traffic obfuscation techniques add another layer of defense against detection. The attacker's proxy adds delays between requests to match the timing patterns of legitimate users. They vary prompt content to avoid repetition. They rotate through different user agent strings, IP addresses, and request headers to make each request look like it's coming from a different client. If your detection relies on identifying unusual patterns in request metadata, these obfuscation techniques can significantly delay discovery.

The most advanced operations integrate directly into their customers' applications rather than operating as standalone proxies. The attacker provides an SDK or API wrapper that looks and works like a legitimate AI service SDK. Their customers integrate it into their products. The SDK automatically routes requests through the stolen credentials without the customer even knowing the compute is stolen. The attacker can process thousands of requests per day across dozens of victim accounts while maintaining the appearance of normal, distributed usage from many different sources.

## Detection Challenges and Legitimate-Looking Traffic

The core challenge in detecting LLMjacking is that the traffic is, by design, legitimate-looking. The attacker is making real API calls with valid credentials. The prompts are normal user queries — the attacker's customers are using the stolen compute for the same purposes they would use legitimate compute. The requests pass authentication. They don't exploit vulnerabilities. They don't trigger rate limits. They just cost you money.

Traditional security controls don't apply. Intrusion detection systems won't fire because there's no malicious payload. Web application firewalls won't block because the requests are well-formed. Authentication logs show successful logins with correct credentials. The only signal is behavioral: usage that doesn't match your expectations for that account, that user, or that application.

Behavioral detection requires baselines. You need to know what normal looks like for each API key, each service account, each application. If a key that normally processes ten thousand requests per day suddenly processes fifty thousand, that's a signal. If an application that typically runs batch jobs during off-hours starts making real-time queries twenty-four hours a day, that's a signal. If requests from a particular key start coming from geographic regions where you have no users or infrastructure, that's a signal.

But these signals are noisy. Legitimate usage changes all the time. A marketing campaign drives unexpected traffic. A new feature launches and changes usage patterns. A data science team starts a new experiment. You can't block every anomaly without disrupting legitimate work. The attacker knows this and exploits it by keeping their usage within the range that might be explained by legitimate changes.

The most reliable signal is cost anomalies correlated with usage anomalies. If a key's usage doubles and its cost triples, something changed about the type of requests being made. If an account starts making requests with much longer output tokens than its historical average, someone is using it differently than before. If multiple keys across different projects all show synchronized usage increases at the same time, especially if those keys are managed by different teams, you're likely seeing a credential compromise that affects multiple systems.

## Financial Impact and Response Time

The financial damage from LLMjacking scales linearly with time to detection. Every day the attacker has access, they process more requests and generate more cost. Unlike a data breach where the damage is bounded by the size of the dataset that was exposed, LLMjacking has no natural upper limit. The attacker can continue reselling access until you discover and revoke it.

Observed detection times in the Bizarre Bazaar cases ranged from three days to forty-seven days. The three-day cases were organizations with aggressive cost monitoring and automated alerting on usage spikes. The forty-seven-day cases were organizations that only reviewed billing monthly and didn't notice the anomaly until the invoice arrived. The financial difference was proportional: organizations that detected quickly lost thousands of dollars; organizations that detected slowly lost tens or hundreds of thousands.

Response time after detection matters just as much. Revoking a single compromised key is fast. Revoking all keys and rotating all credentials across your entire infrastructure takes hours or days. During that window, the attacker might still have active access through credentials you haven't rotated yet. Organizations that respond to LLMjacking with piecemeal key rotation often discover weeks later that the attacker had access through multiple vectors and some of those vectors weren't addressed in the initial response.

The correct response is comprehensive credential rotation, forensic investigation to determine how the compromise occurred, and architectural changes to prevent recurrence. This isn't a quick fix. It's a multi-day or multi-week incident response process. During that process, your development teams can't deploy, your CI/CD pipelines might be frozen, and your production services might need emergency patches to use new credentials. The operational cost of remediation often exceeds the direct financial cost of the stolen compute.

## Prevention Through Architecture

The long-term defense against LLMjacking isn't better monitoring or faster detection — it's architecture that limits the blast radius of any single compromised credential. If a single API key can be used to process unlimited requests with unlimited cost, that key is a single point of failure. The attacker who compromises it can do unlimited damage until you notice and respond.

Key-level rate limiting provides a first layer of defense. Each key should have a maximum request rate and a maximum cost per time window. If a key exceeds its limit, requests are rejected regardless of whether the usage is legitimate or malicious. This doesn't prevent LLMjacking, but it caps the damage per compromised key. The attacker who wants to process a million dollars of stolen compute needs to compromise a hundred keys if each key is limited to ten thousand dollars per month.

Principle of least privilege applies to model access. Not every key needs access to every model. Not every service account needs to call GPT-5 or Claude Opus 4.5. If your internal analytics pipeline only needs access to a small fine-tuned model, the credentials it uses should be scoped to only that model. The attacker who compromises those credentials can't use them to resell access to frontier models because the credentials don't have that capability.

Geographic and network-based restrictions add another layer. If a particular key should only ever be used from your production VPC or specific egress IPs, enforce that at the authorization level. Requests from other locations should be blocked, logged, and investigated. This doesn't help if the attacker compromises infrastructure inside your network, but it prevents the most common scenario where stolen keys are used from attacker-controlled infrastructure outside your environment.

Continuous authentication for high-value operations moves beyond static keys to dynamic, short-lived credentials. Instead of an API key that lasts forever, use tokens that expire after minutes or hours and must be refreshed through an authenticated process. The attacker who steals a token gets a limited window of access. By the time they integrate it into their resale infrastructure, the token is expired. They need to compromise the token issuance process itself, which is a much harder target than stealing a static key from a developer's laptop.

## The Next Ten Years of LLMjacking

Operation Bizarre Bazaar is the first publicly attributed, large-scale LLMjacking campaign. It will not be the last. The economics are too favorable, the attack surface is too large, and the detection is too difficult. As AI inference becomes more expensive and more central to business operations, the value of stolen compute increases. The attacker who can reliably steal and resell AI access has found a sustainable criminal business model that scales with the growth of the AI industry itself.

The defense is not a single control or a silver bullet technology. It's the combination of monitoring, architecture, response capabilities, and organizational discipline. Monitor for cost anomalies and usage anomalies continuously. Design architecture that limits blast radius of compromised credentials. Build response capabilities to rotate credentials comprehensively and quickly when compromise is detected. Maintain discipline around secrets management, credential hygiene, and least privilege access.

The organization that treats API keys as high-value secrets equivalent to production database credentials will fare better than the organization that treats them as configuration parameters. The organization that can detect and respond to credential compromise in hours will lose thousands where others lose hundreds of thousands. The organization that architects for compromise, assuming that some credentials will eventually be stolen, will survive LLMjacking incidents that would be catastrophic for organizations that assume perfect prevention.

The next category of defense moves from preventing attacks to surviving them. Rate limiting, quotas, and throttling determine how much damage an attacker can do even when they have valid credentials and legitimate-looking traffic.

