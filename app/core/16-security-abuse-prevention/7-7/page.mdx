# 7.7 — Multi-Tenancy Access Isolation

The attacker is not always an outsider trying to break in. Sometimes they are already inside — as a legitimate user of Tenant B trying to access Tenant A's data. In multi-tenant AI platforms, the most dangerous vulnerability is not a sophisticated exploit. It is a missing WHERE clause. A forgotten tenant ID filter. A context variable that defaults to null instead of rejecting the request. These are the mistakes that leak customer data across tenant boundaries, destroy trust instantly, and end careers.

Multi-tenancy in AI systems is fundamentally different from traditional SaaS multi-tenancy. Traditional applications isolate database rows. AI platforms must also isolate models, embeddings, fine-tuning jobs, retrieval indexes, prompt templates, conversation history, feedback data, and the runtime inference context that flows through every request. The attack surface is larger. The failure modes are subtler. And when isolation breaks, the blast radius is total.

## The Three Isolation Boundaries

Multi-tenant AI platforms operate across three isolation boundaries, each with different trade-offs between security, cost, and operational complexity. **Data isolation** means tenant data is stored separately — different database schemas, different S3 prefixes, different vector indexes. Every query includes a tenant filter. Every write operation validates tenant ownership. This is the minimum standard. If your platform does not enforce data isolation at the storage layer, you do not have a secure multi-tenant system. You have a data breach waiting to happen.

**Model isolation** means each tenant gets their own fine-tuned model, their own embedding model, or their own inference endpoint. This prevents one tenant's fine-tuning data from leaking into another tenant's responses. It prevents prompt injection attacks in one tenant from affecting another tenant's results. But it also multiplies your infrastructure costs. If you have 500 tenants and each needs a dedicated fine-tuned GPT-5.1 model, you are managing 500 model deployments, 500 sets of weights, and 500 independent scaling configurations. Model isolation is the most expensive form of isolation and the hardest to scale.

**Compute isolation** means tenants run on separate infrastructure — different Kubernetes namespaces, different GPU pools, different API rate limit buckets. This prevents one tenant's burst traffic from throttling another tenant's requests. It prevents a denial-of-service attack in one tenant from cascading across your platform. But it introduces operational complexity. You now have per-tenant capacity planning, per-tenant autoscaling, and per-tenant cost allocation. Most platforms do not need full compute isolation. But high-value enterprise customers will demand it, especially in regulated industries where shared compute infrastructure creates audit risk.

The decision of which isolation boundaries to enforce is not technical. It is a product decision that balances security requirements, customer expectations, cost structure, and operational maturity. A startup serving 20 customers can afford full model and compute isolation. A platform serving 10,000 customers cannot. But every platform, regardless of scale, must enforce data isolation. That boundary is non-negotiable.

## Tenant Context as a First-Class Primitive

The most common cause of cross-tenant data access is not a sophisticated exploit. It is **context loss** — the tenant ID gets dropped somewhere in the request chain and the system defaults to returning all data instead of no data. This happens when tenant context is passed as a parameter instead of enforced as a primitive. In a secure multi-tenant system, tenant context is not something you remember to add to your queries. It is something the system refuses to execute without.

Every request must carry tenant context from the moment it enters the system until the moment it returns a response. This means the authentication layer extracts the tenant ID from the user's token and injects it into a request context object that flows through every downstream service. The authorization layer validates that the user belongs to the claimed tenant before allowing the request to proceed. The data layer enforces tenant filtering at the ORM level, not at the application level. If a developer writes a query that does not include a tenant filter, the query is rejected by the database driver before it executes.

This is not paranoia. This is the only architecture that prevents accidental cross-tenant access. Developers make mistakes. Code review misses things. A single forgotten tenant filter in a reporting query can expose every customer's data to every other customer. The defense is to make it impossible to write a query that does not include tenant context. If your ORM does not support tenant-scoped connections, write a wrapper that does. If your vector database does not support tenant-scoped indexes, partition your data at ingestion time and enforce partitioning at query time. The operational cost of this enforcement is high. The cost of a cross-tenant data leak is total.

## Preventing Cross-Tenant Model Access

Data isolation prevents one tenant from reading another tenant's stored data. But in AI systems, data also flows through models, embeddings, and retrieval pipelines. A tenant's data can leak in four ways: through shared embeddings, through shared retrieval indexes, through fine-tuning on shared base models, and through prompt injection that manipulates cross-tenant context.

**Shared embeddings** are the most common source of cross-tenant leakage. If you generate embeddings for Tenant A's documents and Tenant B's documents using the same embedding model, and then store both sets of embeddings in the same vector index, a similarity search for Tenant B might return Tenant A's documents if the embeddings are close enough. The mitigation is simple but non-negotiable: every vector index must be tenant-scoped. Either you partition the index by tenant ID and enforce the partition filter at query time, or you create separate indexes per tenant. The first approach scales better. The second approach is simpler to secure.

**Shared retrieval indexes** create the same problem at a different layer. If your RAG pipeline retrieves documents from a shared index and relies on application-level filtering to remove cross-tenant results, you are one missing filter away from leaking customer data. The retrieval layer must enforce tenant isolation before results are returned to the application. This means every retrieval query includes a tenant filter that the retrieval engine enforces at the index level, not at the re-ranking level. If your retrieval engine returns 100 candidates and then filters to 10 after checking tenant ownership, you have already exposed 90 candidates to the wrong tenant in your logs, your metrics, and your debugging traces.

**Fine-tuning on shared base models** introduces a subtler risk. If Tenant A fine-tunes a model on their proprietary data, and then Tenant B fine-tunes the same base model on their data, Tenant B's model may retain traces of Tenant A's fine-tuning. This is not a hypothetical risk. Research from 2024 and 2025 consistently shows that sequential fine-tuning on the same base model allows later fine-tuning jobs to recover information from earlier jobs through careful prompting. The mitigation is to isolate fine-tuning jobs by starting from the original base model for every tenant, never from another tenant's fine-tuned checkpoint. This multiplies storage costs but eliminates cross-tenant model leakage.

**Prompt injection across tenant boundaries** happens when an attacker in Tenant A crafts a prompt designed to retrieve information about Tenant B by exploiting shared system prompts, shared retrieval context, or shared conversation history. The defense is to treat tenant context as a security boundary in every prompt. If your system prompt includes examples, those examples must be tenant-scoped. If your retrieval context includes metadata, that metadata must be tenant-filtered. If your conversation history includes past interactions, those interactions must belong to the current tenant. Any shared content — system instructions, retrieval results, few-shot examples — must be validated for tenant ownership before being included in the prompt.

## The Shared Infrastructure Trust Model

Multi-tenant AI platforms run on shared infrastructure. Shared API gateways, shared Kubernetes clusters, shared GPUs, shared vector databases, shared observability pipelines. This creates a **trust model problem**: how much do you trust the infrastructure to enforce isolation, and how much do you enforce at the application layer?

The answer depends on your threat model. If your threat model includes malicious infrastructure operators, you need end-to-end encryption, tenant-specific encryption keys, and application-layer enforcement of every isolation boundary. If your threat model includes compromised infrastructure but not malicious operators, you need strong access controls, audit logging, and infrastructure-layer isolation backed by application-layer validation. If your threat model is limited to accidental cross-tenant access by legitimate users, application-layer isolation is sufficient.

Most platforms operate in the second category. They trust their infrastructure team but assume infrastructure can be compromised. This means the application enforces tenant isolation even when the infrastructure is shared. Every query includes a tenant filter. Every API call includes a tenant header. Every log line includes a tenant ID. Every metric is tagged by tenant. This redundancy seems wasteful. It is not. It is the defense-in-depth that prevents a single compromised service from leaking data across tenant boundaries.

But redundancy only works if every layer enforces isolation independently. If the application relies on the database to enforce tenant filtering, and the database relies on the application to pass the correct tenant ID, neither layer is actually enforcing isolation. Both are trusting the other. The secure model is that every layer enforces tenant isolation as if every other layer is compromised. The authentication layer validates the tenant. The authorization layer validates the tenant. The data layer validates the tenant. The observability layer validates the tenant. Each validation is independent. Each validation fails closed. If any layer cannot determine the tenant, the request is rejected.

## Tenant Context in Agent Workflows

Agents complicate multi-tenancy because they operate asynchronously, across multiple turns, with internal planning steps that may not carry explicit tenant context. An agent starts processing a task for Tenant A, makes a tool call that spawns a background job, and then retrieves results hours later. If the background job does not carry tenant context, it might access data from Tenant B. If the result retrieval does not validate tenant context, it might return data to the wrong tenant.

The mitigation is to treat tenant context as immutable state that flows through every agent action. When an agent workflow begins, the system captures the tenant ID from the initiating request and stores it in the workflow state. Every tool call the agent makes includes the tenant ID as a parameter. Every retrieval the agent performs includes the tenant ID as a filter. Every result the agent returns is validated against the original tenant ID before being presented to the user. If tenant context is missing at any step, the workflow fails immediately rather than proceeding with default or inferred context.

This creates operational complexity. Agent workflows that span hours or days must persist tenant context across multiple service restarts, database failovers, and infrastructure migrations. The workflow engine must guarantee that tenant context survives every failure mode. This is why agent platforms that support multi-tenancy use workflow engines with durable state — systems like Temporal, AWS Step Functions, or Kubernetes operators that persist workflow state to durable storage and rehydrate it on every step. If your agent framework does not support durable workflow state, your multi-tenant agents are a data leak waiting to happen.

## Testing Cross-Tenant Isolation

You cannot verify multi-tenant isolation by inspection. You must test it. This means **adversarial tenant testing** — running tests where Tenant A actively tries to access Tenant B's data using every available API, query path, and workflow. These tests should cover every isolation boundary: data queries, model inference, retrieval pipelines, fine-tuning jobs, conversation history, feedback data, audit logs, and billing records. If any test succeeds in accessing cross-tenant data, you have a critical vulnerability.

The most effective isolation tests are automated and run on every deployment. They use real tenant accounts, real API keys, and real data. They attempt to access cross-tenant data through direct queries, through parameter tampering, through missing filters, through default values, and through edge cases like null tenant IDs or wildcard tenant selectors. They verify that every API endpoint rejects cross-tenant requests with a 403 Forbidden response, not a 500 Internal Server Error that might leak information about the existence of the other tenant's data.

But automated tests only catch the vulnerabilities you thought to test for. The vulnerabilities you did not think of are the ones that appear in production. This is why mature multi-tenant platforms also run periodic **manual red-team exercises** where a security engineer with Tenant A credentials spends a day trying to break into Tenant B's data. They inspect logs, manipulate API parameters, exploit race conditions, and probe every shared service for isolation failures. The results of these exercises inform the next round of automated tests. The loop never ends.

Multi-tenancy is not a feature you build once and declare complete. It is an ongoing operational discipline. Every new feature, every new API endpoint, every new shared service introduces new cross-tenant attack surface. The only defense is continuous testing, continuous enforcement, and continuous paranoia that the next missing tenant filter is one commit away.

Your audit logs record who accessed what, when they accessed it, and whether access was granted or denied. The next subchapter, 7.8 — Audit Trails and Access Logging, covers how to build immutable audit logs, what to log at every access decision, and how to use those logs to detect anomalies and investigate incidents when isolation inevitably fails.
