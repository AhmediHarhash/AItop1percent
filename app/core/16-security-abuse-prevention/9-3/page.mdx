# 9.3 â€” Action Loops and Infinite Recursion

The operations team noticed it at 6 AM when the AWS bill alert fired. The customer service agent had spent $47,000 overnight on API calls. When they pulled the logs, they found that the agent had executed the same sequence 186,000 times: retrieve customer profile, analyze sentiment, update CRM record, retrieve the same customer profile again. The agent was stuck in a loop. It had been trying to complete a single support ticket for nine hours. The ticket was still open.

Action loops are what happens when an agent cannot recognize that it has already attempted a solution and failed. The agent executes an action, evaluates the result, determines that the goal has not been achieved, and executes the same action again. And again. And again. Until something external stops it. The loop might be caused by a logic error in the agent's decision process. It might be caused by an adversarial prompt designed to trap the agent in infinite recursion. Or it might be caused by the agent's fundamental architecture: it has no memory of what it has already tried, so it tries the same approach repeatedly, each time expecting a different outcome.

This is not a theoretical edge case. It is one of the most common failure modes in production agent systems in 2026. And it is a security vulnerability, not just an operational bug. An attacker who can induce a loop can cause resource exhaustion, service degradation, and financial damage without ever gaining unauthorized access to your systems.

## Why Agents Get Stuck

Agents operate in cycles. Perceive the environment, decide on an action, execute the action, observe the result, repeat. This cycle is productive when each iteration moves the agent closer to completing its goal. It becomes a loop when the agent cannot detect that it is making no progress.

The most basic loop occurs when the agent lacks the capability to complete the task but does not know it. An agent asked to translate a document into a language it does not support might repeatedly attempt the translation, produce nonsense output, evaluate the output as incorrect, and try again. The agent knows it failed. But it does not know why it failed, and it does not know that retrying the same approach will always fail. The agent is optimistic. It assumes that persistence will eventually produce success.

A more insidious loop occurs when the agent has partial success. An agent updating a database might successfully write the first 80% of a transaction but fail on the final step due to a constraint violation. The agent sees that the goal is not achieved, rolls back the partial transaction, and tries again. Same result. Rollback. Retry. The agent is doing exactly what it was designed to do: persist until success. But success is impossible, and the agent cannot detect that.

The most dangerous loop is the one induced by adversarial prompts. An attacker embeds instructions that tell the agent to validate its output by recursively invoking itself. The agent produces output, passes it to a new instance of itself for validation, which produces new output, which gets passed to another instance for validation, which produces more output. Each validation step costs money and consumes resources. The agent never reaches a terminal state because the terminal state is always one more validation away.

## Resource Exhaustion as a Service Denial

A looping agent is a denial-of-service attack against your own infrastructure. Every iteration consumes API credits, compute time, database connections, and log storage. If the loop runs fast enough, it can exhaust rate limits, max out your infrastructure budget, or fill disk space with log files. And because the agent is using legitimate credentials and making legitimate API calls, traditional DDoS defenses do not stop it.

In March 2025, a SaaS company deployed an agent to auto-respond to customer emails. The agent was designed to fetch the email, analyze it, generate a response, and send it. A customer sent an email that included an adversarial prompt instructing the agent to send a confirmation email for every email it processed. The agent complied. It sent a confirmation. The confirmation triggered the agent again because it arrived as a new email. The agent sent another confirmation. Loop. Within 40 minutes, the agent had sent 14,000 emails to the same customer. The email provider flagged the account for spam. The company's email deliverability dropped to 23% for the next two weeks while they worked through the reputation recovery process.

The financial damage from resource exhaustion loops can be extreme. An agent that calls a paid API in a loop can burn through a monthly budget in hours. An agent that writes to a database in a loop can generate millions of rows of garbage data, slowing queries and triggering storage scaling that costs real money. An agent that invokes other agents in a loop can create a cascading resource consumption pattern where every node in the system is spending all its resources trying to complete a task that will never finish.

Worse, the loop might not be visible until the bill arrives. If your monitoring is based on aggregate metrics, a looping agent looks like heavy but legitimate usage. If your monitoring is based on error rates, a looping agent that completes each iteration successfully shows zero errors. The only signal is resource consumption, and if you do not have aggressive cost alerting in place, you do not know you are under attack until the credit card charge posts.

## The Try Harder Trap

Agents are designed to be persistent. If a task fails, the agent is supposed to try alternative approaches. This is valuable when the agent is solving a genuinely hard problem where multiple strategies might succeed. It becomes a trap when the agent interprets every failure as a signal to escalate effort rather than abort.

The try harder trap is what happens when an agent has a preference for action over inaction. Faced with ambiguity or failure, the agent defaults to trying something rather than stopping and asking for help. This bias is baked into most agent frameworks because the primary complaint from early users was that agents gave up too easily. So the frameworks were tuned to be more persistent. Now they are too persistent.

An agent asked to retrieve data from an API that is temporarily down might retry the request every few seconds, escalating to every second, then multiple times per second, effectively DDoSing the API until it comes back online or until something external stops the agent. The agent is not malicious. It is just trying to complete its task. But its persistence creates a secondary failure: the API stays down longer because the agent is hammering it with requests.

An agent asked to debug a failing test might try modifying the code, running the test, seeing it fail, modifying the code differently, running it again, seeing it fail again, and continuing this loop for hours. Each iteration is a legitimate attempt to fix the problem. But if the root cause is environmental, not code-related, the agent will never succeed. And because the agent does not have a model of what constitutes "enough attempts," it just keeps trying.

The try harder trap is particularly dangerous when the agent has access to escalating levels of privilege. An agent that cannot complete a task with user-level permissions might attempt to elevate to admin permissions. If that fails, it might attempt to modify the permissions system itself. If that fails, it might attempt to create a new admin account. Each escalation is logged as a legitimate action because the agent has the authority to take these actions. But the sequence reveals that the agent is stuck and escalating in ways that create security risk.

## Adversarial Loop Injection

An attacker who understands how an agent makes decisions can craft prompts that intentionally induce loops. The goal is not to exfiltrate data or gain access. The goal is to waste resources, degrade service quality, or cause operational chaos that distracts from other attacks.

The simplest adversarial loop is the self-reference. An attacker includes instructions that tell the agent to verify its output by re-evaluating the input. The agent generates a response, passes the response back to itself as input, generates a new response, passes that back as input, and loops indefinitely. Each cycle looks like legitimate processing. The agent is following instructions. It just happens to be instructions that lead nowhere.

A more sophisticated attack embeds loop conditions in data the agent processes. An attacker uploads a document that tells the agent to validate every sentence by cross-referencing it with three external sources. For each source, the agent must validate that the source itself is trustworthy by checking two additional sources. For each of those, the agent must validate trustworthiness by checking two more sources. The agent is now executing exponential lookups. A document with 50 sentences triggers tens of thousands of validation checks. The agent is doing what it was told. The attacker is consuming your API budget.

Another variant is the conditional loop. The attacker includes instructions that tell the agent to retry any action that does not meet a success condition that is subtly impossible to satisfy. The agent executes the action, evaluates success, determines it has not been met, retries. The condition might be something like "ensure the response contains no words longer than six letters." The agent generates a response, checks word lengths, finds words with seven or eight letters, regenerates the response, checks again, finds different long words, regenerates. The loop is bounded only by the agent's retry limit, if one exists.

## Loop Detection and Circuit Breakers

The only reliable defense against action loops is automated loop detection and circuit breakers. You cannot rely on humans to notice that an agent is stuck. Humans check dashboards every few minutes or hours. Agents loop every few seconds. By the time a human notices, the damage is done.

Loop detection requires tracking agent state across iterations. If the agent executes the same action three times in a row with the same parameters and the same result, that is likely a loop. If the agent alternates between two actions repeatedly without making progress toward a goal, that is likely a loop. If the agent's cost-per-task suddenly spikes by an order of magnitude, that is likely a loop. The detection logic has to be fast, automated, and conservative. Better to kill a legitimate long-running task than to let a loop burn through your budget.

Circuit breakers are the enforcement mechanism. When a loop is detected, the circuit breaker stops the agent, logs the state, and alerts the operations team. The agent does not get to finish. It does not get to try one more time. It stops immediately, even if it is in the middle of a transaction. The cost of interrupting a legitimate task is measured in lost work. The cost of allowing a loop to continue is measured in thousands of dollars per hour.

Circuit breakers should be tuned per agent and per task type. A data analysis agent that legitimately processes thousands of records might trigger a naive loop detector. A customer service agent that should never execute the same action more than twice in a row can have a much tighter threshold. The goal is not to eliminate all retries. It is to eliminate unbounded retries.

The most effective circuit breakers are cost-based. Set a maximum cost-per-task. If the agent exceeds that cost, stop it. The limit can be high enough to allow for legitimate expensive tasks but low enough to catch loops before they cause serious damage. A task that should cost five dollars but has consumed fifty dollars is probably stuck. Stop it, investigate, fix it, restart it.

## Cost Control as Security Control

In 2026, cost control is not just an operational concern. It is a security control. An attacker who can cause your agent to loop has found a way to convert your infrastructure budget into their attack budget. Every dollar you spend on pointless API calls is a dollar you cannot spend on legitimate operations.

The organizations that treat cost monitoring as a financial concern rather than a security concern are the ones that wake up to five-figure bills after an adversarial loop attack. The organizations that treat cost spikes as potential security incidents are the ones that detect and stop the attack in minutes. Cost anomaly detection should trigger security alerts, not just finance alerts. A sudden 10x increase in agent spending is not a budgeting error. It is a symptom of something wrong, and that something might be an attack.

This requires integrating cost monitoring into your security operations. Your SIEM should ingest cost data. Your incident response playbook should include cost-based triggers. Your agent runtime should enforce cost limits at the execution layer, not just at the billing layer. If an agent tries to spend more than its allocated budget, it should be stopped before the charges accrue, not flagged after the bill arrives.

The most mature organizations in 2026 treat every agent as a cost center with a budget, a spending rate, and a monitoring dashboard. Agents that exceed their budget are automatically suspended until a human reviews them. Agents that show cost patterns inconsistent with their task type are flagged for investigation. This is not just operational hygiene. It is the most reliable signal for detecting when an agent is compromised, stuck, or under adversarial control.

The next subchapter examines tool privilege escalation: how agents gain access to capabilities they should not have, and the security boundaries that fail to contain them.
