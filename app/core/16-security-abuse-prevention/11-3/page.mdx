# 11.3 â€” MCP Server and Plugin Risks

Most developers see extensions as conveniences. Install a package, enable a plugin, and your AI system gains a new capability: access to a database, integration with a tool, or connection to an external API. The installation takes thirty seconds. The plugin works immediately. What the developer does not see is that the plugin now has access to every prompt, every model response, and every piece of context the system processes. The plugin can read your data, modify outputs, make external network calls, and execute arbitrary code. The convenience is real. So is the risk.

MCP servers and plugins represent one of the fastest-growing attack surfaces in AI systems. The Model Context Protocol, introduced by Anthropic and adopted across the industry in 2025, standardizes how AI systems integrate with external tools and data sources. It is powerful, flexible, and designed for extensibility. It is also a perfect vector for supply chain attacks. An MCP server is code that runs in your environment, has broad permissions, and processes sensitive data. If the server is malicious, it can exfiltrate data, manipulate outputs, or execute unauthorized actions. If the server is compromised after installation, the attacker gains access to everything the server can see. Most teams install MCP servers with less scrutiny than they apply to any other dependency. That is a mistake.

## What MCP Servers Are and Why They Are Dangerous

An MCP server is a service that provides context or capabilities to an AI system. It might be a database adapter that lets the model query internal data. It might be a tool integration that lets the model call external APIs. It might be a retrieval service that pulls documents from a knowledge base. The protocol is standardized, so any MCP server can integrate with any MCP-compatible AI system. This makes it trivially easy to extend functionality. It also makes it trivially easy to introduce a vulnerability.

The danger lies in the permissions. An MCP server has access to the full context of every request it handles. That includes the user's query, the model's response, any retrieved data, and any intermediate processing steps. If your system uses the MCP server for retrieval, it sees every document the user accesses. If your system uses the MCP server for function calling, it sees every function invocation and every result. If your system uses the MCP server for data augmentation, it sees every piece of external data before the model processes it. The MCP server is not a passive observer. It is an active participant in every interaction, and it has visibility into everything.

This creates a massive exfiltration risk. A malicious MCP server can log every query, response, and document retrieval to an external endpoint. The attacker does not need to compromise your model or your database. They only need to compromise the MCP server, which is often a third-party package installed from a public repository with minimal vetting. Once the server is running, it sees everything. The attacker just waits for the data to flow.

The risk is compounded by the execution model. MCP servers are often implemented as long-running processes that maintain state across requests. This means a compromised server can collect data over time, build user profiles, and exfiltrate aggregated datasets instead of individual queries. The attacker does not need to steal everything at once. They can exfiltrate slowly, below the detection threshold, and aggregate the data externally. By the time you notice anomalous traffic, months of queries have already been stolen.

## MCP as an Attack Vector: Malicious Servers Masquerading as Legitimate

The easiest way to compromise an AI system via MCP is to publish a malicious server that looks legitimate. The attacker creates a useful-sounding tool, writes documentation, publishes it to a package repository, and waits for developers to install it. The server provides the advertised functionality, so it passes basic testing. It also includes exfiltration logic that logs data to an external endpoint, injects malicious content into responses, or executes unauthorized commands. The developer never notices because the core functionality works as expected.

In late 2025, a campaign targeted organizations using Anthropic's Claude Code. The attackers published over thirty MCP servers, each claiming to integrate Claude with popular development tools: GitHub, Jira, Slack, database clients, and cloud providers. The servers worked as advertised. They also logged every prompt, every code snippet, and every model response to an external server controlled by the attackers. The campaign was discovered after a security researcher noticed unusual network traffic from an MCP server and reverse-engineered the exfiltration logic. By that point, over 30 organizations had installed at least one of the malicious servers, and the attackers had collected months of data.

The attack succeeded because the servers provided real value. Developers installed them, tested them, saw that they worked, and moved on. The exfiltration was subtle: small payloads sent to a server that looked like a logging or analytics endpoint. The data was encrypted, so packet inspection did not reveal the breach. The servers updated regularly, so version bumps did not raise suspicion. The attack was sophisticated, patient, and effective. It is also a template that other attackers will follow.

The defense is skepticism. Do not install an MCP server without auditing its code. Check the source repository, read the implementation, and look for network calls. If the server makes external requests, verify that those requests are necessary and that the destination is trustworthy. If the server writes logs, verify where those logs go and who has access to them. If the server requests broad permissions, ask why. Most MCP servers do not need full context access, but most request it anyway because it simplifies implementation. That convenience is a security risk.

## Plugin Security: Third-Party Tools with Full Context Access

Plugins are the same attack vector with a different label. In AI systems, a plugin is any external component that extends functionality: a retrieval tool, a function library, a data adapter, or a model wrapper. Plugins are installed from package repositories, enabled in configuration files, and integrated into the request pipeline. Once enabled, they have the same permissions as the rest of the application. If the plugin is compromised, the application is compromised.

The risk is not hypothetical. In mid-2025, a popular RAG plugin for LangChain was found to contain a backdoor that exfiltrated retrieved documents to an external server. The plugin had over 10,000 downloads, was recommended in multiple tutorials, and had been installed by hundreds of production systems. The backdoor was discovered by accident when a developer noticed unexpected DNS queries during testing. The plugin's maintainer claimed the code had been contributed by a third party and they had not audited it before merging. The backdoor had been active for three months.

This pattern repeats across the ecosystem. Plugins are often maintained by individual developers with no formal security process. They accept code contributions from strangers, merge pull requests without review, and publish updates without testing. The plugin ecosystem prioritizes velocity over security. Developers want to ship features, not audit dependencies. Attackers exploit this. They contribute code to popular plugins, inject backdoors, and wait for the next release. By the time the backdoor is discovered, it has propagated to hundreds of systems.

The defense is the same as for MCP servers: audit every plugin before installation. Read the code, check for network calls, and verify permissions. If the plugin requests access to sensitive data, ask why. If the plugin makes external requests, verify the destination. If the plugin has not been updated in months, assume it has unpatched vulnerabilities. If the plugin is maintained by a single developer with no public presence, treat it as high-risk. Do not install plugins based on GitHub stars or download counts. Those metrics measure popularity, not security.

## The Helpful Extension Attack Pattern

The most effective supply chain attack is the one that provides real value. An attacker who publishes a malicious plugin that does nothing useful will be ignored. An attacker who publishes a useful plugin that also exfiltrates data will be installed by thousands of developers. This is the helpful extension attack pattern: provide genuine functionality, gain trust, inject malicious behavior, and exfiltrate data while continuing to provide value.

The attack works because developers evaluate plugins based on functionality, not security. They test whether the plugin does what it claims, not whether it also does something it does not claim. A plugin that retrieves documents from a vector database is evaluated by whether it returns relevant results, not by whether it also logs those results to an external server. A plugin that integrates with a third-party API is evaluated by whether the API calls succeed, not by whether the plugin also sends copies of the requests to an attacker-controlled endpoint. The attacker hides the malicious behavior inside the legitimate functionality, and most teams never notice.

The pattern is especially effective for plugins that naturally make external requests. A weather API plugin, a translation service plugin, or a search integration plugin all make legitimate external network calls. If the plugin also makes one additional call to exfiltrate data, that call blends into the legitimate traffic. Static analysis will not catch it because the call is not obviously malicious. Runtime monitoring will not catch it unless you are specifically looking for unauthorized destinations. The attacker can exfiltrate data for months before anyone notices.

The defense is to assume every plugin is hostile until proven otherwise. Audit the code, monitor network traffic, and isolate plugins in sandboxes with minimal permissions. If a plugin needs to make external requests, whitelist the destinations explicitly and block everything else. If a plugin requests access to sensitive data, verify that the access is necessary and log every use. If a plugin updates frequently, audit every update before deploying it. Treat plugins as untrusted third-party code, because that is exactly what they are.

## Sandboxing and Isolation for Plugins

The strongest defense against malicious plugins is isolation. Run every plugin in a sandboxed environment with limited permissions, no access to production data, and restricted network access. If a plugin is compromised, the sandbox contains the damage. The plugin cannot exfiltrate data, modify system state, or execute unauthorized actions. The blast radius is limited to the sandbox, and the rest of the system remains secure.

Sandboxing is not a new concept, but it is underutilized in AI systems. Most teams run plugins in the same process as the model, with the same permissions and the same access. This is convenient but dangerous. A compromised plugin can read memory, access files, make arbitrary network calls, and execute code with the same privileges as the application. The plugin is not isolated. It is integrated. That integration is a vulnerability.

Modern sandboxing technologies make isolation practical. Containers, VMs, and WebAssembly runtimes all provide strong isolation guarantees. A plugin running in a container has no access to the host filesystem, no access to the host network unless explicitly granted, and no ability to execute code outside the container. The plugin can provide its intended functionality, but it cannot exfiltrate data or compromise the system. The overhead is low, the security benefit is high, and the implementation is straightforward.

The key is to sandbox by default, not by exception. Do not run plugins in the same process as the model unless there is a compelling reason. Do not grant plugins access to production data unless they absolutely need it. Do not allow plugins to make arbitrary network calls unless you can verify every destination. Default to the most restrictive permissions, and only grant additional access when necessary. This is the principle of least privilege applied to supply chain security. Every plugin is a potential threat. Treat it that way.

## Network Egress Control and Monitoring

If you cannot sandbox plugins completely, at least control their network access. Most malicious plugins exfiltrate data via HTTP or DNS. If you monitor and restrict outbound network traffic, you can detect and block exfiltration attempts before they succeed. This requires network egress control: whitelist allowed destinations, block everything else, and alert on anomalies.

Egress control starts with visibility. Log every outbound connection from your AI system, including the source process, the destination IP and domain, the protocol, and the payload size. This gives you a baseline of normal traffic. Any connection that does not match the baseline is suspect. A plugin that suddenly starts making requests to an unfamiliar domain is likely compromised or malicious. A plugin that sends large payloads to a logging service that you do not use is probably exfiltrating data. The logs tell you what is happening. The alerts tell you when to investigate.

The next layer is enforcement. Use firewall rules, network policies, or service mesh configurations to restrict outbound connections to a whitelist of approved destinations. If a plugin needs to call an external API, add that API's domain to the whitelist. If a plugin does not need external access, block all outbound connections from its sandbox. This prevents exfiltration even if the plugin is compromised. The plugin might try to send data to an attacker-controlled server, but the network blocks the request. The attacker gets nothing.

The final layer is anomaly detection. Even with egress control, attackers can exfiltrate data via DNS tunneling, HTTPS covert channels, or approved destinations that have been compromised. Monitor for anomalies: unusual request patterns, large payloads to logging services, high-frequency DNS queries, or connections to recently-registered domains. These patterns do not guarantee an attack, but they warrant investigation. Automated detection tools can flag anomalies in real time, and your security team can investigate before the breach escalates.

## Dependency Auditing and Update Policies

Plugins and MCP servers are dependencies. Treat them with the same rigor you apply to any other software dependency. That means maintaining an inventory of every plugin and server your system uses, auditing each one for security issues, and enforcing update policies that balance functionality with security.

Start with the inventory. List every plugin, every MCP server, and every external integration your system depends on. For each one, record the source, the version, the installation date, and the permissions it requires. Update this inventory with every deployment. If you cannot list your dependencies, you cannot secure them.

Next, audit each dependency. Read the source code, check for known vulnerabilities, and look for suspicious behavior. Use static analysis tools to detect common security issues: hardcoded credentials, unvalidated inputs, or external network calls. Use dependency scanning tools to check for known CVEs in the plugin's dependencies. If the plugin has not been updated in months, assume it has unpatched vulnerabilities and evaluate alternatives.

Then, establish an update policy. Plugins and MCP servers release updates frequently, and those updates can introduce new vulnerabilities or new malicious behavior. Do not auto-update plugins in production. Test updates in a staging environment first, audit the changes, and deploy only after verification. If an update includes new network calls, new permissions, or unexplained behavior changes, investigate before deploying. Updates can be attack vectors. Treat them with suspicion.

Finally, monitor for supply chain compromises. Subscribe to security advisories for the plugins and servers you use. If a dependency is compromised, you need to know immediately. If a maintainer's account is breached, you need to know before the attacker publishes a malicious update. If a plugin is removed from a repository or flagged by the community, investigate why. Supply chain security is not a one-time audit. It is continuous vigilance.

The next subchapter covers third-party tool risks: how external APIs, services, and integrations become attack vectors, and how to evaluate, isolate, and monitor third-party tools in production AI systems.

