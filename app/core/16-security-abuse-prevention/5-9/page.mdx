# 5.9 — Defense: Memory Boundaries and Session Isolation

The session started normally. A customer service agent asked the AI assistant to pull up a customer's order history. The system retrieved the records, answered questions, helped resolve an issue. The agent closed the session and moved to the next customer. Three hours later, a different agent opened a new session for a different customer. The AI assistant, unprompted, referenced the first customer's order details. The memory system had failed to clear conversation state. What was supposed to be an isolated session had leaked into the next one. The system that was built to remember context within a conversation was now remembering context across conversations, across agents, across customers. The memory system had become a data retention and leakage problem.

Memory boundaries define what state persists, at what scope, for how long, and with what access controls. Session isolation ensures that state from one conversation cannot affect another conversation. These are foundational security properties. If you design memory systems without clear boundaries, you build a system that accumulates sensitive data without expiration, mixes context across users, and leaks information through temporal side channels. Memory is necessary for coherent multi-turn conversations. But uncontrolled memory is a security liability.

## Session Boundaries and What Persists

A session is a unit of interaction between a user and the AI system. It has a beginning, a duration, and an end. During the session, the system remembers prior exchanges to maintain conversation coherence. The user asks a question, the model answers, the user follows up, and the model's response incorporates context from the earlier exchange. This requires memory. The question is: what happens to that memory when the session ends?

The stateless ideal is that nothing persists. When the session ends, all memory evaporates. The system forgets every prompt, every response, every piece of context. The next session starts with a blank slate. There is no cross-session leakage because there is no cross-session state. Every interaction is independent. This is the simplest and most secure design. It's appropriate for public-facing systems, anonymous interactions, and any scenario where continuity across sessions isn't valuable.

The stateful reality is that most applications need some persistence. A customer support system benefits from remembering past interactions with the same customer across sessions. A personal assistant needs long-term memory to be useful. A document analysis tool should remember which documents a user has worked with. The question shifts from "should we persist memory" to "what should we persist, at what scope, and for how long."

## Memory Scoping Levels

Memory can be scoped at the conversation level, the session level, or the user level. Each scope has different security and functional implications.

Conversation-level memory persists only within a single continuous conversation. The user sends messages, the system responds, the conversation continues. As long as the conversation is active, memory persists. The moment the conversation ends — the user closes the window, navigates away, or explicitly ends the session — the memory is deleted. This is appropriate for interactions where continuity is valuable within a conversation but not across conversations. A brainstorming session. A single troubleshooting interaction. A one-time document review.

Session-level memory persists across multiple conversations within a session. A session might span hours or days. The user starts multiple conversations during the session, and each conversation has access to memory from prior conversations in the same session. This is appropriate for workflows that span multiple interactions but should eventually expire. A customer service agent working a shift has a session that spans their entire shift. Their interactions with the AI assistant persist across customers but reset when the shift ends.

User-level memory persists indefinitely across all sessions for a specific user. The system remembers everything the user has ever told it, every document they've worked with, every preference they've expressed. This creates the richest experience — the AI assistant "knows" the user and doesn't require re-explaining context. It's also the highest-risk design. User-level memory accumulates sensitive data over time, creates a massive attack surface, and requires long-term storage and governance.

The right scope depends on the application's purpose and the data's sensitivity. For public-facing tools handling anonymous users, conversation-level memory is appropriate. For authenticated applications with user accounts, session-level or user-level memory becomes necessary. For regulated domains — healthcare, finance, legal — even conversation-level memory may be too much if it creates data retention obligations.

## Expiration Policies

Memory that persists must eventually expire. Indefinite retention is both a security risk and a compliance problem. GDPR mandates that personal data be retained only as long as necessary. HIPAA requires that patient data be disposed of when no longer needed for treatment or operations. SOX imposes retention schedules on financial records. Retaining memory indefinitely violates these requirements and creates a growing attack surface.

Expiration policies define when memory is deleted. Conversation-level memory expires when the conversation ends. Session-level memory expires when the session ends — either explicitly when the user logs out or implicitly after a timeout period. User-level memory expires based on time or activity — delete memory older than 90 days, delete memory from inactive users, delete memory when a user deletes their account.

The timeout value depends on the application's needs and regulatory requirements. A customer support system might retain session memory for 8 hours — the length of a typical agent shift. A personal productivity assistant might retain user memory for 90 days — long enough for ongoing projects but short enough to avoid indefinite accumulation. A healthcare application might retain conversation memory for 24 hours — long enough for a multi-turn diagnostic conversation but short enough to minimize retention risk.

Expiration must be enforced automatically. If deletion depends on application logic calling a cleanup function, it will fail. The application crashes. The cleanup job doesn't run. State accumulates. Expiration policies should be implemented at the storage layer. Memory stored in a database with a TTL column that automatically deletes expired rows. Memory stored in a cache with native expiration support. Memory stored in a system that enforces retention schedules as a platform feature.

You monitor expiration effectiveness. Track the volume of stored memory over time. If it grows unboundedly, expiration isn't working. Track the age of stored memory. If you see records older than your retention policy allows, deletion is failing. Alert on these conditions. Memory retention failures are security incidents. They indicate that sensitive data is being stored longer than your policies permit and longer than your legal obligations allow.

## Memory Validation and Scanning

Memory systems store content provided by users and generated by models. That content can include prompt injection payloads, PII, malicious instructions, or exfiltration attempts. If memory storage is naive — accept whatever text is provided and persist it — you're storing attack payloads that will execute later when the memory is retrieved and used as context.

Memory validation scans content before storage. Every piece of text destined for memory passes through filters that detect injection attempts, PII, policy violations, and malicious patterns. If the scan detects a problem, the system refuses to store the content. This prevents poisoned memory. An attacker can't inject a payload in one conversation and have it execute when retrieved in a future conversation because the storage layer rejected it.

The validation scan is similar to output filtering but applied at the storage boundary instead of the response boundary. PII detection runs on text before it's stored in user memory. Injection detection looks for patterns like "ignore previous instructions" or multi-turn attack setups. Policy enforcement checks whether the content violates usage policies — no storing instructions to generate prohibited content, no storing hate speech, no storing instructions that will cause the model to violate policies in future interactions.

The tradeoff is that aggressive memory validation limits what users can store. If a user legitimately wants the assistant to remember that their previous conversation included a discussion of injection attacks — they're researching security — the validation system might flag "ignore previous instructions" as a payload and refuse to store it. False positives in memory validation degrade user experience. The user asks the assistant to remember something, and the system silently refuses. The user repeats themselves in future sessions, frustrated that the assistant forgot.

Balancing validation strictness with usability is application-specific. High-risk applications — those exposed to adversarial users, those handling regulated data — run strict validation and accept the usability cost. Low-risk applications — personal assistants for authenticated users, internal tools — run lighter validation and trust that users aren't attacking their own memory systems. You calibrate based on threat model.

## Cross-Session Isolation

Memory scoped to a session should not leak into other sessions. A customer service agent's session memory for one shift should not be accessible in the next agent's session. A user's browser session should not have access to another user's session memory even if they're using the same device. Cross-session isolation ensures that session boundaries are enforced at the storage and retrieval level.

Session IDs must be unguessable and tamper-proof. A sequential session ID — session1, session2, session3 — allows attackers to enumerate sessions and attempt access. A cryptographically random session ID — a UUID or 128-bit random token — makes guessing infeasible. Session IDs must be transmitted securely and validated on every access. If the session ID is in a cookie, it must be HttpOnly and Secure. If it's in a URL parameter, it must be ephemeral and single-use.

Session memory retrieval must validate ownership. When a request arrives with a session ID, the system checks that the requesting user owns that session. If User A presents a session ID belonging to User B, access is denied. This prevents session hijacking and cross-user access. The validation happens at the storage layer, not just in application logic. If application code forgets the check, the storage layer enforces it.

Session memory is deleted when the session ends. Explicit logout triggers immediate deletion. Timeout-based expiration triggers deletion after inactivity. Either way, once a session is terminated, its memory is gone. This limits the window in which session memory can be accessed and reduces the risk of long-term exposure if a session ID is compromised.

## Memory in Multi-Tenant Systems

In multi-tenant platforms, memory must be isolated by tenant. A user from Tenant A should not have access to memory from Tenant B. A session in Tenant A should not see memory stored by Tenant B. This requires tenant-scoped memory storage and retrieval with validation on every access.

Every memory record includes a tenant ID. Session memory includes the tenant that owns the session. User memory includes the tenant that owns the user. Conversation memory includes the tenant that initiated the conversation. Retrieval queries filter by tenant ID. A request from Tenant A retrieves only memory records where tenant equals A. The database enforces this filtering, not just the application.

The isolation extends to memory access controls. Tenant admins can access memory for their own tenant but not for other tenants. Operations teams access memory through tenant-scoped tooling. If an ops engineer needs to debug a memory issue for Tenant A, they access Tenant A's memory with audit logging, but they cannot access Tenant B's memory unless explicitly granted permission for that tenant as well.

This is the same isolation architecture described in the previous subchapter but applied to memory systems specifically. Memory is another storage layer that requires tenant boundaries. If you isolate your model instances and your databases but not your memory systems, you've left a leakage path.

## The Stateless Ideal Versus Practical State Requirements

Statelessness is ideal from a security perspective. No state means no persistence risk, no cross-session leakage, no long-term attack surface. But statelessness limits functionality. Conversations without memory are incoherent. Multi-turn interactions require re-stating context every time. Applications that need personalization or learning require memory.

The compromise is to be as stateless as possible while storing only the minimum state necessary for the application's functionality. Don't store full conversation transcripts if you only need to remember key facts. Don't retain memory indefinitely if 30 days is sufficient. Don't persist memory at the user level if session-level memory meets the need. Default to stateless. Add memory only when it's necessary and with the shortest retention period that satisfies the requirement.

You audit memory usage regularly. What's being stored? How much? For how long? Is all of it necessary? Can any of it be deleted sooner? Can any of it be stored at a narrower scope? Memory systems tend to accumulate cruft over time. Features add memory without removing it. Retention policies lengthen without revisiting whether the longer retention is justified. Regular audits prevent unbounded growth and keep memory storage aligned with actual needs.

## Designing Memory Systems with Security from the Start

Memory systems designed without security in mind become dangerous over time. They accumulate sensitive data without expiration. They lack access controls. They allow cross-session and cross-user leakage. Retrofitting security is painful — it requires changing storage schemas, rewriting access logic, implementing expiration where none existed, and migrating live data to new structures.

Design memory systems with security boundaries from the start. Tenant ID, user ID, and session ID are first-class fields in the memory schema. Expiration is a native property of every stored record. Access control checks happen at the storage layer. Scoping is enforced by database indexes and query filters, not just application logic.

Memory validation is part of the storage interface. You don't accept arbitrary text and persist it. You scan it, validate it, and reject it if it violates policies. The storage layer is the enforcement point, not the application. This ensures that all paths that write to memory — even ones you add later — go through validation.

You test memory isolation. Create two sessions, store sensitive data in one, verify it's not accessible from the other. Create two tenants, store data for one, verify it's not retrievable by the other. Test expiration: store memory with a short TTL, wait for expiration, verify it's deleted. These tests catch isolation and expiration failures before they reach production.

Memory boundaries and session isolation are not secondary concerns. They're foundational to building AI systems that users can trust with sensitive data. Every conversation generates state. Every interaction creates memory. If you don't control where that state goes, how long it persists, and who can access it, you've built a system that leaks by design. The next layer of defense addresses what happens when users attempt to extract training data or proprietary information through carefully crafted prompts.

