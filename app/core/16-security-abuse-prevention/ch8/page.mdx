# Chapter 8 — RAG Security and Knowledge Base Attacks

When you add retrieval to generation, you add an entire attack surface. Every document in your knowledge base becomes a potential injection vector. Every embedding becomes a manipulation target. Every retrieval step becomes a decision point where the attacker can influence what the model sees, what it trusts, and what it says. RAG does not just augment the model with knowledge — it opens a channel where adversarial content can flow directly into the context window, wrapped in the legitimacy of "retrieved information." The model does not evaluate document trustworthiness. It assumes retrieved content is authoritative. That assumption is the exploit.

Poisoned documents are not hypothetical. An attacker who can write to your knowledge base — through user uploads, scraped content, compromised integrations, or feedback loops — can inject instructions, manipulate citations, and create retrieval triggers that surface malicious content exactly when needed. The model reads the poison, follows the instructions, and outputs the attack. The user sees a response backed by "sources" and trusts it. The attacker does not need to compromise the model. They just need to compromise the documents the model reads. Your RAG pipeline is only as secure as the least-trusted document it can retrieve.

---

- **8-1** — RAG as an Injection Surface: Why Retrieval Creates Risk
- **8-2** — Poisoned Documents: Malicious Content in Knowledge Bases
- **8-3** — Prompt Injection via Retrieved Content (Indirect Injection)
- **8-4** — Vector and Embedding Weaknesses (OWASP LLM08:2025)
- **8-5** — The Poison-Feedback Loop: Poison to Retrieval to Trust to Learning
- **8-6** — Citation Manipulation and Source Spoofing
- **8-7** — The Provenance Ladder: Source Trust Scoring
- **8-8** — Defense: Document Sanitization and Quarantine Pipelines
- **8-9** — Defense: Human Review for High-Impact Documents
- **8-10** — Defense: Knowledge Base Versioning and Rollback
- **8-11** — Secure RAG Architecture Patterns

---

*The document the model retrieves is the attack — and the model thinks it is the truth.*
