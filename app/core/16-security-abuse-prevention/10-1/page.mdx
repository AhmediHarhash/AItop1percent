# 10.1 — Denial of Service in AI: Different Than Traditional DoS

The security team had implemented robust traditional DoS protection. Rate limiting at the gateway. IP reputation filtering. Distributed infrastructure with auto-scaling. When the AI-powered customer service system launched in September 2025, they felt confident. Within eighteen hours, the system was effectively offline — not from too many requests, but from thirty-seven requests. Each prompt was carefully crafted to consume maximum context, trigger multiple tool calls, and generate responses near the token limit. The load balancers showed green. The infrastructure was barely stressed. The monthly inference budget exhausted in less than a day. Cost per request averaged two thousand four hundred dollars.

Traditional denial of service protection is built for a world where requests are cheap to process and volume is the weapon. AI systems invert this model. A single request can cost more to process than ten thousand requests to a traditional web application. The attacker's advantage is structural — they can make you spend a hundred dollars while spending ten cents on the attack. Every defensive principle you learned from protecting web applications needs reconsideration when the economics flip this direction.

## The Cost Asymmetry Problem

Traditional DoS attacks work through volume. Send a million requests, overwhelm the server capacity, bring the system down. The attacker needs resources — botnets, bandwidth, infrastructure. Defense works because you can detect volume, rate-limit aggressively, and make the attack expensive relative to the defense. AI systems break this model completely.

A single prompt that asks the model to analyze a hundred pages of contract text, compare it against regulatory requirements, generate a compliance report with citations, and provide risk assessments costs real money. The attacker types one hundred fifty words. Your system processes fifty thousand tokens. The request takes forty-five seconds. The cost is sixteen dollars. The attacker made one request. Your traditional DoS protection sees nothing unusual. They make eight more requests with different contract lengths and complexity levels. Your monthly budget drops by two hundred dollars in three minutes.

This is not theoretical. A legal AI platform in late 2025 discovered that a single user had created twelve free trial accounts and was systematically submitting the most expensive possible document analysis requests. Each request maxed out the context window with dense legal text and requested comprehensive outputs. The user never looked at the results. Over six days, this pattern cost the platform nineteen thousand dollars. The IP-based rate limiting saw twelve different users making reasonable request rates. The per-user quotas were set for normal usage patterns. The attacker stayed under every threshold while systematically maximizing cost.

The cost asymmetry means volume is no longer the primary weapon. Complexity becomes the weapon. An attacker who understands your pricing model can craft individual requests that cost ten, fifty, or a hundred times what a normal request costs. They do not need to overwhelm your infrastructure. They need to exhaust your budget or make your unit economics unsustainable. Traditional DoS defense focuses on availability. AI DoS defense must focus on cost.

## Attack Surface Beyond Volume

Web application DoS has a known attack surface. Connection exhaustion. CPU saturation. Memory overflow. Bandwidth consumption. Database query overload. AI systems add new attack surfaces that do not exist in traditional applications, and most of them are accessible through the prompt itself.

**Context window exhaustion** is the simplest. Most AI systems have context limits — a hundred thousand tokens, two hundred thousand tokens, a million tokens for the most capable models. Attackers can craft prompts that include enormous amounts of text, either as direct input or by referencing documents your system retrieves. A RAG system that retrieves the top twenty most relevant chunks becomes an attack surface when an attacker can craft queries that retrieve the twenty longest, most complex chunks. Your retrieval logic works correctly. The attacker just made your system do the most expensive possible work.

**Tool call amplification** turns your system's capabilities into weapons. An AI agent with access to database queries, API calls, or file operations can be prompted to make hundreds of tool calls in a single session. A prompt that asks "check the status of all pending orders and send a notification to each customer" might trigger a thousand database queries and a thousand email API calls. Your system has the capability. The attacker just asked for it in a way that maximizes cost and latency.

**Inference loops** happen when responses trigger additional prompts, creating cycles that consume resources exponentially. A creative writing assistant that supports multi-turn conversations becomes an attack surface when an attacker scripts interactions that generate long responses, each of which triggers another long prompt. A single session that normally costs fifty cents can be stretched to twenty dollars through strategic turn-taking that keeps the model generating.

**Streaming endpoint exhaustion** exploits the real-time nature of AI responses. Traditional slowloris attacks keep connections open with minimal data transfer. AI streaming endpoints can be attacked by requests that generate extremely long outputs, holding connections open for minutes while consuming tokens continuously. Your infrastructure is designed to handle streaming. The attacker makes every stream as long and expensive as possible.

These attack surfaces exist because of what makes AI systems useful — flexibility, context handling, tool integration, streaming responses. An attacker does not need to exploit bugs or vulnerabilities. They exploit intended functionality at scale or cost extremes.

## Why Traditional Defenses Fail

Rate limiting based on request count fails immediately. An attacker making two requests per minute stays under every reasonable threshold while each request costs fifty dollars. IP-based blocking fails when attackers rotate addresses or use legitimate proxies. Geographic filtering fails when attacks come from the same regions as your legitimate users. Connection limits fail when each connection is valid and the problem is what happens inside that connection.

Traditional DoS protection assumes requests are roughly equivalent in cost. A GET request and a POST request might differ slightly in processing, but the difference is small enough that rate limiting by count works. In AI systems, one request might cost a thousand times more than another. Rate limiting by request count is measuring the wrong variable.

Autoscaling fails when the problem is cost, not capacity. Adding more inference servers does not help if the attack is exhausting your token budget, not your compute capacity. Scaling up makes the problem worse — you process the expensive requests faster, burning through budget at higher speed. A payment processing company found this in October 2025 when their autoscaling response to a prompt flooding attack tripled their daily inference costs before anyone realized the traffic was malicious.

Web application firewalls fail because there is no malicious payload to detect. The prompts are semantically valid. The requests follow the API contract. The attacker is not injecting code or exploiting bugs. They are simply asking for the most expensive version of what your system legitimately offers. A WAF that blocks SQL injection and XSS attempts has nothing to block when the attack is a valid prompt requesting comprehensive analysis of a deliberately complex document.

## The Availability-Quality-Cost Triangle

Defending AI systems from DoS attacks requires balancing three variables that traditional DoS defense does not face. You must maintain availability, preserve quality, and control cost. Optimizing for any two creates vulnerability in the third.

If you focus on availability and quality — making sure every user gets excellent responses with low latency — you leave cost unprotected. Attackers exploit this by maximizing per-request costs until your budget exhausts or your unit economics collapse. A customer support AI that guarantees sub-three-second response times with comprehensive answers is vulnerable to prompts that force the most expensive inference path while staying under the latency SLA.

If you focus on availability and cost — rate limiting aggressively to control spend — you risk degrading quality for legitimate users. Harsh token limits mean complex legitimate queries get truncated responses. Tight rate limits mean power users hit walls. The system stays online and cheap but stops being useful. A code generation tool that limits context to ten thousand tokens to control cost cannot handle the legitimate use case of analyzing a large codebase.

If you focus on quality and cost — providing excellent responses while staying in budget — you may sacrifice availability. Queuing requests to smooth out costs, throttling during high usage periods, or restricting access when budgets run low all impact availability. A financial analysis AI that pauses new requests when approaching monthly budget limits maintains quality and cost control but fails availability during critical end-of-month usage spikes.

Traditional DoS defense optimizes for availability at any cost. If the system stays online, defense succeeded. AI systems cannot operate this way. Staying online while burning ten thousand dollars per hour on malicious traffic is not success. Staying online while giving every user truncated useless responses is not success. You must defend all three variables simultaneously, which means every defensive measure has trade-offs that do not exist in traditional infrastructure.

## Attack Economics That Favor the Attacker

The fundamental problem is economic asymmetry. In traditional DoS attacks, the attacker needs resources roughly proportional to the damage they want to cause. To overwhelm a web server with a million requests per second, the attacker needs infrastructure capable of generating a million requests per second. This costs money, limits the scale of attacks, and makes attackers detectable.

In AI DoS attacks, the attacker's cost is decoupled from the defender's cost. An attacker who spends five dollars on API calls to your system can force you to spend five hundred dollars on inference. An attacker who writes a script that generates complex prompts programmatically might spend an hour of their time to create an attack that costs you thousands. The attacker does not need botnets, bandwidth, or infrastructure. They need knowledge of how your system prices compute and creativity in crafting expensive requests.

This asymmetry means attacks are accessible to low-sophistication actors. A traditional DDoS attack requires technical skill, infrastructure, or money to rent botnets. An AI DoS attack requires understanding of your API documentation and some experimentation to find expensive request patterns. A motivated individual can execute what would have required an organized group in traditional DoS scenarios.

The economic advantage extends to persistence. Traditional DoS attacks are expensive to sustain. Bandwidth costs money. Botnets cost money. Infrastructure costs money. Attackers usually run attacks in bursts — take the target down for hours or days, then stop. AI DoS attacks can run low and slow. An attacker making two expensive requests per hour, staying under rate limits, slowly draining your budget, can sustain the attack indefinitely at minimal cost to themselves. Detection is harder because the traffic looks legitimate.

## Detection That Focuses on Cost, Not Volume

Effective defense starts with measuring what matters. Request count is the wrong metric. Requests per second is the wrong metric. Concurrent connections is the wrong metric. These are all volume metrics designed for traditional DoS. AI DoS defense requires cost metrics.

Track cost per request in real time. When a request costs ten times your median, that is a signal. When a user account consistently generates requests in the top five percent of cost distribution, that is a signal. When geographic regions or IP ranges show cost patterns that diverge from normal usage, that is a signal. Cost distribution is your primary detection surface.

Track resource consumption patterns at the prompt level. Prompts that max out context windows. Prompts that trigger more than five tool calls. Prompts that generate responses longer than your ninety-fifth percentile. Prompts that use specific model features known to be expensive — like chain-of-thought reasoning, multi-turn planning, or code execution. These patterns are not malicious by themselves, but clustering of these patterns within accounts or time windows indicates potential abuse.

Track the ratio between input and output tokens. Normal usage has characteristic ratios — most prompts are relatively short and generate responses that are longer but not excessively so. Attackers trying to maximize cost often show anomalous ratios — extremely long inputs designed to consume context, or prompts engineered to generate maximum-length outputs. Monitoring the distribution of this ratio across users and sessions reveals abuse that volume metrics miss.

Track budget consumption velocity. Your monthly budget should decline at a predictable rate based on traffic patterns. Sudden acceleration in burn rate, especially outside normal high-traffic periods, indicates something changed. When budget consumption velocity increases while request volume stays constant or grows only slightly, cost per request is the variable. Something or someone is making your requests more expensive.

## Defense Design Principles

Traditional DoS defense is reactive — detect the attack, block the source, scale up capacity, wait for it to end. AI DoS defense must be proactive — design the system to make expensive attacks expensive for the attacker, limit the maximum damage any single request or user can cause, and build cost controls into the architecture before abuse happens.

Principle one: cap the maximum cost of any single request. Set hard limits on context window usage. Set hard limits on output token generation. Set hard limits on tool call counts per request. Set hard limits on inference time. A request that hits any of these limits gets truncated or rejected. This is a quality trade-off — legitimate complex requests may hit these limits — but it prevents any single request from becoming a budget catastrophe. A request cannot cost more than fifty dollars if your system refuses to process beyond the cap.

Principle two: implement cost-aware rate limiting. Do not limit by request count. Limit by cumulative cost per user per time window. A user who makes a hundred cheap requests stays under the limit. A user who makes five expensive requests hits the limit. The system adapts to actual resource consumption, not arbitrary request counts. This requires tracking cost attribution in real time, which most traditional rate limiting systems do not support.

Principle three: separate free and paid tier economics completely. Free tier users get hard per-request caps that prevent any single request from being expensive, and monthly quotas that limit cumulative abuse. Paid tier users get higher limits but still have cost-aware monitoring and anomaly detection. Attackers prefer free tiers because there is no payment friction. Your free tier must be economically defensible even under sustained abuse.

Principle four: make cost-increasing features opt-in, not default. Long context windows, extended output generation, tool calling, multi-turn conversations — these are powerful features that increase utility and cost. Requiring users to explicitly enable these features creates friction for attackers and gives you clear signal when someone is using expensive capabilities. A user who enables maximum context on every request is either a power user or an abuser. Watch closely.

Principle five: monitor cost per user cohort, not just aggregate cost. Your overall daily spend might look normal while one user or a small group of users consumes thirty percent of it. Aggregate metrics hide targeted abuse. Per-user, per-account, and per-cohort metrics surface it. When ten free trial accounts all created on the same day show identical cost patterns, that is not coincidence.

## The Reality of Incomplete Defense

You cannot prevent all AI DoS attacks without degrading service for legitimate users. The same features that make your system powerful make it vulnerable. You cannot perfectly distinguish between a power user legitimately using expensive features and an attacker deliberately maximizing cost. The economics of AI inference mean any public-facing AI system is vulnerable to economic exploitation by someone willing to spend time understanding your cost model.

What you can do is limit the maximum damage, detect abuse faster than attackers can drain your budget, and make sustained abuse expensive or tedious enough that most attackers move to easier targets. Defense is not about perfection. Defense is about making the attack harder than the attacker wants to invest and detecting it before the damage becomes existential.

The next subchapter covers the most common technique attackers use once they understand your system's cost model: prompt flooding and rate limit bypass strategies that exploit the gap between request volume and resource consumption.

