# 7.9 — Authentication Integration Patterns

Authentication is the one security boundary you do not control. You do not own your users' passwords. You do not manage their second factors. You do not decide when their credentials expire or get revoked. That responsibility belongs to their enterprise identity provider — their Okta tenant, their Azure AD, their Google Workspace. Your job is to integrate with those systems correctly, trust them exactly as much as you should, and fail safely when they fail. Most AI platforms get this wrong. They reinvent authentication instead of delegating it. They store passwords instead of federating identity. They treat API keys like long-lived secrets instead of short-lived tokens. This is how AI systems become the weakest link in enterprise security.

The modern authentication stack for production AI has four layers: enterprise SSO for human users, OAuth 2.1 for delegated access, API key management for machine clients, and service account authentication for agents. Each layer has different threat models, different rotation policies, and different failure modes. You cannot build a secure AI system by bolting authentication on at the end. You must design for federation, delegation, and key rotation from the first line of code.

## Enterprise SSO and Identity Federation

If your AI platform serves enterprise customers, you do not get to choose how users authenticate. The customer chooses. They already have an identity provider. They already have SSO. They already have policies for password complexity, MFA, session timeout, and account lockout. Your platform must integrate with their existing identity infrastructure, not replace it. This means supporting **SAML 2.0**, **OpenID Connect**, and **SCIM** for user provisioning.

SAML 2.0 is the legacy standard, but it is still the most widely deployed SSO protocol in large enterprises. When a user tries to access your platform, your system redirects them to their identity provider. The identity provider authenticates the user — password, MFA, biometrics, whatever the enterprise requires — and then returns a signed SAML assertion that proves the user's identity. Your platform validates the assertion, extracts the user's attributes, and issues a session token. You never see the user's password. You never store their credentials. You trust the identity provider to authenticate them correctly, and you validate the cryptographic signature on the assertion to ensure it has not been tampered with.

OpenID Connect is the modern alternative to SAML. It is built on OAuth 2.1 and uses JSON Web Tokens instead of XML assertions. The flow is similar: redirect to the identity provider, authenticate, return a signed ID token. But OIDC is simpler to implement, easier to debug, and better suited for API-driven architectures. Most new SSO integrations in 2026 use OIDC. But most legacy enterprise customers still require SAML. If you only support one protocol, you exclude half the market. Production AI platforms support both.

SCIM — System for Cross-domain Identity Management — is the provisioning protocol that most teams forget. SSO handles authentication. SCIM handles user lifecycle. When an employee joins the company, SCIM creates their account in your platform. When they change roles, SCIM updates their permissions. When they leave, SCIM deactivates their account. Without SCIM, the customer's IT team must manually create, update, and delete accounts in your system. This does not scale. It creates lag. It creates orphaned accounts — former employees whose access was never revoked. SCIM automates the lifecycle and closes the gap between "employee terminated" and "access revoked" from days to seconds.

But SSO introduces a single point of failure. If the identity provider is down, your users cannot log in. If the identity provider is compromised, your system trusts the attacker's assertions. This is why mature platforms implement **defensive federation** — they trust the identity provider for authentication, but they layer on additional access controls at the application level. The identity provider says "this is Alice." Your platform checks its own database to confirm that Alice is still an active user, that Alice's account is not locked, that Alice's tenant is not suspended, and that Alice's permissions allow the requested action. You trust the identity provider for authentication. You do not trust it for authorization. That distinction is critical.

## OAuth 2.1 for Delegated Access

OAuth 2.1 is the foundation of modern API authentication. It allows a user to grant your AI platform limited, scoped access to their data in another system — their email, their calendar, their CRM, their file storage — without giving your platform their password. This is how your AI agent reads a user's emails to draft responses, accesses their Google Drive to retrieve documents, or updates their Salesforce records after a conversation. OAuth is also how your platform issues access tokens to client applications — mobile apps, browser extensions, third-party integrations — without exposing long-lived credentials.

The OAuth 2.1 flow starts with the user authorizing your application. Your app redirects the user to the authorization server, which prompts the user to grant specific permissions — "read your email," "access your files," "update your calendar." After the user consents, the authorization server redirects back to your app with an authorization code. Your app exchanges that code for an access token, which it then uses to call the API on the user's behalf. The access token is short-lived — typically 1 hour — and scoped to the specific permissions the user granted. If the token is compromised, the blast radius is limited by scope and time.

OAuth 2.1 improves on OAuth 2.0 by mandating PKCE — Proof Key for Code Exchange — for all clients. PKCE prevents authorization code interception attacks, where an attacker steals the authorization code during the redirect and exchanges it for an access token before the legitimate app can. With PKCE, the app generates a random secret and sends a hash of that secret during the authorization request. When exchanging the code for a token, the app must prove it knows the original secret. This protects mobile and single-page apps that cannot securely store client secrets.

But OAuth tokens are still bearer tokens. Anyone who possesses the token can use it. This makes token storage the critical security boundary. Access tokens should never be stored in local storage, cookies, or any client-side storage that JavaScript can access. They should be stored in memory only, or in secure storage like iOS Keychain or Android Keystore. Refresh tokens — long-lived tokens that issue new access tokens — should be stored in even more restricted storage and should rotate on every use. If a refresh token is used twice, both requests should be rejected and the user should be prompted to re-authenticate. This detects token theft.

## Passkeys and Passwordless Authentication

Passwords are the weakest link in authentication. They are reused. They are phished. They are leaked in breaches. Multi-factor authentication helps, but it is not immune to phishing. An attacker can trick a user into approving a push notification. An attacker can steal OTP codes in real-time. The future of authentication is passwordless, and the standard that is winning is **passkeys** — FIDO2-based credentials that use public-key cryptography and biometric verification.

Passkeys work like SSH keys but for humans. When a user creates a passkey, their device generates a public-private key pair. The private key stays on the device, protected by biometrics or a PIN. The public key is sent to your server and associated with the user's account. When the user signs in, your server sends a challenge. The device signs the challenge with the private key and returns the signature. Your server verifies the signature with the public key. If it matches, the user is authenticated. The private key never leaves the device. The signature cannot be replayed. The authentication cannot be phished.

Passkeys are synced across devices using platform-specific systems — iCloud Keychain for Apple devices, Google Password Manager for Android, Windows Hello for Microsoft. This makes passkeys more convenient than hardware security keys while maintaining the same security properties. A user who sets up a passkey on their phone can use it on their laptop. A user who loses their phone can recover their passkeys from their cloud account. The user experience is seamless. The security is cryptographic.

For AI platforms, passkeys are especially important because they protect high-value actions — fine-tuning a model, deleting a dataset, changing access policies. These actions should require step-up authentication, where the user must re-authenticate even if they already have a valid session. Passkeys make step-up authentication fast and secure. The user touches their fingerprint reader or looks at their camera. The device signs the challenge. Access is granted. No password to type. No OTP to copy. No push notification to approve. Just cryptographic proof that the person at the device is authorized.

## API Key Management and Rotation

API keys are the authentication mechanism for machine clients — scripts, CI/CD pipelines, batch jobs, and third-party integrations. Unlike user sessions, which expire after hours or days, API keys are long-lived. Unlike OAuth tokens, which are scoped and delegated, API keys often have full account access. This makes API key compromise one of the most common vectors for data breaches in AI systems. An API key leaks in a GitHub commit, in a Slack message, in a Docker image. An attacker finds it and has unrestricted access to your platform.

The first defense is to treat API keys like passwords. They should be generated with cryptographic randomness, stored hashed on the server, and transmitted securely. When a user creates an API key, your system shows the key once and then never again. If the user loses the key, they must revoke it and create a new one. This prevents key exposure in support tickets, in screenshots, and in logs. The hashed key on the server should use a key derivation function like bcrypt or Argon2, not a simple hash like SHA-256. This makes brute-force attacks infeasible even if the database is compromised.

The second defense is **key rotation**. API keys should have expiration dates — 90 days for low-privilege keys, 30 days for high-privilege keys, 7 days for admin keys. When a key approaches expiration, the system should notify the owner and allow them to rotate it without downtime by issuing a new key while the old key is still valid. For 24 hours, both keys work. This gives the owner time to update their code. After 24 hours, the old key is revoked. Rotation should be mandatory, not optional. If a key expires without rotation, it stops working. No grace periods. No extensions. Forced rotation is the only way to limit the blast radius of key compromise.

The third defense is **key scoping**. API keys should be scoped to the minimum permissions needed for their use case. A key used by a CI/CD pipeline to run evaluations should not have permission to delete datasets. A key used by a batch job to retrieve embeddings should not have permission to fine-tune models. A key used by a third-party integration to read conversation history should not have permission to modify access policies. Scoping reduces the damage an attacker can do with a stolen key. It also creates an audit trail — if a key with read-only permissions suddenly starts making write requests, that is anomalous and should trigger an alert.

Some teams implement **key prefixes** — encoding metadata in the key itself. A key starting with "sk-prod" is for production. A key starting with "sk-test" is for testing. A key starting with "sk-admin" has elevated privileges. Prefixes make it easier to identify leaked keys in public repositories. GitHub scans for keys with known prefixes and alerts the repository owner. But prefixes also make keys easier to identify for attackers. The trade-off depends on your threat model. If key leakage in repositories is your primary concern, use prefixes. If targeted attacks against your platform are your primary concern, avoid them.

## Service Account Authentication for Agents

Agents introduce a new authentication challenge: how does an autonomous agent authenticate when it operates on behalf of a user but without the user present? The agent might run for hours or days. It might spawn background jobs that outlive the user's session. It might make decisions that require escalated privileges — deleting data, approving expenses, initiating refunds. You cannot use the user's session token because it will expire. You cannot use a shared API key because it does not capture which user initiated the action. You need **service account authentication** — a system where the agent has its own identity, its own credentials, and its own audit trail.

Service accounts are non-human identities that authenticate with credentials issued by your platform. When an agent workflow starts, the system creates a service account scoped to the user and the task. The service account has a unique identifier, a short-lived token, and permissions inherited from the user who started the workflow. Every action the agent takes is logged under the service account's identity, but the audit log also records the originating user. This allows forensic reconstruction: "Service account sa-12345, acting on behalf of user Alice, accessed document 67890 at 2026-02-11T14:32:00Z."

Service account tokens should be short-lived — 15 minutes to 1 hour — and automatically renewed by the agent runtime. The agent never stores credentials. It requests a token from the credential provider at the start of every action. If the credential provider is unavailable, the agent fails gracefully rather than continuing with expired credentials. This prevents a class of attacks where an attacker hijacks a long-running agent and uses its credentials hours after the user's session has ended.

But service accounts create a new risk: privilege escalation. If an agent can act on behalf of any user, it can escalate its own privileges by switching to a higher-privileged user. The defense is to bind service accounts to the user at creation time. A service account created for Alice can only act as Alice. It cannot switch to Bob. It cannot escalate to an admin account. The binding is cryptographic — the service account token includes the user ID in a signed claim that the agent runtime cannot modify. If the agent attempts to access resources outside Alice's permissions, the request is rejected at the authorization layer.

This is the authentication stack that production AI systems run on. It is complex. It requires multiple protocols, multiple token types, and multiple rotation policies. But it is also the only architecture that supports both human users and autonomous agents, both web applications and API clients, both enterprise SSO and consumer-grade passkeys. Authentication is not a feature. It is the foundation. Every other security control depends on it.

The next chapter, Chapter 8 — RAG Security and Knowledge Base Attacks, shifts from identity and access control to content security — how to protect retrieval pipelines from poisoned documents, adversarial embeddings, and cross-tenant information leakage in shared knowledge bases.
