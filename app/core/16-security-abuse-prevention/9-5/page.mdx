# 9.5 â€” Tool Chain Exploitation in Multi-Step Workflows

The research agent was good at its job. It searched databases, extracted relevant documents, summarized findings, and generated reports. Each step used a different tool. Search returned document IDs. Retrieval fetched full text. Summarization condensed content. Generation compiled the final report. The workflow had four steps. The attacker only needed to compromise one.

In late 2025, a legal research firm deployed an agent that retrieved case law, summarized precedents, and drafted memos. The agent used a tool chain: search tool, document retrieval tool, citation formatter, and memo generator. Each tool had input validation. The search tool blocked injection attempts. The retrieval tool sanitized file paths. The formatter rejected malformed citations. But the tools validated their own inputs, not each other's outputs. The attacker discovered that the search tool's output became the retrieval tool's input without intermediate validation. By crafting a search query that returned adversarial document metadata, they poisoned the retrieval step. The metadata contained instructions disguised as citation formatting. When the citation formatter processed it, the instructions executed. The firm caught it after three fabricated case citations appeared in a client memo. The tool chain was individually secure but collectively vulnerable.

## The Seam Between Tools

Multi-step agents orchestrate workflows by chaining tool calls. Each tool performs a specific function. Each tool has defined inputs and outputs. The agent decides which tool to call, passes outputs from one tool as inputs to the next, and combines results into a final answer. This architecture is powerful. It's also architecturally vulnerable at every handoff point.

**Tool chain exploitation** is the practice of compromising one tool in a sequence to poison downstream tools. The attacker doesn't break any individual tool. They manipulate data as it flows between tools. The orchestrator treats tool outputs as trusted data. If tool A returns adversarial content disguised as legitimate output, tool B processes it without additional validation. The attack succeeds not by breaking validation, but by bypassing it through the workflow.

The core problem is trust transitivity. The agent trusts tool A to return well-formed data. Tool B trusts the agent to provide well-formed inputs. The agent assumes tool A's output is safe to pass to tool B. If tool A's output is attacker-controlled, the assumption breaks. The agent becomes an unwitting courier for adversarial data.

Consider a typical tool chain: search, retrieval, analysis, generation. The search tool accepts a user query, returns matching document IDs, and the orchestrator passes those IDs to the retrieval tool. The retrieval tool fetches documents and passes content to the analysis tool. The analysis tool extracts insights and passes them to the generation tool, which writes the final output. Four tools, three handoff points. Each handoff is a potential injection site.

## Data Poisoning Between Steps

The simplest attack poisons tool outputs to influence downstream tools. The attacker controls input to tool A. Tool A processes the input and returns output. The output looks legitimate. But the output contains hidden instructions, adversarial data, or malformed structures that tool B will misinterpret.

An example: a web search agent uses a search tool that returns page titles, URLs, and snippets. The agent passes these results to a summarization tool. The attacker creates a web page with a title that includes prompt injection syntax disguised as metadata. The search tool returns the title as-is. The orchestrator passes the title to the summarizer. The summarizer processes the title as part of the content to summarize. The hidden instructions in the title execute. The summarizer is compromised not by the user's query, but by the search tool's output.

Structured output poisoning is more subtle. Many tools return structured data: JSON objects, database rows, API responses. The orchestrator parses this structure and passes fields to other tools. If the attacker can control field values, they can inject adversarial content into specific fields that downstream tools treat as trusted. A calendar tool returns event descriptions. The agent passes descriptions to a notification tool. The attacker schedules an event with a description containing instructions. The notification tool processes the description and executes the instructions. The calendar tool's validation didn't consider downstream tool vulnerabilities.

File-based chains are especially vulnerable. Tool A writes intermediate results to a file. Tool B reads that file. If tool A doesn't sanitize outputs, or tool B doesn't validate inputs, the file becomes an injection channel. The agent treats the file as trusted internal data. The attacker treats it as a writable attack vector. This pattern appears in data processing pipelines, report generation systems, and document workflows where agents persist intermediate state to disk.

## The Orchestrator as Target

Tool chain attacks don't just target individual tools. They target the orchestrator that coordinates the chain. The orchestrator decides which tools to call, in what order, with what inputs. If the attacker can manipulate the orchestrator's decision logic, they can redirect the workflow, skip security checks, or force the agent to call tools in unsafe sequences.

Decision hijacking works by poisoning the data the orchestrator uses to choose next steps. Many orchestrators use the previous tool's output to decide what to do next. If the search tool returns zero results, the orchestrator might call a fallback tool. If the validation tool returns an error, the orchestrator might retry with relaxed parameters. The attacker crafts inputs that trigger specific decision branches. The orchestrator follows its logic, but the logic leads to an exploitable state.

In early 2026, a customer support agent used a tool chain: ticket classification tool, knowledge base search tool, response generation tool. The orchestrator chose the search query based on the classification. The attacker submitted a ticket crafted to be classified as "billing issue." The classification triggered a search in the billing knowledge base, which had looser content restrictions than the general knowledge base. The attacker's ticket contained injection syntax disguised as a billing question. The search tool retrieved the attacker's own previous ticket as a match. The response generator processed the retrieved ticket as example content. The injection executed. The orchestrator made every decision correctly. The workflow led to compromise.

Loop exploitation is another orchestrator-level attack. Some workflows include loops: retry logic, iterative refinement, multi-turn tool sequences. The orchestrator calls a tool, evaluates the output, and decides whether to call another tool or return a result. The attacker forces the orchestrator into a loop by providing inputs that never satisfy the exit condition. The orchestrator keeps calling tools, each iteration passing slightly modified attacker-controlled data. After enough iterations, the accumulated transformations create an exploitable state. The orchestrator's own retry logic becomes the attack vector.

## Multi-Step Attacks That Evade Per-Tool Validation

The most dangerous tool chain exploits require multiple steps to succeed. No single tool is compromised. Each tool validates its inputs and produces safe outputs. But the composition of safe steps produces an unsafe result. The attack succeeds at the system level even though every component is secure at the unit level.

Staged injection is one pattern. Step one: the attacker uses tool A to store adversarial data in a location tool B will later read. Step two: the attacker triggers a workflow that calls tool B. Tool B reads the stored data, treating it as trusted internal state. The injection executes. Tool A's validation didn't consider what tool B would do with the data. Tool B's validation assumed the data came from a trusted source. Both assumptions were correct in isolation and wrong in combination.

Privilege escalation through tool chaining exploits permission boundaries. Tool A is restricted and low-privilege. Tool C is powerful and high-privilege. Tool B sits in between. The attacker can't call tool C directly because they lack permissions. But they can call tool A, which calls tool B, which calls tool C. The orchestrator doesn't check whether the original user should have access to tool C. It only checks whether tool B is allowed to call tool C. The answer is yes. The tool chain becomes a privilege escalation ladder. Each step is authorized. The sequence is exploitative.

Output amplification attacks use tool chains to magnify small compromises. The attacker injects a single adversarial token into tool A's input. Tool A's validation catches most of the payload but lets one token through. Tool A passes output to tool B. Tool B processes the token and produces three tokens of output, one of which is adversarial. Tool B passes output to tool C. Tool C processes it and produces ten tokens, three of which are adversarial. By the end of the chain, a single-token injection has become a full payload. No tool was individually compromised. The chain amplified the signal.

## Cross-Tool Validation Gaps

Most tool validation is local. The tool checks that inputs are well-formed, within expected ranges, and don't contain obvious attack patterns. But tools don't validate whether their outputs are safe for downstream consumption. The tool outputs what its logic determines is correct. The orchestrator assumes correct outputs are safe outputs. This assumption fails when adversarial inputs produce correct but exploitative outputs.

A document retrieval tool validates that file paths are within allowed directories. It successfully blocks path traversal attacks. But it doesn't validate the content of retrieved documents. If a document contains adversarial instructions, the retrieval tool returns it anyway because the file path was valid. The downstream summarization tool processes the document content as trusted. The path validation prevented one attack. It didn't prevent content-based attacks. The gap between tools is where the exploit lives.

Semantic validation is even harder. A tool can validate that an input is a well-formed email address without validating whether sending an email to that address is safe. A tool can validate that a date is in ISO format without validating whether scheduling an event on that date is appropriate. A tool can validate that a SQL query is syntactically correct without validating whether executing it is authorized. Structural validation catches malformed inputs. Semantic validation requires understanding intent, context, and downstream effects. Most tools only do the former.

The orchestrator is supposed to fill these gaps, but orchestrators are often thin. They route data between tools, track workflow state, and handle errors. They don't deeply validate every intermediate value. They assume tools output safe data. If that assumption is wrong, the orchestrator propagates unsafe data through the chain.

## Defense Requires End-to-End Validation

Securing tool chains requires treating the entire workflow as the unit of security, not individual tools. Each tool validates its own inputs. The orchestrator validates that tool outputs are safe to pass to subsequent tools. Data flows through the chain only after validation at every boundary.

Output sanitization is one mitigation. Every tool sanitizes its outputs before returning them to the orchestrator. Sanitization strips or escapes content that downstream tools might misinterpret as instructions. The tool doesn't know which downstream tools will consume its output, so it sanitizes defensively. This prevents tool A from accidentally passing adversarial content to tool B, even if tool A is functioning correctly.

Orchestrator-level validation checks tool outputs before using them. When tool A returns data, the orchestrator validates it against a schema before passing it to tool B. The validation checks structure, types, ranges, and content patterns. If tool A returns unexpected data, the orchestrator rejects it rather than propagating it. This turns the orchestrator into a security boundary, not just a routing layer.

Tool chain contracts formalize what each tool expects from its upstream dependencies and guarantees to its downstream consumers. The contract specifies input preconditions, output postconditions, and invariants. Tools enforce contracts at runtime. The orchestrator enforces that tool outputs satisfy the next tool's contract. Contract violations halt the workflow. This prevents incompatible tools from being chained in unsafe ways and catches output poisoning when it violates downstream expectations.

Least privilege for tools limits what each tool can do and what data it can access. Tools only see the data they need for their specific function. If a search tool is compromised, it can't access user data. If a summarization tool is exploited, it can't call the email tool. Tool isolation contains the blast radius. A compromised tool can't directly poison other tools because it can't reach them. The orchestrator mediates all inter-tool communication and enforces access boundaries.

Workflow monitoring tracks data as it flows through tool chains. The system logs inputs, outputs, and decisions at every step. When an agent produces an unsafe result, auditors trace the data backward through the chain to identify where contamination entered. Monitoring doesn't prevent attacks, but it makes them detectable and traceable. Teams can identify compromised workflows before the contamination spreads to other users.

But even with defenses, tool chains remain high-risk. Every handoff is a trust boundary. Every output is a potential input to an untrusted downstream consumer. The more tools in the chain, the larger the attack surface. The more complex the orchestration logic, the more opportunities for decision hijacking. Multi-step workflows are where agents are most powerful and most vulnerable. In goal hijacking, you'll see how attackers target not just the data flowing through tool chains, but the agent's understanding of what it's trying to accomplish.

