# Section 16 — AI Security and Abuse Prevention

The attacker is already inside. Not metaphorically. Literally. Every user prompt is untrusted input. Every retrieved document is a potential payload. Every tool call is an execution path an adversary can hijack. In October 2025, a zero-click prompt injection called EchoLeak compromised Microsoft 365 Copilot through nothing more than a poisoned email sitting in a user's inbox. The user never opened it. The AI assistant processed it automatically, executed the embedded instructions, and exfiltrated sensitive business data to an external URL. The attack required no credentials, no malware, no social engineering beyond crafting the right string of characters. This is the security landscape of 2026: AI systems that interpret language, infer intent, call tools, and act autonomously have become attack surfaces unlike anything traditional security was built to handle.

This section teaches you to think like an attacker and build like a defender. The threat taxonomy is not theoretical. Prompt injection topped OWASP's LLM security risks for two consecutive years because the vulnerability is architectural, not incidental. Jailbreaks succeed twenty percent of the time in an average of forty-two seconds because models are trained to be helpful, and helpfulness can be exploited. Model extraction attacks steal your competitive edge through nothing more than API queries. LLMjacking operations hijack your compute to resell inference at criminal marketplaces. Rogue agents act as insider threats, capable of goal hijacking and privilege escalation at speeds no human can match. The teams that ship secure AI products understand that security is not a feature you add after launch. Security is architecture you design from the first line of the system prompt.

The twelve chapters ahead cover every attack surface in modern AI systems. You will learn the six categories of AI security risk and how they map to your architecture. You will study prompt injection and jailbreaks not as abstractions but as specific techniques with specific defenses. You will understand why tools create privilege escalation paths and how to constrain them. You will see how retrieval-augmented generation turns every document into an injection vector and how to build secure RAG pipelines. You will confront model theft, data exfiltration, economic attacks, and supply chain compromise. You will learn to detect attacks in progress and respond before damage spreads. Each chapter ends with three artifacts: an attack playbook showing how adversaries exploit the vulnerability, a defense-in-depth stack showing how to layer protections, and a detection checklist showing how to catch attacks in production.

The security mindset is simple: assume adversarial users, adversarial inputs, and adversarial environments. If you do not design for abuse, someone else will exploit it.

---

## Chapters

### Chapter 1 — The AI Security Threat Landscape
Why AI systems are fundamentally different attack surfaces, the unified threat taxonomy, and the security mindset.

### Chapter 2 — Prompt Injection Attacks and Defenses
Direct injection, indirect injection, instruction hierarchy confusion, and layered defenses.

### Chapter 3 — Jailbreaks and Safety Bypass
Role-play attacks, semantic chaining, encoded jailbreaks, and hardening system prompts.

### Chapter 4 — Tool Abuse and Privilege Escalation
Unauthorized tool calls, tool chaining attacks, MCP server exploits, and least-privilege design.

### Chapter 5 — Data Exfiltration and Leakage
System prompt extraction, context window leakage, cross-tenant exposure, and memory poisoning.

### Chapter 6 — Model Theft and Extraction
Query-based extraction, policy recovery, watermarking, rate shaping, and behavioral fingerprints.

### Chapter 7 — Identity, Access, and Entitlements
Impersonation, session hijacking, entitlement abuse, and role-based access control.

### Chapter 8 — RAG Security and Knowledge Base Attacks
Poisoned documents, the poison-feedback loop, provenance scoring, and secure RAG architecture.

### Chapter 9 — Agent Security and Autonomous Systems
Shadow agents, goal hijacking, action loops, and approval checkpoints.

### Chapter 10 — Denial of Service and Economic Attacks
Token bombs, cost exhaustion, LLMjacking, and circuit breakers.

### Chapter 11 — Supply Chain and Model Security
Compromised models, MCP server risks, vendor failures, and dependency management.

### Chapter 12 — Detection, Monitoring, and Incident Response
Anomaly detection, attacking the monitors, tamper-evident trails, and incident playbooks.

---

*The attacker only needs to succeed once. You need to succeed every time. This section teaches you how.*
