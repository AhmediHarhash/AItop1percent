# 7.6 — Scoped Tokens and Capability-Based Security

A customer requested API access to integrate your AI service into their workflow automation platform. You generated an API key for their account. The key had full access to their subscription: all models, all tools, all data, all rate limits. Two weeks later, their automation platform was breached. The attacker extracted all stored API keys from customer accounts, including yours. Your customer's API key was now in attacker hands — with full access to their account, no way to revoke just the compromised key without breaking their entire integration, and no visibility into which specific actions the attacker was performing because all actions looked like legitimate API usage from the customer's key.

The problem wasn't the breach — breaches happen. The problem was the blast radius. A single compromised credential gave access to everything the account could do. There was no way to limit the key to just the features the integration needed. No way to expire the key automatically after the integration's short-term data migration was complete. No way to revoke access to one tool without revoking the entire key. The security model was binary: you have the key and can do everything, or you don't have the key and can do nothing. Real security needs more granularity.

## The Limitations of Binary Access

Traditional API authentication uses long-lived, high-privilege credentials. A user logs in, gets a session token, and that token represents full account access until it expires or is explicitly revoked. An API integration gets an API key, and that key represents full account access forever or until manually rotated. The model works when systems have a small, stable set of capabilities and a clear trust boundary between inside and outside. If you trust the user, you trust them with everything their account permits. If you trust the API integration, you trust it with everything the API offers.

This breaks down in AI systems for three reasons. First, AI capabilities are expansive and composable. An account might have access to fifteen different models, forty tools, six data sources, and three external integrations. Not every use case needs all of them. An automation that generates daily reports needs read access to data and the report generation model. It doesn't need write access, user management tools, or the expensive frontier model. But if the API key grants full account access, the automation has all of it.

Second, AI integrations are increasingly automated and distributed. The API key isn't held by a human who understands its power and guards it carefully. It's stored in environment variables, configuration files, CI/CD pipelines, third-party automation tools, mobile apps, browser extensions. Each storage location is a potential leak point. When the leak happens, the attacker gets everything the account can do — not just what the integration needed.

Third, the lifespan mismatch. A user's session token might live for two hours. An API key for an integration might live for months. A key embedded in a mobile app might live for years, hardcoded in a binary distributed to millions of devices. The longer a credential lives, the higher the probability it leaks, and the longer the window between leak and detection. A two-hour session token compromised at hour one gives the attacker one hour of access. A two-year API key compromised at month one gives the attacker twenty-three months of access if the leak is never detected.

A logistics company learned this in March 2025 when a developer accidentally committed their production API key to a public GitHub repository. The key had been active for fourteen months. The repository was indexed by credential-scanning bots within six hours. By the time the company discovered the leak three days later, the compromised key had been used to make seventy-three thousand API calls, generating eleven thousand dollars in unexpected model usage costs. The calls were exploratory — the attacker was testing what the key could do. They accessed customer delivery addresses, shipment histories, and route optimization data. The company revoked the key, but that broke their entire logistics platform until they regenerated and redeployed a new key across eighteen microservices.

## Scoped Tokens: Embedding Permissions in Credentials

A scoped token is a credential that carries its own permission set. Instead of representing full account access, it represents access to a specific subset of capabilities, for a specific duration, under specific constraints. The token itself encodes what it can do. The system validates not just that the token is legitimate, but that the action being requested is within the token's scope.

The simplest form is feature-scoped tokens. A token for a report generation integration has read access to analytics data and access to the report model, but nothing else. If someone tries to use that token to access customer PII or invoke a model fine-tuning job, the request fails — not because the account lacks those permissions, but because the token doesn't grant them. The token's scope is narrower than the account's capabilities.

The second form is time-scoped tokens. A token issued for a temporary data export job expires after six hours. After expiration, the token is invalid regardless of whether the account is still active. A token issued for a mobile app session expires after thirty days, forcing the app to re-authenticate. Time scoping limits the blast radius of a leak: even if the token is compromised, the attacker's window of access is bounded.

The third form is action-scoped tokens. A token might permit only read operations, or only specific write operations. A token for a content moderation tool can flag content and update moderation status, but can't delete accounts or access payment information. A token for a monitoring dashboard can query metrics but can't modify system configuration. The action scope ensures that even if the token is used maliciously, the damage is limited to the actions the token permits.

The fourth form is resource-scoped tokens. A token might have access to a specific dataset, a specific customer's records, a specific project within a multi-tenant system. A customer success manager gets a token scoped to their assigned accounts — they can access those accounts' data but not others. A data science team gets a token scoped to anonymized data in the analytics environment, with no access to production data. Resource scoping prevents lateral movement: the attacker who compromises one token can't use it to access resources outside its scope.

## Token Introspection and Validation

The token carries its scope, but the system must validate it on every request. Validation happens in three parts. First, authenticity: is the token legitimate, or is it forged? This requires cryptographic signatures. The token is signed by the issuer using a private key. The validator checks the signature using the public key. If the signature is invalid, the token is rejected. The signature ensures the token hasn't been tampered with — an attacker can't modify the scope to grant themselves more access.

Second, freshness: is the token still valid, or has it expired? The token includes an issued-at timestamp and an expiration timestamp. The validator checks the current time against these timestamps. If the token is expired, it's rejected. If the token was issued in the future (a sign of clock skew or forgery), it's rejected. Freshness checks prevent replay attacks where an attacker uses an old, captured token.

Third, scope compliance: does the token's scope permit the action being requested? The validator extracts the scope claims from the token and compares them to the request. If the request is to invoke a model, the validator checks whether the token's scope includes that model. If the request is to write data, the validator checks whether the token permits write actions. If the request is to access a specific resource, the validator checks whether the token is scoped to that resource. Scope compliance is the core of capability-based security: the token explicitly lists what it can do, and anything not listed is forbidden.

A healthcare SaaS platform implemented scoped tokens for their AI diagnostic assistant used by external clinics. Each clinic got a token scoped to their own patients' data, specific diagnostic models approved for their region, and read-only access to clinical guidelines. The token was signed, time-limited to ninety days, and included metadata about the clinic's licensing jurisdiction. When a clinic made a request, the validation layer checked: is the signature valid, is the token expired, does the request target a patient in this clinic's scope, is the requested model permitted in this jurisdiction, is the action type (read or write) within the token's capabilities. If any check failed, the request was denied before reaching the model or data layer.

The result: a compromise of one clinic's token gave the attacker access only to that clinic's data, only for the remaining lifespan of the token, only for read operations, only with models appropriate to that jurisdiction. The blast radius was bounded in four dimensions. When a token leaked through a third-party analytics integration seven months after deployment, the attacker accessed two hundred patient records — from one clinic, during a three-week window before the token expired, with no ability to modify data or access other clinics. The breach was still serious and reportable. But it was contained to a scope far smaller than if the token had represented full account access.

## Read-Only Tokens for Auditing and Monitoring

The monitoring team needs visibility into AI system performance: request volumes, latency, error rates, model usage, cost metrics. They don't need access to request content, customer data, or system configuration. But the monitoring dashboard was built with admin-level API keys because that was the only authentication method available. When a monitoring team member's laptop was stolen, the company had to assume the thief had admin access to the AI platform — even though the stolen credentials were only ever used for reading metrics.

Read-only tokens solve this by granting visibility without control. A token can permit reading logs, metrics, and metadata, but deny all write operations. The token can't modify configurations, can't trigger deployments, can't delete data, can't invoke models — it can only observe. If the token leaks, the attacker gains visibility into your system's operations, which is an information disclosure risk, but they can't use the token to directly harm the system.

The challenge with read-only tokens is defining what "read" means in an AI system. In a traditional database, read means SELECT queries. Write means INSERT, UPDATE, DELETE. In an AI system, a "read" operation might include invoking a model with a prompt, because the response doesn't modify state — it's just output. But invoking a model costs money. If an attacker gets a read-only token and makes ten million model inference requests, they haven't modified your data, but they've cost you a hundred thousand dollars.

So read-only for AI systems often means read-only for metadata and logs, not read-only for model invocation. A monitoring token can query request counts, error rates, latency percentiles. It can't invoke models. An audit token can retrieve access logs, permission changes, and configuration history. It can't invoke models or modify policies. A debugging token can read traces, inspect requests, and view model outputs. It might permit model invocation, but with strict rate limits and only in non-production environments.

The read-only token becomes a least-privilege tool for teams that need visibility but not control. Your monitoring infrastructure uses read-only tokens. Your audit and compliance tools use read-only tokens. Your business intelligence dashboards use read-only tokens. External auditors get temporary read-only tokens scoped to compliance-relevant logs. If any of these tokens leak, the attacker gains visibility — which you address by ensuring your logs don't contain sensitive data — but not the ability to act.

## Time-Limited and Ephemeral Tokens

The data migration required moving three months of customer interaction data from the old platform to the new AI system. The migration script needed write access to import historical data. The script would run once, take approximately four hours, and never be needed again. The team could have created a long-lived API key with write access, run the migration, and then remembered to revoke the key afterward. Or they could have created a time-limited token that expired six hours after issuance, ensuring that even if they forgot to revoke it, the token would become useless automatically.

Time-limited tokens reduce the cost of credential hygiene. Revoking credentials requires remembering to do it, having the access to do it, and verifying it was done. Every manual step is an opportunity for failure. Time-limited tokens handle revocation automatically through expiration. The token is issued with a maximum lifespan. When the lifespan ends, the token is invalid, regardless of whether anyone remembered to revoke it.

The shortest-lived tokens are ephemeral: issued on demand for a single operation, valid for seconds or minutes, and automatically invalidated after use. A user wants to export a report. The frontend requests an export token from the backend. The backend issues a token scoped to report export, valid for sixty seconds, usable once. The frontend uses the token to call the export API. The API validates the token, generates the report, and marks the token as consumed. The token is now invalid even though it hasn't expired yet. If an attacker intercepts the token, they have a sixty-second window to use it, and only if they use it before the legitimate request does.

Ephemeral tokens are expensive to implement because they require token state tracking. The system must remember which tokens have been issued, which have been consumed, and which are still valid. For long-lived tokens, you can validate stateless — the token signature proves it was legitimately issued, and the expiration timestamp proves it's still valid, with no need to store token state. For ephemeral tokens, you need a token registry: a database of active tokens, their scopes, their expiration times, and their usage status. Every token validation requires a database lookup. At high request volume, this becomes a performance bottleneck.

The trade-off is between security and scalability. Stateless tokens scale infinitely — validation is pure computation, no coordination needed, every validator can work independently. But once issued, a stateless token is valid until expiration regardless of revocation attempts. Stateful tokens allow instant revocation — you delete the token from the registry, it's immediately invalid everywhere — but require central coordination and database queries on every validation.

Most systems use hybrid approaches. Long-lived tokens for routine operations are stateless: session tokens for logged-in users, API keys for stable integrations, service-to-service authentication. These tokens expire eventually and can be rotated periodically. Short-lived tokens for sensitive operations are stateful: tokens for password reset, tokens for email verification, tokens for one-time admin actions. These tokens need instant revocation capability and have low enough volume that the database lookup cost is acceptable.

## Capability Tokens for Tool Access

Your AI model has access to twenty-three tools: database queries, API calls, file operations, email sending, payment processing, analytics, reporting. Not every user should permit the model to invoke every tool. A customer success user should allow the model to query customer records and send emails, but not process payments. A developer in a test environment should allow the model to query test databases and call staging APIs, but not touch production. A data analyst should allow the model to run read-only queries and generate reports, but not write data.

Capability tokens encode which tools the model can invoke on behalf of the user. When a user sends a prompt, the request includes a capability token. The token lists the permitted tools. When the model decides to invoke a tool, the orchestration layer checks whether that tool is in the token's capability list. If yes, the tool call proceeds. If no, the tool call is blocked, and the model is informed that the tool is unavailable. The model must generate a response without that tool, or inform the user that the requested action isn't permitted.

This prevents privilege escalation through prompt injection. If an attacker injects a prompt that instructs the model to "send an email to all customers with this phishing link," and the user's capability token doesn't include the email tool, the model can't execute the instruction. The orchestration layer blocks the tool call. The capability token acts as a allowlist enforced at the tool invocation boundary.

A financial services company implemented this for their AI-powered trading assistant used by analysts, traders, and compliance officers. Analysts got tokens with read-only data access and analytical tools. Traders got tokens with market data access and order simulation tools, but not order execution — actual trades required manual approval. Compliance officers got tokens with read access to trade logs and reporting tools. The model was the same for all users. The tool access differed based on their capability token.

When a trader asked the model to "execute this trade," the model generated a tool call to the order execution API. The orchestration layer checked the trader's capability token. It included order simulation but not order execution. The tool call was blocked. The model received an error indicating the tool was unavailable and responded: "I've simulated this trade, and the results look favorable. To execute, you'll need to submit the order through the manual approval workflow." The model tried to help within its capabilities and guided the user toward the approved process when it couldn't.

## Token Revocation and Rotation

Scoped tokens reduce blast radius. They don't eliminate breach risk. A token with limited scope is still a credential, and if it leaks, it grants whatever access it was scoped to. The difference is you now have options. With a single, long-lived, full-access API key, revocation is binary: revoke the key and break everything that depends on it, or don't revoke and accept the security risk. With multiple scoped tokens, revocation is granular: revoke the compromised token and only the integration using that token breaks.

A media company issued separate tokens for each of their AI integrations: content recommendation engine, automated transcription service, sentiment analysis dashboard, internal search, chatbot. Five integrations, five tokens, each scoped to the minimum capabilities needed. When their transcription service provider had a breach and advised all customers to rotate credentials, the company revoked the transcription token, issued a new one, and updated the transcription service configuration. The other four integrations continued working. Revocation impacted one service for one hour during rotation. With a single shared API key, all five integrations would have broken simultaneously during rotation.

Token rotation is the practice of periodically replacing credentials before they leak. A token issued today is revoked and replaced in thirty days, regardless of whether a compromise is suspected. Rotation limits the lifetime of any credential, ensuring that even an undetected leak has a bounded window of validity. The challenge is automation. Manual rotation — generating a new token, updating every system that uses the old token, revoking the old token — is error-prone and often skipped. Automated rotation — systems that request new tokens before old ones expire, update their configuration, and seamlessly transition — is complex to implement but scales reliably.

The most sophisticated systems use overlapping token validity. When it's time to rotate, the system issues a new token but doesn't immediately revoke the old one. For a grace period (maybe one hour), both tokens are valid. Services can update to the new token during this window. After the grace period, the old token is revoked. This prevents race conditions where a service tries to use the old token after it's been revoked but before it received the new token. The overlap allows coordination-free rotation: services pull the new token when convenient, with no need to synchronize the cutover moment.

## Principle of Least Privilege Through Token Design

The principle of least privilege says: grant only the access required for the task, nothing more. In practice, this is hard to achieve because determining the minimum required access takes effort, and it's easier to grant broad access upfront. Scoped tokens make least privilege practical by separating privilege definition from credential issuance. You define once what each integration or use case needs. Every time you issue a token for that use case, it automatically has the appropriate scope.

A customer onboarding team needs to run an AI assistant that verifies customer-submitted documents, extracts key information, and populates account records. The access requirements: read submitted documents, invoke the document analysis model, write to the new customer database. The team defines a token scope: document-verification-scope, which includes read access to the document storage bucket, access to the analysis model, and write access to the customer DB with restrictions (can only insert new records, can't update or delete existing ones).

Every time an onboarding agent starts a session, the system issues a token with document-verification-scope. The token is time-limited to eight hours — the length of a work shift. It's resource-scoped to only documents submitted in the last thirty days and only customer records created in the last thirty days. It's action-scoped to the verification workflow: read document, analyze, write result. The agent can't access historical documents, can't modify established customer accounts, can't invoke models outside the verification workflow. The scope is tight enough to limit damage from a compromised account, broad enough to let the agent do their job.

The team didn't need to think about least privilege on every token issuance. They thought about it once when defining the scope. The system enforces it automatically every time a token is issued. This scales. The security team defines scopes for common use cases. Teams request tokens with the appropriate scope. The system issues tokens with embedded restrictions. Even if a team doesn't understand the security implications, they get least-privilege access by default because the scope was designed correctly upfront.

The shift from coarse-grained, long-lived, high-privilege credentials to fine-grained, time-limited, capability-scoped tokens is one of the most effective security improvements AI systems can adopt. It doesn't prevent attacks. It contains them. A breach that would have exposed your entire system now exposes one component, for a limited time, with limited capabilities. The attacker still got in. The damage is bounded. That's the difference between a security incident and a company-ending catastrophe.

The next subchapter covers federated identity and third-party authentication — how you handle access when users authenticate through external providers, how you map external identities to your internal roles, and how you prevent identity confusion attacks where an attacker authenticates as one user in one system and is treated as a different user in yours.

