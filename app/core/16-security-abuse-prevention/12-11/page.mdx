# 12.11 â€” Disclosure: Communicating About Security Events

Transparency builds trust. Silence destroys it. This is not a philosophical claim. It is a measurable pattern observed across hundreds of security incidents in AI systems from 2024 through 2026. Companies that disclosed security events quickly and honestly retained 87 percent of affected customers on average. Companies that hid incidents, minimized severity, or delayed disclosure until forced by regulators or press reports lost an average of 41 percent of affected customers within six months. The difference was not the severity of the incident. The difference was whether the company treated customers as stakeholders who deserved transparency or as liabilities who needed to be managed. Customers can forgive a security incident. They do not forgive being lied to.

**Disclosure** is the process of communicating about security events to the people who need to know: internal stakeholders, affected customers, regulators, and in some cases the public. It is not PR spin. It is not damage control. It is the operational requirement to inform people who are impacted by a security event so they can make informed decisions about their own risk. Teams that treat disclosure as an afterthought discover that the disclosure failure causes more damage than the original incident. The technical response fixes the vulnerability. The disclosure response determines whether the organization retains customer trust, regulatory credibility, and employee confidence.

## Internal Disclosure: Who Needs to Know and When

The first disclosure happens inside the organization. Not everyone needs to know about every security event, but the right people must be informed immediately. A critical data breach that exposes customer information requires notification to executive leadership, legal, communications, customer success, and engineering within the first hour. A low-severity vulnerability discovered in a development environment requires notification to the security team and the responsible engineering team but does not require executive escalation. The framework is simple: inform everyone whose decisions or actions depend on knowing this information.

Engineering leadership must know about security events that require immediate remediation, significant resource allocation, or cross-team coordination. They need to know within the first hour of discovery for critical issues, within the first day for high-priority issues. They do not need detailed technical forensics. They need severity, impact, affected systems, remediation timeline, and resource requirements. The disclosure to engineering leadership is not a request for permission. It is operational coordination to ensure the fix gets the priority and resources it needs.

Legal must know about security events that create regulatory obligations, contractual liability, or litigation risk. They need to know immediately for any incident that involves personal data, financial data, health data, or minors. They need to know within 24 hours for incidents that might trigger notification requirements under GDPR, CCPA, HIPAA, or other regulations. Legal does not decide whether to disclose. Legal advises on the disclosure timing, content, and method to ensure compliance and manage liability. The mistake teams make is treating legal as an obstacle to disclosure rather than as a partner in managing the organizational risk.

Customer success and support must know about security events that affect customers or that customers might discover independently. They need to know before customers start asking questions. A prompt injection vulnerability that allowed some users to see data from other accounts requires immediate notification to customer success so they can respond to inquiries. A model degradation issue that causes incorrect outputs requires notification so support teams understand why customers are reporting problems. The disclosure to customer-facing teams must include what happened, what customers might experience, what has been fixed, and what customers should do if they are concerned. Customer success operates as the first line of trust repair.

Communications and public relations must know about security events that might become public through media reporting, regulatory disclosure, or social media. They need to know early enough to prepare messaging, coordinate with legal on disclosure requirements, and plan the communication strategy. Communications does not control the disclosure. Communications ensures the disclosure is clear, consistent, and delivered through the right channels. The worst-case scenario is a security event becoming public through a leak or a third-party report before the company has prepared any communication. The organization looks incompetent and evasive even if the actual response was fast and effective.

Executive leadership must know about security events that create significant business risk, regulatory risk, or reputational risk. The threshold for executive notification depends on the organization, but general guidance is: notify executives immediately for any incident that could lead to regulatory penalties, major customer churn, or public disclosure. Notify executives within 24 hours for incidents that require budget reallocation, significant engineering effort, or changes to product roadmap. Executives do not need to be involved in remediation. They need to understand the risk, the response, and the organizational impact so they can make informed strategic decisions.

The internal disclosure must happen through documented channels. A Slack message is not sufficient. A verbal conversation is not sufficient. The disclosure must be logged in an incident tracking system with timestamp, recipients, and content. This documentation protects the organization during audits, investigations, and litigation. It also creates accountability. An incident that is disclosed properly has a clear chain of responsibility. An incident communicated through informal channels creates confusion about who knew what and when.

## External Disclosure: Customers, Regulators, and the Public

External disclosure is legally required in many cases and operationally necessary in most others. The decision is not whether to disclose. The decision is when, how, and to whom. A data breach that exposes personal information of European Union residents requires notification to affected individuals within 72 hours under GDPR. A breach that exposes health information requires notification under HIPAA. A breach that exposes financial information requires notification under state and federal laws depending on jurisdiction. Regulatory disclosure is not optional. It is a legal obligation with specific timelines and content requirements. Teams that miss regulatory deadlines face penalties that often exceed the cost of the original incident.

Customer disclosure is required when customers are directly affected by a security event and need to take action to protect themselves. A credential leak requires customer disclosure so affected users can change passwords. A data breach requires customer disclosure so affected individuals can monitor for identity theft. A model manipulation incident that caused incorrect outputs requires customer disclosure so affected customers can review decisions made based on those outputs. The disclosure must be specific. It must explain what happened, what data was affected, what the company has done to remediate, and what the customer should do next. Vague disclosures that say "we take security seriously" without explaining the actual impact are worse than no disclosure. They signal that the company is hiding something.

Public disclosure is required when the incident has broad impact, affects a large population, or is likely to become public knowledge through other means. A widespread prompt injection vulnerability that affected thousands of users requires public disclosure. A model poisoning incident that compromised outputs for a deployed product requires public disclosure. An abuse campaign that targeted vulnerable populations through the AI system requires public disclosure. Public disclosure happens through blog posts, press releases, or regulatory filings depending on the audience and the context. The public disclosure must be factual, complete, and transparent. It must acknowledge the failure, explain the fix, and describe the changes being made to prevent recurrence.

The content of external disclosure must balance transparency with security. The disclosure must be honest about what happened without providing a detailed exploitation guide for attackers who have not yet discovered the vulnerability. A disclosure that says "we discovered a vulnerability that allowed unauthorized access to user data" is sufficient. A disclosure that includes the exact API endpoint, the specific payload, and the step-by-step instructions to reproduce the vulnerability is irresponsible. The goal is to inform affected parties so they can assess their risk and take protective action, not to teach additional attackers how to exploit the system.

The timing of external disclosure is a judgment call that balances legal requirements, customer needs, and security risk. If the vulnerability is fixed and there is no evidence of active exploitation, disclosure can happen immediately after the fix is deployed and verified. If the vulnerability is fixed but there is evidence of exploitation, disclosure must happen immediately so affected parties can respond. If the vulnerability is not yet fixed but is being actively exploited, disclosure must happen even though the fix is incomplete, because affected parties need to know they are at risk. The only scenario where disclosure is delayed is when an active investigation is underway and disclosure would compromise law enforcement efforts. Even then, affected parties must be notified as soon as the investigation allows.

## Disclosure Timing and Legal Considerations

Disclosure timelines are driven by legal requirements, customer impact, and practical coordination constraints. GDPR requires notification to supervisory authorities within 72 hours of becoming aware of a personal data breach. It requires notification to affected individuals without undue delay if the breach poses a high risk to their rights and freedoms. HIPAA requires notification to affected individuals within 60 days of discovery. CCPA requires notification without unreasonable delay. State breach notification laws in the United States vary but typically require notification within 30 to 90 days. The legal timelines are maximums, not targets. Faster disclosure is better unless there is a specific operational or investigative reason for delay.

The phrase "becoming aware" is legally significant. An organization becomes aware of a breach when it has sufficient information to determine that a breach has occurred, not when the investigation is complete. Teams that delay disclosure while conducting exhaustive forensics to determine every affected record are violating notification timelines. The initial disclosure can acknowledge uncertainty: "We have confirmed that customer data was accessed without authorization. We are continuing to investigate the scope and will provide updates as we learn more." Perfect information is not required. Reasonable certainty is required.

Legal review is necessary but must not become a bottleneck that delays time-sensitive disclosure. The legal review ensures the disclosure meets regulatory requirements, does not create additional liability through inaccurate statements, and coordinates with any ongoing investigations. The legal review should take hours, not days. A disclosure that is delayed by a week while legal debates wording is a disclosure that has already violated regulatory timelines. The coordination between security, legal, and communications must be practiced in advance so that when a real incident occurs, the disclosure workflow is fast and efficient.

Disclosure to regulators happens in parallel with disclosure to affected parties, not sequentially. The GDPR notification to a supervisory authority and the notification to affected individuals happen on the same timeline. The mistake teams make is assuming they must complete the regulatory notification before notifying customers. This is incorrect. Regulatory notification and customer notification are independent obligations that both must be met within their respective timelines. The regulatory notification provides detail on the breach, the impact, and the remediation. The customer notification provides actionable information customers need to protect themselves.

The disclosure must be documented. Every external communication about a security incident must be saved, timestamped, and stored in the incident record. This documentation is essential for audits, investigations, and litigation. It also ensures consistency. If a company tells one regulator that the breach affected 10,000 records and tells another regulator it affected 5,000 records, the inconsistency creates legal problems even if both numbers are reasonable estimates based on ongoing investigation. The documentation ensures the organization can demonstrate that disclosure was timely, accurate, and complete.

## Crafting Security Communications That Build Trust

The language of disclosure matters. A disclosure that is defensive, vague, or filled with corporate jargon destroys trust. A disclosure that is clear, factual, and respectful of the affected parties builds trust even in the context of a serious failure. The goal is not to minimize the incident. The goal is to give people the information they need to understand what happened and what they should do.

The disclosure must start with a clear, direct statement of what happened. "On March 15, 2026, we discovered that an unauthorized party accessed customer account data through a vulnerability in our API" is clear. "We recently became aware of a potential security event that may have resulted in unauthorized access to certain information" is vague and evasive. The reader should understand the nature of the incident from the first sentence. Burying the key facts in the third paragraph is a signal that the organization is more concerned with managing perception than with informing affected parties.

The disclosure must specify what data was affected. "The accessed data included names, email addresses, and account creation dates. It did not include passwords, payment information, or message content" is specific. "Customer information may have been accessed" is not specific. The affected party needs to know what data was involved so they can assess their own risk. If the investigation is ongoing and the full scope is not yet known, say that explicitly: "We have confirmed that names and email addresses were accessed. We are continuing to investigate whether additional data types were involved and will provide an update within 48 hours."

The disclosure must explain what the organization has done to fix the problem. "We deployed a patch on March 16 that closes the vulnerability. We have reviewed our systems and found no evidence of similar vulnerabilities. We are implementing additional monitoring to detect unauthorized access attempts" is concrete. "We take security seriously and are working to address this issue" is empty. The affected party needs to know that the vulnerability has been fixed and that the organization is taking steps to prevent recurrence. This is where transparency builds trust. If the fix is incomplete, acknowledge it and explain the timeline for full remediation.

The disclosure must tell affected parties what they should do. "If you are an affected customer, we recommend changing your password and enabling two-factor authentication. We have sent individual notifications to all affected accounts with specific guidance" is actionable. "Please contact us if you have questions" is not actionable. The affected party should not need to guess what protective steps they should take. The disclosure should provide clear, specific recommendations based on the nature of the incident. If there is nothing the affected party needs to do because the fix fully addressed the risk, say that too.

The tone must be professional, respectful, and accountable. The disclosure should acknowledge the seriousness of the incident, take responsibility without deflecting blame, and express commitment to doing better. "We recognize that this incident represents a failure of our security practices. We are committed to learning from this incident and implementing changes to prevent similar failures in the future" is accountable. "While no system is perfectly secure, we have taken steps to enhance our protections" is defensive. The affected party does not need an apology essay. They need confidence that the organization understands what went wrong and is fixing it.

## When Not to Disclose: Active Investigations and Threat Intelligence

There are limited scenarios where disclosure is appropriately delayed. The most common is when law enforcement is actively investigating the incident and has requested that the organization not disclose publicly because disclosure would compromise the investigation. This happens when the attacker is still being tracked, when evidence is being gathered for prosecution, or when disclosure would alert other members of a coordinated threat actor group. Even in these cases, affected parties must still be notified. The delay applies to public disclosure, not to individual notification of people whose data was breached.

The second scenario is when disclosure would create immediate additional risk. If a vulnerability is discovered but has not yet been exploited, and the fix cannot be deployed for operational reasons such as requiring downtime for a critical system, disclosure might be delayed until the fix is deployed. The delay is measured in days, not weeks. The risk calculation is straightforward: is the risk of exploitation during the delay period smaller than the risk of exploitation after public disclosure before the fix is ready? If the answer is no, disclose immediately and accept the operational disruption required to deploy the fix under emergency conditions.

The third scenario is when disclosure would reveal threat intelligence that is more valuable kept confidential. If a security team discovers an active campaign by a sophisticated adversary and disclosure would alert the adversary that they have been detected, disclosure might be delayed while the team gathers intelligence and coordinates with law enforcement or threat intelligence partners. This scenario is rare and applies primarily to nation-state actors or organized crime groups conducting long-term campaigns. It does not apply to opportunistic attackers or to vulnerabilities discovered through standard security testing.

In all three scenarios, the delay is temporary and specific. It is not a blanket excuse to avoid disclosure. The organization must document the reason for delay, the duration of delay, and the plan for eventual disclosure. The delay must be reviewed regularly. A delay that was justified on day one might not be justified on day 30 if the investigation has stalled or if the operational fix is still not ready. The default is disclosure. Delay is the exception that requires active justification.

## Disclosure as Organizational Competence

The ability to disclose security incidents clearly and quickly is a signal of organizational maturity. Companies that disclose well are companies that have prepared in advance, practiced the workflow, and built the internal coordination required to respond at speed. Companies that handle disclosure poorly are companies that are improvising under pressure, discovering gaps in their communication processes, and making decisions without clear frameworks. The disclosure capability is built through preparation, not through crisis management.

The preparation includes pre-drafting disclosure templates for common incident types. A data breach disclosure template. A service disruption disclosure template. A model manipulation disclosure template. The templates include placeholders for incident-specific details but provide the structure, tone, and key content areas that every disclosure must cover. When a real incident occurs, the team starts with the template and customizes it, rather than starting from a blank page under time pressure. The templates are reviewed and updated annually to reflect changes in regulations, business operations, and communication channels.

The preparation includes defining roles and approval workflows. Who drafts the disclosure? Who reviews it for technical accuracy? Who reviews it for legal compliance? Who reviews it for tone and clarity? Who has final approval? Who handles distribution? The workflow must be fast enough to meet regulatory timelines. A disclosure that requires five levels of approval and takes three days to finalize is a disclosure process that will fail during a time-sensitive incident. The workflow should allow a disclosure to go from initial draft to published communication within four to eight hours for a high-priority incident.

The preparation includes practicing disclosure through tabletop exercises. Simulate a data breach. Simulate a model manipulation incident. Simulate a vulnerability disclosure from an external researcher. Walk through the disclosure workflow: who gets notified internally, when does legal get involved, what gets communicated externally, how is the communication distributed, how are follow-up questions handled. The exercise reveals gaps in the process, unclear roles, and bottlenecks that would cause delays during a real incident. A team that has practiced disclosure three times is faster and more coordinated than a team that has never practiced.

Disclosure is not the end of incident response. It is the beginning of trust repair. The organization that discloses transparently earns the opportunity to prove it has learned from the failure. The proof comes through visible changes: new security controls, updated processes, third-party audits, public commitments to improvement. Disclosure without follow-through is worse than silence. It signals that the organization views disclosure as a compliance checkbox rather than as a commitment to do better. The disclosure sets expectations. The follow-through determines whether those expectations are met.

The final step after disclosure is not moving on. It is learning. Every security incident, regardless of severity, is an opportunity to improve. The post-incident review determines what failed, why it failed, and what changes will prevent similar failures. Remediation fixes the vulnerability. Disclosure restores trust. The post-incident review ensures the organization gets better.
