# 7.4 — Entitlement Abuse: Premium Bypass, Trial Farming, Receipt Spoofing

The attacker never sent a single malicious prompt. Every API call looked legitimate. Every request stayed within rate limits. Every model output was reasonable. And over eighteen months, they extracted four hundred and sixty-seven thousand dollars worth of premium AI features without paying a cent. The attack wasn't technical — it was economic. They understood that your entitlement system had a seventeen-second window between subscription validation and feature access, and they automated a process that created accounts, consumed premium features, and vanished before the payment verification completed.

Business logic attacks don't look like security incidents. They look like customer activity. The logs show successful authentications, valid API keys, normal usage patterns. The fraud isn't in the request itself — it's in the entitlement chain that determines whether the user should be allowed to make that request in the first place. And because these attacks exploit the gap between what your system promises and what your payment infrastructure confirms, they scale silently until the finance team notices the revenue shortfall.

## The Economics of Entitlement Abuse

**Entitlement abuse** is any method that allows a user to access paid features, higher quotas, or premium capabilities without the corresponding payment or authorization. Unlike prompt injection or jailbreaking — which try to bypass content filters — entitlement abuse bypasses the business model. The attacker's goal is economic, not technical. They want the expensive model, the higher rate limit, the advanced tools, the enterprise features. They want what paying customers get, without paying.

The math is straightforward. If your premium tier costs twenty-nine dollars per month and provides access to Gemini 3 Pro with a ten-times-higher rate limit, and an attacker can generate fifty fake premium accounts per day, they're extracting forty-three thousand five hundred dollars of value per month. If each fake account survives for an average of eleven days before detection, the attacker cycles through fifteen hundred accounts monthly. That's enough to run a competing service, resell access at a discount, or simply consume resources you're now paying for without revenue to offset it.

The damage compounds. Every fake premium account consumes infrastructure capacity that real customers needed. Every trial-farmed user occupies a database slot, a rate limiter entry, a monitoring dashboard line item. Your observability tools show growth. Your finance team sees cost increases without corresponding revenue. Your customer support team gets complaints from real users hitting capacity limits because attackers filled the quota first. The abuse doesn't just steal from you directly — it degrades service for legitimate users.

## Trial Farming: The Endless Evaluation

A logistics company launched a free trial in April 2025: fourteen days of full access to their AI routing assistant, normally priced at two hundred dollars per month for small fleets. Within six weeks, they had eleven thousand trial accounts. Conversion rate was 0.3%. The finance team assumed low product-market fit. The engineering team knew better. When they analyzed email domains, seventy-two percent were disposable email services. When they checked usage patterns, the median trial account made API calls for exactly thirteen days, stopped, and a new account from a similar email pattern appeared within hours.

The attackers weren't evaluating the product. They were farming it. Each trial gave them thirteen days of free API access. By rotating accounts, they ran a permanent free-tier operation with premium features. The company was effectively providing free infrastructure to a competitor who resold access at eighty dollars per month — undercutting them while using their own compute.

Trial farming works because trials are designed for low friction. You want real prospects to sign up easily, so you minimize verification. Email confirmation, maybe a credit card on file that won't be charged yet. The attacker automates account creation with disposable emails, virtual credit card numbers that pass validation but decline on charge, or stolen credit cards that will be reported fraudulent before the trial ends. Each new account resets the clock.

The classic defense — requiring credit card upfront — reduces trial signups by thirty to fifty percent depending on your market. That's real lost revenue from real prospects. So teams try softer controls. Limit trials per IP address. Block disposable email domains. Require phone verification. Each control has a bypass. Residential proxy networks rotate through millions of real IP addresses. Disposable email services launch new domains faster than you can blocklist them. SMS verification costs the attacker twelve cents per number through bulk SMS services, which is cheaper than paying for your product.

The effective defense is behavioral. Real trial users explore features, test different inputs, read documentation, maybe contact support. Trial farmers hit the API with production-scale traffic from day one. Real users ramp up over days. Farmers start at maximum quota immediately. Real users have diverse usage patterns. Farmers run the same queries repeatedly, often at suspiciously regular intervals. If your trial account makes four thousand API calls in the first six hours with identical request patterns, it's not a prospect — it's automation.

## Premium Bypass: Accessing What You Didn't Pay For

The SaaS platform had three tiers: Basic at nine dollars per month with access to Gemini 3 Flash and a rate limit of fifty requests per day, Pro at forty-nine dollars with Gemini 3 Pro and five hundred requests per day, Enterprise at custom pricing with Claude Opus 4.5 and unlimited requests. The entitlement logic lived in a service that checked subscription status before routing requests to the model API. A developer noticed that if you sent a request with a model parameter set to a premium model while subscribed to Basic, the entitlement service returned an error — but if you sent the same request with a misspelled model name that the system couldn't recognize, it defaulted to the highest-tier model available to avoid breaking the user experience.

That default behavior was documented nowhere. It was a failsafe added during a production incident nine months earlier when a model name typo caused a cascade of user-facing errors. The fix: if the model name is unrecognized, fall back to the most capable model to preserve functionality. The side effect: anyone who knew the trick could access premium models by intentionally misspelling the model parameter. For seven months, a subset of Basic-tier users sent requests with model names like "opus-45" or "gemini-pro-3" — close enough to look like typos, wrong enough to trigger the fallback logic.

Premium bypass attacks exploit gaps in your entitlement enforcement layer. The gaps appear in three common places. First, race conditions between subscription validation and feature access. Your payment processor takes two seconds to confirm a subscription is active. Your API responds in three hundred milliseconds. If the entitlement check is asynchronous and non-blocking, there's a window where a cancelled subscription still grants access. Second, client-side enforcement. If your frontend disables the premium model selector for Basic users but your backend API doesn't enforce the same restriction, anyone inspecting network traffic can replay requests with premium model parameters. Third, failover logic. Systems designed to degrade gracefully under failure often degrade upward — granting more access than intended when checks fail, because denying access angers users more than giving access costs money.

The financial impact is invisible until you measure it. Your logs show model usage. Your billing system shows subscription tiers. If you never join those two datasets, you never see that twenty-three percent of your Opus 4.5 API calls came from Basic-tier accounts. The abuse looks like growth. Your infrastructure costs rise. Your per-customer revenue doesn't. Eventually the unit economics stop working, and the finance team blames the product for being unprofitable when the real problem is that you're serving premium features at basic-tier prices to anyone who reverse-engineered your API.

## Receipt Spoofing and Fake Purchase Validation

The mobile app used in-app purchases through Apple and Google's payment systems. Users bought AI credits in bundles: ninety-nine cents for ten credits, four ninety-nine for sixty credits, nine ninety-nine for one hundred fifty credits. After purchase, the app sent the receipt to the backend for validation. The backend called Apple's receipt verification API, confirmed the purchase was legitimate, and credited the user's account. Standard implementation, recommended by both platforms.

An attacker realized the receipt verification API had a sixty-second timeout. If the API call took longer than sixty seconds, the backend assumed the receipt was valid rather than risk blocking a real customer's purchase. The attacker used a man-in-the-middle proxy to intercept their own device's requests to Apple's verification endpoint, introduced artificial latency, and forced timeouts. The backend, seeing repeated timeouts, assumed Apple's service was degraded and credited the account anyway. Over four months, the attacker generated thirty-two thousand dollars worth of credits from a single ninety-nine-cent purchase.

Receipt spoofing is any technique that convinces your system a purchase occurred when it didn't. The most common method: replaying valid receipts. A user makes a legitimate purchase. The attacker captures the receipt data — either by compromising the user's device, by being the user and inspecting network traffic, or by exploiting a vulnerability in your app's receipt handling. They then replay that receipt to your backend, claiming it represents a new purchase. If your backend doesn't track which receipts it has already processed, it credits the account again. One purchase becomes infinite credits.

The defense is receipt deduplication: store every processed receipt identifier, reject duplicates. But storage has a cost. Apple and Google receipts can be kilobytes each, and a high-volume app processes millions per month. Storing every receipt forever is expensive. So teams add retention policies: keep receipts for ninety days, then purge. The attacker waits ninety-one days and replays the receipt. Your deduplication table no longer has a record of it, so you credit the account again.

More sophisticated attacks forge receipts entirely. Apple's receipt validation API requires a shared secret configured in App Store Connect. If your shared secret leaks — hardcoded in your app binary, accidentally committed to a public repository, exposed in a server-side vulnerability — an attacker can generate fake receipts that pass validation because they're signed with your secret. Google's approach uses JSON Web Tokens signed with a service account key. Same vulnerability: if the key leaks, receipts can be forged.

The nuclear option: attacker compromises your backend's receipt validation logic entirely. If your validation code runs in a server environment with weak access controls, or if it's possible to inject environment variables that override the validation endpoint URL, an attacker can redirect validation requests to their own fake validation service that always returns success. Your app sends a receipt. Your backend calls what it thinks is Apple's API. It's actually calling attacker-controlled infrastructure that says "yes, valid purchase, credit the account." The logs show successful validation. The receipts are completely fabricated.

## Quota Exhaustion Through Legitimate-Looking Abuse

The enterprise customer signed a contract for one million API requests per month at three cents per request, thirty thousand dollars monthly. Their usage was predictable: thirty thousand requests per day, spread evenly across business hours, perfectly aligned with their stated use case of customer support automation. Then in month six, they hit one million requests by the ninth day of the month. They requested a quota increase to five million requests, citing rapid growth. The account team approved it, excited about expansion revenue.

By month eight, they hit five million requests by day twelve. Another increase request, this time to ten million. The account team hesitated. The customer provided business justification: they'd expanded to three new markets, each with its own support operation. The numbers looked reasonable. Quota approved. By month ten, they hit ten million requests by day fifteen. The customer requested twenty million.

At this point someone in finance ran the unit economics. The customer's contract was still priced at three cents per request. At twenty million requests, that's six hundred thousand dollars monthly. But the customer's actual per-request cost to the AI provider was four point two cents — margin-negative at scale. When the account team reviewed usage logs in detail, they found something subtle. The customer was making requests with extremely short prompts and responses, often single-sentence exchanges. The median prompt was eleven tokens. The median response was nine tokens. They were using the world's most expensive model as a glorified keyword lookup system, optimizing for maximum request count at minimum token cost per request.

The customer wasn't violating terms of service. They were exploiting a pricing model designed for typical usage patterns. The contract charged per request, not per token. The team assumed requests would average two hundred to four hundred tokens total. The customer engineered their system to minimize tokens per request and maximize request count, extracting far more compute value than the contract intended.

Quota exhaustion abuse happens when users structure their usage to extract maximum value from your pricing model's weakest dimension. If you charge per request, they minimize request payload. If you charge per token, they maximize tokens per request with padding, repeated context, or unnecessary verbosity. If you charge per month with unlimited usage, they run the system at maximum capacity every minute of every day. The usage is technically legitimate — nothing in the request structure violates your API contract — but the economic intent is adversarial.

The fix requires repricing or contract renegotiation, which is politically fraught. You signed a contract. The customer is operating within it. Changing terms mid-contract risks legal disputes, damages the relationship, and signals to other customers that your pricing isn't stable. But continuing the contract at current terms loses money on every request. The correct move was to design the pricing model correctly from the start — understanding all the dimensions users can optimize and pricing accordingly. By the time you discover the exploit, you're stuck with it until renewal.

## The Cost of Entitlement Abuse at Scale

A company with two hundred thousand monthly active users discovered through forensic analysis that eleven percent of their user base was engaged in some form of entitlement abuse. Trial farming, premium bypass through API manipulation, receipt replay attacks, quota optimization. Not all abusers were sophisticated. Many were ordinary users who found a trick — a shared tutorial on Reddit, a YouTube video showing how to get premium features free — and used it without thinking of it as fraud.

The revenue impact was two point four million dollars annually. That's revenue they should have collected but didn't, because users accessed paid features without payment. The infrastructure cost impact was one point one million annually — compute, storage, and bandwidth consumed by abusive accounts. The operational cost was three hundred and twenty thousand annually — engineering time investigating abuse, customer support handling disputes when accounts were banned, legal time dealing with chargebacks and fraud claims.

But the largest cost was opportunity cost. The abuse consumed capacity that legitimate paying customers needed. During peak hours, real customers hit rate limits because abusive accounts filled the quota first. Real customers experienced slower response times because abusive accounts saturated the model API. Real customers waited longer for support because the support queue was filled with disputes from banned accounts claiming they did nothing wrong. The abuse made the product worse for everyone who paid for it.

The hardest part of entitlement abuse is that it sits between engineering and business. Engineering sees technical problems with clear technical solutions: better validation, stricter enforcement, more sophisticated detection. Business sees customer experience problems: every control you add creates friction for legitimate users, reduces conversion, increases support load. The trial farming fix that requires phone verification drops trial signups by thirty percent. The premium bypass fix that adds latency to every request makes the product feel slower. The receipt validation fix that stores every receipt forever increases infrastructure costs.

You can't solve entitlement abuse with engineering alone. You can't solve it with business policy alone. You need both, and you need to accept that every defense has a conversion cost. The goal isn't perfect enforcement — it's economic equilibrium where the cost of abuse to you is less than the cost of abuse detection and prevention, and the friction cost to legitimate users is less than the revenue loss from unchecked abuse. That equilibrium point is different for every product, and it shifts as attackers adapt.

The teams that handle entitlement abuse well treat it as an ongoing operational problem, not a one-time security fix. They monitor the ratio of premium feature usage to premium subscriptions weekly. They audit trial conversion funnels for patterns that indicate farming. They track receipt validation failure rates and investigate spikes. They run regular experiments adding or removing friction to see how conversion and abuse rates shift together. They accept that some abuse will always exist, and they optimize for minimizing total cost — direct loss, opportunity cost, prevention cost, friction cost — not minimizing abuse count.

Your system will leak entitlement. The question is whether you know how much, where, and whether the leak is growing faster than your ability to detect and patch it. Most teams find out only when finance runs the numbers and discovers the product is unprofitable despite growing usage. By then, the abuse is entrenched, the exploits are documented in user communities, and fixing it requires either repricing the product or breaking backward compatibility with thousands of users who expect the exploit to keep working.

The next subchapter covers role-based access control — how you structure permissions so that not every user has access to every feature, and how you prevent role escalation attacks that turn basic users into administrators through privilege manipulation.

