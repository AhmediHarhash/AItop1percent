# 8.5 — Progressive Rollout Strategies

In October 2025, a customer support platform deployed a new response generation model to all users simultaneously. The model had passed every gate — automated eval scores improved by 6 percent, human review showed better coherence, A/B testing with 500 users showed 11 percent higher satisfaction. The team felt confident. Thirty minutes after deployment, support ticket volume tripled. The regression was subtle: the model generated responses 40 percent faster on average, but for complex queries involving account-specific history, it occasionally skipped critical steps. At 500 concurrent users, this affected seven interactions per hour. At 47,000 concurrent users, it affected 650 interactions per hour. The team rolled back after two hours, but the damage compounded — users who received incomplete responses then submitted follow-up tickets, and the support queue took three days to clear. The eval system caught nothing. The A/B test sample size was too small to surface the rare-but-critical failure mode. The rollout strategy was the only missing control.

Progressive rollout is not about testing — it is about **controlled exposure to reality at the scale where problems become visible before they become catastrophic**. Every gate you have built so far operates in a simulation of production. Automated evals use test sets. Human review uses samples. A/B testing uses limited traffic. None of these replicate the full complexity of production — the edge cases, the concurrent load, the interaction patterns that only emerge when thousands of users engage simultaneously. Progressive rollout is the final gate. It exposes the new system to real production traffic in increments, monitors for regressions at each step, and halts if problems appear. It is the difference between a controlled deployment and a production incident.

## The Principle of Gradual Exposure

Gradual exposure means you increase the percentage of traffic seeing the new system in stages — 1 percent, 5 percent, 10 percent, 25 percent, 50 percent, 100 percent — and you wait at each stage long enough to observe behavior before proceeding. The waiting period is called **bake time**. During bake time, you monitor regression metrics, review edge cases, and validate that the new system behaves as expected under real load. If metrics degrade, you halt the rollout. If metrics hold, you proceed to the next stage.

The reason this works is statistical and operational. At 1 percent traffic, a regression that affects one in every 500 interactions becomes visible within hours instead of weeks. You catch it when it impacts 20 users instead of 10,000. At 5 percent traffic, concurrency patterns start to emerge — you see how the system behaves when multiple users trigger the same edge case simultaneously. At 25 percent traffic, you validate cost scaling — what looked sustainable at small scale may reveal inefficiencies when traffic volume increases. At 50 percent traffic, you confirm that your infrastructure can handle the load without degradation. Each stage surfaces a different class of risk. Skipping stages means skipping the signal that would have caught the problem.

The increments and bake times are not arbitrary. They are calibrated to your traffic volume, your metric sensitivity, and your tolerance for impact radius. A system serving 10 million requests per day can detect a 0.5 percent regression at 1 percent traffic within four hours. A system serving 100,000 requests per day may need 5 percent traffic and 24 hours of bake time to observe the same signal. The lower your traffic volume, the larger your initial rollout percentage needs to be to generate statistically significant signal. The higher your traffic volume, the more granular your rollout stages can be.

## Rollout Strategies: Percentage, Segment, Geography

There are three primary rollout strategies, and the best deployments combine all three.

**Percentage-based rollout** assigns a random percentage of traffic to the new system. At 5 percent rollout, every twentieth request sees the new model. This is the simplest strategy and the most statistically sound — random assignment eliminates selection bias. If performance degrades at 5 percent rollout, you know the problem is in the new system, not in the user population. Percentage-based rollout is the default for most deployments. It works well when your user population is homogeneous and your primary concern is catching regressions that affect all users equally.

**User-segment-based rollout** assigns specific cohorts to the new system. You might roll out to free-tier users before paid users, to internal employees before external customers, or to users in low-risk industries before high-risk industries. Segment-based rollout lets you test with populations where failure has lower consequences. If the new system regresses, you catch it with users who have higher tolerance for errors or where contractual obligations are lower. The downside is that segment-based rollout introduces selection bias — free-tier users may have different usage patterns than paid users, and a regression that only affects paid users will not surface until you roll out to that segment.

**Geographic rollout** deploys the new system to specific regions first. You might roll out to a single availability zone, a single data center, or a single country. Geographic rollout is essential when your system has region-specific behavior — language models that perform differently across languages, or content moderation systems that need to respect local regulations. It also limits infrastructure risk. If the new system causes a data center outage, it affects one region instead of all regions. The downside is that geographic rollout may not surface usage patterns that are unique to other regions. A model that works perfectly in North America may fail on European data formats or Asian language variants.

## Combining Rollout Strategies

The most robust rollouts layer all three strategies. You start with percentage-based rollout in a single geographic region, then increase percentage and expand geography, then roll out to higher-risk user segments last.

A typical rollout plan for a high-stakes system looks like this. Stage one: 1 percent of traffic in US-West region, free-tier users only, 24-hour bake time. Stage two: 5 percent of traffic in US-West region, all user tiers, 24-hour bake time. Stage three: 10 percent of traffic in US-West and EU-West regions, all user tiers, 48-hour bake time. Stage four: 25 percent of traffic in all regions, all user tiers, 72-hour bake time. Stage five: 50 percent of traffic in all regions, all user tiers, 72-hour bake time. Stage six: 100 percent rollout. Each stage combines percentage increase, geographic expansion, and segment expansion. Each bake time is long enough to observe regressions in the metrics that matter.

The reason you layer strategies is that each one catches different failure modes. Percentage-based rollout catches regressions that affect all users. Segment-based rollout catches regressions that only affect high-value or high-risk users. Geographic rollout catches regressions that depend on regional infrastructure or language. A rollout plan that uses only one strategy will miss regressions that the other strategies would have caught.

## Rollout Velocity: How Fast to Increase Exposure

Rollout velocity is the time between stages. Move too fast and you do not give regressions time to surface. Move too slow and you delay value delivery. The correct velocity depends on three factors: your traffic volume, your metric sensitivity, and your organizational risk tolerance.

For high-traffic systems, you can move faster. A system serving 10 million requests per day can progress from 1 percent to 5 percent to 10 percent within 72 hours because each stage generates enough traffic to surface regressions quickly. For low-traffic systems, you need to move slower. A system serving 100,000 requests per day may need a week at 5 percent rollout to accumulate enough data to detect a 2 percent regression.

For high-risk systems, you move slower regardless of traffic volume. A medical diagnostic system, a financial fraud detection system, or a content moderation system for child safety cannot afford to miss regressions. The cost of a production incident outweighs the cost of delayed deployment. These systems use longer bake times — 72 hours at 1 percent, a week at 5 percent, two weeks at 25 percent. The deployment takes a month, but the probability of a catastrophic failure drops by an order of magnitude.

For low-risk systems, you can move faster. An internal recommendation system or a non-customer-facing summarization tool can progress from 1 percent to 100 percent in a week. If a regression surfaces, the consequences are limited. The trade-off favors speed.

## Bake Time: How Long to Wait at Each Level

Bake time is the duration you spend at each rollout percentage before proceeding to the next stage. It is the most important variable in progressive rollout. Too short and you ship regressions. Too long and you delay value. The correct bake time depends on how long it takes for your regression metrics to accumulate enough signal to detect a meaningful degradation.

If your primary metric is response quality and you receive 1,000 human reviews per day, a 1 percent rollout generates 10 reviews per day for the new system. To detect a 5 percent quality drop with statistical confidence, you need at least 40 reviews. That requires four days of bake time. If your primary metric is task success rate and you process 100,000 requests per day, a 1 percent rollout generates 1,000 requests per day for the new system. To detect a 2 percent success rate drop, you need at least 2,000 requests. That requires two days of bake time.

The formula is straightforward: calculate the sample size required to detect your minimum meaningful regression, divide by your daily traffic at the rollout percentage, and that is your minimum bake time. Add buffer for weekends, holidays, and unusual traffic patterns. A two-day minimum becomes four days when you account for Saturday and Sunday. A four-day minimum becomes a week when you account for reduced traffic during holiday weeks.

Bake time is also the window where you manually review edge cases. Automated metrics catch broad regressions. Human review catches subtle regressions that only appear in specific contexts. At 5 percent rollout, you sample 50 interactions per day and review them in detail. You look for the patterns that automated metrics miss — tone shifts, factual errors, formatting inconsistencies. If you find a pattern, you investigate. If the pattern is isolated, you continue. If the pattern is systemic, you halt the rollout.

## Rollout Automation vs Manual Promotion

Some rollouts are fully automated. The system progresses from 1 percent to 5 percent to 10 percent on a schedule, and promotion happens automatically if metrics stay green. Other rollouts require manual approval at each stage. An engineer reviews the metrics, confirms that no regressions have surfaced, and clicks a button to proceed to the next stage.

Automated rollout works well for low-risk systems with high confidence in the eval suite. If your automated regression gates have never missed a production incident in the past year, and your rollout metrics align perfectly with your eval metrics, you can safely automate progression. The system monitors metrics in real time, compares them to baseline, and halts automatically if thresholds are breached. Human review happens only when the system detects a problem.

Manual promotion is required for high-risk systems, new systems without deployment history, or systems where eval metrics are not perfectly predictive of production outcomes. A human reviews the rollout metrics at each stage, examines edge cases, and decides whether to proceed. The decision is not just statistical — it incorporates context that automated systems cannot evaluate. If a regression is statistically insignificant but qualitatively concerning, the human can halt. If a metric degrades slightly but the degradation is explainable and acceptable, the human can proceed.

Most organizations start with manual promotion and graduate to automated rollout after they have proven that their eval suite catches every regression the rollout phase would catch. The timeline for this transition is typically six to twelve months. During that period, you compare manual decisions to what an automated system would have decided. If they align 95 percent of the time, you automate with manual override. If they align 100 percent of the time, you automate fully.

## Feature Flags for AI System Rollouts

Feature flags are the mechanism that enables progressive rollout. A feature flag is a configuration variable that controls which users see which version of the system. When the flag is set to 5 percent, 5 percent of traffic is routed to the new model. When the flag is set to 100 percent, all traffic is routed to the new model. The flag can be toggled instantly without redeploying code.

The feature flag system must support percentage-based routing, segment-based routing, and geographic routing. It must allow you to set targeting rules: 5 percent of free-tier users in US-West, 10 percent of all users in EU-West, 25 percent of enterprise customers globally. It must support gradual rollout — you should be able to schedule automatic percentage increases on a timeline, with manual approval gates at each stage. It must integrate with your monitoring system so that metric thresholds can trigger automatic rollback.

Modern feature flag platforms — LaunchDarkly, Split, Statsig — provide all of this out of the box. They also provide kill switches: a single button that instantly reverts all traffic to the old system if a catastrophic regression is detected. The kill switch is the emergency brake. If a regression surfaces that your monitoring system did not catch, any engineer can activate the kill switch and stop the bleeding immediately.

Feature flags also enable A/B testing during rollout. At 50 percent rollout, you are running a large-scale A/B test — half your traffic sees the old system, half sees the new system. You can compare metrics side by side and confirm that the new system is not just meeting thresholds but outperforming the baseline. If the new system underperforms, you halt. If it outperforms, you proceed.

## Rollout Communication: Who Needs to Know

A rollout is not just a technical operation. It is an organizational event. The people who need to know include Engineering, Product, Customer Support, Trust and Safety, Legal, and executive leadership. Each stakeholder needs different information at different stages.

Engineering needs real-time access to rollout metrics. They monitor dashboards, review edge cases, and make the decision to proceed or halt at each stage. Product needs summary updates at each stage — what percentage is live, what the metrics show, when the next stage begins. Customer Support needs advance warning before each stage so they can prepare for potential ticket volume increases. Trust and Safety needs to know when the rollout reaches 25 percent because that is when usage patterns become diverse enough to surface edge cases that small-scale testing missed. Legal needs to know when the rollout completes so they can update compliance documentation. Executive leadership needs a one-line update when the rollout completes successfully or a detailed incident report if the rollout is halted.

The communication cadence depends on the rollout velocity. For a slow rollout — one stage per week — you send updates at the start of each stage. For a fast rollout — multiple stages per day — you send updates only when milestones are reached or when problems are detected. The key is that no stakeholder should be surprised. If Customer Support starts receiving tickets about a regression, they should already know that a rollout is in progress and have escalation instructions ready.

## Emergency Rollout Procedures for Critical Fixes

Not all rollouts follow the gradual progression. Sometimes you need to deploy a fix immediately — a security patch, a compliance update, or a critical bug fix that is causing active harm in production. In these cases, you skip the progressive rollout and deploy to 100 percent immediately.

Emergency rollout procedures are defined in advance. The criteria for emergency deployment are written down: active data breach, active safety incident, active compliance violation, or system outage affecting more than 25 percent of users. The approval chain is shortened — instead of requiring sign-off from Product, Engineering, and Legal, you require sign-off from a single on-call engineering leader. The monitoring requirements are reduced — instead of 24-hour bake times, you monitor for the first hour and review edge cases manually during that window.

Even in an emergency, you do not skip all gates. You still run automated regression tests. You still review human eval samples if time permits. You still monitor the same metrics — you just accept higher risk in exchange for faster deployment. The decision to use emergency rollout procedures is logged and reviewed after the fact. If emergency procedures are invoked more than once per quarter, it is a signal that your standard rollout process is too slow, and you need to optimize for faster iteration without sacrificing safety.

Progressive rollout is the final layer of defense between a tested system and a production disaster. It does not replace evaluation — it complements it. Automated evals catch regressions in controlled environments. Human review catches regressions in sampled interactions. Progressive rollout catches regressions at scale, under real load, with real users, in real time. The question the rollout phase answers is not whether your system works in theory — the question is whether your system works in practice, when the edge cases you did not anticipate start appearing by the hundreds.

The next layer of control is **input distribution monitoring** — ensuring that the traffic your model sees in production matches the traffic it was evaluated on, and detecting when that distribution shifts in ways that invalidate your eval results.
