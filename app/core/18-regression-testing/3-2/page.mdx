# 3.2 — Behavioral Tests: Verifying Expected Characteristics

In October 2024, a healthcare AI company deployed a new diagnostic assistant model. The model passed all accuracy tests. It correctly identified conditions from symptom descriptions at 91 percent accuracy, up from 88 percent baseline. The team celebrated and pushed it to production. Within 48 hours, the product manager received angry messages from clinical users. The model was giving correct diagnoses, but it had started adding disclaimers to every response. A user would describe chest pain and shortness of breath. The model would respond: "Based on your symptoms, this may indicate myocardial infarction. However, I am an AI assistant and cannot provide medical advice. Please consult a licensed physician immediately. This response is for informational purposes only and does not establish a doctor-patient relationship."

The disclaimer was legally appropriate for some contexts. It was clinically disastrous for this one. The tool was designed for use by physicians during patient consultations, not by patients seeking self-diagnosis. The physicians already understood the tool's limitations. The disclaimers added no value, cluttered the interface, and slowed down clinical workflows. Users stopped trusting the tool because it felt defensive and uncertain. The company rolled back the model, investigated, and discovered that the fine-tuning process had inadvertently trained the model to mimic the disclaimer-heavy style of web medical content in the training data. The model learned that disclaimers correlated with higher ratings in human feedback. It started adding them everywhere.

Accuracy testing caught none of this. The diagnoses were correct. Behavioral testing would have caught it immediately. Behavioral tests verify that outputs have expected characteristics beyond correctness. They check format, tone, structure, length, and adherence to style guidelines. They catch regressions in user experience that accuracy metrics miss entirely.

## What Behavioral Tests Measure

Behavioral tests measure properties of outputs that are independent of correctness. A response can be factually accurate while being behaviorally wrong. It can be wrong in tone—too formal, too casual, too defensive. It can be wrong in format—JSON when you expected text, markdown when you expected plain language, lists when you expected prose. It can be wrong in structure—missing required sections, including forbidden sections, violating length constraints. It can be wrong in style—using jargon when you required plain language, using passive voice when you required active voice, including disclaimers when you required concise answers.

Behavioral requirements are context-dependent. A customer support bot should be polite, empathetic, and solution-oriented. A legal research tool should be precise, formal, and citation-heavy. A creative writing assistant should be stylistically flexible and avoid repetition. A medical diagnostic tool used by physicians should be clinically direct without defensive disclaimers. A coding assistant should generate syntactically valid code with explanatory comments. These requirements define the contract between your system and its users. Behavioral tests enforce that contract.

The challenge is that behavioral requirements are often implicit. Teams build systems with unstated assumptions about tone and format. Those assumptions are not documented, not tested, and not enforced. A model change violates the assumptions, and the team only discovers it when users complain. Making behavioral requirements explicit is the first step toward testing them.

## Defining Behavioral Requirements

Before you can test behavioral compliance, you must define what compliance means. This requires collaboration between product, design, and domain experts. You answer questions like: What tone should the system use? What format should outputs follow? What structural elements are required? What length constraints apply? What terminology is acceptable? What terminology is forbidden? What disclaimers are required, and when? What refusal behavior is expected?

A content moderation system might have behavioral requirements like: all decisions must include a reason, all reasons must reference specific policy violations, refusals must be polite but firm, and explanations must avoid describing the violating content in detail. A customer service bot might require: responses must start with acknowledgment of the user's issue, solutions must be actionable, escalation offers must be included when the bot cannot resolve the issue, and all responses must be under 150 words unless the user requests detail. A coding assistant might require: all code must be syntactically valid in the target language, all functions must include docstrings, all non-obvious logic must include inline comments, and generated code must pass a linter.

These requirements are testable. You can write automated checks that verify whether an output starts with acknowledgment, whether a reason references a policy, whether code passes a linter. The key is specificity. "Responses should be polite" is not testable. "Responses must not contain profanity, insults, or dismissive language" is testable. "Outputs should be well-formatted" is not testable. "Outputs must be valid JSON conforming to the specified schema" is testable. Specificity transforms behavioral requirements into behavioral tests.

## Types of Behavioral Tests

Behavioral tests fall into several categories based on what property they verify. **Format tests** check that outputs conform to expected structure. If you expect JSON, the test verifies that the output is valid JSON and conforms to your schema. If you expect markdown, the test verifies markdown validity and checks that required sections are present. If you expect a specific template structure, the test verifies that all required fields are populated and no forbidden fields appear.

Format tests are the easiest to automate. A JSON format test parses the output and validates against a schema. A markdown format test checks for required headers and validates link syntax. A template format test uses regex or structured parsing to verify that required elements are present. Format tests are binary: the output either conforms or it does not. This makes them high-signal and low-noise.

**Tone tests** check that outputs match the intended emotional and stylistic register. A customer support bot should not respond with clinical detachment. A medical tool should not respond with cheerful exclamation points. A legal tool should not use casual slang. Tone testing is harder than format testing because tone is subjective, but it is still automatable with the right approach.

One approach is to use a classifier model trained to detect tone. You label a set of examples as "appropriate tone" or "inappropriate tone" and train a classifier on linguistic features like word choice, sentence structure, punctuation, and formality markers. The classifier runs on every test output and flags tone violations. Another approach is to use rule-based heuristics. If your system must be formal, you flag outputs containing contractions, slang, or exclamation points. If your system must be empathetic, you flag outputs lacking acknowledgment phrases or containing dismissive language.

Tone classifiers are not perfect. They require ongoing tuning as your system evolves. But they catch gross violations reliably. A model that starts responding to frustrated users with "That's not a bug, it's a feature" will fail tone testing even if the factual content is defensible. Tone tests prevent user experience disasters that accuracy metrics miss entirely.

**Instruction-following tests** verify that the model obeys explicit constraints given in the prompt. If the prompt says "respond in three sentences," the output should contain exactly three sentences. If the prompt says "do not include code," the output should contain no code blocks. If the prompt says "format your response as a bulleted list," the output should be a bulleted list. Instruction-following is a behavioral property. A model can give a correct answer while violating the instruction.

Instruction-following tests are common in evaluation benchmarks, but teams often neglect them in production regression suites. This is a mistake. Instruction-following regressions are common during fine-tuning because the model learns task-specific behavior and loses general instruction-following ability. A model fine-tuned on conversational data might stop following formatting instructions. A model fine-tuned on code generation might stop respecting length constraints. Instruction-following tests catch these regressions.

**Refusal behavior tests** verify that the model refuses inappropriate requests and accepts appropriate requests. A content policy-compliant model should refuse to generate hate speech, violence, and illegal content. It should not refuse to discuss these topics in an educational context. It should not refuse benign requests because they contain sensitive keywords. Refusal testing ensures that safety tuning has not made the model overly cautious or insufficiently cautious.

Refusal tests include both positive and negative examples. Positive examples are requests the model should handle. Negative examples are requests the model should refuse. A regression in either direction is a failure. A model that starts refusing more benign requests is a false positive regression. A model that starts accepting more harmful requests is a false negative regression. Both regressions harm user experience and carry different risks.

**Citation and attribution tests** verify that claims are supported by citations when required. A research assistant that makes claims without citations is behaviorally non-compliant even if the claims are factually correct. A legal tool that cites cases incorrectly or fabricates citations is behaviorally non-compliant even if the legal reasoning is sound. Citation testing checks that citations are present, that they are formatted correctly, that they reference real sources, and that the sources actually support the claims made.

Citation testing requires external validation. You cannot verify citation accuracy without checking whether the cited source exists and whether it says what the model claims it says. This requires retrieval of the cited source and comparison of the claim to the source content. Citation tests catch hallucinated references, misattributed quotes, and unsupported claims. These are behavioral failures, not correctness failures, because the underlying reasoning might be sound even if the citation is fabricated.

## Measuring Behavioral Compliance

Behavioral compliance is measured as a percentage of test cases that meet all behavioral requirements. If your behavioral test suite contains 80 examples and 74 pass all checks, your behavioral compliance rate is 92.5 percent. You compare this rate across baseline and candidate models. If the candidate has significantly lower compliance than baseline, you have a behavioral regression.

The challenge is defining what "pass" means for subjective tests like tone. Format tests are binary: valid JSON or invalid JSON. Tone tests require thresholds. If your tone classifier outputs a score from 0 to 1 representing appropriateness, you must choose a threshold above which outputs are considered compliant. Too strict a threshold produces false positives where acceptable outputs fail. Too loose a threshold produces false negatives where inappropriate outputs pass.

Threshold selection requires calibration against human judgment. You collect a set of outputs and have domain experts label them as appropriate or inappropriate. You tune the threshold to maximize agreement with expert labels. You accept that some disagreement will remain because tone is subjective. The goal is not perfect agreement. The goal is catching gross violations reliably while minimizing false positives.

Some behavioral requirements are multi-dimensional. A customer support response might need to be polite, solution-oriented, and under 150 words. All three requirements must be met for the output to be compliant. If any single requirement fails, the output fails. This creates a composite pass/fail score. Multi-dimensional behavioral tests are stricter than single-dimension tests because failure on any dimension causes failure overall.

## Designing Behavioral Test Cases

Behavioral test cases should cover the range of scenarios where behavioral failures are likely. If you require polite tone, include test cases with frustrated or adversarial users where the model might be tempted to respond defensively. If you require JSON format, include test cases with ambiguous queries where the model might revert to natural language. If you require citations, include test cases where supporting evidence is sparse and the model might hallucinate references.

Behavioral test cases do not need ground truth for correctness. They need ground truth for behavior. A citation test case specifies that the output must include citations. It does not specify what the correct answer is. A format test case specifies that the output must be valid JSON. It does not specify what the JSON should contain. This makes behavioral test cases easier to create than correctness test cases because you are testing structure rather than semantics.

Behavioral tests often reuse examples from your golden set. You run the same examples through behavioral checks and correctness checks simultaneously. The example might pass correctness testing but fail behavioral testing or vice versa. Both signals are valuable. An output that is correct but behaviorally non-compliant needs prompt tuning or post-processing. An output that is behaviorally compliant but incorrect needs model improvement.

## Catching Behavioral Regressions in Practice

Behavioral regressions are common during model updates. Fine-tuning on task-specific data can degrade instruction-following. Prompt changes can inadvertently alter tone. Safety tuning can increase refusal rates on benign queries. Output format changes can break downstream parsing. Without behavioral testing, these regressions reach production and degrade user experience.

A legal research company discovered this in mid-2025. They fine-tuned their model on recent case law to improve accuracy. Accuracy improved by four percentage points. Behavioral compliance dropped by fifteen percentage points. The model had stopped including citations for nearly a third of its claims. Users noticed immediately. The company rolled back the model, added citation tests to their regression suite, and re-tuned the model with citation compliance as an explicit objective. The final model achieved both accuracy and behavioral compliance.

Behavioral testing protects user experience in a way that accuracy testing cannot. Users do not interact with accuracy metrics. They interact with outputs. If those outputs are correct but annoying, verbose, dismissive, or poorly formatted, the user experience suffers. Behavioral tests ensure that correctness improvements do not come at the cost of usability. They enforce the contract between your system and its users.

The next subchapter covers consistency tests: how to verify that similar inputs produce similar outputs, how to detect instability caused by sampling or retrieval variance, and how to set thresholds that catch real consistency failures without flagging harmless variation.
