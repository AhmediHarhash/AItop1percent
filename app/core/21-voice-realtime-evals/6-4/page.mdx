# 6.4 — Topic Coherence: Maintaining Context Across Turns

In October 2025, a healthcare voice assistant handled a call from a patient asking to refill a prescription. The conversation started on topic. By turn six, the system was asking about insurance coverage for a completely different medication the patient had mentioned once in passing. By turn nine, the patient gave up and requested a human agent. The system had 96% intent recognition accuracy and 94% ASR word error rate. Every component metric looked fine. The conversation was incoherent.

Topic coherence is whether the conversation stays focused on the user's goal. It's the measure of whether each turn connects logically to the previous turns, whether the system remembers what the conversation is about, and whether the dialog progresses toward resolution instead of wandering into tangents. A conversation can be grammatically perfect, factually accurate, and low-latency, and still fail if the system loses track of what the user is trying to accomplish.

## What Topic Drift Looks Like

The most common pattern is slot-filling distraction. The user mentions a detail in passing. The system latches onto it as a new intent and pivots the entire conversation. A user calls to schedule an appointment and says "I need to see the doctor next week, and also I need to get my test results from last month." The system hears two intents: schedule appointment and retrieve test results. It asks: "Would you like to schedule an appointment or get your test results?" The user says "Schedule the appointment first." The system begins the scheduling flow, asks for preferred date and time, then suddenly asks: "Which test results did you want?" The user is confused. They're in the middle of scheduling. The system jumped back to the secondary intent.

This is the context-switching failure. The system treats every detected intent as equally important and switches between them without completing one first. A human would say "Let me schedule your appointment, and then we'll get your test results." The system doesn't have that sequential discipline. It ping-pongs between intents, and the user loses track of where the conversation is.

The second pattern is reference resolution failure. The user says "I need to change that." The system doesn't know what "that" refers to. It asks: "What would you like to change?" The user, frustrated, says "The appointment time I just gave you." The system still can't resolve the reference because it doesn't maintain a discourse model. It asks the user to repeat the appointment time from scratch. The conversation has lost coherence because the system can't track what "that" means in context.

A travel booking system in early 2026 measured topic coherence by tracking unresolved references. In 19% of conversations, the user used a pronoun or demonstrative — "it," "that," "the one I mentioned" — that the system couldn't resolve. The conversation would stall. The user would rephrase, providing the full noun phrase instead of the reference. The rephrasing added an average of 2.3 turns per conversation. The lack of reference resolution didn't just break coherence. It inflated turn count and frustrated users.

## Measuring Topic Coherence

The simplest measure is topic drift rate: the percentage of conversations where the system changes topic without the user initiating the change. You define the primary topic as the intent from the first user utterance. Any turn where the system's response addresses a different intent without the user explicitly requesting it is a drift event. Topic drift rate is drift events divided by total conversations.

This requires intent tagging at the turn level. You log the detected intent for every user utterance and the intent the system's response addresses. If they match, the turn is coherent. If they diverge, it's a drift event. A logistics company in mid-2025 implemented turn-level intent tracking. They found topic drift in 14% of conversations. In 9% of cases, the drift was caused by ASR errors that made the system think the user changed topics. In 5% of cases, the drift was caused by the dialog manager's policy, which prioritized certain intents over others regardless of conversational context.

The second measure is context retention across turns. You track entities and parameters mentioned in earlier turns and measure whether the system successfully references them later. If a user says "I want to book a flight to Seattle" in turn one, and the system asks "Where are you flying to?" in turn three, context retention failed. The system should remember Seattle from turn one. Context retention rate is the percentage of later-turn references that correctly use information from earlier turns.

A customer service voice system in late 2025 measured context retention. They found that 88% of turn-two references were correct — the system remembered what was said in turn one. But only 61% of turn-six references were correct. Context decayed across turns. The dialog manager's state representation didn't adequately preserve earlier information. They refactored the state model to maintain a full conversation history instead of just the last two turns. Context retention at turn six rose to 84%.

## What Breaks Topic Coherence

The most common technical cause is stateless dialog management. Each turn is processed independently. The system doesn't maintain a representation of what has been discussed, what has been decided, or what the current goal is. It re-detects intent on every turn. If the user's utterance is ambiguous, the system might detect a different intent than the one guiding the conversation so far.

A user is in the middle of a funds transfer. They've specified the source account and the amount. The system asks for the destination account. The user says "My savings account." The system's NLU detects "savings account" and triggers a new intent: check savings account balance. The conversation derails. The system is now asking if the user wants to hear their savings balance, when the user was trying to specify a transfer destination. The system lost coherence because it didn't know the conversation was already inside a transfer flow.

The fix is intent contextualization. The dialog manager maintains a goal stack. The current goal is "complete funds transfer." Any new intent detected during this flow is evaluated in context. If the detected intent is "check balance," the system asks: is this a new top-level request, or is this the user providing a parameter for the current goal? The utterance "My savings account" in the context of "waiting for transfer destination" is interpreted as a parameter, not a new intent. The system stays coherent.

The second cause is multi-intent utterances without prioritization. The user says something that contains two intents: "I want to pay my bill and also update my mailing address." The system hears both. It doesn't know which to handle first. It picks one arbitrarily — often the one with higher confidence, which isn't necessarily the one the user prioritizes. It starts updating the mailing address. The user interrupts: "Wait, I wanted to pay the bill first." The system has broken coherence by handling intents out of the user's intended order.

The solution is explicit sequencing. When the system detects multiple intents, it asks: "I can help with both. Would you like to pay your bill first, or update your address first?" The user specifies. The system proceeds in that order. One additional turn buys you coherence for the rest of the conversation.

## Coherence and Conversational Repair

Even well-designed systems experience coherence breaks. The ASR mishears a word, the user misstates something, the system infers the wrong intent. The difference between good and bad systems is how they recover.

A good system detects incoherence and repairs it. The detection signal is user pushback: "That's not what I asked," "I didn't say that," "Can we go back?" When the user signals confusion or disagreement, the system doesn't plow forward. It stops, confirms the current understanding, and resets if necessary. "I'm sorry, let me make sure I understand. You want to schedule an appointment, is that right?" The user confirms or corrects. Coherence is restored.

A bad system ignores pushback. The user says "That's not what I meant," and the system treats it as a new utterance to be classified. It detects low confidence, asks the user to repeat, and proceeds with the same misunderstanding. The conversation spirals. The user repeats themselves three times, the system still doesn't course-correct, the user escalates or hangs up.

An insurance company in 2026 instrumented conversational repair. They tracked utterances that indicated user confusion: "No," "That's wrong," "I didn't ask that," "Wait," "Go back." When one of these signals appeared, the system triggered a repair flow: pause, summarize current understanding, ask for confirmation. Conversations with repair flows had 79% task success. Conversations with user confusion signals but no repair had 41% task success. Repair didn't just restore coherence. It rescued conversations that were headed for failure.

## Topic Coherence in Multi-Turn Clarification

Clarification dialogs are coherence minefields. The system doesn't understand something. It asks for clarification. The user provides it. The system integrates the new information and proceeds. If any step fails, the conversation loses coherence.

The failure usually happens in integration. The system asks: "Which account do you want to transfer from?" The user says "The one I just opened last week." The system doesn't have a record of when accounts were opened. It can't resolve "the one I just opened last week." It asks: "Can you provide the account number?" The user is frustrated. They just gave identifying information. The system ignored it and asked for something else. The conversation feels incoherent because the system's follow-up question doesn't acknowledge the user's answer.

The coherent version: "I don't have information on when your accounts were opened. Can you tell me the last four digits of the account, or the account type?" The system acknowledges that it can't use the information provided and explains what it needs instead. The user understands why the clarification is necessary. Coherence is maintained.

A banking voice system in late 2025 implemented explicit acknowledgment for unresolvable references. Instead of ignoring what it couldn't process and asking a different question, it said: "I couldn't match that description. Can you provide the account number instead?" This single change lifted topic coherence scores from 71% to 83%. Users felt heard even when the system couldn't resolve their reference.

## The Coherence-Efficiency Tradeoff

Maintaining topic coherence requires conversational overhead. The system has to acknowledge what the user said, confirm understanding, and explicitly transition between topics. All of that adds turns. You can maximize efficiency by skipping acknowledgments and confirmations, but you risk losing coherence. You can maximize coherence by confirming every reference and transition, but you inflate turn count.

The optimal balance is selective confirmation. Confirm when ambiguity is high. Don't confirm when confidence is high and the risk is low. If a user says "I want to check my balance" and ASR confidence is 0.96, don't confirm — just provide the balance. If the user says "I want to transfer to my spouse's account" and the system detects three possible accounts, confirm which one before proceeding. Selective confirmation keeps turn count low while maintaining coherence on high-risk interactions.

A retail voice system in 2026 tested selective confirmation. Version A confirmed every parameter. Median turns: 8.2. Topic coherence: 91%. Version B confirmed only when confidence was below 0.85 or when the action was high-risk. Median turns: 6.1. Topic coherence: 87%. The four-point coherence drop was acceptable given the two-turn efficiency gain. They shipped version B.

## Coherence Across Long Conversations

Short conversations — three to five turns — are easy to keep coherent. The user's goal is fresh, the context is minimal, the risk of drift is low. Long conversations — 10 to 20 turns — are where coherence collapses.

The primary failure mode is goal dilution. The user starts with a clear goal. As the conversation progresses, they mention side concerns, ask tangential questions, or bring up related but distinct issues. The system treats each mention as equally important. The conversation forks into multiple threads. By turn 15, neither the user nor the system remembers what the original goal was.

The solution is goal anchoring. The system maintains an explicit representation of the primary goal. Any new intent that arises is evaluated: is this a refinement of the primary goal, a prerequisite to the primary goal, or a separate goal? If it's a refinement or prerequisite, integrate it. If it's separate, defer it: "I can help with that too. Would you like to finish scheduling your appointment first, or switch to updating your payment method?" The user decides. The system keeps the primary goal visible.

A telecommunications company in early 2026 implemented goal anchoring for complex service calls. The system displayed the current goal in the call log visible to support agents who might take over. When the system detected a new intent, it classified it as "primary," "related," or "unrelated." Unrelated intents triggered a deferral prompt. Primary goal completion rate — percentage of conversations that completed the original intent — rose from 68% to 81%.

## The User Experience of Incoherence

Users don't think in terms of topic coherence. They think: "This conversation is going in circles," or "The system isn't listening," or "I've told it three times and it still doesn't get it." Those frustrations are symptoms of coherence failure.

The most damaging symptom is repetition. The system asks the same question twice. The user provided the answer in turn three. The system asks again in turn seven. The user assumes the system lost the information or didn't understand the first time. Trust erodes. A voice system that forgets what you told it five turns ago feels unreliable.

A government services hotline in mid-2025 tracked user frustration signals: raised voice, profanity, explicit complaints like "I already told you that." 47% of frustration events were preceded by the system asking for information the user had already provided. The root cause was state management. The dialog manager maintained a sliding window of the last three turns. Anything said more than three turns ago was discarded. The system would literally forget what the user had said and ask again. They expanded the state window to preserve the full conversation. Frustration events dropped by 61%.

## Measuring Coherence Through Human Review

Automated coherence metrics are proxies. The real measure is whether a human listener would describe the conversation as coherent. You sample conversations weekly, have trained reviewers listen, and score them on a coherence rubric:

- **5**: Every turn logically follows from the previous turns. The conversation feels like a purposeful progression toward the goal.
- **4**: Mostly coherent, with one or two minor digressions that don't derail the conversation.
- **3**: Noticeable coherence issues. The system changes topics abruptly or forgets context, but the user can recover.
- **2**: Significant incoherence. The conversation feels disjointed. The user has to repeat themselves or correct the system multiple times.
- **1**: Completely incoherent. The system is having a different conversation than the user. No clear progression toward the goal.

You track the percentage of conversations scoring 4 or 5. That's your coherence rate. A SaaS company in late 2025 ran weekly coherence reviews. They sampled 150 conversations per week. Coherence rate started at 68%. They used low-scoring conversations to identify failure patterns. They found the system frequently lost coherence when users asked follow-up questions after completing a task. "I just paid my bill. When will it post?" The system treated this as a new conversation and asked for account verification again, even though the user had just been authenticated. They fixed the post-task context retention. Coherence rate rose to 79% over 10 weeks.

## Coherence as a Predictor of Success

Topic coherence predicts task success and FCR. Conversations rated as coherent by human reviewers have 86% task success. Conversations rated as incoherent have 49% task success. Coherence is not just a quality metric. It's a leading indicator of whether the conversation will achieve its goal.

The mechanism is trust. When the conversation is coherent, the user trusts that the system understands them. They provide information freely, they follow the system's instructions, they stay engaged. When the conversation is incoherent, the user loses trust. They become guarded, they repeat themselves defensively, they look for an escape route to a human agent or to hanging up. Incoherence doesn't just make the conversation feel bad. It makes the outcome worse.

A financial advisory voice system in 2026 tracked the correlation between coherence and FCR. Conversations scored as coherent had 88% FCR. Conversations scored as incoherent had 53% FCR. Incoherent conversations were twice as likely to result in a follow-up call because the user left the conversation unsure whether the system had actually understood and addressed their need. Improving coherence wasn't just about user experience. It was about reducing repeat contacts.

## Why Component Metrics Miss Coherence

You can have perfect ASR, perfect intent recognition, and perfect response accuracy and still produce an incoherent conversation. Coherence is an emergent property of the dialog flow, not a property of individual components. It depends on how turns connect to each other, how context is maintained, how the system sequences actions toward a goal. None of that shows up in component-level metrics.

This is why teams that only monitor ASR accuracy and intent precision are blindsided when users complain that conversations are confusing or frustrating. Every component is working correctly. The integration is broken. Coherence is the integration metric. It measures whether the system's behavior across turns makes sense to the user. If it doesn't, all the accurate components in the world won't save the conversation.

Topic coherence is the metric that tells you whether your voice system is having the same conversation the user thinks they're having. Optimize it, or accept that users will give up before reaching their goal.

Next, we'll examine intent recognition accuracy in the context of spoken conversations — where disfluencies, partial utterances, and hesitations make intent harder to extract than in text.
