# 9.4 — Connection State Management for Long Conversations

A 30-second voice interaction and a 30-minute conversation require different infrastructure. The short interaction tolerates simple connection handling—establish, exchange audio, close. The long conversation must survive network transitions, detect when the user has silently disappeared, and clean up resources gracefully when the conversation ends.

Most teams design for the short interaction and discover problems when users stay connected for extended periods. The WebSocket connection stays open long after the user closed the app. The server allocates memory for a conversation that ended twenty minutes ago. The client reconnects after a brief network dropout but creates a new session instead of resuming the old one, forcing the user to restart.

In mid-2025, a voice journaling application let users record thoughts throughout the day in a continuous conversation that could span hours. The team built connection handling for quick entries and launched. Within three days, their server memory usage grew linearly with uptime. The servers ran out of memory every six hours and crashed. The team discovered 4,000 connections in state "open" despite having only 300 active users. Most connections belonged to users who had closed the app without formally ending the session. The server kept those connections open, waiting for audio that would never arrive, leaking memory until crash.

Long-lived connections need lifecycle management, failure detection, and resource cleanup that short interactions do not.

## Connection Lifecycle: Establish, Maintain, Gracefully Close

Every connection passes through stages. Establishment is when client and server negotiate protocol, exchange capabilities, and allocate resources. Maintenance is when the connection is actively carrying audio or idle but expected to resume. Closure is when either side explicitly terminates the connection and releases resources.

Establishment sets up state. The server allocates buffers, initializes conversation context, and prepares to receive audio. The client configures codecs, starts capturing audio, and prepares to play responses. If establishment fails, you retry or surface an error. If it succeeds, you transition to maintenance.

Maintenance is the longest phase. The connection is open but may be idle. Users pause mid-conversation, set their phone down, or get interrupted. You cannot close the connection every time audio stops—that would force users to reconnect constantly. But you cannot keep connections open indefinitely when users are done.

The challenge is distinguishing between a pause and abandonment. A three-second pause is normal. A three-minute pause might mean the user walked away. A thirty-minute pause almost certainly means they are gone. But "almost certainly" is not "definitely," and closing a connection while a user is still present destroys their experience.

Graceful closure happens when the client explicitly signals it is done. The server receives a close frame, flushes buffered data, persists conversation state, and deallocates resources. The client receives acknowledgment and closes its connection. Both sides know the session ended cleanly.

Ungraceful closure happens when the connection drops without warning. The client crashes, the network fails, the user force-closes the app. The server does not receive a close frame. It must detect absence and clean up anyway.

## Heartbeat and Keepalive: Detecting Connection Health

A heartbeat is a small message sent periodically to confirm the connection is alive. The client sends a ping. The server responds with a pong. If the server does not receive a ping within the expected interval, it assumes the client is gone. If the client does not receive a pong, it assumes the server is unreachable.

The heartbeat interval is a tradeoff. Frequent heartbeats detect failures quickly but generate network traffic and wake mobile devices from low-power states. Infrequent heartbeats reduce overhead but take longer to detect failures.

Most production systems use heartbeat intervals between 10 and 60 seconds. A 10-second interval detects failures within 20 to 30 seconds (one missed heartbeat is not conclusive; you wait for two or three). A 60-second interval detects failures within two to four minutes.

A voice assistant for elderly users used 15-second heartbeats during active conversation and 45-second heartbeats during idle periods. Active conversations needed fast failure detection to prompt reconnection quickly. Idle connections tolerated slower detection to conserve mobile battery. The system transitioned between intervals based on whether audio had been exchanged in the last 30 seconds.

Heartbeats also serve as keepalive signals to prevent intermediate network devices from closing idle connections. Many corporate firewalls close TCP connections that have been idle for 5 to 15 minutes. Regular heartbeats keep the connection active in the firewall's eyes even when no audio flows.

The heartbeat should be small. A one-byte ping and one-byte pong are sufficient. Sending large heartbeat payloads wastes bandwidth. The point is to confirm the connection exists, not to exchange data.

## Detecting Zombie Connections: When the Client Is Gone But the Server Does Not Know

A zombie connection is open on the server but the client has disappeared. The client crashed, the user force-quit the app, or the network path broke in a way that prevented proper connection closure. The server holds resources for a session that will never resume.

Zombie connections accumulate. If you average 1,000 concurrent users and 2% of disconnections are ungraceful, you accumulate 20 zombie connections per day if you never clean them up. Over weeks, thousands of zombie connections consume memory and connection slots.

You detect zombies with timeout policies. If you have not received a heartbeat within the expected interval, the client is probably gone. If you have not received audio or any message within a longer threshold—say, five minutes—the client is definitely gone.

The detection threshold must exceed the heartbeat interval by enough to tolerate network delays and temporary packet loss. If your heartbeat interval is 30 seconds, you should not declare the connection dead after 35 seconds. A single lost heartbeat packet would trigger false positives. Declare the connection dead after 90 to 120 seconds—three or four missed heartbeats.

A customer service voice AI tracked time since last message received. If 90 seconds passed with no heartbeat or audio, the server sent a ping proactively. If the client responded, the connection was alive. If no response arrived within 15 seconds, the server declared the connection dead and released resources. This proactive ping reduced zombie connection accumulation from 2% to 0.1% of sessions.

## Session Timeout Policies: When to Assume Abandonment

Even if the connection is technically alive with heartbeats flowing, the user might have abandoned the session. They left the app open in the background, or they paused mid-conversation and forgot about it. You must decide how long to wait before closing the session.

The timeout depends on expected usage patterns. A voice assistant for quick commands should timeout after two to five minutes of inactivity. A voice journaling app where users pause frequently should timeout after thirty to sixty minutes. A customer service system where users are on hold should not timeout at all during the call.

The timeout should be long enough that legitimate pauses do not trigger false abandonment but short enough that you do not waste resources on genuinely abandoned sessions. Measure actual user behavior: track the distribution of pause durations during active sessions. The 99th percentile pause duration is a reasonable timeout threshold.

A voice meditation app let users pause mid-session to follow instructions silently. Pause durations ranged from 10 seconds to 8 minutes with a median of 90 seconds and 99th percentile of 6 minutes. The team set session timeout to 10 minutes. Users who paused for 6 minutes were not disconnected. Users who paused for 10 minutes were assumed to have fallen asleep or walked away.

When timeout occurs, notify the user if possible. Send a message to the client: "Are you still there?" If the user responds, reset the timeout. If no response arrives within 30 seconds, close the connection. This gives users a chance to prevent disconnection if they are still present.

## Reconnection Handling: Resume vs Restart

Mobile users experience brief network interruptions constantly. They walk through a dead zone, ride an elevator, or switch from WiFi to cellular. The connection drops. Seconds later, network connectivity returns. The question is whether you resume the previous session or start a new one.

Resuming preserves conversation context, user state, and any work in progress. The user does not have to repeat themselves. But resuming requires the server to retain session state after disconnection, identify returning clients, and reattach them to their previous session. This is complex.

Restarting is simpler. The client connects, gets a new session, and starts fresh. The user loses conversation history and must re-establish context. For quick interactions, this is acceptable. For long conversations, it destroys the experience.

The decision depends on session duration and state complexity. If sessions are stateless and short, restart. If sessions accumulate important context, resume.

A voice-controlled smart home system implemented resumption with a 60-second window. If the client reconnected within 60 seconds of disconnection, the server reattached it to the previous session with full context. If more than 60 seconds elapsed, the server started a new session and the user had to reissue commands. The 60-second window covered brief network interruptions like elevator rides but did not force the server to hold state indefinitely.

Resumption requires session identifiers. When the client connects, it sends a session ID if it is attempting to resume. The server checks whether that session still exists and has not timed out. If yes, resume. If no, start fresh. The session ID must be unpredictable to prevent malicious users from hijacking other users' sessions.

## Graceful Degradation When the Server Is Overloaded

When your server is overloaded, you cannot accept all incoming connections. You must reject some or degrade quality for all. Rejecting connections outright is better than accepting them and failing to provide acceptable service.

A voice assistant platform measured server CPU utilization continuously. When utilization exceeded 80%, the system stopped accepting new connections and returned an error to clients: "Service temporarily unavailable, please try again in a moment." When utilization exceeded 90%, the system also started closing idle connections to free capacity for active conversations. This aggressive shedding prevented cascading failure where overload caused slow responses, which caused clients to retry, which increased load further.

The alternative is to accept all connections but degrade quality. Switch to lower-bitrate codecs, reduce response verbosity, or increase latency by batching requests. Users get degraded service instead of outright rejection. For critical applications, degraded service is better than no service. For non-critical applications, rejection forces users to retry later when capacity is available.

Graceful degradation requires advance planning. You cannot implement it during an outage. You must build rate limiting, connection shedding, and quality reduction into your architecture before you need it.

## Cleaning Up Resources on Connection Close

When a connection closes, resources must be released. Buffers must be freed, conversation state must be persisted or discarded, and any downstream services must be notified that the session ended. Failure to clean up causes resource leaks.

The cleanup process is straightforward for graceful closure. The client sends a close frame. The server receives it, triggers cleanup handlers, and confirms closure. The client disconnects. Both sides agree the session ended.

Cleanup is harder for ungraceful closure. The server does not receive a close frame. It detects absence through timeout or heartbeat failure. It triggers cleanup handlers, but the client is already gone and cannot acknowledge. The server must handle partial cleanup state—what if cleanup partially completes and then crashes?

Idempotent cleanup solves this. Design cleanup handlers so they can run multiple times without harm. If the server crashes mid-cleanup and restarts, it can re-run cleanup for all detected zombie connections without corrupting state.

A voice platform tracked session state in a distributed database. When a connection closed, the server marked the session as "closing" in the database, executed cleanup steps, then marked it "closed." If the server crashed between "closing" and "closed," a background job detected sessions stuck in "closing" state for more than one minute and re-ran cleanup. This ensured all sessions eventually cleaned up even if the responsible server crashed.

## Connection State Monitoring and Alerts

You need visibility into connection health across your fleet. Metrics should include: active connection count, zombie connection count, graceful vs ungraceful closure rate, average session duration, heartbeat timeout rate, and reconnection success rate.

Active connection count tells you current load. If it grows without bound, you have a zombie accumulation problem. If it drops suddenly, you have a server crash or network partition.

Zombie connection count tells you cleanup effectiveness. If zombies accumulate, your timeout policies are too lenient or your cleanup handlers are failing. Target zombie rate below 0.5% of active connections.

Graceful vs ungraceful closure rate tells you client behavior and network quality. If 20% of closures are ungraceful, you have either a buggy client that crashes frequently or a network environment where connections drop regularly. If 2% of closures are ungraceful, your client and network are behaving normally.

Reconnection success rate tells you whether your resumption logic works. If users attempt to reconnect and fail because their session timed out or the server lost state, reconnection success rate drops. Target reconnection success above 95% for disruptions within your resumption window.

A healthcare voice platform tracked all these metrics and configured alerts: active connection count growing faster than user registration rate (zombie accumulation), graceful closure rate below 80% (client or network problems), reconnection success rate below 90% (resumption problems), or zombie connection count exceeding 1% of active connections (cleanup failures). Each alert mapped to a specific operational problem with a defined response.

---

You have chosen a transport protocol, chunked audio appropriately, buffered to tolerate jitter, handled packet loss, and managed connection lifecycle. The final piece of the streaming infrastructure is audio encoding—the codec that determines how much bandwidth each conversation consumes and whether your audio quality survives compression.

