# 12.7 — Sensitive Data Redaction in Transcripts

Transcripts contain everything. A user says their social security number to verify identity. A patient says their diagnosis. A customer reads their credit card number. A caller mentions their home address, their email, their mother's maiden name. The speech-to-text system transcribes it all verbatim. The transcript is stored, indexed, searchable. If you do not redact sensitive data, you have created a compliance violation and a breach risk. Redaction is not optional. It is mandatory for every voice system that handles regulated data.

The question is not whether to redact. The question is what to redact, when to redact it, and how to verify that redaction is complete. Teams that treat redaction as a simple find-and-replace operation discover too late that partial redaction is worse than no redaction. A transcript that says "my social security number is XXX-XX-1234" is still a violation because the last four digits are visible. A transcript that says "I live at REDACTED in Austin" is still a privacy leak because the city is intact. Redaction is not masking random tokens. It is systematically identifying and removing every instance of sensitive data across multiple categories, formats, and edge cases.

## What to Redact: Regulatory and Risk Perspectives

Personal identifiable information tops the redaction list. Names, addresses, phone numbers, email addresses, dates of birth, social security numbers, driver's license numbers, passport numbers, account numbers. If a data element can identify a specific individual, it must be redacted unless your legal basis for processing explicitly permits its retention. GDPR treats many of these as high-risk personal data. CCPA defines them as covered information. Redaction reduces your exposure. A transcript that says "caller verified identity" is lower risk than a transcript that says "caller provided SSN 123-45-6789."

Protected health information requires aggressive redaction. HIPAA defines eighteen identifiers that must be removed to achieve de-identification under the Safe Harbor method. This includes names, geographic subdivisions smaller than state, dates related to an individual, phone numbers, email addresses, social security numbers, medical record numbers, health plan numbers, account numbers, certificate or license numbers, vehicle identifiers, device identifiers, web URLs, IP addresses, biometric identifiers, full-face photographs, and any other unique identifying number or code. A transcript containing any of these is PHI. Redacting just the diagnosis is not sufficient. You must redact all eighteen categories.

Payment card information falls under PCI-DSS. A user reading a sixteen-digit credit card number, a CVV code, an expiration date—any of these in a transcript makes that transcript subject to PCI requirements. Most organizations redact all payment data from transcripts immediately. The cost of storing PCI-regulated transcripts is not worth the marginal value. If a user says their credit card number, redact the entire number. Do not keep the first six or last four digits. Full redaction is safer than partial masking.

Credentials and secrets are often overlooked. A user saying "my password is summer2025" or "the API key is sk-abc123def456" creates a security incident if the transcript is stored unredacted. Developers sometimes read API keys aloud during troubleshooting calls. Customers sometimes share passwords when they should not. Redaction systems must detect credential patterns—common password formats, API key prefixes, OAuth tokens, database connection strings—and redact them. A leaked API key in a transcript is as dangerous as a leaked key in a log file.

Internal identifiers and business-sensitive data require redaction in some contexts. Employee IDs, internal project code names, unreleased product details, proprietary algorithms mentioned in customer support calls. These are not regulated under GDPR or HIPAA, but they are sensitive from a business perspective. Many enterprises redact internal identifiers from transcripts used for training or shared across teams to reduce information leakage. The redaction policy here is risk-based, not compliance-based.

## Real-Time Redaction vs Post-Processing Redaction

Real-time redaction removes sensitive data as the transcript is generated, before it is stored. The speech-to-text system produces a transcript, a redaction layer scans for sensitive patterns, and the redacted version is written to storage. The raw, unredacted transcript never persists. This is the safest approach. If the data never lands in storage, it cannot leak from storage. Real-time redaction is the gold standard for high-compliance environments—healthcare, financial services, government.

Real-time redaction introduces latency. A transcript that takes two hundred milliseconds to generate may take an additional fifty to one hundred milliseconds to redact if the redaction logic is complex. Named entity recognition models, regex pattern matching across dozens of patterns, contextual analysis to distinguish a social security number from a transaction ID—all of this takes time. If your voice system has strict latency requirements, real-time redaction may push you over the threshold. You must balance compliance and user experience. Most teams accept the latency cost because the compliance risk is unacceptable.

Post-processing redaction stores the raw transcript first, then applies redaction in a batch job minutes or hours later. This reduces latency during the interaction but creates a window where unredacted data is at risk. If a breach occurs between transcript generation and redaction, you leak sensitive data. If the redaction job fails or is delayed, unredacted transcripts accumulate. Post-processing redaction is only acceptable if the raw transcripts are stored in a highly restricted environment—encrypted at rest, access-controlled, audit-logged—and if the redaction job runs frequently enough to minimize exposure windows.

Some teams use a hybrid approach: immediate partial redaction followed by deeper redaction. The real-time layer redacts high-confidence patterns—social security numbers that match the exact format, credit card numbers that pass the Luhn check. The post-processing layer applies more expensive NER models and contextual analysis to catch edge cases. This reduces real-time latency while maintaining strong redaction coverage. The trade-off is complexity. You now have two redaction pipelines to maintain, test, and audit.

Redaction timing determines liability windows. If you store raw transcripts for even sixty seconds before redacting, those sixty seconds are a compliance exposure. If your redaction job runs every ten minutes, you have a ten-minute window where unredacted data is accessible. Regulators do not care that you "planned to redact eventually." They care that unredacted data was accessible when it should not have been. Minimize the window between transcript generation and redaction. Ideally, make it zero by redacting in real time.

## Redaction Accuracy and False Negative Risks

Redaction systems fail in two ways: false positives and false negatives. A false positive redacts something that is not sensitive. A user says "I moved here in 1985" and the redaction system removes "1985" thinking it is a birthdate. This is annoying but not dangerous. A false negative fails to redact something that is sensitive. A user says "my social is four five six seven eight nine zero one two" and the redaction system does not recognize the spoken-digit format. This is a compliance violation and a breach risk.

False negatives are the critical failure mode. A redaction system that redacts ninety-nine percent of sensitive data and misses one percent is not good enough if the one percent includes social security numbers, credit card numbers, or PHI. You cannot tell a regulator "we redacted most of it." Either you redacted all sensitive data or you did not. Redaction accuracy must approach one hundred percent for high-risk categories. This requires multiple detection methods: regex patterns, named entity recognition models, contextual analysis, and manual review of samples.

Regex-based redaction catches structured patterns: social security numbers in the format XXX-XX-XXXX, credit card numbers as sixteen consecutive digits, phone numbers in standard formats. Regex is fast and deterministic. It either matches or it does not. But regex fails on variations. A user saying "my social is 123 45 6789" with spaces instead of hyphens may not match a strict regex. A user spelling out digits—"one two three four five six seven eight nine"—will never match a numeric regex. Regex is necessary but not sufficient.

Named entity recognition models detect person names, locations, organizations, dates. NER models trained on conversational text can identify "John Smith" or "456 Oak Street" even when the format varies. NER is more flexible than regex but also more error-prone. A model may misclassify "Apple" the company as "Apple" the fruit and fail to redact. A model may identify "Smith" as a name when the user is discussing a blacksmith. NER models must be validated on representative voice transcripts, not just on written text. Spoken language has different patterns.

Contextual analysis improves accuracy by considering the surrounding text. If a user says "my number is 123-45-6789" immediately after being asked "what is your social security number," the system can be highly confident that "123-45-6789" is a social security number even if the format is ambiguous. If the same number appears in a sentence about transaction IDs, the confidence should be lower. Context-aware redaction requires understanding the conversation flow. This typically means maintaining short-term state across the transcript and applying rules based on recent turns.

Manual review of redaction samples is the final verification layer. Randomly sample one hundred redacted transcripts per week. Have a human reviewer check whether any sensitive data was missed. If you find a miss, investigate the root cause. Was it a pattern the regex did not cover? Was it an NER failure? Was it a format the system had never seen? Add the missed case to your test suite and update the redaction logic. Iterate weekly. Redaction accuracy improves over time only if you measure failures and fix them.

## Verification of Redaction Completeness

Redaction is not complete until you verify that no sensitive data remains. This requires automated checks and human review. Automated checks scan redacted transcripts for known sensitive patterns. If a transcript claims to be redacted but still contains a string matching a social security number regex, the redaction failed. Flag the transcript, investigate, and re-redact. Automated verification catches obvious failures: incomplete redactions, redaction jobs that did not run, partial failures in batch processing.

Human review catches subtle failures. A reviewer reads a sample of redacted transcripts and looks for indirect identifiers—context clues that reveal identity even when names are redacted. A transcript that says "the caller lives at REDACTED in apartment 3B and works at REDACTED hospital as a REDACTED" might still be identifiable if apartment 3B at that hospital has only one occupant. Redaction of direct identifiers is not always sufficient. Human reviewers assess whether the redacted transcript is truly anonymized or merely pseudonymized.

Re-identification testing validates redaction strength. Take a set of redacted transcripts and attempt to re-identify individuals using only the information in the transcript plus publicly available data. If you can re-identify even one person, the redaction is insufficient. This is a labor-intensive process, but it is the only way to verify that redaction achieves de-identification. Some enterprises run re-identification tests quarterly on a sample of redacted data. If re-identification is possible, they strengthen the redaction logic.

Redaction logs must capture what was redacted, when, and by which version of the redaction logic. If a transcript contains ten redactions, the log should record ten redaction events with the entity type, the original span, and the redaction method. This allows you to audit redaction completeness. If a regulator asks "did you redact all social security numbers from transcripts," you can query the redaction logs and show how many SSNs were detected and redacted. Logs are your proof of compliance.

Some teams store redacted transcripts and redaction maps separately. The redacted transcript is the public-facing version. The redaction map is metadata that shows what was redacted and where. This allows reversible redaction if you have a legal basis to access the original data. For example, law enforcement may request the unredacted transcript under a valid warrant. The redaction map lets you reverse the process for that one transcript without storing the raw unredacted version for all transcripts. This is a niche requirement and introduces complexity. Most teams simply delete the raw transcript after redaction and never store the unredacted version.

## Redaction for Different Use Cases: Training, Analytics, Support

Training data requires the most aggressive redaction. If you use transcripts to fine-tune a language model, any unredacted sensitive data in the training set may be memorized by the model. A model trained on transcripts containing social security numbers can reproduce those numbers in generated outputs. This is a catastrophic failure. Training transcripts must be redacted to the point of de-identification. Remove all direct identifiers, all quasi-identifiers, all PII, all PHI. What remains should be generic conversational patterns, not identifiable individuals.

Analytics use cases require redaction that preserves analytical value while removing identifiers. If you analyze transcripts to understand common customer intents, you need the semantic content but not the names. Redacting "my name is Sarah Johnson" to "my name is REDACTED REDACTED" preserves the sentence structure and the intent without exposing identity. If you analyze transcripts to measure sentiment, you need the emotional tone but not the specific account numbers. Redaction for analytics balances privacy and utility. Too much redaction destroys analytical value. Too little redaction violates privacy.

Support use cases may require less aggressive redaction or time-limited access to unredacted data. A support agent reviewing a transcript to resolve a complaint may need to see the caller's name and account number to provide effective service. But the support agent should not have access to full unredacted transcripts indefinitely. Many voice platforms provide time-limited access: a support agent can view the unredacted transcript for seventy-two hours after the call. After that, the system automatically redacts the transcript and the agent can only see the redacted version. This reduces the window of exposure while enabling effective support.

Sharing transcripts across teams requires redaction policies that reflect the recipient's need and authorization. Engineering teams reviewing transcripts to debug a system issue do not need to see caller names or social security numbers. Redact everything that is not technically necessary. Legal teams reviewing transcripts for litigation may need access to unredacted versions. Apply role-based access controls. Engineering sees redacted transcripts. Legal sees unredacted transcripts under access audit. Compliance sees both and audits the delta.

Redaction policies must be documented per use case. A data governance document should specify what is redacted for training, what is redacted for analytics, what is redacted for support, and what is redacted for sharing. Each use case has a different risk profile and a different redaction threshold. Training data is highest risk and requires the most redaction. Support data is lower risk if access is time-limited and role-controlled. Document the policy. Enforce it in code. Audit compliance.

## Redaction as a Continuous Process

Redaction is not a one-time operation. As your voice system evolves, new sensitive data patterns emerge. A new product feature asks users for their passport number. A new support flow collects insurance policy numbers. A new compliance requirement classifies employee IDs as sensitive. Your redaction logic must evolve to match. Treat redaction as a continuous process, not a static implementation.

New redaction patterns must be added when new data types are introduced. If your product roadmap includes a feature that collects driver's license numbers, add driver's license number detection to your redaction pipeline before the feature launches. Do not wait until the first unredacted driver's license number appears in a transcript. Plan redaction as part of feature development. Every new data type collected must have a corresponding redaction rule.

Redaction effectiveness must be monitored over time. Track the number of redactions per transcript, the types of entities redacted, the false positive rate, the false negative rate. If you suddenly see a drop in the number of social security numbers redacted per day, investigate. Did users stop providing them, or did the redaction logic break? If you see a spike in redactions of a previously rare entity type, investigate. Did a new use case emerge, or is the NER model misfiring?

Redaction failures must be treated as security incidents. If you discover that a transcript containing unredacted PHI was accessible to unauthorized users, that is a breach. Report it to your compliance team. Investigate the root cause. Determine how many other transcripts may be affected. Remediate immediately. Redaction is a security control. When it fails, escalate.

Redaction is the difference between a defensible voice system and a compliance disaster. It is not something you add later. It is foundational. Build it first. Verify it continuously. Treat failures as critical incidents. Your voice system's regulatory and legal viability depends on it.

