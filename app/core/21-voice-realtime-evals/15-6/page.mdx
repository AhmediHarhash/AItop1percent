# 15.6 — The Hold Time Tax: Waiting Costs Money Too

The average call to a voice AI system lasts four minutes. The average amount of time the user is actually speaking or hearing responses is ninety seconds. The remaining two and a half minutes is silence, hold time, thinking pauses, and system latency. In text-based AI, that time costs nothing. In voice AI with per-minute billing, you pay for every second of silence.

A customer support platform discovered this in their first month of production in late 2025. Their average conversation quality was excellent. Their cost-per-conversation was three times higher than projected. The culprit was not model selection or prompt efficiency. It was hold time. Users paused to think. The system waited for speech-to-text to finalize. Handoffs between components added latency. All of it billed. They paid for four minutes of connection time to deliver ninety seconds of actual AI interaction.

The hold time tax is the hidden cost multiplier in voice systems. You optimize your prompts. You choose efficient models. You compress your responses. But if your system architecture creates thirty seconds of waiting per conversation, you pay for that waiting just as much as you pay for inference. Unlike text systems where thinking time is free, voice systems charge for the privilege of letting users pause.

## The Billing Clock Never Stops

Voice providers bill by connection time, not by inference time. When a user calls your system, the billing clock starts. It runs continuously until the call ends. Every second counts. The user says hello: billing. The system processes speech-to-text: billing. The LLM generates a response: billing. The text-to-speech engine renders audio: billing. The user pauses to think about what they heard: billing. The user asks a follow-up question: billing. The entire loop repeats: billing.

Compare this to text-based AI. A user sends a message. Your system thinks. Fifteen seconds later, it responds. You pay for the inference time—maybe two seconds of actual compute. The thirteen seconds the user spent waiting for the response cost you nothing. In voice, those thirteen seconds cost the same as the two seconds of actual processing. The wait time is not an optimization opportunity. It is a direct cost.

A telehealth voice assistant had an average conversation duration of three minutes twenty seconds. Their actual model inference time per conversation was forty-two seconds total—speech-to-text, LLM reasoning, and text-to-speech combined. The remaining two minutes thirty-eight seconds was wait time: user pauses, system latency, silence detection delays, and end-of-speech detection. They paid for three minutes twenty seconds. They received value from forty-two seconds. The hold time tax was seventy-nine percent of their bill.

## The Components of Hold Time

Hold time breaks into three categories: queue time, thinking time, and handoff time. Queue time is when your system is waiting to start processing—the user has spoken, but your speech-to-text pipeline has not begun transcription yet. Thinking time is when the user pauses mid-conversation, and your system remains connected waiting for them to continue. Handoff time is the latency between components—speech-to-text completes, but the LLM has not started inference yet, or the LLM completes but text-to-speech has not started rendering.

Queue time is controllable. It is a function of your architecture. If your speech-to-text provider has a two-second delay between when the user stops speaking and when transcription completes, that is two seconds of queue time per user turn. In a five-turn conversation, that is ten seconds of queue time. At ten cents per minute of connection time, queue time alone costs you sixteen cents per conversation. Multiply that by ten thousand conversations per day, and queue time costs you sixteen hundred dollars daily, forty-eight thousand per month.

Thinking time is partially controllable. You cannot eliminate user pauses—people need time to think—but you can detect when a pause has become abandonment. If a user has not spoken for thirty seconds, they might have walked away from the phone. Your system is still connected. You are still being billed. A voice assistant for a food delivery service discovered they were paying for an average of forty-five seconds of thinking time per conversation. Half of that was legitimate pauses. Half was users who got distracted and forgot they were on a call. They implemented a fifteen-second silence timeout. If the user had not spoken in fifteen seconds, the system prompted: "Are you still there?" If no response in five more seconds, the call ended. Average thinking time dropped to twenty-two seconds. Monthly costs dropped eleven percent.

Handoff time is entirely controllable. It is your architecture tax. If your system processes speech-to-text, then waits for that result to return before calling the LLM, then waits for the LLM to return before calling text-to-speech, you are creating sequential handoff delays. Each handoff might be three hundred milliseconds. Across three handoffs, that is nine hundred milliseconds per turn. In a six-turn conversation, that is 5.4 seconds of pure handoff latency. You pay for every millisecond.

## Reducing Hold Time Through Architecture

The most effective way to reduce hold time costs is to pipeline your components. Do not wait for speech-to-text to fully complete before starting LLM inference. Stream partial transcriptions to the LLM. Start generating responses before the user has finished speaking. This collapses handoff time from sequential delays to overlapping processing. A financial services voice assistant reduced their average handoff time from 1.8 seconds per turn to four hundred milliseconds by streaming partial transcripts and starting LLM inference before speech-to-text finalized.

Implement aggressive end-of-speech detection. Traditional speech-to-text systems wait for a long pause—often seven hundred milliseconds or more—to ensure the user has finished speaking. That is seven hundred milliseconds of silence you pay for on every user turn. Modern systems use predictive end-of-speech detection that analyzes prosody and phrasing to detect sentence completion in three hundred milliseconds or less. The tradeoff is occasional false positives where the system interrupts a user mid-sentence. For most applications, the cost savings justify the occasional interruption.

A customer service voice system reduced per-conversation costs by eighteen percent by tuning end-of-speech detection. Their original configuration waited eight hundred milliseconds of silence before considering speech complete. They reduced it to four hundred milliseconds for simple intents and six hundred milliseconds for complex queries. False positive rate—instances where the system interrupted the user—increased from 0.3 percent to 1.8 percent. User satisfaction dropped by less than one percentage point. Cost per conversation dropped from eleven cents to nine cents. The business accepted the tradeoff.

## Measuring Hold Time Costs

You measure hold time by instrumenting your voice pipeline with timing data at every stage. Record when the user starts speaking, when speech-to-text begins processing, when it completes, when LLM inference begins, when it completes, when text-to-speech begins, when it completes, when audio playback starts, when it ends. The gaps between these events are your hold time components. Sum them across a conversation. Compare total hold time to total connection time. The ratio tells you how much of your bill is pure waiting.

Build dashboards that show hold time as a percentage of total conversation duration. If your average conversation is three minutes and forty seconds of that is hold time, your hold time percentage is eighteen percent. Track this metric over time. If it increases, your system is getting slower—either because of provider latency, increased traffic creating queuing delays, or architectural changes that add handoff time. If it decreases, your optimizations are working.

A voice AI platform tracked hold time percentage as a key cost metric. In October 2025, their hold time percentage was twenty-three percent. They implemented streaming pipelines, reduced end-of-speech detection delays, and optimized handoff logic. By December, hold time percentage was fourteen percent. Total conversation durations stayed roughly the same—users still took the same amount of time to complete their tasks—but the system spent less time waiting. Cost per conversation dropped from fourteen cents to twelve cents. Same user experience. Lower cost.

## The Hold Time Versus User Experience Tradeoff

Reducing hold time sometimes degrades user experience. If you set end-of-speech detection too aggressively, the system interrupts users. If you implement silence timeouts too short, the system disconnects users who are still engaged but thinking. If you pipeline components too aggressively, you start generating responses before the user has finished their question, leading to irrelevant answers.

The correct tradeoff depends on your application. A voice assistant for quick transactions—order food, book a ride, check account balance—can tolerate aggressive timeouts and fast end-of-speech detection. Users expect speed. A voice assistant for complex customer support—troubleshooting a technical issue, explaining a financial product—needs longer timeouts and conservative end-of-speech detection. Users need time to explain problems.

A voice AI company ran A/B tests on end-of-speech detection timing. Group A experienced four hundred millisecond detection delays. Group B experienced seven hundred milliseconds. Group A had 2.1 percent interruption rate. Group B had 0.4 percent. User satisfaction in Group A was 4.2 out of 5. Group B was 4.4 out of 5. Cost per conversation in Group A was nine cents. Group B was eleven cents. The company chose Group A for transactional intents and Group B for support intents. Different use cases, different tradeoffs.

## Hold Time as a Cost Optimization Lever

When you need to reduce costs, hold time is often easier to optimize than model selection or prompt engineering. Switching from a frontier model to a smaller model might save you two cents per conversation but degrade quality. Reducing hold time by twenty percent might save you the same two cents without any quality impact. The user never perceives hold time reduction as a degradation—they perceive it as the system being faster.

A conversational AI platform needed to reduce costs by fifteen percent to hit quarterly budget targets. They evaluated three options: switch to smaller models, compress prompts further, or reduce hold time. Model switching would save eighteen percent but risked quality regressions. Prompt compression would save eight percent but had already been optimized heavily. Hold time reduction could save twelve percent with no quality risk. They chose hold time. They implemented streaming pipelines, tuned end-of-speech detection, and optimized provider handoffs. Costs dropped thirteen percent. Quality metrics stayed flat. User satisfaction actually increased slightly because the system felt more responsive.

Hold time optimization has compounding effects. Reducing hold time by one second per conversation might save you a fraction of a cent per conversation. But that one second reduction applies to every conversation. At one hundred thousand conversations per month, one second per conversation is one hundred thousand seconds, or 1,667 minutes, or twenty-eight hours of billed time saved. At ten cents per minute, that is two hundred seventy-eight dollars per month. Multiply by twelve months: over three thousand dollars annually from one second of optimization.

## The Invisible Line Item

Hold time costs never appear as a separate line item on your voice provider invoice. They are buried in total connection time. Your bill says you used forty-two thousand minutes last month. It does not say how much of that was actual inference versus waiting. Without instrumentation, you cannot see the hold time tax. You just know your costs are higher than expected.

A healthcare voice platform received a bill for six thousand two hundred dollars in January 2026. They expected four thousand based on their conversation volume and model costs. They could not explain the two-thousand-dollar gap. They instrumented their pipeline and discovered that thirty-eight percent of their billed time was hold time—silence detection delays, user pauses longer than necessary, and handoff latency. That thirty-eight percent was two thousand three hundred fifty-six dollars of their monthly bill. The gap was explained. They spent February optimizing hold time. March bill was four thousand four hundred dollars. Same traffic. Eighteen hundred dollars saved.

The hold time tax is not a bug. It is a feature of per-minute billing models. Voice providers charge for connection time because that is the resource they provision—an open audio stream, regardless of whether audio is flowing. The way to minimize the tax is not to negotiate different billing terms. It is to minimize the time your system spends waiting. Every millisecond of latency you remove is a cost reduction. Every second of unnecessary silence is money you no longer spend.

Cost attribution—understanding exactly which parts of your multi-provider pipeline are consuming which portions of your budget—turns from a quarterly billing exercise into a real-time operational necessity when hold time alone can shift your margins by double digits.

