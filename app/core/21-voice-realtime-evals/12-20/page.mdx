# 12.20 — Biometric Consent Frameworks Across Jurisdictions

One consent form does not work everywhere. A US telecommunications company launched voice authentication globally in early 2025 using a single consent disclosure designed for Illinois BIPA compliance. The disclosure was clear, specific, and legally sound — for Illinois. It informed users that biometric voiceprints would be collected, described the retention period, and obtained affirmative written consent before enrollment. When European regulators audited the system under GDPR and the EU AI Act, they found the consent framework non-compliant. The disclosure did not identify the data controller by legal name and contact information. It did not specify the legal basis for processing biometric data. It did not inform users of their right to withdraw consent. It did not explain cross-border data transfers. The consent form that satisfied Illinois law violated European law. The company faced enforcement action in three EU member states and had to re-consent forty-three thousand European users. The cost of assuming regulatory equivalence was seven hundred thousand euros in legal fees, engineering rework, and regulatory fines.

Biometric consent requirements vary dramatically across jurisdictions. The United States has no federal biometric privacy law — regulation occurs at the state level, with different states imposing different consent standards, retention requirements, and enforcement mechanisms. The European Union treats biometric data as a special category of personal data under GDPR and as a high-risk AI system under the AI Act, both imposing strict consent and transparency requirements. Other jurisdictions — Canada, Australia, Brazil, Singapore — have their own frameworks. A voice authentication system serving users in multiple jurisdictions must comply with the strictest applicable law for each user, or implement jurisdiction-specific consent flows that adapt to where the user is located.

## US State-by-State Biometric Consent Requirements

Illinois BIPA is the most stringent state biometric privacy law in the United States and the most frequently litigated. It requires written consent before collecting biometric identifiers or biometric information. "Written consent" does not require a physical signature, but it requires affirmative, documented agreement — a user clicking "I agree" after reviewing a standalone biometric disclosure. The disclosure must inform the user of the specific purpose for collection, the length of time the biometric data will be retained, and that biometric identifiers are being collected. Generic language like "we may collect data to improve our services" is insufficient. The disclosure must explicitly state "we will collect a voiceprint" or equivalent language that makes clear the biometric nature of the data.

Illinois BIPA also requires a written policy, made available to the public, that establishes a retention schedule and destruction guidelines for biometric identifiers. A financial institution implementing voice authentication under BIPA published a biometric data retention policy stating: "Voice biometric identifiers are retained for the duration of the customer relationship. Upon account closure, voiceprint data is deleted within thirty days. Users may request deletion of their voiceprint at any time by contacting customer service, and deletion will be completed within fourteen business days." The policy was linked from the consent disclosure and published on the company's privacy policy page. This level of transparency is required under BIPA and increasingly expected under other frameworks.

Texas CUBI takes a different approach. It requires informed consent, but not written consent. "Informed consent" means the user must be aware that biometric identifiers are being collected and must agree to the collection, but the form of that agreement is less prescriptive than Illinois. A user verbally agreeing to enrollment after hearing a disclosure over the phone may satisfy Texas informed consent requirements, whereas Illinois requires a documented action like clicking a consent button. Texas CUBI also requires destruction of biometric identifiers within a reasonable time after the purpose for collection expires, but it does not require a published retention policy.

Washington's My Health My Data Act, enacted in 2023 and enforced beginning in 2024, regulates consumer health data including biometric data collected in health contexts. It requires affirmative consent for collection, use, or disclosure of health data, with stricter requirements than standard data privacy laws. A healthcare company offering voice authentication for prescription refills in Washington had to obtain separate consent for voiceprint collection beyond standard account terms of service, and the consent had to allow for easy withdrawal. The company implemented a one-click consent withdrawal option in the user account portal, allowing users to revoke biometric consent and delete their voiceprint without contacting customer support.

California privacy laws — CCPA and CPRA — classify biometric identifiers as sensitive personal information requiring heightened protection. While California does not have BIPA-style consent requirements, users have the right to know what biometric data is collected, the right to request deletion, and the right to opt out of the sale or sharing of biometric data. A retail company operating in California had to update their privacy notice to explicitly list "voiceprints for authentication" as a category of sensitive personal information collected, provide a clear deletion request mechanism, and ensure that voiceprints were never shared with third parties without explicit opt-in consent.

Other states are enacting or proposing biometric privacy laws as of 2026. Arkansas, Montana, and New York have passed biometric privacy legislation with varying requirements. A voice authentication platform serving users nationwide must either implement jurisdiction-specific consent flows for each state or adopt a national consent standard that complies with the strictest state law. Most companies in 2026 choose the latter — building consent flows that meet Illinois BIPA requirements for all US users, ensuring nationwide compliance without the complexity of state-by-state variations.

## EU Biometric Consent Under GDPR and AI Act

The European Union's GDPR treats biometric data as a special category of personal data under Article 9, subject to a general prohibition on processing unless one of the limited exceptions applies. The most common exception for voice authentication is explicit consent. "Explicit consent" under GDPR is more stringent than ordinary consent. It requires a clear affirmative action, specific and informed agreement, and the ability to withdraw consent as easily as it was given.

Explicit consent for biometric data requires a standalone consent action. A pre-checked box does not suffice. A general data processing agreement does not suffice. The user must be presented with a clear statement of what biometric data will be processed, for what purpose, and must take an affirmative action to agree — clicking "I consent to biometric processing" or equivalent. A European bank implemented this by presenting a dedicated biometric consent screen during voice authentication enrollment. The screen stated: "We will create a unique voiceprint based on your speech to verify your identity in future calls. This is biometric data protected under GDPR. You have the right to refuse this processing and use alternative authentication methods. Do you consent to biometric voiceprint processing?" Two buttons appeared: "I consent" and "No, use alternative authentication." Clicking "I consent" was logged with timestamp and user ID. Clicking "No" routed the user to SMS-based authentication.

GDPR consent must be informed. The user must understand what they are consenting to. This requires providing clear information about the data controller's identity, the purpose of processing, the retention period, the user's rights — including the right to withdraw consent, the right to access their biometric data, and the right to request deletion. A telecommunications company's GDPR-compliant consent disclosure included all of these elements in a two-paragraph statement presented before enrollment. The disclosure identified the legal entity acting as data controller, explained that voiceprints would be used solely for identity verification, stated that voiceprints would be retained until account closure or consent withdrawal, and provided a link to detailed information about GDPR rights.

The EU AI Act adds additional transparency requirements for biometric identification systems classified as high-risk AI. Users must be informed that they are interacting with an AI system. They must be provided with information about the system's capabilities and limitations. They must be informed of their right to lodge a complaint with a supervisory authority if they believe the system is being operated unlawfully. A financial institution deploying voice authentication under the AI Act updated their consent disclosure to include: "Voice authentication is performed by an AI system that analyzes your speech characteristics. The system has a false acceptance rate below 0.01% and a false rejection rate below 2%. If you experience repeated authentication failures or believe the system is operating incorrectly, you may contact our data protection officer or file a complaint with your national data protection authority."

Consent withdrawal must be as easy as consent provision. If a user can enroll in voice authentication with two clicks, they must be able to withdraw consent and delete their voiceprint with two clicks. A European insurance company implemented a consent management portal where users could view all active biometric consents, see when consent was provided, and revoke consent with a single button click. Revoking consent immediately triggered voiceprint deletion and logged the withdrawal event. The user received an email confirmation: "Your biometric voiceprint consent has been withdrawn and your voiceprint has been deleted from our systems. You will now use password authentication for account access."

## Obtaining Meaningful Biometric Consent in Voice

Obtaining meaningful consent during a voice interaction — over the phone, without a visual interface — is harder than obtaining consent through a web or mobile app. Users cannot read a detailed disclosure. They cannot click a consent button. They must listen to spoken information and provide verbal agreement. This raises questions about whether verbal consent can meet the "written consent" standard under Illinois BIPA or the "explicit consent" standard under GDPR.

Illinois BIPA's "written consent" requirement is interpreted broadly by courts to include electronic consent mechanisms. Clicking a button on a mobile app or website after reviewing a disclosure is written consent. Verbally agreeing after hearing a disclosure may not be, unless the verbal agreement is captured and documented in a way that demonstrates informed, affirmative consent. A telecommunications company addressed this by implementing a voice-based enrollment flow that combined verbal disclosure with documented consent. When a user called to enroll in voice authentication, the IVR system stated: "To enroll in voice authentication, we will create a unique voiceprint from your speech. This is biometric data. We will store your voiceprint securely and use it only to verify your identity in future calls. Your voiceprint will be retained as long as your account is active and will be deleted within thirty days of account closure. You may request deletion at any time. Do you consent to this biometric data collection? Say yes to consent, or say no to use a different authentication method." The user's spoken response was recorded and transcribed. The system confirmed: "Thank you. Your consent has been recorded and you are now enrolling in voice authentication." The recorded audio and transcript were stored as evidence of consent.

GDPR's explicit consent standard can be met through verbal consent if the verbal agreement is clearly documented and the user was adequately informed. A European bank implemented voice-based biometric enrollment using a similar flow. The IVR disclosure included all required GDPR elements — data controller identity, purpose, retention period, rights to access and deletion, complaint mechanisms. The user's verbal "yes" was recorded. The system sent a follow-up SMS after enrollment: "You have enrolled in voice authentication. Your biometric voiceprint is now active. To withdraw consent and delete your voiceprint, reply DELETE to this message or call customer service." The combination of verbal consent during enrollment and easy withdrawal via SMS was deemed compliant by the bank's data protection officer and passed a regulatory audit.

Accessibility is a challenge. Users with hearing impairments may struggle to hear a spoken disclosure. Users with speech impairments may struggle to provide verbal consent. A healthcare company addressed this by offering multiple enrollment paths. Users who preferred voice enrollment could use the IVR flow. Users who preferred visual enrollment could use the mobile app, which presented a written disclosure with a consent button. Users who needed accessibility accommodations could request assistance from a live agent, who could read the disclosure aloud at a slower pace, answer questions, and document consent through a secure web form while the user remained on the call.

## Consent for Enrollment vs Verification

Biometric consent frameworks must distinguish between consent for enrollment — collecting and storing a voiceprint — and consent for verification — using a stored voiceprint to authenticate. These are separate processing activities with different purposes and different consent implications.

Enrollment consent is the primary consent required under biometric privacy laws. It covers the collection and storage of the voiceprint. A user who consents to enrollment agrees that their voiceprint will be created and retained. Without enrollment consent, you cannot collect a voiceprint.

Verification consent is more nuanced. Once a user has consented to enrollment and a voiceprint is stored, can you use that voiceprint for verification without seeking separate consent each time? The answer depends on jurisdiction and how the initial consent was scoped. If the enrollment consent explicitly stated "we will use your voiceprint to verify your identity in future calls," then ongoing verification is covered by the initial consent. If the enrollment consent only covered collection and storage without specifying use, separate verification consent may be required.

Most consent frameworks in 2026 combine enrollment and verification into a single consent that covers both activities. The consent disclosure states: "We will create a voiceprint from your speech and use it to verify your identity when you call us." This approach simplifies consent management and aligns with user expectations — users enrolling in voice authentication expect that the voiceprint will be used for authentication, not simply collected and stored unused.

Transaction-specific consent is an emerging issue. Should users be asked to consent each time their voiceprint is used for a high-risk transaction, such as authorizing a wire transfer? GDPR's principle of consent specificity suggests that consent for routine authentication may not cover high-risk uses without explicit additional consent. A European financial institution addressed this by implementing two-tier consent. The initial enrollment consent covered voiceprint use for routine authentication — account access, balance inquiries, low-value transactions. High-value transactions — wire transfers above ten thousand euros — required explicit transaction-specific consent. During the transaction, the system stated: "You are authorizing a wire transfer of fifteen thousand euros. For your security, we will use your voiceprint to verify this transaction. Do you consent to this use of your biometric data for transaction authorization?" The user's verbal "yes" was recorded and linked to the transaction record.

## Managing Consent Across Jurisdictions

A global voice authentication system must handle users in different jurisdictions with different consent requirements. The simplest approach is to adopt the strictest standard globally — if Illinois BIPA requires written consent and GDPR requires explicit consent, use a consent flow that meets both standards for all users everywhere. This ensures compliance without complexity, but it may impose unnecessary friction on users in jurisdictions with lighter requirements.

The more sophisticated approach is jurisdiction-specific consent flows. User location is determined at enrollment — either through IP geolocation, phone number country code, or self-declaration. Based on location, the user is presented with a consent disclosure tailored to local requirements. Illinois users see BIPA-compliant disclosures. European users see GDPR and AI Act-compliant disclosures. Texas users see CUBI-compliant disclosures. This approach minimizes friction by applying only the necessary legal requirements to each user, but it requires building and maintaining multiple consent flows.

A financial services company implemented jurisdiction-specific consent using a consent management platform that mapped user locations to regulatory requirements. The platform stored templates for each jurisdiction's required consent language. During enrollment, the user's phone number was parsed to extract the country code. The country code was mapped to a jurisdiction — US phone numbers were further mapped to states based on area code and exchange. The appropriate consent template was selected and presented. Consent acceptance was logged with the jurisdiction identifier, ensuring that the company could demonstrate compliance with the applicable law during audit.

Cross-border consent management is particularly complex. If a user enrolls in one jurisdiction and later accesses the service from another jurisdiction, which consent framework applies? A European user who enrolls in voice authentication while in Germany, then travels to the United States and attempts to use voice authentication, is still protected by GDPR even while physically in the US. A US user who enrolls in California, then moves to Illinois, may now be protected by Illinois BIPA. A telecommunications company addressed this by applying the strictest applicable consent framework to each user. If a user had ever been subject to Illinois BIPA — based on enrollment location or residence — the company treated that user as a BIPA-protected user permanently, even if they moved to a different state. This over-compliance ensured that the company never lost coverage by assuming a user was no longer subject to a strict law.

Consent documentation must be retained across jurisdictions. You must be able to prove, for each user, that you obtained compliant consent under the applicable law. This requires logging consent events with sufficient detail to survive audit in any jurisdiction where the user might be protected. A European bank's consent logging included: user identifier, timestamp, jurisdiction at enrollment, consent disclosure version, consent response, IP address or phone number, and the full text of the disclosure presented. This level of documentation allowed the bank to produce evidence of GDPR-compliant consent for European users, BIPA-compliant consent for Illinois users, and jurisdiction-appropriate consent for users everywhere else.

## The Consent Framework as Operational Discipline

Biometric consent is not a one-time legal review. It is an operational discipline that must be embedded in enrollment flows, consent management systems, user account portals, and deletion workflows. Every time you update your consent disclosure — to reflect a new retention policy, a new legal requirement, or a service change — you must re-consent affected users. Every time a user requests deletion, you must honor it. Every time a regulatory framework changes, you must assess whether your consent approach remains compliant.

The cost of consent management is real. Engineering effort to build jurisdiction-specific flows. Legal review to ensure compliance across multiple frameworks. Ongoing monitoring to detect regulatory changes. Re-consent campaigns when policies change. Deletion workflow maintenance. A global voice authentication platform estimated that biometric consent management accounted for eighteen percent of total system development cost and eleven percent of ongoing operational cost. These costs are not optional. They are the price of lawful biometric processing.

The risk of consent failure is catastrophic. A single consent defect can expose the entire user base to regulatory action. A single jurisdiction's enforcement can force costly remediation across all jurisdictions. A single BIPA lawsuit can turn into a class action with statutory damages in the millions. The only viable approach is to treat biometric consent with the gravity it deserves under law — as a foundational requirement, not an afterthought.

Voice authentication is powerful. The compliance and governance frameworks that make it lawful are complex. Chapter Twelve has covered the enterprise dimensions — call centers at scale, multi-region compliance, biometric regulation, synthetic voice detection, consent across borders. The next chapter shifts to a different challenge: how do you design conversation flows that recover gracefully when voice systems fail or misunderstand? We turn to conversational recovery patterns.
