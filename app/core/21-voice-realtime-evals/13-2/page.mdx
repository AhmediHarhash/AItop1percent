# 13.2 — In-Turn Recovery vs Cross-Turn Recovery

The difference between recovering inside the current conversational turn and waiting until the next turn is the difference between invisible correction and obvious failure. When you detect a problem and fix it before the user finishes hearing your response, the user never knows anything went wrong. When you detect a problem and wait until the next turn to correct it, the user has already heard the error, internalized it, and formed a judgment about system quality. Recovery that happens within the same turn is a technical success. Recovery that happens across turns is damage control.

Most teams default to cross-turn recovery because it is architecturally simpler. You let the current response finish, log the error, and use the next user utterance as an opportunity to issue a correction or clarification. This works in text chat where users can scroll back and see the full conversation history. In voice, where users cannot scroll back and have no visual record of what was said, cross-turn recovery feels jarring. The system appears to contradict itself or admit incompetence. In-turn recovery avoids this by fixing the problem in real-time, before it becomes part of the conversation record the user is building in their head.

## In-Turn Recovery: Fixing Before the User Hears the Mistake

In-turn recovery means detecting a failure while the response is being generated or spoken and altering the output before it reaches the user. This requires real-time monitoring of every component in the generation pipeline — the LLM, the TTS renderer, the audio streamer — and the ability to interrupt, modify, or replace content mid-stream.

The most common form of in-turn recovery is TTS substitution. If the LLM generates a response that contains an unpronounceable token, an incorrect word, or a formatting artifact that TTS cannot render, the system detects this during TTS processing and substitutes a corrected version before the audio is played. The user hears a clean, fluent response. They never know the original text contained an error.

A healthcare voice assistant in mid-2025 used in-turn TTS substitution to handle medication names. The LLM occasionally generated medication names with minor spelling errors — "Lipitor" as "Lipiter," "Metformin" as "Metforman" — that TTS would render phonetically as nonsense words. The system maintained a dictionary of 3,000 common medication names with their correct pronunciations. During TTS rendering, it compared each word in the LLM output against the dictionary. When it found a word with a Levenshtein distance of 1 or 2 from a dictionary entry, it substituted the correct spelling before sending the text to TTS. The substitution happened in 40-70ms, well within the overall TTS rendering budget of 280ms. Users heard the correct medication name. The error never surfaced.

In-turn recovery also applies to semantic errors caught early. If the LLM begins generating a response that contradicts known facts or violates business rules, and you detect this within the first 20-30 tokens of generation, you can cancel the generation, issue a corrective instruction to the LLM, and restart. If the restart completes before the original generation would have finished, the user experiences no delay. If the restart takes longer, the user experiences a slight pause, but not a spoken error followed by a correction.

The challenge with in-turn semantic recovery is speed. You must detect the error early enough in generation to cancel and restart without exceeding your latency budget. If the LLM generates 40 tokens per second and your error detection logic runs on every token, you have 25 milliseconds per token to decide whether to continue or cancel. Most semantic error detection takes longer than this, which is why in-turn semantic recovery is rare in production. Teams that implement it usually rely on simple heuristics — keyword blocklists, pattern matching for known bad outputs, confidence thresholds — rather than deep semantic analysis.

A customer service voice bot for a telecom company in late 2025 used in-turn cancellation to prevent the LLM from hallucinating plan details. The company offered 12 mobile plans with specific price points, data limits, and features. The LLM occasionally generated responses that combined features from multiple plans or invented prices that did not exist. The system monitored the LLM's token stream for plan names and prices. If it detected a plan name followed by a price that did not match the known price for that plan, it canceled generation, prepended a corrective instruction to the prompt — "Only mention the exact prices listed in the plan database. Do not approximate or combine plans." — and restarted generation. The cancellation and restart took an average of 320ms, compared to the original generation time of 1.1 seconds. In 78% of cases, the restarted generation completed before the original would have, so the user experienced no delay. In the remaining 22%, the user experienced a delay of 200-400ms, which was perceptible but acceptable compared to hearing an incorrect price and then receiving a correction.

The key to in-turn recovery is that it produces a single, coherent response. The user hears one answer, and it is correct. There is no "wait, actually..." or "let me correct that." The conversation flows naturally because the error never reached the user's ears.

## Cross-Turn Recovery: Correcting After the User Has Heard the Error

Cross-turn recovery means detecting an error after the response has been spoken and using the next conversational turn to issue a correction or clarification. This is the fallback when in-turn recovery is not feasible — either because the error was not detected until after the response completed, or because correction would take longer than the user's tolerance for delay.

The most common form of cross-turn recovery is the clarification request. The system delivers a response, detects that the response may have been based on a misunderstood user input, and uses the next turn to ask for confirmation or clarification. "I heard you say X — is that correct?" This gives the user an opportunity to correct the system's understanding before proceeding further. It also signals to the user that the system is uncertain, which can increase trust if done sparingly and decrease trust if done frequently.

A travel booking voice assistant in early 2026 used cross-turn clarification for ambiguous dates. When the user said "I want to fly next Friday," the system generated a response assuming next Friday was seven days from the current date. But "next Friday" is ambiguous — it could mean the upcoming Friday or the Friday of the following week. After delivering the initial response, the system issued a clarification in the next turn: "Just to confirm, I have you flying on March 14th. Is that the date you meant?" If the user confirmed, the conversation continued. If the user corrected, the system adjusted and re-quoted. The clarification added one extra turn to the conversation, but it prevented booking errors.

Cross-turn recovery can also take the form of explicit correction. The system delivers a response, detects an error in what was said, and uses the next turn to correct itself. "Actually, I need to correct what I just said — the price is 49 dollars, not 59 dollars." This is transparent and builds user trust in the system's honesty, but it also exposes the error. The user now knows the system made a mistake. If this happens rarely, it is acceptable. If this happens frequently, it signals unreliability.

A financial advisory voice assistant in mid-2025 used cross-turn correction for stock prices. The LLM occasionally generated responses with outdated or incorrect stock prices, either because the knowledge cutoff was stale or because the LLM hallucinated a number. The system cross-checked the spoken price against a real-time stock price API after the response was delivered. If the discrepancy was greater than 5%, the system issued a correction in the next turn: "I need to update that — the current price is actually 142 dollars per share, not 138 dollars." Users appreciated the transparency, but the frequency of corrections — about one per twelve conversations — was high enough that some users questioned whether they could trust any of the prices the system provided. The team eventually moved to in-turn validation, querying the stock price API before generation and constraining the LLM to use only verified prices. Cross-turn corrections dropped to fewer than one per hundred conversations.

The risk with cross-turn recovery is that it breaks conversational flow. Human conversations rarely include explicit self-corrections. When they do, they signal confusion or uncertainty. A voice AI that frequently corrects itself signals the same. Users begin to question every response, even the correct ones. They start asking for confirmations or verifications because they do not trust the system to get it right the first time.

## When to Use In-Turn vs Cross-Turn Recovery

The decision between in-turn and cross-turn recovery depends on three factors: detectability, correctability, and latency.

Detectability: Can you detect the error before the response is fully delivered? If the error is in TTS rendering, you can detect it during TTS processing, which happens before the audio plays. If the error is in LLM generation, you can detect it during generation if you monitor the token stream. If the error is in semantic accuracy, you can detect it only if you have a real-time validation mechanism that runs faster than generation. If detection happens after delivery, in-turn recovery is impossible.

Correctability: Can you correct the error without regenerating the entire response? If the error is a single word substitution, you can correct it with a local edit. If the error is a factual claim embedded in a complex explanation, you may need to regenerate the entire response, which takes time. If correction is fast, in-turn recovery is feasible. If correction is slow, cross-turn recovery is the only option.

Latency: Can you detect and correct the error within your latency budget? If your total response budget is 1.2 seconds and error detection takes 300ms and correction takes 400ms, you can fit in-turn recovery within 1.9 seconds, which is acceptable for voice. If detection takes 600ms and correction takes 1.1 seconds, your total time is 2.9 seconds, which exceeds user tolerance. In that case, cross-turn recovery — delivering the flawed response in 1.2 seconds and issuing a correction in the next turn — is better than making the user wait 2.9 seconds for a corrected response.

The general rule: use in-turn recovery whenever detection and correction fit within your latency budget. Use cross-turn recovery when they do not. In-turn recovery is invisible. Cross-turn recovery is visible. All else equal, invisible is better.

## Context Preservation Across Recovery Types

One of the hardest challenges in both in-turn and cross-turn recovery is preserving conversational context. When you interrupt generation to fix an error, you risk losing the thread of the conversation. When you issue a correction in the next turn, you risk confusing the user about which information is current and which is outdated.

In-turn recovery requires maintaining a coherent narrative despite mid-stream changes. If you cancel an LLM generation halfway through and restart with a corrective prompt, the restarted generation must flow naturally from what the user last heard. If the user's last utterance was "What is the weather in Seattle?" and the LLM started generating "The weather in Seattle today is sunny with a high of —" before you detected an error and canceled, the restarted generation cannot begin with "Seattle's weather is..." because the user is already expecting the completion of the previous sentence. The restart must pick up where the cancellation left off, maintaining grammatical and semantic continuity.

A navigation voice assistant in late 2025 struggled with in-turn context preservation during route recalculations. When the user deviated from the planned route, the system would cancel the current turn-by-turn instruction mid-sentence and start issuing new instructions based on the updated route. But the cancellation was abrupt — "In 500 feet, turn left on — Recalculating. Turn right on Main Street." The user heard two contradictory instructions in rapid succession and did not know which to follow. The fix was to complete the current instruction before issuing the recalculation: "In 500 feet, turn left on Oak Street. Route updated — your next turn will be right on Main Street in half a mile." The transition was explicit, and the user understood that the second instruction superseded the first.

Cross-turn recovery requires signaling clearly which information is being corrected. If you issue a correction without referencing what you are correcting, the user may not connect the correction to the original error. If you reference the error too vaguely, the user may not remember which part of the previous response you are correcting. The correction must be specific enough to disambiguate but concise enough to fit within a single turn.

A pharmacy voice assistant in early 2026 issued corrections like "Actually, the copay is 15 dollars" without referencing what the original incorrect copay was. Users who had already mentally moved on from thinking about copay amounts did not register that a correction had been issued. They assumed 15 dollars was a new piece of information, not a replacement for an earlier piece. The fix was to make corrections explicit: "I said the copay was 25 dollars, but I need to correct that — it is actually 15 dollars." The reference to the original incorrect value helped users update their mental model accurately.

## The User's Mental Model of Conversation State

Users build a mental model of the conversation as it progresses. Each turn adds information to that model. When you use in-turn recovery, you modify the current turn before it is added to the model, so the model remains accurate. When you use cross-turn recovery, you add an incorrect turn to the model and then issue a correction, which requires the user to retroactively edit the model. This cognitive load is small for a single correction but compounds if corrections are frequent.

A voice assistant that issues cross-turn corrections more than once per conversation risks fragmenting the user's mental model. The user starts to lose confidence in which pieces of information are current and which have been superseded. This is especially problematic in domains like healthcare, finance, or legal advice, where incorrect information can have consequences. In those domains, in-turn recovery is strongly preferred because it ensures the user's mental model is never polluted with incorrect information.

But in-turn recovery is not always possible. Some errors cannot be detected until after the response is delivered. Some corrections take longer than the latency budget allows. In those cases, cross-turn recovery is the only option. The key is to minimize its frequency. If cross-turn corrections happen in fewer than one in fifty conversations, users perceive them as rare anomalies and trust is preserved. If they happen in more than one in ten conversations, users perceive the system as unreliable and trust degrades.

A legal document voice assistant in mid-2025 had cross-turn corrections in 18% of conversations. Users described the system as "uncertain," "unreliable," and "hard to trust." The team analyzed correction triggers and found that 60% of corrections were for information that could have been validated before delivery — clause numbers, document dates, party names. They moved validation to run during LLM generation, blocking generation until validation passed. Cross-turn corrections dropped to 4% of conversations. User trust scores increased by 35 percentage points.

## Hybrid Recovery: In-Turn Detection, Cross-Turn Correction

Some systems use a hybrid approach: detect errors in-turn but issue corrections cross-turn. This is useful when detection is fast but correction is slow. The system detects a problem while generating the response, flags it internally, delivers the potentially flawed response to avoid delay, and then issues a correction in the next turn if the flaw is confirmed.

This approach is common for factual validation. The LLM generates a response that includes a factual claim — "The policy covers up to 50,000 dollars in liability." The system flags the number for validation, delivers the response to the user, runs a validation check against the policy database in the background, and if the validation fails, issues a correction in the next turn: "I need to correct that — the policy covers up to 100,000 dollars in liability."

The advantage is that the user does not wait for validation. The response is delivered within the normal latency budget. The correction happens only if needed, and it happens in the next turn when latency is less critical. The disadvantage is that the user hears incorrect information, even briefly. In low-stakes domains — entertainment, general information, casual conversation — this is acceptable. In high-stakes domains — medical advice, financial transactions, legal guidance — it is not.

A healthcare voice assistant in late 2025 used hybrid recovery for medication dosage information. The LLM generated responses that included dosages, the system delivered the response immediately, validated the dosage against a drug database in the background, and issued a correction if the dosage was wrong. The approach kept latency low but resulted in users occasionally receiving incorrect dosage information for 5-10 seconds before the correction was issued. After a near-miss incident where a user almost took the wrong dosage because they hung up before hearing the correction, the team switched to in-turn validation. Dosage claims were validated before generation, and the LLM was constrained to use only validated dosages. Latency increased by an average of 180ms, but incorrect dosage information was never delivered to users.

The lesson is that hybrid recovery is a latency optimization that sacrifices safety. Use it only in domains where brief exposure to incorrect information has no material consequences. In high-stakes domains, in-turn validation is non-negotiable.

Whether you recover within the same turn or across turns determines whether users notice the error. The next challenge is recovering from ASR failures, where the system misheard the user and must decide whether to guess, ask, or escalate.

