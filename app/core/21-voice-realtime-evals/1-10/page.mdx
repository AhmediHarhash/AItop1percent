# 1.10 — Voice AI Failure Modes That Do Not Exist in Text

The agent talks over the user. The user was mid-sentence, but the agent started speaking anyway. Now both voices overlap. The user stops talking, frustrated. The agent continues, unaware it interrupted. The conversation is broken. This failure mode — barge-in failure — does not exist in text chat. A chatbot cannot talk over the user. The input field waits. The user types at their own pace. There is no overlap, no interruption, no collision of speech. Voice systems have this failure mode. Text systems do not. And if your team has only built text agents, you do not know it exists until your first user calls you rude.

Voice AI has failure modes that are categorically unique to the modality. They emerge from the real-time, bidirectional, always-on nature of voice interaction. They emerge from the fact that speech is temporal — it unfolds over time, and both parties can attempt to speak simultaneously. They emerge from the acoustic complexity of human speech — background noise, accents, disfluencies, overlapping speakers. And they emerge from the user's expectations that a voice agent will behave like a human conversation partner, even though the underlying system is stitched together from ASR, NLU, dialog management, TTS, and network latency.

These failure modes are not edge cases. They are common, predictable, and devastating to user experience when they occur. And text-trained teams miss them entirely, because none of these failures produce a visible error in the transcript. The transcript might look perfect. The conversation was broken anyway. This subchapter catalogs the voice-specific failure modes, explains their root causes, and shows why you need voice-specific eval to catch them before users do.

## Barge-In Failure: The Agent Talks Over the User

Barge-in is the ability of the user to interrupt the agent while it is speaking. The agent is delivering a long response. The user realizes they already know this information, or they want to ask a different question, or they made a mistake in their previous input. The user starts speaking. The agent should stop immediately. If it does not, the agent is talking over the user. This is barge-in failure. It is the voice equivalent of a chatbot ignoring the user's new message and continuing to stream its previous response.

Barge-in failure happens when the system's interruption detection is too slow, too conservative, or entirely absent. The user starts speaking. The ASR pipeline detects speech, but it waits to confirm that the speech is intentional and not just background noise. By the time the ASR confirms, the TTS has already rendered the next two seconds of the agent's response. The agent keeps talking. The user tries again, louder. The ASR finally triggers an interrupt. The agent stops mid-sentence. The user is now annoyed. They had to interrupt twice. The agent sounded oblivious.

The root cause is latency in the interrupt detection path. The user's speech must be detected, classified as intentional (not noise), and propagated to the TTS system to stop playback. This path has multiple components, each with its own latency. If the total interrupt latency exceeds 400 milliseconds, the user perceives the agent as unresponsive. They expect instant cutoff, the way a human would stop talking when interrupted. A 600-millisecond delay feels robotic. A 1,000-millisecond delay feels broken.

Some systems disable barge-in entirely to avoid the complexity. The agent talks. The user cannot interrupt. The user must wait for the agent to finish, then speak. This works in narrow domains where agent responses are always short and relevant. It fails catastrophically when the agent gives a long, unhelpful response and the user has no way to stop it. The user sits in silence, waiting, frustrated. The agent delivers 30 seconds of irrelevant information. The user hangs up. Containment rate drops. The team investigates. They discover that users are abandoning calls during long agent responses. They finally implement barge-in. Too late. The damage is done.

The better approach is to design for fast, reliable barge-in from day one. You optimize the interrupt detection path for latency. You use voice activity detection that triggers on the first 100 milliseconds of user speech. You stream the interrupt signal to the TTS immediately, stopping playback within 300 milliseconds. You test this with real users in realistic noise conditions. You measure the interrupt latency distribution. You fix the outliers. And you monitor barge-in success rate in production — how often does the user attempt to interrupt, and how often does the agent actually stop? If the success rate is below 90%, you have a problem. Users will notice. They will escalate. And your text-based evals will never see it, because the transcript does not capture the overlap.

## ASR-to-State Corruption: The Agent Mishears and Breaks the Conversation

The user says "I need to change my billing address." The ASR hears "I need to change my mailing address." The dialog manager interprets this as a request to update the mailing address, which is a different field in the database. The agent asks "What's your new mailing address?" The user gives their billing address. The agent updates the wrong field. The user discovers the mistake later. They call back, frustrated. The conversation broke because the ASR made a one-word error, and that error corrupted the session state.

This is ASR-to-state corruption. It is unique to voice because the input modality is unreliable. Text chatbots receive exact input. If the user types "billing address," the system sees "billing address." Voice agents receive acoustic signals, which are transcribed with error. Modern ASR systems in 2026 have error rates below 5% in clean conditions, but that is not zero. Five percent error rate means one word in twenty is wrong. If the wrong word is the critical slot value — the name, the account number, the type of request — the entire conversation derails.

The failure is silent and delayed. The ASR transcribes incorrectly. The NLU extracts the wrong entity. The dialog manager updates the wrong state. The agent proceeds with confidence. The user does not notice immediately, because the agent's questions make sense in the context of the wrong interpretation. The user answers the questions. The agent completes the task. The user hangs up. Later, they discover that the wrong field was updated. They blame the agent. The agent cannot defend itself. The transcript shows the agent did exactly what the user asked for — except the user did not ask for that. The ASR misheard.

You cannot eliminate ASR errors. You can design around them. The best voice agents in 2026 implement confirmation loops for high-risk slots. The user says "I need to change my billing address." The agent confirms: "Got it, you want to update your billing address. Is that correct?" The user says "yes." The agent proceeds. If the ASR misheard, the confirmation step gives the user a chance to correct it. The confirmation adds latency. It also prevents catastrophic errors. The trade-off is worth it for any domain where mistakes have consequences — finance, healthcare, legal, account management.

The confirmation can be implicit. The agent says "Okay, what's your new billing address?" This echoes the entity type back to the user. If the ASR heard "mailing" instead of "billing," the agent would say "what's your new mailing address?" The user would catch the error and correct it. This is less intrusive than an explicit "is that correct?" loop, but it still provides a recovery path. The user hears the agent's interpretation and can intervene if it is wrong.

You also need to monitor ASR error rates in production. Not the overall error rate — that is useless. You need to know the error rate for specific slots, specific entities, and specific user populations. If your ASR has a 3% error rate overall but a 12% error rate for account numbers spoken by users with non-American accents, you have a systematic bias that will destroy experience for a subset of your users. Your aggregate metrics look fine. The affected users suffer. You must segment your ASR error analysis by entity type, accent, background noise level, and user demographics. You will find disparities. You will fix them. Or you will lose users.

## TTS Quality Degradation: The Agent Sounds Robotic or Breaks Mid-Sentence

The agent is speaking. Mid-sentence, the voice shifts in pitch, or the cadence becomes unnatural, or a word is mispronounced catastrophically. The user notices. The agent sounds broken. The agent is technically still delivering the response, but the user has stopped listening. They are distracted by how wrong the voice sounded. This is TTS quality degradation. It happens when the TTS model encounters input it was not trained to handle well — technical jargon, numbers, punctuation, non-English names, ambiguous acronyms.

A banking voice agent says "Your balance is $3,205.47." The TTS model mispronounces the cents as "forty-seven dollars" instead of "forty-seven cents." The user hears "three thousand two hundred five dollars forty-seven dollars." The user is confused. They ask the agent to repeat it. The agent repeats the same broken phrase. The user hangs up and checks their balance online. The agent failed to communicate the most basic piece of information — the account balance. The words were correct. The TTS rendering was wrong.

TTS quality degradation is not random. It is systematic. Certain input patterns trigger it reliably. Numbers with decimal points. Strings of digits like account numbers or confirmation codes. Acronyms that can be pronounced multiple ways. Names from non-English languages. URLs. Email addresses. Punctuation-heavy sentences. If your agent ever needs to say these things, you must test the TTS output explicitly. You cannot assume the model will handle them well. Most TTS systems have known failure modes for these patterns.

The fix is preprocessing. Before sending text to the TTS model, you normalize it. You convert "$3,205.47" to "three thousand two hundred five dollars and forty-seven cents" in text form, so the TTS has no ambiguity. You spell out acronyms phonetically. You break long digit strings into smaller chunks: "account number 8-7-6-5-4-3-2-1" instead of "account number 87654321." You remove punctuation that the TTS interprets as prosodic cues in unintended ways. You test the result with real users. You iterate.

Some teams use SSML tags to control TTS pronunciation and prosody explicitly. SSML allows you to specify phonemes, emphasis, pauses, pitch, and speaking rate. It is powerful. It is also brittle. If the SSML is malformed, the TTS may skip the entire sentence or crash. If the SSML is over-specified, the voice sounds unnatural. You must use SSML sparingly and test it extensively. The payoff is that you can force correct pronunciation for domain-specific terms that the TTS would otherwise mangle.

You also need to monitor TTS output quality in production. This is harder than monitoring ASR, because TTS quality is subjective. But you can sample calls, listen to the audio, and flag instances where the TTS rendered text in a way that would confuse or distract the user. You categorize the failures. You identify patterns. You fix the preprocessing rules. You re-deploy. You monitor again. TTS quality does not degrade randomly. It degrades when your agent starts saying new things — new product names, new terminology, new sentence structures. You must catch these before they reach users at scale.

## Latency Spikes: Silence Hangs for Two Seconds and the User Panics

The conversation is flowing smoothly. The user asks a question. The agent responds within 300 milliseconds. The user asks another question. The agent… says nothing. One second. Two seconds. The user says "hello?" The agent suddenly responds, 2,400 milliseconds after the question. The user is rattled. What happened? The agent experienced a latency spike. The backend API was slow. The ASR pipeline stalled. The network dropped packets and retried. The user does not know this. The user only knows that the agent went silent for a long, uncomfortable period, and the silence felt like a failure.

Latency spikes are a failure mode specific to real-time systems. In a text chatbot, a two-second delay is annoying but not catastrophic. The user sees the typing indicator. They know the system is working. In a voice call, two seconds of dead air feels like the system broke. There is no typing indicator. There is only silence. The user cannot distinguish between "the agent is thinking" and "the connection dropped." They assume the worst.

The root cause is variability in pipeline latency. Your median latency is 280 milliseconds. Your 95th percentile latency is 1,100 milliseconds. Your 99th percentile latency is 2,500 milliseconds. Most users experience fast responses. A few users, on every call, experience long delays. Those delays destroy the experience. The user rates the call based on the worst interaction, not the average. A single two-second pause is enough to make the user perceive the agent as unreliable.

You fix latency spikes by identifying and eliminating the tail. You instrument every component in the pipeline. You measure latency at each stage: ASR, NLU, dialog manager, LLM call, API call, TTS, network round-trip. You export percentile latencies, not just averages. You identify which component contributes to the tail. You optimize it. If the tail is caused by an external API, you implement timeouts and fallback responses. If the tail is caused by cold starts in your serverless functions, you keep instances warm. If the tail is caused by network retries, you adjust retry logic or add redundancy.

You also implement latency-triggered acknowledgments. If the system detects that the response will take longer than 600 milliseconds, it inserts an acknowledgment phrase — "let me check on that" — at 400 milliseconds, buying time before the user panics. This does not fix the latency. It manages the user's perception of the latency. The user hears that the agent is working. They tolerate the delay. Without the acknowledgment, the same delay feels like a freeze.

Latency spikes are not rare. In production voice systems at scale, the 99th percentile latency is often three to five times the median. If your median is 300 milliseconds, your 99th percentile might be 1,200 milliseconds. One in every hundred interactions hits this. If your agent handles a thousand calls a day, ten users per day experience a multi-second pause. Those ten users are disproportionately likely to escalate, complain, or churn. You cannot ignore the tail. The tail defines the user's trust in your system.

## Acoustic Noise Corruption: Background Sounds Break ASR

The user is calling from a busy street. Cars are passing. The ASR picks up the car sounds as speech. The agent hears "I want to update my account vroom vroom honk" and tries to parse "vroom vroom honk" as a slot value. The NLU fails. The agent says "I didn't catch that, can you repeat?" The user repeats. Same noise. Same failure. After three attempts, the user gives up. The conversation was broken by the environment, not by the user or the agent. This is acoustic noise corruption. It does not exist in text systems. Text is noiseless. Voice is embedded in the physical world, and the physical world is loud.

Modern ASR systems have noise suppression. They filter out background sounds that do not resemble speech. But the filtering is imperfect. Certain sounds — music, other people talking, TV audio, wind against the microphone — are acoustically similar to speech. The ASR cannot reliably tell the difference. It transcribes the noise as words. The agent receives corrupted input. The conversation derails.

You cannot fix the user's environment. You can detect when the environment is too noisy and adjust the agent's behavior. The ASR includes a confidence score for each transcription. If the confidence is low, the agent can ask the user to move to a quieter location or to repeat more slowly and clearly. This is better than proceeding with corrupted input and making incorrect assumptions. Some systems also provide a noise level indicator to the user: "It sounds like you're in a noisy environment. Can you move somewhere quieter?" This feels intrusive, but it is more honest than pretending the conversation is working when it is not.

Noise corruption is especially destructive for authentication flows. The user is trying to verify their identity by speaking their account number or date of birth. Background noise corrupts the ASR. The agent hears the wrong digits. The agent says "That doesn't match our records." The user repeats. Same noise, same error. After three failed attempts, the agent locks the account or transfers to a human. The user is now frustrated and blocked from self-service, all because of environmental noise. The agent should have detected the noise and switched to DTMF input — using the phone keypad instead of voice — from the start.

You monitor noise corruption by tracking the correlation between low ASR confidence and conversation failure. If low-confidence transcriptions reliably lead to retries, confusion, or escalation, you have a noise problem. You adjust the agent to handle it explicitly. You add fallback paths. You offer alternative input methods. You acknowledge the limitation instead of pretending the system is omniscient.

## State Corruption from Out-of-Order Responses

The user says "I want to cancel my order." The agent starts processing the cancellation. The user immediately adds "Actually, just change the address instead." The agent receives both inputs nearly simultaneously. The first intent — cancel order — is already in the pipeline. The second intent — change address — arrives before the first one completes. The dialog manager processes them out of order. The agent changes the address, then cancels the order. The user ends up with a canceled order and a modified address on a shipment that no longer exists. The conversation state is corrupted.

This failure mode is unique to real-time, low-latency voice systems where user input and agent processing overlap. In a text system, the user types one message, waits for the agent to respond, then types the next message. The sequence is clear. In a voice system, the user can issue multiple commands in rapid succession before the agent finishes processing the first one. If the agent does not handle this correctly, the state becomes inconsistent.

The root cause is the lack of transaction semantics in most dialog managers. The agent processes each utterance as it arrives, without locking the conversation state or ensuring that multi-turn operations complete atomically. The user issues command A. The agent begins executing it. The user issues command B. The agent begins executing that too, even though B might invalidate A. The result is a race condition. Which command completes first? The answer is non-deterministic. The user has no idea what state the system is in.

You fix this by implementing state locking for critical operations. When the agent starts a high-risk action — cancellation, payment, address change — it locks the conversation state. Subsequent user input is queued or rejected until the current operation completes and the agent confirms the result. This prevents the user from issuing conflicting commands mid-operation. It also prevents the agent from applying updates out of order.

You also implement explicit state confirmation. After completing an action, the agent says "Your order has been canceled" or "Your address has been updated." This gives the user a clear signal that the action is done and the state has changed. If the user wants to undo or modify the action, they must issue a new command that acknowledges the new state. The agent does not accept ambiguous or overlapping commands.

State corruption is rare but catastrophic. It usually manifests in edge cases where users change their mind mid-conversation or speak before the agent finishes processing. Most teams never test for this because it requires specific timing — the user must issue the second command in the narrow window between the agent receiving the first command and the agent confirming its completion. But in production, at scale, this narrow window gets hit. Users talk fast. Networks are unpredictable. Commands overlap. State corrupts. You need tests that simulate rapid, overlapping user input and verify that the agent handles it correctly.

## The Failure Mode That Text Teams Do Not Know to Test For

The common thread across all of these failure modes is that they do not produce errors in the transcript. The transcript might show a perfectly coherent conversation. The actual user experience was broken. The agent talked over the user. The agent misheard a critical slot. The TTS mangled a key piece of information. The agent went silent for two seconds. The background noise corrupted the input. The state updated out of order. None of these failures are visible to a text-based eval pipeline that only reviews the semantic content of the conversation.

Text-trained teams ship voice agents with high semantic accuracy and disastrous user experience. The agents pass all the text evals. The agents fail in production. Users complain that the agent is "broken" or "doesn't listen" or "sounds weird." The team investigates. They read the transcripts. The transcripts look fine. They do not know what the users are complaining about. The gap exists because the team never evaluated the voice layer. They evaluated the language layer and assumed it was sufficient. It was not.

Closing the gap requires voice-specific evaluation. You must listen to calls, not read transcripts. You must test barge-in behavior, not just dialog flow. You must measure TTS quality, not just response correctness. You must track latency spikes, not just median latency. You must detect ASR errors on critical slots, not just overall word error rate. You must simulate noisy environments, overlapping commands, and real-world failure conditions. And you must do this continuously, in production, at scale.

If you do not, you will discover these failure modes only after users do. And by then, the damage to your containment rate, your user satisfaction, and your brand is already done.

---

Next, we examine the regulatory landscape for voice AI in 2026 — the compliance surface that is larger and more complex than text AI, and what happens when teams ignore it.

