# 14.8 — The Confirmation-Before-Commit Pattern

Most production systems write state immediately when information is extracted. The user says their email is john at example dot com, the model extracts it, and the email field is populated. The next turn uses that email for business logic. Three turns later, the system sends a confirmation code to john at example dot com. If the extraction was wrong — if the user actually said john dot smith at example dot com — the code goes to the wrong address and the user cannot complete the workflow. The error happened in turn two but surfaced in turn five. By then, recovery is slow and frustrating.

Confirmation-before-commit is a different pattern. Information is extracted but not committed to state. Instead, it is held in pending state while the system confirms with the user. "Just to confirm, your email is john at example dot com — is that correct?" The user says yes, and the email is committed to state. The user says no and corrects it, and the corrected value is committed. Only confirmed information reaches production state. Extraction errors are caught before they propagate.

This pattern adds latency and conversational overhead, but it prevents an entire class of state corruption. Every high-stakes field in a voice system should use confirmation-before-commit. Low-stakes fields can commit immediately. The decision is a trade-off between safety and speed, and the consequences of getting it wrong are asymmetric. Committing bad data to a high-stakes field causes harm. Confirming low-stakes fields causes mild annoyance. The choice is obvious.

## When Confirmation Is Non-Optional

Certain fields are so high-stakes that committing without confirmation is professional negligence. Medication dosage is the canonical example. The user says "fifty milligrams," the system extracts "fifteen milligrams" due to ASR error or model hallucination, and the system commits fifteen to state without confirming. The prescription is filled at the wrong dosage. The patient takes it, assuming the system got it right. The outcome ranges from ineffective treatment to overdose. Confirmation would have caught this in turn two instead of discovering it when the patient receives the prescription.

Financial amounts are similarly non-optional. The user says "transfer five hundred dollars," the system extracts "five thousand dollars," and commits without confirmation. The transfer executes. The user's account is overdrawn. Confirmation would have caught the order-of-magnitude error immediately. The confirmation cost is three seconds of conversation time. The error cost is account fees, potential overdrafts, and destroyed trust.

Legal consent is a third category where confirmation is required by law in many jurisdictions. The user agrees to terms and conditions. The system must confirm that the user understood what they agreed to. "You're agreeing to the data sharing policy — is that correct?" The user confirms, and the consent is recorded with timestamp and audio evidence. Without confirmation, the consent is legally questionable.

Irreversible actions require confirmation. Deleting data, canceling services, or making appointments that trigger downstream processes are irreversible once committed. The user says "cancel my appointment" and the system commits the cancellation immediately. The appointment is removed from the provider's schedule. The slot is given to another patient. The user cannot undo this. Confirmation-before-commit gives the user a veto window. "You want to cancel your March 14 appointment — is that correct?" The user has one chance to catch mistakes before the action becomes permanent.

Identity verification fields require confirmation. Patient ID, account numbers, social security numbers, dates of birth — any field used to verify identity must be confirmed before being used for authentication or authorization. If the system extracts the wrong patient ID and commits it, the conversation might proceed in the context of the wrong patient record. This is a catastrophic error in healthcare, finance, or any regulated domain. Confirmation is a mandatory safety gate.

## Confirmation Phrasing: Concise and Unambiguous

The way confirmation is phrased determines whether users actually validate the information or just say yes reflexively. "Is that correct?" prompts users to think. "Right?" does not. "Just to confirm, your email is john at example dot com — is that correct?" forces the user to process the email address before responding. "Your email is john at example dot com, right?" is a rhetorical question that users answer "yes" to without listening.

The confirmation must state the extracted value explicitly. "I have your email — is that correct?" does not work because the user does not know what email the system has. They cannot validate it. "Your email is john at example dot com — is that correct?" gives the user the information they need to validate. They hear the address, compare it to what they said, and confirm or correct.

The phrasing must be concise. Voice interactions do not tolerate verbosity. "Just to confirm, the email address you would like to use for this interaction is john at example dot com — please let me know if that is accurate" is too long. By the time the system finishes speaking, the user has forgotten the email address. "Your email is john at example dot com — correct?" is concise enough that the user retains the address in working memory and can validate immediately.

The phrasing must avoid ambiguity. "Your email is john at example dot com, is that okay?" is ambiguous. Does "okay" mean the address is correct, or that the user approves of using email as a contact method? "Your email is john at example dot com — is that the right address?" is unambiguous. The question is about correctness, not preference.

Batch confirmations are useful when multiple fields are extracted in a single turn. The user provides their name, email, and phone number in one statement. The system extracts all three and confirms them together. "Got it — your name is John Smith, email is john at example dot com, and phone number is 555-0123. Is that all correct?" This is faster than confirming each field individually. The risk is that if the user corrects one field, the system must disambiguate which field is wrong. "No, that's not right" does not specify whether the name, email, or phone is incorrect. Follow-up clarification is required.

## Handling Confirmation Failures

Confirmation failures fall into three categories: explicit correction, ambiguous response, and non-response. Explicit correction is the cleanest. The system confirms "your email is john at example dot com" and the user says "no, john dot smith at example dot com." The system extracts the corrected value, updates pending state, and confirms again. "Got it, john dot smith at example dot com — is that correct?" The user confirms, and the value is committed.

Ambiguous responses are harder. The system confirms "your email is john at example dot com" and the user says "yeah, that's close" or "something like that." These responses do not clearly confirm or deny. The system must decide whether to commit the value or ask for clarification. A conservative strategy treats any non-yes response as a request for clarification. "Can you spell it out for me to make sure I have it exactly right?" The user spells the email, the system extracts it, and confirms again.

Non-response is the third failure mode. The system confirms "your email is john at example dot com" and the user does not respond. This happens in voice systems when users are multitasking, the audio is poor, or the user is simply not paying attention. The system must decide how long to wait before timing out. A typical timeout is five seconds. After five seconds of silence, the system prompts again. "I didn't catch that — is john at example dot com the right email?" If the user still does not respond, the system escalates. "I need to confirm your email before we continue — is john at example dot com correct?"

When confirmation fails three times — either due to repeated corrections, ambiguous responses, or non-responses — the system escalates to a different confirmation strategy. Instead of confirming verbally, the system asks the user to spell the value character by character. "Let's make sure I have your email right — can you spell it out for me?" Character-by-character entry is slow but eliminates ambiguity. ASR errors on individual characters are easier to detect and correct than errors on full addresses.

Another escalation strategy is visual confirmation for multi-modal systems. The system displays the extracted value on screen and asks the user to confirm by tapping or saying yes. Seeing the value in text removes ASR uncertainty. The user can visually verify correctness instead of relying on memory of what they said versus what the system repeated. Visual confirmation is not possible in audio-only systems, but when screens are available, it is faster and more reliable than verbal confirmation.

## The Confirmation Fatigue Problem

Confirmation-before-commit is safe, but if overused, it destroys conversation flow. A voice system that confirms every extracted field feels robotic and slow. The user provides their name. The system confirms. The user provides their email. The system confirms. The user provides their phone number. The system confirms. By the fifth confirmation, the user is frustrated and starts saying "yes" without listening just to move the conversation forward. Confirmation fatigue undermines the safety benefit because users stop validating.

The solution is selective confirmation. Only high-stakes fields require confirmation. Low-stakes fields commit immediately. The system maintains a confirmation policy that maps each state field to one of three strategies: always confirm, confirm if confidence is low, never confirm. Medication dosage is always-confirm. Preferred appointment time is confirm-if-low-confidence. Preferred name pronunciation is never-confirm.

The confidence threshold for conditional confirmation is tuned based on extraction accuracy. If the model extracts an email address with 98 percent confidence, skip confirmation. If confidence is 75 percent, confirm. The confidence score comes from the model's output probabilities or from a secondary validation model that scores extraction quality. Low confidence indicates ambiguity or potential error. High confidence indicates the extraction is likely correct.

Implicit confirmation is an alternative to explicit confirmation for medium-stakes fields. Instead of asking "is that correct?" the system uses the extracted value in the next response and gives the user an opportunity to correct it naturally. The user says "my email is john at example dot com." The system responds "great, I'll send the confirmation to john at example dot com — now, what time works for you?" The user hears the email repeated. If it is wrong, they correct it. If it is right, they move on. This confirmation is embedded in conversational flow rather than being a separate validation step.

Implicit confirmation only works if the extracted value is repeated clearly. If the system says "got it" without repeating the value, the user has no opportunity to catch errors. The value must be surfaced in a way that allows the user to validate without being explicitly asked. "I'll email you at that address" does not work because the user does not hear what "that address" is. "I'll email you at john at example dot com" works because the user hears the full address.

## Balancing Confirmation with Conversation Flow

The goal is not to confirm everything. The goal is to confirm enough that high-stakes errors are caught without making the conversation unbearable. This requires prioritization. Rank state fields by stakes. The top 10 to 20 percent of fields get explicit confirmation. The next 20 to 30 percent get implicit confirmation or confidence-based confirmation. The remaining 50 to 70 percent commit immediately.

The ranking is domain-specific. In a prescription refill system, dosage, medication name, and patient ID are top-tier. Pharmacy location and contact preference are mid-tier. Preferred language and time of day for follow-up calls are low-tier. In a financial transfer system, account number, transfer amount, and recipient are top-tier. Transfer description and notification preference are mid-tier. Preferred currency display format is low-tier.

The confirmation budget is the total number of explicit confirmation requests tolerated per conversation. User research from multiple production voice systems in 2026 shows that users tolerate two to four explicit confirmations in a fifteen-turn conversation without noticeable frustration. Beyond four, satisfaction scores drop. The budget forces prioritization. If the conversation needs to extract ten fields and only four can be confirmed, confirm the four highest-stakes fields and commit the rest immediately or use implicit confirmation.

Confirmation can be batched to reduce perceived frequency. Instead of confirming three fields in three separate turns, confirm all three in one turn. "Just to confirm: your medication is lisinopril, the dosage is fifty milligrams, and your pharmacy is on Main Street — is that all correct?" This counts as one confirmation event in the user's mental model, even though it is validating three fields. Batching reduces confirmation fatigue while maintaining safety.

## Pending State Architecture

Confirmation-before-commit requires a two-tier state architecture. Pending state holds extracted information that has not been confirmed. Committed state holds confirmed information that is used for business logic. Extraction writes to pending state. Confirmation promotes pending state to committed state. Business logic reads only from committed state.

The separation ensures that unconfirmed data never affects production decisions. If the system extracts an email address but has not confirmed it yet, the email is in pending state. If the next turn requires sending a code to the user's email, the system either confirms the pending email first or refuses to proceed. "I need to confirm your email before I can send the code — is john at example dot com correct?" The user confirms, the email is promoted to committed state, and the code is sent.

Pending state has a timeout. If information is extracted but not confirmed within five turns, the system prompts the user to confirm. If still not confirmed after three prompts, the pending value is discarded. This prevents pending state from accumulating indefinitely. A conversation that extracts twenty fields but only confirms ten would have ten orphaned pending values. The timeout clears them.

The pending-to-committed promotion is atomic. When the user confirms a batch of fields, either all fields are promoted or none are. If the user says "no, that's not right" to a batch confirmation, all fields remain in pending state and the system asks which specific field is wrong. Partial promotion is not allowed because it creates inconsistency. The user corrected something, but the system does not know which field, so none can be trusted.

Rollback on correction is another architectural requirement. If the user confirms an email in turn five, it is promoted to committed state. In turn twelve, the user says "actually, my email is different." The system must roll back the committed email to pending state, extract the new value into pending state, and confirm again. Committed state is not immutable — user corrections can demote values back to pending.

## Measuring Confirmation Effectiveness

Confirmation effectiveness is measured by comparing error rates with and without confirmation. The baseline is immediate-commit: every extraction is committed without confirmation. The error rate is the percentage of committed values that the user later corrects. If 3 percent of extracted emails are corrected by users in later turns, the immediate-commit error rate is 3 percent. The confirmation-enabled system confirms before committing. The error rate is the percentage of confirmed values that the user later corrects. If 0.5 percent of confirmed emails are later corrected, the confirmation error rate is 0.5 percent.

The error reduction is 3 percent minus 0.5 percent equals 2.5 percentage points. Confirmation catches 83 percent of extraction errors before they are committed. The cost is the confirmation overhead: the number of additional conversational turns required for confirmation. If the average conversation has three confirmations and each confirmation adds one turn, the cost is three turns. The trade-off is whether three extra turns are worth an 83 percent reduction in committed errors.

The answer depends on error consequences. In a system where errors cause financial loss, security breaches, or safety risks, an 83 percent reduction is worth ten extra turns. In a system where errors are low-stakes and easily corrected later, an 83 percent reduction is not worth three extra turns. The confirmation strategy is tuned to domain stakes.

User frustration is measured by tracking abandonment rates. If confirmation fatigue causes users to hang up mid-conversation, the confirmation strategy is too aggressive. Abandonment rate is compared across cohorts: users who experienced zero confirmations, users who experienced one to two confirmations, users who experienced three to four confirmations, and users who experienced five or more confirmations. If abandonment spikes at five confirmations, the confirmation budget is set to four.

Correction-after-confirmation rate is the percentage of confirmed values that the user later corrects. This should be near zero. If users frequently confirm a value and then correct it later, the confirmation phrasing is ineffective. Users are saying "yes" without actually validating. The phrasing needs to be more explicit or the value needs to be repeated more clearly.

Confirmation-before-commit is the safest state management pattern for high-stakes fields. It prevents extraction errors from propagating to business logic. It gives users a veto window before irreversible actions. It creates an audit trail showing that users explicitly validated critical information. The cost is conversational overhead, but for fields where errors cause harm, the cost is justified. The next subchapter covers cross-channel state synchronization — what happens when users interact with your system through multiple channels simultaneously.
