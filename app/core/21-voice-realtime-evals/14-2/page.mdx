# 14.2 — Slot Corruption: When Entity Extraction Goes Wrong

A wrong slot value is not just one bad turn. It is the foundation every subsequent turn builds on.

A retail customer called a pharmacy voice system in mid-2025 to refill a prescription. The system asked for the prescription number. The customer read it aloud: "RX seven three two nine four B." The ASR heard "RX seven three two nine four D." The system extracted the slot, stored it, and proceeded to ask for the customer's date of birth for verification. The customer provided it. The system asked if they wanted the same dosage as last time. The customer said yes. The system asked for their preferred pickup location. The customer chose the downtown branch. The system confirmed the order and said it would be ready in two hours.

When the customer arrived at the pharmacy, the prescription was not ready. The pharmacist looked up RX seven three two nine four D. No such prescription existed in the system. The pharmacist asked for the prescription bottle. The customer showed it. The correct number was RX seven three two nine four B. The error occurred in the first turn. The customer spent four minutes providing information. The pharmacy spent staff time processing the conversation. The customer left without their medication. The slot corruption — a single-character ASR error — invalidated the entire transaction.

This is slot corruption. Slots are the structured data extracted from user utterances and stored as session state. In a prescription refill, the critical slots are prescription number, patient name, and date of birth. In a travel booking, the critical slots are origin, destination, departure date, return date. In a technical support call, the critical slots are account number, device model, error code. Slots are the skeleton of the conversation. When a slot is corrupted — extracted incorrectly, stored incorrectly, or retrieved incorrectly — the entire conversation structure collapses.

## How Slots Get Corrupted

Slots corrupt through three primary mechanisms. The first is **ASR transcription error**. The ASR system hears the user's speech and produces a text transcription. If the transcription contains an error in a portion of the utterance that corresponds to an entity, the entity is corrupted at the source. Certain entity types are especially vulnerable. Alphanumeric strings — confirmation codes, license plates, prescription numbers — contain characters that sound similar. The letter B sounds like D. The letter M sounds like N. The number fifteen sounds like fifty.

Proper nouns are another high-risk category. City names, street names, medication names, product names — these are often outside the ASR model's training distribution. The ASR may never have encountered the street name "Tchoupitoulas" or the medication name "Atorvastatin." It transcribes phonetically plausible but incorrect alternatives. "Atorvastatin" becomes "a tour of statin." "Tchoupitoulas" becomes "chop it to us." The LLM attempts to extract a street name from "chop it to us." It either fails entirely or hallucinates a plausible but wrong street name.

Numbers are the most fragile entity type in voice. The difference between "fifteen hundred" and "fifty hundred" is one phoneme. The difference between "twenty fifteen" and "twenty fifty" is one phoneme. The difference between "one point five" and "one point fifteen" is hard to hear in noisy environments or with certain accents. If the slot is a dollar amount, a date, a quantity, or a measurement, a single-phoneme ASR error can change the meaning by orders of magnitude. "I want to transfer fifteen hundred dollars" becomes "I want to transfer fifty hundred dollars." The system initiates a five-thousand-dollar transfer. The user reviews their account later and panics.

The second corruption mechanism is **entity extraction error**. Even if the ASR transcription is perfect, the LLM must identify which portions of the transcription correspond to which slots. If the user says "I need to fly from Boston on the fifteenth to San Francisco and return on the twenty-second," the LLM must extract four entities: origin equals Boston, destination equals San Francisco, departure date equals the fifteenth, return date equals the twenty-second. Extraction errors occur when the LLM misparses the sentence structure, misidentifies entity boundaries, or assigns entities to the wrong slots.

Extraction errors are common when entity mentions are ambiguous or when multiple entities of the same type appear in one utterance. "I want to go from New York to New York on New Year's." Two of those instances of "New York" refer to a city. One refers to a state. One is part of a holiday name. The LLM must disambiguate. If it extracts "New York to New York" as origin and destination, it has created a malformed route. If the user says "change my flight from Tuesday to Thursday," the LLM must identify which existing slot value represents Tuesday and update it to Thursday. If the session state contains both a departure date and a return date, and both are currently weekdays, the LLM must infer from context which one the user is referring to. If it infers incorrectly, the wrong slot is updated.

The third corruption mechanism is **confirmation bypass and false acceptance**. Many voice systems implement confirmation steps for critical slots. After the user provides a high-stakes entity — a credit card number, a shipping address, a prescription name — the system repeats it back and asks for confirmation. "You said your card number is four one two three four five six seven eight nine zero one two three four. Is that correct?" The user is supposed to verify. If correct, they say yes. If incorrect, they say no and provide the correct value.

Confirmation bypass happens when the user says yes without actually verifying. The user is distracted, in a hurry, or conditioned by other interfaces to say yes reflexively. The system asked a question. The expected response is yes. The user says yes. The system accepts the corrupted value as confirmed. This is especially common for long alphanumeric strings. The user cannot hold sixteen digits in working memory while listening to the system read them back. They say yes based on the assumption that the system probably got it right, or they do not want to slow the conversation down by asking for a repeat. The confirmation step, designed to catch corruption, instead legitimizes it.

False acceptance happens when the ASR misrecognizes the user's confirmation response. The user says "no, that is wrong." The ASR hears "no that is right" or interprets the phrase as affirmative based on prosody. The system proceeds as if the user confirmed. The user realizes the error only when they see the downstream consequence — the incorrect charge on their credit card statement, the package delivered to the wrong address, the wrong medication dispensed.

## Detecting Slot Corruption

Slot corruption often goes undetected until it causes a visible failure. The system attempts to validate the slot value against a database. The query returns no results. The transaction fails. The user complains. By then, the corruption has propagated through multiple turns, and recovery is expensive. The alternative is to detect corruption proactively, before the failure occurs.

The first detection method is **confidence thresholding at extraction**. Every ASR transcription and every LLM entity extraction has an associated confidence score. ASR confidence reflects the acoustic model's certainty about the transcription. LLM confidence reflects the language model's certainty about the extracted entity. If either confidence is below a threshold, treat the extraction as uncertain and prompt for confirmation. For high-stakes slots — payment information, medical information, legal agreements — use a high threshold, ninety percent or ninety-five percent. For low-stakes slots — user preferences, optional fields — use a lower threshold, seventy-five percent or eighty percent.

Confidence thresholding reduces false accepts but increases false rejects. If the threshold is too high, the system will reject correct extractions and annoy users by asking for confirmation unnecessarily. If the threshold is too low, the system will accept incorrect extractions and accumulate corrupted state. The optimal threshold depends on the cost asymmetry. If a false accept costs more than a false reject — as with financial transactions — bias toward high thresholds. If a false reject costs more than a false accept — as with optional preference settings — bias toward low thresholds.

The second detection method is **semantic validation**. Even if confidence is high, validate that the extracted value makes sense in context. If the slot is a date, check that it is not in the past when a future date is required, not more than a year in the future for near-term bookings, and not on an impossible date like February thirtieth. If the slot is a quantity, check that it is within reasonable bounds. An order for fifty thousand units of a consumer product is almost certainly an error. A phone number with fifteen digits is malformed. A ZIP code that does not exist in the postal database is corrupted.

Semantic validation requires domain-specific rules. Build a validation function for each slot type. The function takes the extracted value and returns a boolean indicating whether the value is plausible. If implausible, reject the value and prompt for re-entry. If plausible but unusual, prompt for confirmation. "You said you want to book fifty seats. That is a large group. Is that correct?" The user either confirms or corrects. Semantic validation catches errors that confidence scores miss — cases where the ASR transcription and LLM extraction are both high-confidence but the result is nonsensical.

The third detection method is **cross-slot consistency checking**. Some slots have logical dependencies. If the user is booking a round-trip flight, the return date must be after the departure date. If the user is scheduling a medical appointment, the appointment date must be a date when the clinic is open. If the user is ordering a product for delivery, the delivery address must be within the service area. After extracting multiple related slots, validate their consistency. If inconsistent, identify which slot is most likely corrupted — usually the most recently extracted one — and prompt for re-verification.

Consistency checking also applies to temporal patterns. If the user provided their date of birth earlier in the conversation and now provides an age that is inconsistent with that date of birth, one of the two values is corrupted. Prompt the user to resolve the inconsistency. "Earlier you said your date of birth is March fifth, nineteen eighty-five, which would make you forty years old, but you just said you are thirty-five. Can you confirm your age?" The user clarifies. The system updates the corrupted slot.

The fourth detection method is **anomaly detection from historical patterns**. If you have historical data on slot values for a particular conversation type, you can detect outliers. If ninety-five percent of prescription refill calls involve prescription numbers that start with RX and are followed by six digits, and the current call extracted a prescription number that starts with TX and has eight digits, that is an anomaly. Flag it for confirmation. If ninety percent of flight bookings involve departure dates within the next thirty days, and the current booking extracted a departure date eighteen months in the future, that is an anomaly. Confirm it.

Anomaly detection requires enough historical data to establish baselines. It works well for high-volume conversation types — customer service, appointment scheduling, order placement. It works poorly for novel or rare conversation types where there is no historical distribution to compare against. Use anomaly detection as a supplementary signal, not the sole detection method.

## Preventing Slot Corruption

Detection is reactive. Prevention is better. The first prevention strategy is **clarification requests for ambiguous entities**. If the user says "I want to fly to Portland," there are two cities named Portland in the United States — Portland, Oregon and Portland, Maine. The system should not guess. It should ask: "Did you mean Portland, Oregon or Portland, Maine?" The user clarifies. The correct city is stored. No corruption occurs.

Clarification applies to any entity type with known ambiguities. If the user says a street name that exists in multiple cities, ask which city. If the user says a product name that matches multiple SKUs, ask which variant. If the user says a date like "the fifteenth" without specifying a month, ask which month. Clarification adds a turn, but it eliminates ambiguity. Ambiguity is a source of corruption. Eliminating it eliminates the risk.

The second prevention strategy is **structured elicitation for high-risk slots**. Instead of asking the user to provide a complex entity in free-form speech, break it into smaller, easier-to-recognize pieces. Instead of "What is your credit card number?" ask "What is the first four digits of your card?" Then "What is the next four?" Then "What is the next four?" Then "What is the last four?" Four-digit sequences are easier for ASR to transcribe accurately than sixteen-digit sequences. The user can focus on pronouncing each segment clearly. The system can apply higher confidence thresholds to each segment.

Structured elicitation works for addresses, phone numbers, confirmation codes, and any entity that can be decomposed into smaller parts. The trade-off is conversation length. Breaking a sixteen-digit card number into four prompts takes longer than asking for it all at once. But the accuracy gain often justifies the extra turns. For high-stakes transactions, accuracy matters more than speed.

The third prevention strategy is **read-back confirmation for critical slots**. After extracting a high-stakes slot, immediately read it back to the user and ask for explicit confirmation. Use exact wording. Do not paraphrase. If the user said "four one two three four five six seven eight nine zero one two three four," read back "four one two three four five six seven eight nine zero one two three four" exactly as you heard it. The user can compare the read-back to what they intended. If it matches, they confirm. If it does not match, they correct.

Read-back confirmation is most effective when the user can easily detect errors. For short entities — a single word, a two-digit number, a simple address — read-back works well. For long alphanumeric strings, read-back is less effective because the user cannot hold the entire string in memory. For those cases, combine read-back with segmented elicitation. Read back each segment immediately after the user provides it. "You said the first four digits are four one two three. Correct?" The user confirms or corrects while the segment is still fresh in memory.

The fourth prevention strategy is **fallback to alternative input modalities**. If a slot cannot be extracted reliably through voice, offer an alternative. "I am having trouble hearing the prescription number. You can say it again, or if you prefer, I can send you a text message and you can type it in." The user chooses the text option. The system sends an SMS with a link. The user clicks the link, types the prescription number into a web form, and submits. The system retrieves the value and continues the voice conversation. The slot is populated accurately. No corruption occurred.

Modality fallback requires infrastructure. The system must have the user's phone number. The system must integrate with an SMS gateway and a web service. The user must have access to a device where they can receive and respond to the SMS. But when these conditions are met, modality fallback is the most reliable way to capture complex entities. Many pharmacy voice systems in 2026 use this approach for prescription numbers. Many banking voice systems use it for account numbers. The user speaks for conversational portions of the interaction and types for high-accuracy data entry.

## Recovering From Corrupted Slots

Even with prevention, corruption will occur. When it does, recovery must be fast and minimally disruptive. The first recovery strategy is **immediate re-prompt on low confidence**. If the system extracts a slot value but the confidence is below the threshold, do not accept the value. Prompt the user to repeat. "I did not catch that. Can you say your prescription number again?" The user repeats. The system attempts extraction again. If confidence is still low after two or three attempts, escalate to an alternative input method or a human agent.

Immediate re-prompt works only if the system detects the low confidence in real time. If the system accepts the value despite low confidence and discovers the error later, immediate re-prompt is no longer an option. The conversation has moved on. The user has provided other information. Re-prompting now will confuse the user. They will wonder why the system is asking for something they already provided. This confusion erodes trust.

The second recovery strategy is **targeted correction prompts when validation fails**. If the system attempts to validate a slot value and the validation fails, prompt the user to provide the correct value without asking them to repeat everything. "I could not find a prescription with that number. Can you double-check the number on your bottle and read it to me again?" The user looks at the bottle. They read the number carefully. The system extracts it again. This time, with the user's heightened attention, the accuracy improves.

Targeted correction works because it focuses the user's attention on the specific piece of information that is wrong. The user does not have to guess what went wrong. The system tells them. They can take corrective action. Contrast this with a generic error message like "Something went wrong. Let's start over." The user has no idea what went wrong. They are forced to repeat everything, including information that was captured correctly. Frustration increases. Task completion decreases.

The third recovery strategy is **partial rollback with confirmation of retained state**. If a slot is corrupted and must be re-collected, roll back only that slot, not the entire conversation. "I need to verify your prescription number again. I still have your name, date of birth, and preferred pickup location. Let me just confirm the prescription number." The user provides it. The system updates the slot. The conversation continues from where it left off. The user does not lose progress. They do not repeat information unnecessarily.

Partial rollback requires precise state management. The system must know which slots are valid and which are corrupted. It must present the retained state to the user for confirmation, so the user knows what the system remembers. If the system says "I still have your name and date of birth" but does not say what those values are, the user cannot verify that the system has them correctly. The system should say "I still have your name as John Smith and your date of birth as March fifth, nineteen eighty-five. Is that still correct?" The user confirms or corrects.

The fourth recovery strategy is **escalation to human agent with annotated state**. If the slot cannot be collected accurately after multiple attempts, transfer the user to a human agent. Provide the agent with the full session state, including all extracted slots and their confidence scores. Highlight the problematic slot. The agent can see that the system attempted to extract a prescription number three times, with confidence scores of seventy-two percent, sixty-eight percent, and seventy-five percent, and all three extractions were different values. The agent knows immediately that this is an ASR problem. They ask the user to spell the prescription number letter by letter. Problem solved.

Escalation to a human is not a failure. It is a controlled handoff. The failure is forcing the user to repeat information to the agent that they already provided to the system. The system must pass the conversation context and the accumulated state to the agent. The agent must be able to see the state in a readable format. Many voice systems in 2026 integrate with agent desktop software that displays the voice conversation transcript, the extracted slots, and the confidence scores in a dashboard. The agent can review the context in seconds and pick up where the voice system left off.

## Slot Validation as a Continuous Process

Slot validation is not a single checkpoint at the end of the conversation. It is a continuous process that occurs at every turn. After each entity extraction, validate the entity. After each slot update, validate the update. After multiple related slots are populated, validate their consistency. Before executing an action based on slot values, validate that the action is correct.

Continuous validation catches corruption early, before it propagates. A corrupted slot detected in turn three can be corrected in turn four. A corrupted slot detected in turn fifteen, after the user has provided twelve more pieces of information, requires rolling back or invalidating a significant portion of the conversation. The later the detection, the higher the recovery cost.

Continuous validation also provides feedback to the model. If the system consistently extracts low-confidence values for a particular slot type, that signals a training deficiency. The ASR model may need more training data for that accent or that vocabulary. The LLM may need fine-tuning on entity extraction for that domain. If the system consistently extracts values that fail semantic validation, that signals a logic error in the extraction prompt or the slot schema. These patterns are visible only through continuous monitoring and validation.

Slot corruption is not an edge case. It is a central challenge in voice system design. The systems that handle it well — through prevention, detection, and graceful recovery — deliver reliable experiences. The systems that ignore it accumulate silent errors until the conversation collapses. The difference is not whether corruption occurs. It always does. The difference is whether the system catches it before the user experiences the consequence.

---

*Next: 14.3 — The Correction Loop Anti-Pattern: Asking the Same Question Forever*
