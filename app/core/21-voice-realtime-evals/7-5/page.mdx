# 7.5 — Context Recovery After Barge-In: Resuming the Conversation

In early 2025, a healthcare voice assistant deployed across sixty primary care clinics allowed patients to interrupt at any time during appointment scheduling. The barge-in worked perfectly — audio stopped within 180 milliseconds, the system acknowledged the interruption, and the user spoke. But what happened next broke the experience. After the user interrupted to say "actually I need Tuesday not Wednesday," the system responded with "I can help you schedule an appointment. What day works for you?" It had forgotten the entire conversation. Patients repeated themselves three, four, five times per call. Abandonment rate hit 43%. The root cause was not the barge-in detection — that was excellent. The root cause was context recovery. The system had no mechanism to understand what was interrupted, what the user just said, and how to continue from there. It treated every barge-in as a full conversation reset.

Context recovery is the hardest technical problem in barge-in design. When a user interrupts, they are not starting over. They are continuing. They expect the system to remember what was being discussed, understand their correction or addition, and resume the conversation intelligently. A system that forgets everything the moment it is interrupted is functionally unusable for any task more complex than setting a timer.

## The Three-State Context Problem

When barge-in occurs, the system must track three simultaneous contexts. First, the **pre-interruption context** — everything that happened before the barge-in. This includes the full conversation history, the current task state, and what the agent was in the middle of saying when interrupted. Second, the **interruption utterance** — what the user just said that caused the barge-in. This is new information that must be integrated into the existing context. Third, the **post-interruption context** — the updated state after combining the previous context with the new information, which determines what the agent should say next.

Most systems handle the first and second states adequately. They log conversation history. They capture the user's interruption via speech-to-text. The failure happens in the third state — the synthesis. How do you combine a partial agent utterance, a user interruption, and the prior conversation into a coherent next response? If the agent was saying "your appointment is scheduled for Wednesday at three p.m." and the user interrupted after "Wednesday" to say "actually make it Thursday," the post-interruption context must reflect that the appointment day changed from Wednesday to Thursday, the time is still three p.m., and the next response should confirm the updated appointment without re-asking for information the user already provided.

The three-state problem is compounded by the fact that the pre-interruption context includes an incomplete utterance. The agent did not finish speaking. You do not know what it was about to say. Maybe it was about to ask for confirmation. Maybe it was about to offer an alternative. The partial utterance contains intent that was never delivered. You must decide whether that intent still matters or whether the user's interruption renders it irrelevant.

## Partial Utterance Completion vs Abandonment

When the agent is interrupted mid-sentence, you face a decision: complete the thought or abandon it. **Completion** means the system internally finishes the agent's intended utterance, integrates that completed thought into context, then responds to the user's interruption with full knowledge of what it was trying to say. **Abandonment** means the system discards the partial utterance entirely, treats the interruption as the new starting point, and generates the next response based only on pre-interruption history plus the user's new input.

Neither approach is universally correct. Completion is necessary when the partial utterance contains information the user has not yet received. If the agent was saying "your flight departs from terminal C, gate fourteen," and the user interrupted after "terminal," the system must remember that gate fourteen was part of the intended message. If the user asked "which gate?" the answer should be gate fourteen, not a confused "let me check" response. Completion ensures that information already generated but not yet spoken is not lost.

Abandonment is correct when the user's interruption invalidates the agent's in-progress statement. If the agent was saying "would you like to upgrade to business class for four hundred ninety-five dollars," and the user interrupted after "business class" to say "no thanks, just economy," completing the price utterance is pointless. The user has already rejected the offer. The system should abandon the partial utterance and move to the next relevant step, which is confirming the economy booking.

The decision rule is straightforward: if the partial utterance contains **information** the user needs, complete it. If the partial utterance contains a **question** or **offer** the user has already answered or rejected via their interruption, abandon it. The complexity is that this determination must happen in real time, within the 300-millisecond window between barge-in detection and the agent's next response. You cannot ask a human to decide. The system must infer intent from partial text.

## Context Corruption During STT Integration

Speech-to-text transcription of the interruption utterance introduces its own context risk. STT is not instant. Depending on your pipeline, transcription may take 150 to 400 milliseconds after the user stops speaking. During that window, the system is in limbo. It knows barge-in occurred. It does not yet know what the user said. If you wait for STT to complete before generating the next response, you add latency. If you generate a response before STT completes, you risk responding to the wrong thing.

A European banking voice assistant in mid-2025 optimized for speed by generating responses the moment barge-in was detected, using a predicted transcription based on acoustic features before the final STT result arrived. This reduced response latency by 220 milliseconds. It also caused the system to respond to the wrong utterance 11% of the time. A user would say "I need to transfer funds," the system would predict "I need to check my balance" based on early acoustic cues, and respond with balance information before the correct transcription arrived. By the time the correct STT result was available, the agent had already committed to the wrong response path. The user would then interrupt again to correct the system, creating a correction loop.

The alternative — waiting for full STT before responding — is correct but slow. The user experiences a pause between finishing their interruption and hearing the agent's response. If that pause exceeds 500 milliseconds, it feels like the system is confused or processing. The solution most production systems converge on is **partial STT streaming with confidence gating**. The STT system streams partial results as the user speaks. If the partial transcription reaches high confidence (typically above 0.90) and the user pauses for more than 400 milliseconds, the system treats the partial result as final and generates a response. If confidence is low or the user is still speaking, it waits for the complete transcription. This hybrid approach cuts latency without introducing high error rates, but it requires STT systems that support streaming partial results with per-word confidence scores — not all do.

## Resume vs Restart: The Continuity Decision

After barge-in, the system must decide whether to **resume** the conversation from where it was interrupted or **restart** the current task from the beginning. Resume means the agent picks up the thread of the prior conversation, acknowledging what was already discussed and continuing forward. Restart means the agent treats the interruption as a signal that the prior path was wrong and begins the task again from the top.

Resume is correct when the user's interruption is a correction, clarification, or addition. If the agent was collecting information for a restaurant reservation — date, time, party size — and the user interrupted to say "actually make it six people not four," the system should update party size to six and continue with the next required field (dietary restrictions, seating preference, etc.). It should not restart by re-asking for the date. The user already provided the date. Restarting wastes their time and signals that the system did not understand the correction.

Restart is correct when the user's interruption indicates they want to change the task entirely. If the agent was booking a restaurant reservation and the user interrupted to say "cancel that, I want to order delivery instead," resuming the reservation flow is wrong. The user has pivoted to a different task. The system should abandon the reservation context and start the delivery flow from the beginning.

The challenge is distinguishing corrections from pivots in real time. Linguistic cues help. Interruptions that begin with "actually," "wait," "no," or "I meant" are usually corrections. Interruptions that begin with "cancel," "forget that," "never mind," or "instead" are usually pivots. But users do not always follow these patterns. A user might say "make it Thursday" without any preamble, and the system must infer from context whether "Thursday" is a correction to an existing appointment day or a pivot to scheduling a different appointment.

The most reliable signal is **intent overlap**. If the user's interruption shares the same intent as the current task, it is likely a correction. If it introduces a new intent, it is likely a pivot. A fintech voice assistant in late 2025 used intent classification on every interruption utterance. If the classified intent matched the active task intent (both are "schedule_payment"), the system resumed. If the intents diverged (active task is "schedule_payment," interruption is "check_balance"), the system restarted with the new intent. This reduced incorrect resumptions by 68% compared to heuristic-based rules.

## Handling Multi-Turn Context Across Interruptions

Barge-in does not happen in isolation. A single conversation may contain three, five, ten interruptions. Each one adds complexity to the context graph. If the user interrupted the agent three times during a single task, the context must correctly track the state after each interruption and integrate all corrections without losing information.

A logistics voice assistant used by delivery drivers allowed them to interrupt to update delivery status, report delays, or ask questions mid-route. A typical interaction looked like this: Agent begins describing the next stop. Driver interrupts to report traffic delay. Agent acknowledges delay and updates ETA. Agent resumes route description. Driver interrupts to ask for customer phone number. Agent provides phone number. Agent resumes route description. Driver interrupts to confirm delivery completion. Each interruption required context recovery without losing the thread of the route guidance.

The system tracked context using a **task state machine** with interruption checkpoints. Every time barge-in occurred, the system saved the current state (which step in the route guidance, which fields had been provided, which questions had been asked), processed the interruption as a sub-task, then restored the saved state and resumed. This worked well for single-level interruptions but broke when interruptions nested. If the driver interrupted the agent's answer to their interruption, the context stack became corrupted. The system would resume at the wrong checkpoint, repeat information, or lose track of which delivery stop was active.

The solution was a **context stack** rather than a single checkpoint. Each interruption pushed a new context frame onto the stack. When the interruption was resolved, the system popped the frame and resumed the previous context. This allowed interruptions to nest arbitrarily deep without losing state. The driver could interrupt the agent's response to their previous interruption, then return cleanly to the original route guidance when finished. The stack structure mirrored how human conversations handle nested digressions — you pause the main topic, handle the digression, then return to the main topic exactly where you left off.

## Evaluating Context Recovery Quality

You measure context recovery by comparing the agent's post-interruption response to the correct response given full context. The metric is **context preservation rate** — the percentage of barge-in events where the agent's next response correctly incorporates all prior context plus the interruption utterance. A response is correct if it continues the task without requesting information the user already provided, acknowledges the user's correction, and does not contradict any previously established facts.

A travel booking voice assistant in January 2026 tracked context preservation rate across 18,000 barge-in events. Initial rate was 71%. The system was losing context in 29% of interruptions. The failures broke down as follows: 14% were restarts when the system should have resumed, 9% were lost slot values (the user had provided a date earlier, the system re-asked for it after barge-in), 4% were contradictions (the user said "economy class," the agent later referenced business class), and 2% were complete context loss (the system responded as if the conversation had just started).

The team fixed the restart failures by implementing intent overlap detection. They fixed the lost slot values by explicitly preserving all filled slots across barge-in events, even when the task state was reset. They fixed the contradictions by running a consistency check on the generated response before speaking it — if the response referenced a slot value that contradicted a value provided earlier in the conversation, the system flagged it and regenerated. These changes brought context preservation rate to 94%. The remaining 6% were cases where the user's interruption was genuinely ambiguous and the system's interpretation was defensible even if not optimal.

Context recovery is not binary. Some failures are catastrophic — the system forgets the entire conversation. Some are minor — the system repeats a single piece of information. Evaluators should classify failures by severity. Catastrophic failures (complete context loss, task restarts when the user wanted to resume) receive a severity score of 1.0. Major failures (lost slot values, contradictions) receive 0.6. Minor failures (redundant confirmations, slightly awkward phrasing) receive 0.2. The **weighted context preservation rate** multiplies each failure by its severity, giving a more nuanced view of context quality than a binary pass-fail metric.

## The Confirmation Loop After Barge-In

After recovering context, the agent faces a choice: confirm the updated state or proceed immediately. Confirmation adds latency and feels redundant if the user's interruption was unambiguous. Proceeding without confirmation risks acting on a misunderstood correction. The decision depends on the **confidence of the integrated context** and the **cost of error** if the interpretation is wrong.

If the user interrupted to say "change the date to March fifth" and the system has high confidence that the date slot should now be March fifth, explicit confirmation is optional. The agent can proceed with "got it, March fifth" as a lightweight acknowledgment and continue to the next field. If the user interrupted with a partial sentence, an ambiguous pronoun, or a complex multi-slot correction ("move it to next week and add another person"), confidence is lower and explicit confirmation is necessary. The agent should restate the understood changes: "so that's Tuesday March twelfth for three people, is that right?"

Cost of error is the other variable. For low-stakes tasks like setting a timer or playing music, proceeding without confirmation is fine. If the system misunderstood, the user will interrupt again to correct. For high-stakes tasks like financial transactions, medical appointments, or legal agreements, explicit confirmation is mandatory. The user must verbally confirm the updated state before the system acts on it. A system that transfers the wrong amount of money because it misunderstood a barge-in correction is not just bad UX — it is a liability event.

The best systems use **adaptive confirmation**. After integrating the user's interruption, the system calculates a confidence score based on STT confidence, intent classification confidence, and slot extraction confidence. If the combined confidence exceeds 0.92 and the task is low-stakes, the system proceeds with a lightweight acknowledgment. If confidence is below 0.92 or the task is high-stakes, the system confirms explicitly. This balances speed and safety without forcing a one-size-fits-all confirmation policy.

## When Context Cannot Be Recovered

Some barge-ins are unrecoverable. The user interrupted in the middle of a complex multi-step explanation, said something completely unrelated, and expects the system to continue. Or the STT transcription is so garbled that the system cannot extract meaning. Or the user interrupted to reject the entire task but did not specify what they want instead. In these cases, context recovery fails not because the system is broken but because the information needed to recover is not present.

When recovery fails, the system must fail gracefully. The worst response is to pretend everything is fine and generate a nonsense reply. The second-worst response is to restart the task from the beginning without telling the user. The correct response is to **acknowledge the gap** and ask for clarification. "I did not quite catch that, can you say it again?" or "I want to make sure I have this right — you want to change the appointment, correct?" The user expects the system to be robust, not omniscient. Admitting uncertainty and asking for help is far better than guessing wrong and forcing the user to interrupt again to correct the error.

A customer service voice assistant deployed in late 2025 implemented a **recovery confidence threshold**. After every barge-in, the system calculated how confident it was in the integrated context. If confidence exceeded 0.85, it proceeded. If confidence was between 0.60 and 0.85, it confirmed explicitly. If confidence was below 0.60, it admitted uncertainty and asked the user to repeat or clarify. This tiered approach reduced user frustration during ambiguous interruptions by 54% compared to a system that always guessed.

The key insight is that users tolerate clarification requests far more than they tolerate wrong assumptions. A system that asks "sorry, which date did you want?" after a barge-in is mildly annoying. A system that confidently books the wrong date because it guessed is infuriating. When in doubt, ask. When confident, proceed. The threshold between the two is the most important calibration point in your context recovery strategy.

Context recovery separates functional barge-in from broken barge-in. Detection is table stakes. Recovery is the differentiator. A system that stops talking when interrupted but then forgets everything is worse than a system that does not support barge-in at all — at least the latter does not create the illusion of working. Get recovery right and barge-in becomes one of the most powerful UX features in voice interfaces. Get it wrong and users will mute the microphone and switch to screen-based input.

Next: turn-taking accuracy — how to speak and listen in rhythm without talking over the user or leaving awkward silences.

