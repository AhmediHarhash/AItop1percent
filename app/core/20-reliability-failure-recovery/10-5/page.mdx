# 10.5 — Error Budgets for AI: When Degradation Is Acceptable

The traditional approach to reliability says: maximize uptime, minimize errors, get as close to perfect as possible. This mindset creates a perverse incentive. Engineering becomes conservative. Deployments slow down. Innovation stops. Teams optimize for zero risk instead of optimal value.

Error budgets flip the conversation. Instead of asking "how can we avoid failure," you ask "how much failure can we tolerate while still meeting our commitments?" The budget gives you explicit permission to fail — as long as you stay within bounds.

This is not lowering standards. It is recognizing reality. Every AI system will fail. Models will hallucinate. Latency will spike. Providers will have outages. The question is not whether you fail, but whether you fail within acceptable limits. Error budgets make those limits explicit and measurable.

## The Error Budget Concept

An error budget is the inverse of your SLO. If your SLO is 99 percent quality, your error budget is 1 percent. That 1 percent is how much you are allowed to fail. It is a currency you can spend on velocity, experimentation, and risk-taking.

The budget resets monthly or quarterly, depending on your SLO window. At the start of each period, you have a full budget. Every failure — quality drop, latency spike, downtime — consumes budget. When the budget is exhausted, you stop taking risks. You freeze deployments, fix issues, and restore headroom.

The beauty of error budgets is that they create alignment. Product wants velocity. Engineering wants reliability. The error budget gives both sides what they want within defined boundaries. Product can push for fast releases as long as the budget allows it. Engineering can slow down when the budget is depleted without needing to argue about abstract reliability concerns.

A logistics AI company set a 97 percent accuracy SLO, giving them a 3 percent error budget. In months where their actual accuracy was 98 percent, they had consumed only 2 percent of their budget, leaving 1 percent unspent. That unspent budget signaled they could move faster — deploy more aggressively, test less conservatively, take calculated risks. In months where accuracy dropped to 95 percent, they had overspent their budget by 2 percent. That triggered a deployment freeze and a focus on stability. The budget made the trade-off explicit and removed subjective debate.

## Calculating Error Budgets for AI Systems

Your error budget derives directly from your SLO. If your SLO is 95 percent of responses meet quality criteria, your error budget is 5 percent. If you serve 1 million requests per month, you can tolerate 50,000 failures.

Break the budget down by failure type. Your 5 percent might split into 2 percent for quality failures, 1.5 percent for latency failures, 1 percent for availability failures, and 0.5 percent for refusals. Each failure type has its own sub-budget. This prevents one failure mode from consuming the entire budget.

Track consumption in real time. Your monitoring system counts every failure — wrong answers, slow responses, timeouts, refusals — and categorizes them. At any moment, you know how much budget remains. Dashboards show budget consumption as a percentage and as absolute request counts. Engineering sees both "you have 1.2 percent budget remaining" and "you can tolerate 12,000 more failures this month."

Forecast end-of-period state. Based on current consumption rate, will you finish the period within budget? If you are consuming 0.3 percent per day and have 20 days remaining, you will consume 6 percent total. Your budget is 5 percent. You are on track to overspend by 1 percent unless something changes.

## Quality-Based Error Budgets

Traditional error budgets measure availability and latency. AI error budgets must also measure quality. A model can be fast and available but wrong. Quality degradation consumes budget just like downtime.

Define what counts as a quality failure. For a classification task, any prediction below 90 percent confidence might count as a failure. For a summarization task, any summary flagged by your automated eval as factually inconsistent counts. For a customer service chatbot, any response that triggers a human escalation counts.

Track quality budget separately from availability budget. If your quality SLO is 95 percent and your availability SLO is 99.9 percent, you have two budgets: a 5 percent quality budget and a 0.1 percent availability budget. Quality failures consume one budget. Downtime consumes the other.

Quality budgets are harder to measure than availability budgets because quality is subjective. You need automated eval systems running continuously. Every response gets evaluated. Scores aggregate into hourly, daily, and monthly quality percentages. When quality drops below your SLO threshold, budget is consumed.

A legal research AI set a quality SLO of 92 percent for citation accuracy. Their error budget was 8 percent. They ran automated citation validators on every response. In a typical month, 94 percent of citations were accurate, consuming 6 percent of their budget and leaving 2 percent unspent. In one month, accuracy dropped to 89 percent, overspending the budget by 3 percent. The overspend triggered an investigation that uncovered a data pipeline bug introducing outdated case law. The quality error budget caught the issue before customers complained.

## Error Budget Policies

An error budget is useless without policies that dictate what happens when it is depleted. The policies define the consequences of overspending and the actions required to restore budget.

A typical policy has three states: green, yellow, red. Green means budget consumption is under 50 percent. Normal deployment velocity continues. Yellow means consumption is between 50 and 100 percent. Deployments require additional review and testing. Red means the budget is exhausted. All non-critical deployments freeze until budget is restored.

Define the freeze criteria precisely. Red state means no new features, no model updates, no risky changes. Only critical bug fixes and security patches deploy. This is not negotiable. Product does not get to argue that their feature is important enough to justify an exception. The budget is the authority.

Define the restoration criteria. How does the system exit red state? Option one: wait for the budget to reset at the start of the next period. Option two: implement fixes that reduce failure rates, then measure improved reliability for a defined period to confirm the budget will not be re-exhausted. Most teams use option two for major incidents and option one for minor overages.

Include escalation paths. If the budget is exhausted and business pressure demands a critical deployment, who has authority to override the freeze? Typically a VP-level decision, not a team lead. The escalation path ensures that overrides are rare and considered, not routine.

A healthcare AI company policy: green state allows weekly model deployments, yellow state requires VP approval for deployments, red state freezes all deployments except security fixes. In 18 months, they entered red state twice — once due to a model regression, once due to a provider outage. Both times, the freeze held. Engineering fixed the issues. Budget was restored. The freeze policy prevented panic-driven decisions that would have made things worse.

## When Error Budget Is Exhausted

Budget exhaustion is not failure. It is the system working as designed. You took risks. Some of those risks materialized as failures. The failures consumed your budget. Now the system forces you to slow down and restore reliability.

The first action is the deployment freeze. Communicate it widely. Engineering, product, leadership, and customer-facing teams all need to know. The freeze is not a surprise if you have been tracking budget consumption visibly. Everyone saw it coming.

The second action is incident analysis. Why did you exhaust the budget? Was it a single large incident or accumulated small failures? Was it a model regression, a provider issue, a traffic spike, a data quality problem? Identify root causes, not just symptoms.

The third action is targeted fixes. If a model regression caused quality degradation, roll back or retrain. If provider latency is the issue, implement caching, failover, or rate limiting. If traffic patterns shifted, update your capacity plans. Fix the root cause with urgency.

The fourth action is validation. After implementing fixes, measure their impact. Run your model through eval suites. Monitor production metrics. Confirm that failure rates have dropped. If failure rates remain elevated, the budget will be re-exhausted immediately. Validate before declaring victory.

The fifth action is a postmortem. Document what happened, why it happened, what you fixed, and what you will do differently to prevent recurrence. Share the postmortem widely. Error budget exhaustion is a learning opportunity, not a blame event.

## Error Budget Versus Deployment Velocity

The tension between reliability and velocity is not new. Product wants to ship fast. Engineering wants to ship reliably. The error budget resolves the tension by making trade-offs explicit.

When the error budget is healthy, velocity increases. Teams deploy more frequently, test less exhaustively, and take bigger risks. The budget absorbs failures. This is rational. Overinvesting in reliability when the budget is full wastes effort and slows innovation.

When the error budget is depleted, velocity decreases. Teams deploy less frequently, test more thoroughly, and avoid risky changes. This is also rational. Taking risks when the budget is exhausted means breaching SLOs, which damages trust and triggers contract penalties.

The error budget creates a dynamic equilibrium. In stable periods, velocity increases until failure rates rise and consume budget. As budget depletes, velocity decreases until failure rates drop and budget is restored. The system self-regulates.

The alternative is static trade-offs. Engineering always tests exhaustively, even when reliability is already excellent. Or product always pushes for speed, even when reliability is on the edge of collapse. Static trade-offs are suboptimal. Dynamic trade-offs based on error budget state are adaptive.

A SaaS AI company tracked error budget and deployment frequency over a year. In months where budget consumption was below 50 percent, they deployed an average of 12 times. In months where consumption was above 75 percent, they deployed an average of 4 times. Deployment velocity flexed with reliability state. The result: they maintained 98.5 percent quality while deploying 94 times in 12 months — faster than teams with static deployment cadences.

## Monthly Error Budget Reviews

Error budgets need regular review. Monthly or quarterly reviews assess how budget was consumed, whether policies were followed, and whether the budget allocation is still correct.

Start with consumption trends. Did you stay within budget? If yes, were you far below budget, suggesting you could afford to move faster? If no, what caused the overage and what was done to fix it?

Examine failure mode distribution. Did quality failures consume more budget than expected? Did latency failures consume less? Should you reallocate budget across failure modes to reflect actual system behavior?

Assess policy adherence. When budget was exhausted, did the freeze policy hold? Were there override requests? Were overrides justified? If the policy was routinely violated, either the policy is wrong or organizational discipline is lacking.

Evaluate SLO appropriateness. Is your SLO too aggressive, causing frequent budget exhaustion and constant firefighting? Is it too conservative, leaving budget consistently unspent and slowing deployment velocity unnecessarily? Adjust SLOs based on error budget data.

Include product and engineering in reviews. Both sides need to see the data. Product learns what risky deployments cost in terms of budget consumption. Engineering learns where reliability investments have the highest impact. The review is a shared learning process, not an engineering-only postmortem.

A fintech startup conducted monthly error budget reviews with their entire engineering and product leadership team. They displayed budget consumption, failure breakdowns, and deployment velocity trends. Over six months, they adjusted their quality SLO from 90 percent to 93 percent after consistently leaving 4 percent of their 10 percent budget unspent. The adjustment tightened quality expectations and still left 7 percent budget for velocity. The reviews created shared understanding and continuous improvement.

## Error Budgets for Different AI Failure Types

Not all AI failures are equal. Hallucinations are different from refusals. Latency spikes are different from factual errors. Your error budget should reflect this reality.

Allocate separate budgets to distinct failure types. A customer support chatbot might have a 5 percent total error budget split into 2 percent for factual errors, 1.5 percent for refusals, 1 percent for latency, and 0.5 percent for availability. Each type consumes its own budget.

Weight failures by severity. A minor factual error might consume 1 unit of budget. A major hallucination might consume 10 units. A factual error that creates legal liability might consume 100 units. The weighting reflects business impact, not just error count.

Track correlation across failure types. When quality degrades, does latency also spike? When provider availability drops, do refusal rates increase? Correlated failures signal systemic issues, not isolated problems. The error budget data reveals these correlations.

Adjust allocations based on observed failure patterns. If you allocated 1 percent for latency failures but consistently consume 2 percent, reallocate from another category or tighten your overall SLO. The budget should match reality, not aspirations.

A healthcare diagnostics AI tracked four error budget categories: diagnostic accuracy, refusal rate, latency, and availability. They weighted diagnostic errors 10 times higher than latency failures because wrong diagnoses had clinical consequences while slow responses were merely annoying. The weighting ensured that a single diagnostic error triggered the same budget response as ten latency spikes, reflecting actual risk priorities.

Your error budget is permission to fail intelligently. It measures how much failure you can tolerate, allocates that tolerance across failure modes, and enforces policies when limits are reached. Without it, reliability becomes a vague aspiration subject to endless debate. With it, reliability becomes a measurable trade-off with explicit consequences and shared accountability.

In 10.6 — SLA Design for AI Products: What to Promise Customers, we examine how to translate internal SLOs into external contractual commitments with financial teeth.
