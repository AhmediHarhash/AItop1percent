# 10.3 — Multi-Dimensional SLOs: Latency, Quality, Cost Tradeoffs

The fintech company had separate teams for latency and quality. The infrastructure team owned the "p95 latency under 800ms" SLO. The model team owned the "94% classification accuracy" SLO. Both teams hit their targets every month. Then in September 2025, the infrastructure team deployed an optimization that cut latency to 400ms by reducing the number of retrieval results from 10 to 3. Quality dropped to 87%. The model team escalated. The infrastructure team pointed to their green SLO dashboard. The VP of Engineering asked why nobody was measuring the tradeoff. Nobody had an answer. They spent two months redesigning their SLO framework to make the three-way interaction between latency, quality, and cost explicit.

AI reliability is not one-dimensional. You cannot optimize for quality alone, latency alone, or cost alone. Every decision that improves one dimension affects the others. Faster models are lower quality. Higher quality models cost more. Lower cost inference requires accepting degraded quality or higher latency. The dimensions are coupled. Treating them as independent SLOs leads to local optimization and global dysfunction. Multi-dimensional SLOs make the tradeoffs visible so teams can make coherent decisions.

## The Three-Way Tradeoff

AI systems operate on a three-dimensional frontier defined by latency, quality, and cost. For any given system design, you can plot a point in this space: 500ms latency, 92% quality, 0.03 dollars per request. Every architectural choice moves you along this frontier. Switching to a larger model improves quality but increases latency and cost. Reducing retrieval depth improves latency and reduces cost but degrades quality. Using a cheaper model reduces cost but may degrade both quality and latency if you have to retry more often.

The tradeoff is not symmetric across dimensions. Latency and cost are continuous: you can trade 50ms for 10% lower cost, or 0.01 dollars for 100ms faster response. Quality is discrete and nonlinear: switching from GPT-5-mini to GPT-5 might improve quality by 6 percentage points, but switching from GPT-5 to GPT-5.1 might only improve it by 1 percentage point at much higher cost. Small changes in system design can cause large changes in quality while barely affecting latency or cost.

The constraints also differ by dimension. Latency has user-facing thresholds: under 300ms feels instant, over 2 seconds feels slow. Quality has task-specific minimums: 90% accuracy might be acceptable for content recommendations but catastrophic for fraud detection. Cost has budget ceilings: you can spend no more than a certain amount per request before the product becomes unprofitable. You are not free to move anywhere on the frontier. You are constrained to the region where latency is acceptable, quality meets minimums, and cost stays within budget.

This means that many system designs are infeasible not because they are technically impossible but because they violate one of the three constraints. You could achieve 98% quality by ensembling five large models, but the cost is 10x your budget and the latency exceeds user tolerance. You could achieve 200ms latency by using a tiny model, but the quality drops below acceptable thresholds. The feasible region of the design space is smaller than the technically possible region. Multi-dimensional SLOs define the boundaries of that feasible region.

## When Dimensions Conflict

Conflict happens when improving one dimension requires degrading another, and both dimensions have SLOs. Your latency SLO is 95th percentile under 1 second. Your quality SLO is 93% correctness. Your current system hits 1.2 seconds and 94% correctness. You can meet the latency SLO by switching to a faster model, but that drops quality to 89%. You can meet the quality SLO by staying with the current model, but that violates latency. Both SLOs cannot be met simultaneously with your current architecture. This is a conflict.

Conflict is common during incidents. Your primary model goes down. Failing over to the backup model keeps availability high but degrades quality. Your availability SLO is met. Your quality SLO is violated. Or load spikes and inference latency climbs to 3 seconds. You can switch to a smaller model to bring latency back under target, but quality will drop. You can queue requests to preserve quality, but latency will stay high. One SLO must be violated. Which one?

Conflict also happens during optimization. Your cost per request is too high. You can reduce it by lowering the temperature, reducing max tokens, or switching to a cheaper model. All of these changes risk degrading quality. Or you can reduce cost by batching requests, which increases latency for early requests in the batch. Cost optimization forces tradeoffs with quality or latency.

The traditional response to conflict is priority ordering: decide in advance which SLO is most important, and sacrifice the others if necessary. For a real-time voice assistant, latency is top priority — violate quality before violating latency. For a legal document review system, quality is top priority — violate latency before violating quality. For a high-volume low-margin product, cost is top priority — violate quality and latency if necessary to stay profitable.

Priority ordering works when one dimension clearly dominates. It breaks down when all three dimensions are close to equally important, or when different users prioritize different dimensions. Enterprise customers paying for premium tiers might prioritize quality over latency. Consumer free-tier users might prioritize latency over quality. A single priority order cannot satisfy both. You need more granular tradeoff rules.

## Priority Ordering for SLO Violations

When you cannot meet all SLOs simultaneously, you need explicit rules for which to violate. These rules should be codified, automated, and visible to leadership. Implicit priority decisions lead to inconsistent behavior and blame-shifting during incidents.

The simplest priority order is a strict ranking: quality above latency above availability, or latency above cost above quality. If you can only meet two of three SLOs, you always preserve the top two. If you can only meet one, you preserve the top one. This is easy to implement and reason about. It is also inflexible. It treats all SLO violations as equally bad, when in reality a 1% quality drop is not the same as a 10% quality drop.

Threshold-based priority ordering allows small violations of lower-priority SLOs to preserve higher-priority ones. Your rule might be "preserve quality above 90% at all costs, then minimize latency, then minimize cost." This allows you to violate the latency SLO by 200ms to preserve quality, but not to drop quality below 90% for any latency gain. Thresholds define how much you are willing to degrade one dimension to protect another.

Weighted priority ordering assigns a cost to violating each SLO and minimizes total cost. Violating your quality SLO by 1 percentage point costs 10 units. Violating your latency SLO by 100ms costs 5 units. Violating your cost SLO by 0.01 dollars costs 3 units. During an incident, your system makes decisions that minimize the total cost of violations. This approach is more nuanced but also harder to reason about and explain.

Use-case-specific priority ordering allows different rules for different types of traffic. Your rule might be "for high-value enterprise customers, prioritize quality over latency. For free-tier users, prioritize latency over quality." Or "for time-sensitive queries, prioritize latency. For research queries, prioritize quality." This requires request classification and routing logic, but it lets you serve diverse user bases with different reliability expectations.

Whatever priority scheme you choose, it must be documented and automated. During an incident, engineers should not have to guess whether to fail over to a lower-quality model or queue requests to preserve quality. The system should automatically apply the priority rules you defined. And after the incident, you should be able to explain to leadership why you made the tradeoffs you made, not based on intuition but based on pre-agreed policy.

## Composite SLO Approaches

Instead of managing latency, quality, and cost as separate SLOs, you can define composite SLOs that capture the interaction. A composite SLO is a single metric that combines multiple dimensions into one target.

The simplest composite is a conjunction: "95th percentile latency under 1 second AND quality above 92% AND cost under 0.04 dollars per request." This is not really a composite — it is just three SLOs that must all be met. But framing it as a single statement makes the interdependence explicit. You cannot claim success by hitting two out of three. You must hit all three.

A weighted composite assigns different importance to each dimension: "SLO score equals 0.5 times quality plus 0.3 times latency-percentile-met plus 0.2 times cost-under-budget." Your target is a composite score above 0.9. This allows you to trade dimensions against each other. If quality drops slightly but latency improves a lot, your composite score might still be above target. The weights encode your priorities numerically.

Pareto-based composites define acceptable boundaries without specifying exact targets: "latency must be under 1.5 seconds, quality must be above 88%, and cost must be under 0.05 dollars — beyond those minimums, optimize for the best balance." This defines a feasible region rather than a single point. Any system that operates inside that region meets the SLO. This gives you flexibility to make tradeoffs dynamically without violating SLOs, as long as you stay within bounds.

User-perceived quality composites combine technical metrics into a single user-facing outcome: "SLO is 90% of users successfully complete their task within 2 seconds." This implicitly captures quality, latency, and even availability — if any dimension fails, task completion drops. The advantage is that you measure what users experience, not what engineers instrument. The disadvantage is that it is harder to debug. When the composite SLO is violated, you need additional instrumentation to determine whether the root cause was latency, quality, availability, or cost constraints forcing degraded service.

Composite SLOs reduce reporting complexity — you have one number to track instead of three — but they obscure the underlying tradeoffs. If your composite score is 0.92 but quality is 85% and latency is 400ms, did you meet your target or not? Depends on the weights. Composite SLOs work best when you have clear, stable priorities that can be encoded numerically. They work poorly when priorities shift by use case or over time.

## The Pareto Frontier of AI Reliability

The Pareto frontier is the set of system designs where you cannot improve one dimension without degrading another. Every point on the frontier represents an optimal tradeoff. Every point inside the frontier is suboptimal — you could improve at least one dimension without hurting the others.

For AI systems, the Pareto frontier is defined by model choice, architecture, and configuration. A point on the frontier might be "GPT-5-mini, top-5 retrieval, temperature 0.7, no ensembling" with 600ms latency, 91% quality, 0.02 dollars per request. Another point might be "GPT-5, top-10 retrieval, temperature 0.5, ensembling with two models" with 1.8 seconds latency, 96% quality, 0.12 dollars per request. Both are Pareto-optimal. You cannot move from the first to the second and improve all three dimensions. You improve quality at the cost of latency and cost.

The goal of multi-dimensional SLO design is to find the point on the Pareto frontier that best matches your priorities. If you value quality most, you move toward the high-quality, high-cost, high-latency end of the frontier. If you value latency most, you move toward the low-latency, low-quality, low-cost end. Your SLOs define which part of the frontier you target.

The frontier also shifts over time. When a new model is released, it might offer better quality at the same cost and latency, pushing the frontier outward. When a model provider raises prices, the frontier shifts inward — you get less quality per dollar. When you optimize your retrieval pipeline, the frontier expands — you can achieve the same quality at lower latency. Tracking the frontier helps you understand when you should revisit your SLOs because new tradeoffs are available.

You can visualize the frontier by running experiments with different configurations and plotting the results in three-dimensional space. For a finite set of models and configurations, the frontier is the outer envelope of points. Any configuration inside the envelope is suboptimal. Any configuration on the envelope is a valid candidate. Your SLOs determine which point on that envelope you choose.

## Use Case Specific Priority Ordering

Not all use cases have the same priorities. A conversational assistant prioritizes latency — users expect responses in under a second. A document analysis system prioritizes quality — users can wait five seconds for a correct answer. A high-volume API prioritizes cost — shaving 0.001 dollars per request saves thousands per day. You cannot apply the same priority ordering to all three.

Use case classification is the first step. You tag requests by type: real-time conversational, batch processing, high-stakes decision support, creative generation, low-stakes recommendations. Each type has a different priority order. Real-time conversational requests prioritize latency over quality over cost. Batch processing requests prioritize quality over cost over latency. High-stakes decision support prioritizes quality over latency over cost.

You can implement priority ordering through routing. Requests with latency priority route to fast, low-cost models with slightly lower quality. Requests with quality priority route to slower, more expensive models with higher accuracy. Requests with cost priority route to the cheapest model that meets minimum quality and latency thresholds. Your infrastructure applies the appropriate tradeoff for each request type automatically.

You can also implement priority ordering through degradation strategies. When load spikes, real-time requests degrade by switching to faster models. Batch requests degrade by queuing. High-stakes requests do not degrade — they wait for capacity or return errors rather than serving low-quality responses. Each use case has a different fallback behavior that matches its priority order.

Customer tier also affects priority ordering. Enterprise customers paying premium prices get quality and latency guarantees. Free-tier users get best-effort service with cost prioritized over quality and latency. Your SLOs are segmented by tier: "99% availability, 94% quality, p95 latency under 1 second for enterprise customers" and "95% availability, 88% quality, p95 latency under 3 seconds for free tier." This makes the tiering explicit and ensures you allocate reliability investment proportional to revenue.

## Communicating Multi-Dimensional SLOs

Multi-dimensional SLOs are harder to communicate than single-number SLOs. "99.9% uptime" fits on a dashboard and in a headline. "95th percentile latency under 1 second AND quality above 92% AND cost under 0.04 dollars per request" does not. You need clear communication strategies to make multi-dimensional SLOs understandable to engineering, product, and leadership.

For engineering teams, show all dimensions on a single dashboard with color-coded status: green if all three SLOs are met, yellow if one is violated, red if two or more are violated. Include time-series graphs for each dimension so engineers can see trends. Add annotations for incidents, deployments, and configuration changes so teams can correlate SLO changes with system changes.

For product teams, translate technical metrics into user-facing outcomes: "latency under 1 second means responses feel instant; quality above 92% means fewer than 1 in 12 answers require correction; cost under 0.04 dollars per request means we can serve 1 million requests per month within budget." Product teams care about user experience and unit economics, not milliseconds and percentages. Frame SLOs in terms they understand.

For leadership, report a summary metric that captures overall reliability: "This month, we met all three SLOs for 96% of requests, violated one SLO for 3% of requests, and violated two or more SLOs for 1% of requests." Or use a red-yellow-green status: green if all SLOs are in target ranges, yellow if one is slightly out of range, red if any is severely violated. Leadership wants to know if the system is healthy, not the details of every dimension.

When SLO violations happen, explain the tradeoff in plain language: "We violated the quality SLO by 2 percentage points to avoid violating the latency SLO during the load spike. Based on our priority ordering, we prioritize latency over quality for real-time conversational traffic. The quality drop lasted 45 minutes and affected 12,000 requests." This shows that you made a deliberate decision based on pre-agreed priorities, not a mistake.

## When to Sacrifice One Dimension for Another

Sacrificing one dimension to preserve another is not a failure — it is a deliberate reliability strategy. The question is when to do it and how to decide.

Sacrifice latency to preserve quality when users value correctness over speed. During an incident where your primary model is degraded, you can queue requests and wait for recovery rather than failing over to a lower-quality model. Users wait longer, but they get correct answers. This is the right choice for high-stakes use cases where a wrong answer is worse than a slow answer.

Sacrifice quality to preserve latency when users value responsiveness over correctness. During a load spike, you can switch to a faster, lower-quality model to keep latency under target. Users get slightly worse answers, but they get them quickly. This is the right choice for real-time conversational use cases where latency above 2 seconds causes users to abandon the interaction.

Sacrifice cost to preserve quality and latency when budget flexibility exists. During an incident, you can scale up to more expensive infrastructure or switch to a more expensive model to maintain SLOs. Your cost per request spikes, but your user-facing SLOs stay green. This is the right choice when revenue is much higher than infrastructure cost, and SLO violations would cause customer churn.

Sacrifice availability to preserve quality when serving a wrong answer is worse than serving no answer. For high-risk use cases, you can return errors instead of low-quality responses during degraded states. Your availability SLO is violated, but your quality SLO is preserved. This is the right choice for safety-critical applications where bad outputs cause harm.

The key is that these decisions are made explicitly, based on pre-defined rules, and logged. You do not wing it during an incident. You follow the priority order you defined during calm times. And after the incident, you review whether the priority order produced the right outcomes, and adjust if necessary.

Multi-dimensional SLOs force you to think about reliability as a set of tradeoffs, not as a single target. The next subchapter introduces the framework for managing those tradeoffs over time: reliability budgets and how to spend them.
