# 11.4 — Cross-Functional Incident Teams: Who Needs to Be Involved

The incident started at 2:14am. By 2:45am, Engineering had identified the problem — a hallucination pattern in the customer service agent that was recommending incorrect refund policies. By 3:00am, they had a fix ready to deploy. They rolled it out. At 7:30am, the VP of Customer Success opened Slack and asked why no one told her that hundreds of customers had been given incorrect information about refunds overnight. By 9:00am, Legal wanted to know why they weren't informed that the company might have created binding commitments it couldn't honor. By 10:00am, the incident was no longer about the model — it was about why three departments were handling cleanup for a problem they learned about from customers, not from Engineering.

AI incidents are almost never purely technical. The moment an AI system fails in a way that affects users, the incident becomes cross-functional. Engineering can fix the model, but they cannot decide what to tell customers. They cannot assess legal exposure. They cannot coordinate with the support team handling the fallout. Organizations that treat AI incidents as engineering-only problems learn this lesson the expensive way — with confused communications, duplicated effort, and departments working at cross purposes while users wait.

## Why AI Incidents Require More Than Engineering

Traditional service outages have clear boundaries. The website is down. The API is returning errors. Engineering fixes it, Communications posts a status update, and everyone moves on. AI incidents are different because the failure modes cross organizational boundaries from the start.

When your customer service agent gives incorrect information, Engineering needs to fix the model, but Customer Success needs to identify which customers were affected and what they were told. When your content moderation system fails open and allows prohibited content, Engineering needs to close the hole, but Trust and Safety needs to review what got through and Legal needs to assess regulatory exposure. When your fraud detection system starts blocking legitimate users, Engineering needs to tune the thresholds, but Product needs to decide how to communicate with affected users and Support needs scripts for handling incoming complaints.

The technical fix is necessary but not sufficient. Every AI incident creates ripples across the organization. The cross-functional incident team exists to handle all the ripples at once, with coordinated decision-making and clear communication.

## Core Incident Team Roles

Every AI incident needs an incident commander — the single person who owns the incident response, makes final decisions, and coordinates all other participants. For AI incidents, this is usually an engineering leader with deep understanding of the system, but their job during an incident is not to write code. Their job is to orchestrate the response. They decide who needs to be involved, what information needs to flow where, and when the incident is resolved.

The technical lead is the person actually driving the fix. They coordinate with the engineers doing the work, synthesize what they learn, and report status to the incident commander. For AI incidents, the technical lead needs to understand both the model behavior and the production infrastructure — they might be debugging a prompt that causes hallucinations, a cache issue that serves stale responses, or a traffic surge that overwhelms embeddings generation.

The communications lead manages all outward-facing communication during the incident. They draft status updates for users, coordinate with Support on what to tell customers, and ensure that everyone inside the organization who needs information has it. For AI incidents, this role becomes critical fast because the failure modes are hard to explain to non-technical audiences. The communications lead translates "the fine-tuned model is exhibiting distribution shift relative to the golden set" into "some responses may be less accurate than usual, we are investigating."

These three roles form the core incident team. They can handle many incidents without involving anyone else. But AI incidents often require more.

## Extended Team Roles

**Product** needs to be involved when the incident affects user-facing behavior in ways that require judgment calls about acceptable degradation. If your recommendation system is returning lower-quality suggestions due to an embeddings issue, Engineering can describe the problem, but Product decides whether to fail closed and show nothing, fail open and show degraded recommendations, or show a fallback set of popular items. These decisions affect user experience, retention, and revenue — they are not purely technical.

**Legal** needs to be involved when the incident creates potential liability, regulatory exposure, or contractual issues. If your AI system gave medical advice that was incorrect, made commitments the company cannot honor, exposed user data, or violated content policies you are contractually obligated to enforce, Legal needs to know immediately. Not after the technical fix. Not during the post-incident review. During the incident, while decisions are being made about disclosure, user communication, and remediation.

**Customer Success or Support** needs to be involved when users are already experiencing the problem and contacting the company. They need real-time updates on what is happening, how long it will take to fix, and what they should tell users who are affected. For AI incidents, Support often surfaces the problem before monitoring does — they see the pattern of complaints before the metrics show the degradation. Keeping them in the loop turns them from reactive responders into active participants who can provide early signal.

**Trust and Safety** needs to be involved when the incident involves content policy violations, safety failures, or abuse vectors. If your content moderation system fails, if your agent starts generating harmful content, if an adversary is exploiting your system at scale — Trust and Safety needs to be in the room making decisions about thresholds, reviewing flagged content, and determining next steps.

**Communications or Public Relations** needs to be involved when the incident is likely to become public or when users are asking questions on social media, forums, or public channels. They manage the public narrative, coordinate with the communications lead on messaging, and ensure the company is not surprised by how the incident is being discussed externally.

Not every incident requires every role. But deciding who to involve should be a deliberate choice, not an accident.

## When to Involve Non-Engineering Functions

The default should be: involve them early if there is any possibility they will be needed. The cost of pulling someone into an incident bridge who turns out not to be needed is low. The cost of realizing two hours into an incident that you should have involved Legal from the start is high.

Involve **Product** when the incident requires trade-off decisions about user experience, when the fix will degrade functionality, or when the problem is affecting a user-facing feature. Involve **Legal** when the incident involves user data, incorrect information provided to users, contract violations, or anything that could create regulatory exposure. Involve **Support** when users are already contacting the company or when the incident will require follow-up communication with affected users. Involve **Trust and Safety** when content policies are involved, safety issues are present, or the incident involves adversarial activity. Involve **Communications** when the incident is visible to users, when it affects a significant number of people, or when there is any chance it will be discussed publicly.

When in doubt, involve them. The incident commander can excuse someone from the bridge if it turns out they are not needed. You cannot undo the two hours they missed.

## Communication Between Functions During Incidents

Cross-functional incident teams fail when everyone is talking past each other. Engineering is discussing cache invalidation strategies. Product is asking when users will see normal behavior again. Legal is trying to understand if any HIPAA data was exposed. Everyone is operating at a different level of abstraction, and no one is translating.

The incident commander's job is to prevent this. They maintain a shared mental model of what is happening, what has been tried, what the current plan is, and what decisions need to be made. Every few minutes, they summarize the state of the incident in plain language that every function can understand. Not jargon. Not technical details unless they matter for decisions someone needs to make.

Each function has a single point of contact on the bridge. Legal sends one person, not three lawyers all asking questions. Product sends one person who can make decisions, not a PM who needs to check with their VP. The single point of contact for each function is empowered to make decisions or escalate if a decision exceeds their authority. This prevents the incident from stalling while someone schedules a meeting to discuss whether to involve their boss.

Status updates flow outward from the incident commander to the rest of the organization at regular intervals — every 30 minutes during active incidents, every hour during long-running investigations. These updates follow a consistent format: what happened, what the current status is, what the team is doing now, when the next update will be. Everyone in the organization who might need to know about the incident receives these updates. No one should learn about an AI incident from a customer or from Twitter.

## Pre-Establishing Cross-Functional Relationships

The worst time to meet the people you need during an incident is during the incident. Organizations that handle cross-functional incidents well have established relationships before anything breaks.

Engineering and Product meet regularly to discuss the AI systems in production, the failure modes that matter, and the trade-offs that might need to be made during incidents. They have already had the conversation about acceptable degradation, fail-open versus fail-closed strategies, and who makes the call when the system is borderline. When an incident happens, they are not meeting each other for the first time while under pressure.

Engineering and Legal have a standing relationship for discussing AI risk, data exposure scenarios, and incident disclosure requirements. Legal knows how the AI systems work at a high level. Engineering knows what Legal needs to know during incidents and how much time they have to provide it. They have a shared vocabulary. They are not translating from scratch while the clock is running.

Engineering and Support have a regular sync where Support surfaces patterns in user complaints and Engineering explains recent changes to the AI system. Support knows who to escalate to when they see unusual behavior. Engineering knows that Support's signal is often earlier than metrics. They trust each other.

These relationships are built during peacetime. By the time an incident happens, everyone already knows each other, understands each other's constraints, and can operate at high speed without friction.

## Post-Incident Cross-Functional Review

The post-incident review is not an engineering-only meeting. Every function that was involved in the incident participates. The goal is not to assign blame — the goal is to understand what happened across the full lifecycle of the incident and improve the response for next time.

Product explains what user impact they observed and what decisions they had to make about degraded functionality. Support describes what users were saying and where the communication gaps were. Legal walks through what information they needed and when they got it. Engineering explains the technical root cause and the fix. The incident commander reviews the timeline and the coordination.

Then the team identifies improvements. Not just technical improvements — organizational ones. Did Legal get pulled in too late? Change the runbook to include them earlier. Did Support not have the information they needed to talk to users? Improve the status update format. Did Product have to make a decision without enough context? Add a section to the incident doc that explains user-facing impact in Product terms.

The cross-functional post-incident review turns incidents into organizational learning, not just technical fixes. The next incident will be different, but the team will be better at handling it together.

---

Next, you will explore vendor escalation — what to do when your AI provider is the source of the problem and how to work with provider support during outages.
