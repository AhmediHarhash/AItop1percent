# 9.5 â€” Latency Injection and Timeout Testing

Most teams test for broken systems. They shut down services, kill pods, simulate outages. But in production, complete failures are rare. Slow systems are common. A database query takes twelve seconds instead of 200 milliseconds. An API call times out after thirty seconds. A model inference hangs for ninety seconds before returning. The system is not broken. It is just too slow to be useful.

Users experience this as failure. They wait. They refresh. They give up. They complain. Meanwhile, your monitoring shows everything green. Uptime is 99.9 percent. Error rate is 0.1 percent. Nobody alerts. Nobody responds. The system is failing slowly, and nobody notices until the support team is overwhelmed.

Latency injection is chaos engineering for slow systems. You deliberately add artificial delays to requests. You watch how your system handles them. You find the places where a slow dependency cascades into a system-wide outage. You build the timeouts, circuit breakers, and fallbacks that prevent slowness from becoming unavailability.

## Why Latency Injection Matters

A service that returns errors is easy to handle. You catch the error. You retry. You fail fast. You show the user a clear message. The failure is binary. It works or it does not.

A service that returns slowly is hard to handle. It has not failed yet. Maybe it will respond. Maybe you should wait. But how long? If you wait too long, the user sees a frozen interface. If you time out too early, you waste the computation and retry unnecessarily. There is no clean binary decision. Just trade-offs.

Most systems handle latency poorly. They wait indefinitely. They stack up retries, amplifying load on the slow service. They hold database connections open, exhausting connection pools. They block threads, reducing overall system capacity. A slow dependency becomes a system-wide bottleneck. Then it becomes an outage.

Latency injection exposes these problems before they reach production. You add five seconds of delay to your embedding service. You add ten seconds of delay to your model inference. You add thirty seconds of delay to your vector database. You send normal traffic through the system and watch what breaks. Then you fix it.

## Injecting Latency at Different Layers

Latency can be injected at multiple layers. Each layer reveals different failure modes.

Network latency injection happens at the infrastructure level. You use traffic shaping tools to delay packets. Every request to your vector database takes an extra two seconds. This tests whether your client-side timeouts are configured correctly. If your timeout is five seconds, requests should fail fast. If your timeout is sixty seconds, requests hang forever. Network latency injection reveals which services have reasonable timeouts and which do not.

Service latency injection happens at the application level. You configure your chaos tool to intercept API calls and sleep before responding. You add three seconds to every embedding request. You add seven seconds to every model call. This tests how your application handles slow dependencies. Does it time out gracefully? Does it retry with backoff? Does it fall back to a faster model? Or does it wait indefinitely, blocking the request thread?

Database latency injection happens at the query level. You intentionally run slow queries. You add joins that scan millions of rows. You disable indexes temporarily. This tests whether your application handles slow database operations. Do you have query timeouts? Do you monitor slow query logs? Do you fail fast when a query exceeds expected latency?

Each layer of latency injection reveals a different set of problems. Network latency shows misconfigured client timeouts. Service latency shows missing fallbacks. Database latency shows inefficient queries and missing monitoring. You need to test all three to understand where your system is vulnerable.

## Testing Timeout Behavior

Every external call should have a timeout. Embedding services. Model APIs. Vector databases. SQL queries. If a call takes longer than the timeout, it should fail fast. The application should catch the timeout, log it, and respond appropriately. It should not wait forever.

But most systems have misconfigured timeouts or no timeouts at all. The default HTTP client timeout is often thirty or sixty seconds. The model API timeout might be set to five minutes because inference sometimes takes that long. The database client might have no timeout, waiting indefinitely for a query to return.

Latency injection tests whether your timeouts are correct. You inject latency longer than your configured timeout. If your embedding timeout is three seconds and you inject five seconds of latency, requests should fail at three seconds. If they hang longer, your timeout is not being enforced. If they fail immediately, your timeout is too aggressive.

Timeout testing also reveals cascading failures. Your application times out an embedding request after three seconds. But the retry logic immediately retries. The retry also times out. The system retries again. Now you have three slow requests in flight instead of one. The load on the embedding service triples. Latency increases for all users. What started as a slow response becomes a capacity crisis.

Correct timeout behavior means timing out, logging the failure, and either failing fast or using an exponential backoff before retrying. Latency injection shows you whether you have built that behavior or just assumed it exists.

## User Experience Under Latency

Latency affects user experience more than most failures. A clear error message is frustrating but understandable. A frozen spinner is maddening. Users do not know if the system is working, broken, or stuck. They wait. They click again. They open the browser console. They refresh the page. Each action generates more load, making the problem worse.

Latency injection with real users or user simulations shows how your interface handles slow responses. You inject three seconds of latency into model calls. Do users see a progress indicator? A message saying "Thinking, this may take a few seconds"? Or do they see nothing, just a frozen interface?

You inject ten seconds of latency. Does the interface time out and show an error? Does it continue waiting? Does it let the user cancel the request? Most interfaces do none of these. They wait silently until the server responds or the browser times out, often after a minute or more.

Better systems give users feedback. They show progress indicators. They set client-side timeouts shorter than server-side timeouts so the UI can respond before the server gives up. They let users cancel slow requests. They degrade gracefully, offering a faster but lower-quality option: "This is taking longer than expected. Switch to quick mode?"

Latency injection with user testing reveals the gap between technical timeout configuration and actual user experience. You might have perfect server-side timeouts, but if the client waits indefinitely, users still suffer.

## Cascade Effects of Slow Responses

In distributed systems, latency cascades. One slow service makes the service that calls it slow. That service makes its callers slow. Latency propagates up the stack until user requests time out or the system runs out of capacity.

A common cascade: your model API is slow. It takes fifteen seconds to respond. Your application waits fifteen seconds per request. Request threads are blocked for fifteen seconds. With a hundred concurrent users, you need capacity for 1,500 seconds of blocked threads. Your thread pool is exhausted. New requests queue. Queue times increase. Users see latency growing from fifteen seconds to thirty seconds to sixty seconds. The system is still responding, but so slowly that it is effectively down.

Latency injection reveals these cascades. You inject moderate latency into a single service and watch it amplify through the system. You measure queue depths. You measure thread pool utilization. You measure end-to-end latency from user request to response. If a five-second delay in one service causes a thirty-second delay for users, you have a cascade problem.

Fixing cascades means breaking the propagation. You add timeouts so requests fail fast instead of waiting indefinitely. You add circuit breakers so a slow service is taken out of rotation before it exhausts capacity. You add backpressure so the system rejects requests early instead of queueing them forever. You add fallbacks so slow primary services are bypassed in favor of faster alternatives.

Latency chaos makes cascades visible. Then you can build the mechanisms that prevent them.

## Testing Async and Streaming Under Latency

Some AI systems use asynchronous processing or streaming responses. The user submits a request. The system processes it in the background. The user receives a job ID. They poll for results. Or the system streams tokens as they are generated, showing partial responses in real time.

These patterns change how latency manifests. With polling, latency means the user waits longer between status checks. With streaming, latency means tokens arrive slowly or freeze mid-stream. Both patterns need chaos testing.

Async latency injection means adding delays to background processing. You submit a job. It takes thirty seconds instead of three. Do you have monitoring that alerts on slow job completion? Do users get progress updates? Or do they just see "Processing..." for thirty seconds with no feedback?

Streaming latency injection means adding delays between tokens. The model generates tokens every 100 milliseconds. You inject latency so they arrive every two seconds. Does the UI handle this gracefully? Or does it freeze, leading users to think the stream is broken?

Streaming systems also need to handle mid-stream failures. You start streaming. Halfway through, the model API times out. Does the system retry and resume? Does it show an error? Or does it leave a half-formed response on screen with no indication that it failed?

Async and streaming patterns do not eliminate latency problems. They change them. Latency chaos for these patterns tests whether the change improves user experience or just hides the problem in a different form.

## How Latency Chaos Reveals Tight Coupling

Tight coupling means one service directly depends on another with no fallback, no timeout, and no degradation strategy. If the dependency is slow, the service is slow. If the dependency is down, the service is down.

Latency injection reveals tight coupling. You inject latency into your embedding service. Every feature that uses embeddings becomes slow. Search slows down. Document retrieval slows down. The chatbot slows down. You discover that a single slow dependency impacts the entire system.

Loosely coupled systems isolate latency. If embeddings are slow, search might fall back to keyword search. Document retrieval might return cached results. The chatbot might warn users that responses are slower than usual but still function. The embedding latency is contained to the embedding service. It does not cascade across the system.

Decoupling through chaos means using latency injection to find tight coupling, then building isolation. You add circuit breakers so slow services are bypassed. You add caching so slow dependencies are less critical. You add fallbacks so primary paths can fail without breaking the system. Latency chaos shows you where decoupling is needed. Then you build it.

## Safe Latency Injection in Production

Latency injection is safest in staging. But staging does not have production traffic patterns, production load, or production dependencies. The only way to fully understand latency behavior is to inject latency in production.

Safe production latency injection means controlling blast radius. You inject latency into one percent of requests, not all requests. You inject latency during low-traffic hours, not during peak load. You inject latency for internal users first, then gradually expand to real users. You set kill switches so you can stop the experiment immediately if things go wrong.

You also start small. Inject 500 milliseconds of latency before you inject five seconds. Inject latency into one service before you inject it into multiple services. Observe the impact before you escalate. Production chaos is about learning, not breaking.

Effective latency injection in production requires observability. You need metrics that show latency percentiles, not just averages. You need traces that show where latency is introduced and how it propagates. You need alerts that fire when latency exceeds thresholds. Without observability, latency injection in production is reckless. With observability, it is the most effective way to validate your system's resilience.

Latency is not the absence of failure. It is a form of failure. Systems that handle latency well stay reliable even when dependencies slow down. Systems that do not handle it well degrade into outages. Latency chaos reveals which category your system falls into.

The next step in resilience testing is to formalize chaos engineering into scheduled practice: game days where the team deliberately breaks the system to learn how to fix it.
