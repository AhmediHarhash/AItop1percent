# 10.7 — Feature Flagging for Model Behavior

Feature flags are the control mechanism that lets you turn model capabilities on or off without deploying new code, enable features for specific user segments without exposing them to everyone, and gradually ramp new behaviors from zero to 100 percent traffic with fine-grained control. For traditional software, feature flags control UI elements, API endpoints, and business logic. For AI systems, feature flags control model routing, prompt variants, capability gates, and behavior modifications.

Feature flagging is not optional infrastructure for production AI systems. It is the difference between having control over your deployments and being hostage to whatever behavior the model produces. Without feature flags, deploying a new model capability means all users get it simultaneously. With feature flags, deploying a new capability means you can test it with internal users first, then beta customers, then 5 percent of production traffic, then 20 percent, then 100 percent, with the ability to instantly revert at any stage. Feature flags turn irreversible deployments into reversible experiments.

In June 2025, a medical appointment scheduling assistant wanted to add a new capability where the model could proactively suggest appointment times based on patient history and provider availability. The feature required accessing two additional databases and increased latency by 400 milliseconds. Instead of deploying to all users, they put the feature behind a flag called "proactive-scheduling" and enabled it for 50 internal employees. Within two days, they discovered the latency increase made the experience feel sluggish. They disabled the flag, optimized the database queries to reduce latency to 120 milliseconds, and re-enabled the flag for employees. After confirming good experience, they ramped to 2 percent of patients, then 10 percent, then 50 percent, then 100 percent over three weeks. The feature flag let them iterate safely. Without it, they would have either shipped a sluggish experience to all patients or spent weeks in staging environments that never fully replicate production load characteristics.

Feature flags are the deployment discipline that turns AI systems from unpredictable black boxes into controlled, observable, rollbackable products.

## Feature Flag Architecture for Model Routing

The most common use of feature flags in AI systems is routing traffic between model versions. Flag "use-gpt-5.1" controls what percentage of traffic goes to GPT-5.1 versus GPT-5. Flag "enable-fine-tuned-variant" controls whether a request uses the fine-tuned model or the base model. Flag "claude-opus-rollout" controls the percentage of users seeing Claude Opus 4.5 versus the baseline.

Model routing flags require integration between your feature flag system and your model serving infrastructure. The application checks the flag state before making a model inference request. If the flag is enabled for this user, route to model A. If disabled, route to model B. The flag evaluation must be fast — adding 50 milliseconds to every request to check a flag is unacceptable. Feature flag SDKs from LaunchDarkly, Split.io, and Unleash evaluate flags in single-digit milliseconds by caching flag state locally and updating asynchronously.

The flag configuration defines targeting rules. Enable for internal users. Enable for 10 percent of traffic randomly sampled. Enable for paid customers but not free users. Enable for users in the US but not EU. Enable for users who opted into beta features. The targeting rules let you control exposure precisely. You do not need separate infrastructure for internal testing, canary rollout, and geographic rollout. One flag with multiple targeting rules handles all scenarios.

A customer support platform used LaunchDarkly for model routing with a flag called "model-variant" that had three possible values: baseline, experimental-a, experimental-b. The flag's targeting rules specified: internal employees get experimental-b, users in the beta program get experimental-a with 50 percent probability, all other users get baseline. As experimental-a proved successful, they updated the targeting rules to give all users experimental-a. The flag served as both canary mechanism and full rollout mechanism without code changes.

## Feature Flags for Prompt Variants and Capabilities

Beyond model routing, feature flags control which prompt variant serves a request and which capabilities are enabled. Flag "use-detailed-prompt" switches between a concise system message and a detailed one. Flag "enable-citations" controls whether the model is instructed to include citations. Flag "enable-reasoning-traces" controls whether the model generates intermediate reasoning steps visible to users.

Prompt variant flags let you A/B test prompts without deploying new code. Store both prompt variants in your config system. Use a feature flag to select which variant each user sees. Measure metrics per flag state. If the new prompt improves metrics, ramp the flag to 100 percent. If it regresses, disable it. The iteration cycle is hours, not days.

Capability flags let you gate features that increase cost, latency, or risk. A model that can search external databases, analyze images, or execute code should have each capability behind a flag. Enable the capability for users who need it and can tolerate the trade-offs. Disable for users where the cost or latency is unacceptable. Capability flags turn one model into multiple products tailored to different user needs.

Flags for capabilities also provide instant kill switches. If external database search starts returning errors, disable the "enable-db-search" flag and the model stops attempting database searches. Users get degraded but functional experience instead of broken experience. The kill switch is instant — seconds to disable — compared to deploying a code fix, which takes minutes to hours.

A document intelligence platform had ten capability flags controlling different model features: "enable-table-extraction," "enable-ocr-fallback," "enable-entity-linking," "enable-section-summarization." Each capability added latency and cost. Enterprise customers got all capabilities enabled. Small business customers got a subset. Free users got baseline capabilities only. The flags let them serve multiple customer segments from one codebase and one model without building separate products.

## Gradual Ramp Strategy with Feature Flags

Feature flags enable gradual ramp, the strategy of slowly increasing the percentage of users exposed to a new model or behavior. Start at 0 percent. Ramp to 1 percent. If metrics stay healthy, ramp to 5 percent. Then 10, 25, 50, 75, 100 percent over days or weeks. At each stage, monitor metrics, wait for statistical confidence, and decide whether to continue or rollback.

Gradual ramp is safer than big bang deploys because it limits blast radius. If the new behavior breaks, only the current ramp percentage is affected. If you detect problems at 10 percent, you stop or roll back before the other 90 percent see the bad behavior. The slower the ramp, the more time you have to detect problems at small scale.

Ramp speed depends on risk tolerance and traffic volume. High-risk changes — new models in healthcare or legal domains — ramp slowly, spending days at each percentage. Low-risk changes — UI tweaks in consumer apps — ramp quickly, spending hours at each percentage. High-traffic systems ramp faster because they accumulate data at each percentage quickly. Low-traffic systems ramp slower because they need more time per percentage to reach statistical confidence.

Automated ramp logic uses metrics to decide when to proceed. Define success criteria — error rate below 2 percent, latency below 1.5 seconds at 95th percentile, user satisfaction above 4.2 out of 5. Define sample size needed for confidence — 5,000 requests or 24 hours, whichever comes first. The system automatically ramps when success criteria are met at current percentage and sample size threshold is reached. If success criteria fail, the system alerts humans or automatically rolls back depending on severity.

A healthcare diagnostic model implemented automated gradual ramp using Split.io. The feature flag started at 0 percent. Every 12 hours, an automated job checked whether the current ramp percentage had accumulated 3,000 requests with error rate below 1 percent and false negative rate below 2 percent. If yes, the job increased the flag percentage by the next step in the sequence: 1, 3, 5, 10, 20, 30, 50, 75, 100. If no, the job alerted on-call for investigation. The ramp from 0 to 100 percent took 10 days. The automation removed human bottlenecks from the ramp process while maintaining safety.

## User-Level Consistency and Session Stickiness

Feature flags must maintain consistency for individual users. If a user gets model A on request one and model B on request two within the same session, the experience feels broken. Responses change style. Capabilities appear and disappear. Users lose trust. User-level consistency means once a flag assigns a user to a variant, that user stays on that variant for the duration of the flag test or until explicit reassignment.

Consistency requires stable user identifiers. User ID, session ID, or device ID works. The feature flag system hashes the identifier and uses the hash to assign variant. The hash is deterministic — same identifier always gets the same variant. As long as the user's identifier does not change, their variant assignment does not change.

Session stickiness extends consistency across user sessions. A logged-in user who sees model A on Monday should see model A on Tuesday even if the flag's overall percentage changed between sessions. This requires the feature flag system to remember user assignments, either via user ID stored in the flag system or via client-side cookies or local storage. Most enterprise feature flag systems handle this automatically.

The exception to consistency is when you explicitly want users to switch variants. If a flag started at 50/50 and you are ramping to 100 percent of the new variant, users on the old variant need to migrate to the new variant at some point. The migration should be controlled — notify users if behavior will change, complete the migration during low-traffic periods, or allow users to opt in to the migration early.

A financial advisory platform maintained user-level consistency by hashing user IDs with a stable salt. When the "use-gpt-5.1" flag was set to 30 percent, users with hash values in the bottom 30 percent of the hash space got GPT-5.1. Users in the top 70 percent got GPT-5. As the flag ramped from 30 to 50 to 80 to 100 percent, users who were previously on the old model gradually migrated to the new model. The migration was deterministic, not random. Once a user migrated, they stayed on the new model. The consistency prevented confusing experience changes mid-session.

## Feature Flag Observability and Metrics Segmentation

Feature flags enable observability by segmenting metrics by flag state. Error rate, latency, user satisfaction, task completion — all metrics can be split into "flag enabled" versus "flag disabled" cohorts. The segmentation reveals whether the flagged behavior improves or degrades metrics. Without segmentation, you deploy a feature, watch aggregate metrics, and guess whether any change was caused by the new feature or something else. With segmentation, you know.

Metrics segmentation requires logging flag state per request. Every model inference request logs which flags were enabled for that user. The log joins with outcome metrics — user actions, satisfaction ratings, error events. Analysis queries group by flag state to compute metrics per cohort. The analysis can be real-time dashboards showing live metric comparison or batch analysis querying data warehouses.

The observability extends to multi-flag scenarios. If three feature flags are active simultaneously, metrics can be segmented by all eight combinations of flag states. This reveals interaction effects — maybe flag A improves metrics, flag B improves metrics, but A and B together degrade metrics due to unexpected interaction. Multi-flag segmentation is complex but necessary for systems where multiple experiments run concurrently.

Feature flag platforms provide built-in metric integration. LaunchDarkly integrates with Datadog, Amplitude, and Snowflake. Split.io integrates with Segment and Google Analytics. The integrations automatically segment metrics by flag state without custom instrumentation. Teams should use these integrations when available because manual metric segmentation is error-prone and maintenance-heavy.

A customer support platform integrated LaunchDarkly with Datadog for automatic metric segmentation. Every feature flag's state was included in Datadog traces and metrics. Datadog dashboards showed error rate, latency, and resolution rate split by each active flag's state. When the "use-claude-sonnet-4.5" flag ramped from 20 to 50 percent, the Datadog dashboard immediately showed that the Claude cohort had 8 percent higher resolution rate and 12 percent lower escalation rate. The automatic segmentation made A/B test analysis trivial.

## Feature Flags for Regional and Regulatory Compliance

AI systems often need different behavior in different regions due to regulatory requirements. A model deployed in the EU must comply with GDPR and EU AI Act requirements. A model deployed in healthcare settings in the US must comply with HIPAA. A model deployed in financial services must comply with local regulations that vary by country. Feature flags enable per-region behavior without building separate systems.

Regional flags control capabilities based on user location. Flag "enable-user-data-retention" is true in US, false in EU where GDPR requires data minimization. Flag "enable-automated-medical-advice" is false everywhere except regions where regulatory approval was obtained. Flag "enable-financial-predictions" is true in countries with appropriate licensing. The flags encode regulatory requirements as configuration, making compliance explicit and auditable.

The flags also enable gradual international expansion. Launch in the US with full capabilities. Add EU with restricted capabilities compliant with EU AI Act. Add UK with slightly different restrictions. Each region gets a tailored version of the product without forking the codebase. As regulatory approval is obtained in each region, enable additional capabilities by updating flags.

Regional flags must account for user mobility. A user traveling from the US to the EU should see EU-compliant behavior while in the EU. Geolocation-based flags handle this automatically if the feature flag system evaluates user location per request. User-profile-based flags do not handle mobility unless the user profile updates in real time.

A healthcare diagnostics company used regional feature flags to manage HIPAA compliance in the US and GDPR compliance in the EU. Flag "enable-data-retention" was true in US contexts where HIPAA allows retaining diagnostic data for care continuity, false in EU contexts where GDPR requires explicit consent. Flag "enable-automated-diagnosis" was true in US where they had regulatory clearance, false in EU where clearance was still in progress. The flags let them serve both markets from one model with appropriate compliance controls per region.

## Kill Switches for Emergency Capability Disabling

Every non-essential model capability should have a kill switch — a feature flag that can be instantly disabled if the capability breaks or causes harm. The kill switch is not for gradual ramp or A/B testing. It is for emergency "turn this off now" scenarios. If external API integration starts returning errors, kill the integration. If image analysis starts producing unsafe content, kill image analysis. If cost suddenly spikes due to a bug, kill the expensive capability.

Kill switches must be easily accessible to on-call engineers. A dashboard showing all flags with one-click disable buttons. A CLI command that disables a flag in five seconds. A runbook that clearly documents which flags control which capabilities and when to disable them. During an incident, engineers should not be figuring out which flag to flip or how to access the flag system. They should execute a pre-defined procedure.

Kill switches should be tested regularly. Quarterly chaos engineering exercises should include scenarios where capabilities are disabled via kill switches to verify that the system degrades gracefully. If disabling a flag breaks the system instead of degrading it, the flag is not a kill switch — it is a brittleness point. Test it before you need it.

Post-incident reviews should evaluate whether kill switches were used appropriately. If an incident lasted 45 minutes and a kill switch could have stopped it in 5 minutes, why was the kill switch not used? Lack of awareness? Lack of access? Lack of confidence that disabling the flag would help? Address these gaps through training, runbooks, and culture.

A document analysis platform had kill switches for five high-cost capabilities: OCR processing, table extraction, entity linking, external knowledge base queries, and multi-language translation. When their external knowledge base API started returning 10-second timeouts in October 2025, the on-call engineer disabled the "enable-kb-queries" flag within two minutes of the alert. The model stopped attempting knowledge base queries. Users got answers based only on document content without external augmentation. Experience degraded but did not break. The team fixed the API issue over the next hour and re-enabled the flag. Total user-facing downtime was two minutes instead of an hour because the kill switch allowed instant mitigation.

## Feature Flag Debt and Cleanup Discipline

Feature flags accumulate over time. Flags created for initial rollout remain in the code long after reaching 100 percent. Flags created for A/B tests remain after the test concludes. Flags created for temporary migrations remain after the migration completes. Unmaintained flags create technical debt — code complexity, evaluation overhead, and confusion about which flags are active and why.

Flag cleanup discipline means removing flags after they are no longer needed. A flag that reached 100 percent and has been stable for 30 days should be removed. Remove the flag from the feature flag system. Remove flag evaluation code from the application. Remove flag-conditional logic and make the successful variant permanent. The cleanup deploys like any code change with testing and review.

Temporary flags should have expiration dates. When creating a flag for a canary rollout, set a cleanup deadline — 60 days after creation or 30 days after reaching 100 percent. Feature flag systems like LaunchDarkly support expiration dates that alert when flags become stale. The alert triggers cleanup.

Long-lived flags — flags that control regional behavior, customer tier features, or operational kill switches — are exempt from cleanup. These flags are permanent configuration. But they should be clearly documented as long-lived so engineers know not to remove them. Tag them "permanent" or "operational" in the flag system.

A fintech company implemented flag cleanup discipline in 2025. Every feature flag had a "purpose" field — rollout, experiment, operational, or kill-switch. Rollout and experiment flags had expiration dates 90 days after creation. A monthly job queried the flag system for expired flags and filed Jira tickets to remove them. The team reduced active flag count from 120 to 45 over six months, improving code maintainability and reducing evaluation overhead. The discipline prevented flag accumulation from spiraling out of control.

## Integrating Feature Flags with Incident Response

Feature flags are tools for incident mitigation. When production breaks, flipping flags can often restore service faster than deploying code fixes. Train on-call engineers to think "can I mitigate this with a flag?" before starting emergency code deploys. Build runbooks that map common failure modes to flag actions.

Incident response playbooks should list flags and their intended effects. Playbook for "model latency spike" includes: disable "enable-external-api" flag to stop expensive external calls, disable "enable-reasoning-traces" flag to reduce model computation, reduce "advanced-user-percentage" flag to limit expensive features to fewer users. Playbook for "cost spike" includes: disable expensive capability flags, reduce model quality flags from GPT-5.1 to GPT-5 to lower per-token cost. The playbooks turn flags into incident mitigation levers.

Post-incident, evaluate whether flag-based mitigation was effective. If disabling a flag stopped the incident immediately, consider why that capability was not behind a flag with more conservative rollout. If disabling a flag did not help, update the runbook to remove unhelpful actions. Iterate on playbooks based on real incident experience.

Feature flags should appear in incident timelines. "At 14:22, engineer disabled enable-image-analysis flag to mitigate latency spike." The timeline documents which flags were modified during the incident. Post-incident reviews analyze whether flag actions helped, hindered, or were neutral. The learnings improve future incident response.

A healthcare appointment scheduling platform responded to an incident in December 2025 where latency spiked from 800 milliseconds to 4 seconds due to a dependency service degradation. Within three minutes, on-call disabled two feature flags: "enable-proactive-suggestions" which queried the degraded service, and "enable-multi-provider-search" which made redundant API calls. Latency dropped to 1.1 seconds. Users experienced slightly degraded functionality but acceptable performance. The team fixed the dependency issue over 40 minutes and re-enabled the flags. The feature flags turned a P0 incident into a P2 degradation.

## Feature Flags as Product Experimentation Infrastructure

Beyond deployment safety, feature flags enable product experimentation. Test new UX patterns. Test new model capabilities. Test different prompt strategies. Measure impact on user behavior. Ship the winners. Kill the losers. The experimentation culture accelerates learning and prevents shipping features that users do not want.

Experimentation requires hypothesis-driven flag design. "We believe that enabling reasoning traces will improve user trust. We will measure trust via satisfaction scores and follow-up query rate. If satisfaction increases by 5 percent or follow-up rate decreases by 10 percent, we will ship reasoning traces to all users." The hypothesis defines what you are testing, how you will measure it, and what success looks like. Without the hypothesis, experimentation becomes random feature toggling without learning.

Experiments require sufficient sample size and duration. Running a 50/50 flag split for two days on 500 users will not detect anything but catastrophic differences. Use power analysis to calculate required sample size for your target effect size and statistical confidence. Run the experiment until you reach that sample size or the predetermined duration, whichever comes first.

Document experiment results. Regardless of whether the flag ships or gets removed, record what was tested, what was measured, what was found, and why the decision was made. Future engineers will propose the same experiment. The documentation prevents relitigating questions the team already answered.

A legal research platform ran six product experiments via feature flags in late 2025. Two experiments showed significant improvements and shipped to all users. Three showed no significant difference and were removed. One showed mixed results — improved quality but increased latency beyond acceptable thresholds — and was shelved for future optimization. The experimentation culture, enabled by feature flags, let them learn what users valued without committing to features that did not deliver value.

The next subchapter covers experiment analysis, the statistical methods for detecting real differences between model variants versus random noise, and the pitfalls that lead teams to incorrect conclusions.

