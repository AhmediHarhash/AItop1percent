# 10.5 — Rollback Criteria Design: When to Pull the Plug

Rollback criteria are the thresholds that trigger reverting to the previous model when a deployment degrades. They are not suggestions. They are hard limits that, when crossed, initiate rollback automatically or manually depending on severity. Defining rollback criteria before deployment begins is the difference between controlled incident response and chaotic emergency firefighting. Without predefined criteria, every deployment problem becomes a debate about whether things are bad enough to roll back. With predefined criteria, the decision is mechanical. The metric crosses the threshold. You roll back. You investigate later.

In March 2025, a financial compliance platform deployed a new document analysis model on a Friday afternoon. By Monday morning, three enterprise customers had filed complaints that the model was flagging legitimate transactions as suspicious at twice the baseline rate. The engineering team debated whether to roll back. Product argued the model was more sensitive, which was the goal. Engineering argued the false positive rate was unacceptable. Legal worried about regulatory implications. The debate consumed four hours. By Tuesday, two more customers threatened to churn. The team finally rolled back Wednesday morning, 96 hours after deployment. The delay cost them one customer contract and damaged relationships with four others.

The failure was not deploying a flawed model. Flawed models are inevitable. The failure was lacking rollback criteria that would have triggered automatic revert within hours of the first customer complaint. Clear criteria turn deployment decisions from political negotiations into operational procedures. When latency exceeds 3 seconds at 95th percentile, you roll back. When error rate exceeds 2 percent, you roll back. When three customers escalate concerns within 24 hours, you roll back. The criteria protect you from the optimism bias that makes engineers rationalize degradations instead of fixing them.

## The Three Tiers of Rollback Severity

Rollback criteria fall into three severity tiers based on how much harm the regression can cause and how fast it must be stopped. Tier 1 regressions trigger automatic rollback without human approval. Tier 2 regressions trigger alerts and human investigation with fast decision cycles. Tier 3 regressions trigger monitoring and investigation but do not block continued rollout unless evidence accumulates over days.

Tier 1 criteria are catastrophic regressions that cause immediate, unacceptable harm. Error rates that spike above critical thresholds. Latency that makes the system unusable. Outputs that violate legal or safety requirements. Data leaks that expose private information. Policy violations that trigger regulatory risk. When Tier 1 criteria are met, the system automatically reverts to the baseline model, pages on-call, and logs the incident. No human decision required. The rollback happens in seconds to minutes. Human investigation follows rollback, not before.

Tier 2 criteria are serious regressions that degrade user experience significantly but do not cause immediate catastrophic harm. User satisfaction dropping by more than 10 percent. Task completion rate dropping by more than 8 percent. Refusal rate doubling. Escalation rate increasing by more than 20 percent. Latency increasing by more than 500 milliseconds. When Tier 2 criteria are met, the system alerts on-call, presents comparison data and sample outputs, and waits for human decision. The human reviews evidence, assesses whether the regression is acceptable trade-off or deployment blocker, and either rolls back manually or continues with heightened monitoring. Decision cycle is minutes to hours.

Tier 3 criteria are subtle regressions that may indicate problems but require longer observation to confirm. User satisfaction dropping by 3 to 10 percent. Task completion dropping by 2 to 8 percent. Latency increasing by 100 to 500 milliseconds. Token cost increasing by more than 20 percent. When Tier 3 criteria are met, the system logs the observation, notifies the team via non-urgent channels, and continues rollout. The team reviews during business hours, investigates whether the regression is real or noise, and decides whether to continue, pause for deeper investigation, or roll back. Decision cycle is hours to days.

A customer support platform defined three-tier rollback criteria for their Claude Sonnet 4.5 deployment in November 2025. Tier 1: error rate above 2 percent, latency above 5 seconds at 95th percentile, any output containing customer PII in logs, any content policy violation flagged by automated review. Tier 2: user satisfaction score dropping by more than 0.5 points on a 5-point scale, resolution rate dropping by more than 10 percent, escalation rate increasing by more than 25 percent. Tier 3: satisfaction score dropping by 0.2 to 0.5 points, resolution rate dropping by 3 to 10 percent, response length increasing by more than 30 percent. During rollout, they hit a Tier 2 threshold on day four when escalation rate increased by 28 percent. Investigation found the model was escalating billing disputes that the baseline model had handled autonomously. The team tuned the escalation logic and redeployed successfully. Tier 2 criteria caught the problem before customer impact became severe.

## Defining Thresholds Relative to Baseline Variance

Rollback thresholds must account for normal variance in baseline metrics. If your baseline model's error rate fluctuates between 0.4 percent and 1.1 percent day to day, a new model with 1.0 percent error rate is not a regression — it is within normal range. The threshold must be calibrated to baseline behavior plus a margin that represents meaningful degradation.

The simplest approach is absolute thresholds based on historical baseline data. Measure your baseline model's error rate, latency, refusal rate, and other key metrics over several weeks. Compute mean and standard deviation. Set Tier 1 thresholds at mean plus three standard deviations — extreme outliers that indicate catastrophic failure. Set Tier 2 thresholds at mean plus two standard deviations — clear degradations beyond normal variance. Set Tier 3 thresholds at mean plus one standard deviation — potential degradations that require investigation. This approach works when baseline metrics are stable and normally distributed.

The more sophisticated approach is relative thresholds based on real-time comparison to a control group. Run the new model on some traffic and the baseline model on other traffic simultaneously. Compare metrics between groups in real time. If the new model's error rate is 50 percent higher than the control group's error rate at the same time, that is a regression regardless of whether both rates are within historical ranges. Relative thresholds catch regressions that absolute thresholds miss when baseline metrics drift over time due to changing traffic patterns.

Control charts provide statistical rigor for threshold setting. Plot baseline metrics over time with upper and lower control limits computed from historical variance. When the new model's metrics exceed control limits, the regression is statistically significant. Control charts account for autocorrelation, seasonality, and long-term trends in baseline metrics. They are more complex to implement but more accurate for metrics with significant time-dependent structure.

A healthcare diagnostic model used control charts for rollback thresholds in early 2026. They measured false negative rate, false positive rate, and escalation rate for their baseline model over 90 days. They computed upper control limits using three-sigma rules accounting for day-of-week and time-of-day variance. During canary rollout of a new model, false positive rate exceeded the upper control limit within 36 hours. Automatic rollback triggered. Investigation found the new model was flagging routine lab values as abnormal when collected outside standard testing hours. The control chart caught the regression because it accounted for time-of-day variance in the baseline, which simple absolute thresholds would have missed.

## Business Metrics Versus Technical Metrics as Rollback Triggers

Technical metrics like error rate and latency are easy to measure and fast to detect. Business metrics like user satisfaction and task completion reflect actual user value but are slower to measure and noisier. Rollback criteria need both. Technical metrics catch catastrophic failures within minutes. Business metrics catch silent degradations that technical metrics miss.

Error rate is a technical metric that must trigger Tier 1 rollback. If the model returns HTTP 500 errors or malformed responses on 2 percent of requests, user experience is broken regardless of what business metrics say. Error rate thresholds should be low — often 1 to 2 percent — because errors are unambiguous failures. A model that returns errors 5 percent of the time is not production-ready regardless of how good its non-error responses are.

Latency is a technical metric that must trigger Tier 1 or Tier 2 rollback depending on magnitude. A model that times out 50 percent of requests triggers Tier 1. A model that takes 500 milliseconds longer than baseline triggers Tier 2. Latency thresholds depend on user expectations and task type. A model that takes 3 seconds for real-time chat is broken. A model that takes 3 seconds for document analysis is fine. Calibrate thresholds to your product's latency budget.

User satisfaction is a business metric that triggers Tier 2 or Tier 3 rollback depending on magnitude and measurement confidence. If satisfaction drops by 15 percent within two days with high statistical confidence, trigger Tier 2 rollback. If satisfaction drops by 5 percent with moderate confidence, trigger Tier 3 investigation. Satisfaction is lagging — users need time to interact with the model before forming opinions. Satisfaction is noisy — individual users vary in ratings independent of model quality. But satisfaction is the truth metric that answers whether users prefer the new model.

Task completion is a business metric that triggers Tier 2 rollback. If users abandon tasks 20 percent more often with the new model, the model is failing at its purpose regardless of technical correctness. Task completion requires clear definition of what constitutes task success — a purchase, a form submission, a query resolved without escalation. Once defined, it is measurable from instrumentation and sensitive to model regressions that technical metrics miss.

A document summarization platform used a hybrid rollback approach with technical and business triggers. Tier 1 technical: error rate above 1.5 percent, latency above 4 seconds at 95th percentile. Tier 2 technical: latency above 2.5 seconds, token cost increase above 40 percent. Tier 2 business: user satisfaction dropping by more than 0.4 points, summary acceptance rate dropping by more than 12 percent. Tier 3 business: satisfaction dropping by 0.2 to 0.4 points, acceptance rate dropping by 5 to 12 percent. During a deployment in December 2025, they hit a Tier 2 business trigger when summary acceptance rate dropped by 14 percent. Technical metrics were all normal. Investigation found the model was generating accurate but overly concise summaries that users felt lacked important context. The team rolled back, adjusted the prompt to balance brevity and completeness, and redeployed successfully.

## Rollback Speed and Automation Requirements

When rollback criteria are met, how fast must rollback happen, and should it be automatic or manual? The answers depend on the severity tier and the cost of false positive rollbacks.

Tier 1 rollback must be automatic and fast — seconds to minutes. The regression is causing unacceptable harm. Every second the bad model runs, more users are harmed, more data is corrupted, more regulatory risk accumulates. Automatic rollback requires deployment infrastructure that can switch traffic back to the baseline model without human intervention. Feature flags, traffic routing rules, or deployment orchestration systems that detect threshold violations and execute rollback scripts. The system pages on-call after rollback completes, not before. The goal is stop the bleeding first, understand the wound later.

Tier 2 rollback should be human-in-the-loop but fast — minutes to hours. The regression is serious but not catastrophic. Human judgment improves decision quality because some Tier 2 thresholds are ambiguous. A 12 percent drop in task completion might be acceptable if conversion rate increased by 20 percent — the trade-off requires business judgment. But the decision cycle must be fast. Alert on-call immediately. Present evidence clearly. Provide one-click rollback tooling. The human should spend five minutes reviewing evidence and deciding, not two hours debugging in production while users suffer.

Tier 3 rollback can be manual and slow — hours to days. The regression is subtle and may not be real. Investigate during business hours. Review multiple days of data. Consult with domain experts and stakeholders. Tier 3 is not about emergency response. It is about careful evaluation of whether a small change represents a problem or a trade-off. Manual processes are fine as long as they are structured — assigned owners, clear decision-making frameworks, documented outcomes.

The cost of false positive rollbacks determines how cautious to be with automatic triggers. For low-stakes systems, false positives are cheap — you roll back unnecessarily, lose an hour investigating, and redeploy. For high-stakes systems, false positives are expensive — rolling back a model serving 10 million users requires coordination, communication, and stakeholder approval. High-stakes systems should use higher thresholds for automatic rollback and rely more on Tier 2 human-in-the-loop decisions. Low-stakes systems should use aggressive automatic rollback to minimize user harm.

A content moderation platform built automatic rollback for Tier 1 criteria using LaunchDarkly feature flags. Every model version had a feature flag controlling traffic percentage. A monitoring service watched error rate, latency, and policy violation rate in real time. When any Tier 1 threshold was exceeded, the monitoring service called the LaunchDarkly API to set the new model's flag to 0 percent and the baseline model's flag to 100 percent. Rollback completed in under 10 seconds. On-call received a page with the trigger metric and comparison data. The team investigated, fixed the issue, and redeployed. Automatic rollback caught three incidents in 2025, all within 20 minutes of threshold violations, before customer impact became severe.

## Subgroup Rollback: When the Model Fails for a Specific Segment

Sometimes a model works fine for most users but fails for a specific subgroup. The model handles English queries perfectly but produces gibberish for non-English queries. The model works on short documents but times out on long documents. The model serves individual users fine but fails for enterprise users with complex permissions. Aggregate rollback criteria miss these subgroup failures because the majority of traffic masks the minority's problems.

Subgroup-specific rollback criteria monitor metrics segmented by user attributes, query attributes, or context attributes. Error rate, latency, and satisfaction broken down by language, document length, user tier, geography, or any dimension that might correlate with differential model behavior. If a subgroup's metrics exceed thresholds even while aggregate metrics look normal, rollback for that subgroup. Subgroup rollback is partial — you revert the failing subgroup to baseline while keeping other subgroups on the new model.

Subgroup rollback requires routing infrastructure that can apply different models to different segments. Feature flags per user tier. Routing rules per language. Conditional logic that checks document length before choosing model. The infrastructure is more complex than simple traffic percentage splits, but it enables surgical rollback that protects vulnerable users without sacrificing gains for everyone else.

A multilingual customer support platform detected a subgroup failure during deployment in late 2025. Aggregate metrics showed the new model performing slightly better than baseline. Subgroup analysis revealed that error rate for non-English queries was 12 percent while error rate for English queries was 0.8 percent. The model had been fine-tuned primarily on English data. The team implemented subgroup rollback: English queries stayed on the new model, non-English queries reverted to baseline. They retrained with better multilingual coverage, tested again, and deployed globally once subgroup metrics converged.

## Documenting Rollback Decisions for Future Learning

Every rollback is a learning opportunity. Document what triggered the rollback, what investigation revealed, what fix was applied, and what was learned. The documentation serves three purposes: institutional memory, incident review, and trend analysis.

Institutional memory means future engineers understand why the system behaves the way it does. Six months after a rollback, someone will ask why the model does not use a particular feature that seems obviously useful. The rollback documentation explains that the feature was tried, caused a 15 percent increase in error rate for a specific query type, and was rolled back. Without documentation, the team relearns the same lesson by making the same mistake.

Incident review means the team collectively understands what went wrong and how to prevent recurrence. Post-rollback reviews should answer: what threshold triggered rollback, was the threshold appropriate or should it be adjusted, what was the root cause of the regression, how did testing miss the issue, what process changes would catch this earlier next time? The review is not about blame. The review is about system improvement.

Trend analysis means identifying patterns across multiple rollbacks. If three rollbacks in six months all involved edge cases with long documents, your testing process undersamples long documents. If two rollbacks involved subgroup failures for non-English users, your evaluation process is English-biased. Trends reveal systematic weaknesses that individual incidents do not.

A legal research platform maintained a rollback log in Notion documenting every deployment rollback from 2024-2026. Each entry included: date, model version, rollback trigger, investigation summary, root cause, fix applied, time to resolution, and process learnings. Over two years, they logged 18 rollbacks. Trend analysis revealed that 11 of 18 involved edge cases that were rare in production but nonexistent in eval suites. The insight led them to implement production sampling for eval suite construction, pulling 20 percent of test cases from real production queries monthly. Subsequent rollback rate dropped by 60 percent.

## Communicating Rollback to Stakeholders

Rollback is not just a technical operation. It is a communication event. Users, customers, internal stakeholders, and sometimes regulators need to know that a deployment was rolled back, why, and what happens next. The communication strategy depends on who was affected and how severely.

For Tier 1 rollbacks that affected many users with severe regressions, external communication is required. Send incident notifications to affected customers. Post status updates to public status pages. Provide timeline, root cause summary, and remediation plan. Transparency builds trust. Trying to hide a rollback damages trust when users inevitably notice behavior changes.

For Tier 2 rollbacks that affected moderate numbers of users with moderate regressions, targeted communication is appropriate. Notify affected customers individually if identifiable. Post internal incident reports. Inform executive stakeholders. The communication should be factual, non-defensive, and action-oriented.

For Tier 3 rollbacks that caught subtle regressions before widespread impact, internal communication is sufficient. Document in engineering logs. Inform the immediate team. Mention in sprint retrospectives. No customer communication needed because customer impact was minimal or nonexistent.

The communication cadence should be: immediate notification when rollback occurs, root cause summary within 24 hours, full incident report within one week. The immediate notification acknowledges the issue and sets expectations. The root cause summary explains what went wrong. The incident report documents learnings and prevention measures.

A healthcare diagnostics platform rolled back a deployment in January 2026 after detecting elevated false negative rates in a subgroup of cardiac imaging cases. They communicated via three channels: immediate email to affected hospital partners explaining the rollback and assuring them the baseline model was restored, a 24-hour root cause report explaining that a data imbalance in fine-tuning caused the regression, and a one-week incident report documenting testing process changes to prevent recurrence. The transparency strengthened partner relationships despite the rollback. Partners appreciated being informed proactively rather than discovering issues themselves.

## The Psychological Barrier to Pulling the Plug

The hardest part of rollback is psychological. Engineers are emotionally invested in their work. Rolling back a model they spent weeks training feels like failure. Product managers are invested in shipping features. Rolling back a launch feels like missed goals. Executives are invested in announcements. Rolling back a public release feels like embarrassment. The emotional resistance to rollback is real, and it causes teams to delay decisions that should be mechanical.

Predefined rollback criteria remove emotion from the decision. The metric crossed the threshold. The decision is made. There is no debate about whether things are "bad enough" to roll back. The criteria define "bad enough" before deployment begins. The role of humans is to execute the rollback, investigate the cause, and fix the issue. Not to negotiate whether to roll back.

Team culture must normalize rollback as a standard operational procedure, not a failure. The team that rolled back three times this year and caught regressions before user harm is more competent than the team that never rolled back because they shipped recklessly or got lucky. Rollback is evidence of discipline, not weakness.

Leadership sets the cultural tone. When executives praise teams for fast rollback decisions that protected users, rollback becomes something to be proud of. When executives question why a team rolled back and ask whether it was "really necessary," rollback becomes something to avoid. The former culture ships safer systems. The latter culture ships systems that fail publicly.

A fintech company adopted a "rollback retrospective" practice in mid-2025. Every rollback triggered a blameless retrospective within one week. The team reviewed what happened, what they learned, and how to improve. The retrospective concluded with public recognition in the engineering all-hands for the team member who made the rollback decision. The cultural message: we value protecting users over protecting egos. Over the next year, mean time to rollback decreased by 40 percent and rollback-related customer incidents dropped to near zero. The team learned to pull the plug fast.

The next subchapter covers prompt version observability, tracking what changed when you update system prompts and how to attribute behavior differences to specific prompt edits.

