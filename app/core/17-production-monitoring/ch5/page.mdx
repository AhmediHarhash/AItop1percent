# Chapter 5 — Retrieval and Knowledge Observability

RAG failures are silent and catastrophic. When retrieval returns the wrong documents, the model confidently generates answers grounded in irrelevant or outdated information. When your index goes stale, every response draws from a knowledge base that no longer reflects reality. When your embedding model drifts, semantic similarity stops meaning what it used to mean. The user sees a fluent, well-structured response with no indication that the underlying context was garbage. RAG observability requires monitoring not just whether retrieval happened but whether it retrieved the right things — index freshness, embedding consistency, chunk quality, citation coverage, and the dozen other signals that separate RAG systems that work from RAG systems that hallucinate with citations.

---

- 5.1 — Why RAG Failures Are Silent and Catastrophic
- 5.2 — Index Freshness Monitoring: Staleness Detection and Alerts
- 5.3 — Embedding Drift: When Your Vector Space Stops Matching Reality
- 5.4 — Retrieval Quality Metrics: Recall, Precision, and Context Relevance
- 5.5 — Context Window Utilization: Truncation Tracking and Waste Detection
- 5.6 — Citation and Source Coverage Monitoring
- 5.7 — Source Quality Signals: Dead Links, Outdated Content, Authority Decay
- 5.8 — Chunk Quality Degradation: When Your Splitting Strategy Breaks
- 5.9 — Multi-Index Coordination: Observability Across Knowledge Sources
- 5.10 — RAG Failure Patterns: The Named Anti-Patterns That Kill Accuracy

---

*The worst RAG failures look like the best responses. They are fluent, grounded, cited — and completely wrong because retrieval failed upstream.*
