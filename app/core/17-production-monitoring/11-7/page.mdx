# 11.7 — Cost Forecasting: Predicting Spend from Usage Trends

Cost forecasting turns reactive cost management into proactive budget planning. When you know what next month will cost within 10 to 15 percent accuracy, you can set realistic budgets, negotiate contracts with confidence, and catch unexpected drift before it affects quarterly targets. Forecasting relies on production data: historical spend, usage growth, traffic patterns, and model pricing. The models do not need to be sophisticated. Simple trend analysis catches 80 percent of what matters.

## Why Forecasting Matters

Most teams manage AI costs reactively. They see the invoice at the end of the month, compare it to expectations, and scramble to explain variances. Forecasting flips this. By mid-month, you know what the month will cost. By the end of Q2, you know what Q3 will cost. You plan instead of react.

In September 2025, a customer support platform forecasted October spend at $38,000 based on traffic trends, model usage, and recent cost-per-request averages. Actual October spend: $39,200. The 3 percent error gave Finance confidence to approve Q4 budgets without contingency padding. In November, forecasted spend was $42,000. Actual spend: $54,000. The 29 percent overage triggered investigation within the first week of November when the forecast diverged from actuals. The team found a retry loop bug and fixed it, preventing the problem from compounding through December.

Forecasting accuracy improves over time as you accumulate historical data and refine your models. A new system has little data and high uncertainty. A system running for six months can forecast with 10 percent accuracy. A system running for two years can forecast with 5 percent accuracy barring major changes.

## Traffic-Based Cost Forecasting

The simplest cost forecast multiplies expected request volume by cost per request. If you handle 100,000 requests this month at $0.08 per request, you will spend $8,000. If you expect 120,000 requests next month, you will spend $9,600.

A document summarization service tracks requests per day and cost per request. Over the last 30 days, daily requests averaged 8,200 with a standard deviation of 1,100. Cost per request averaged $0.11. To forecast next month's cost, the team multiplies expected daily requests by days in the month by cost per request: 8,200 requests times 30 days times $0.11 equals $27,060.

This forecast assumes traffic stays flat and cost per request stays flat. Neither assumption is usually true. Traffic grows or contracts. Seasonal patterns shift. Cost per request changes with prompt updates, model selection, and provider pricing. The flat forecast is a baseline. You refine it with trend analysis.

## Trend-Based Forecasting

Traffic rarely stays flat. Most systems grow. Some grow predictably—5 percent per month, 60 percent per year. Some grow erratically—spikes during product launches, drops during holidays. Trend-based forecasting projects historical growth into the future.

A legal research assistant tracked daily requests over six months. January: 2,400 requests/day. June: 4,100 requests/day. Growth rate: 11 percent per month on average. To forecast August spend, the team projects July traffic forward by 11 percent: 4,100 times 1.11 equals 4,551 requests/day. Multiply by 31 days and cost per request: 4,551 times 31 times $0.14 equals $19,750.

Linear trend forecasting works for systems with steady growth. For systems with seasonal patterns—higher traffic in Q4, lower in summer—use seasonal decomposition. Calculate the average traffic for each month of the year over multiple years. Apply the seasonal adjustment to the baseline trend.

A B2B SaaS platform sees 40 percent higher traffic in December than in July. To forecast December spend, they project the annual trend, then multiply by the seasonal factor. If baseline trend suggests 100,000 requests/day and December typically runs 1.4x the annual average, forecasted December traffic is 140,000 requests/day.

Trend forecasting breaks when traffic patterns change abruptly: a major customer churns, a viral feature launches, a competitor enters the market. Monitor forecast accuracy weekly. When actuals deviate from forecasts by more than 15 percent for two consecutive weeks, update the trend model.

## Cost-Per-Request Forecasting

Traffic forecasting predicts request volume. Cost-per-request forecasting predicts how much each request will cost. Both change over time. Prompt updates add tokens. Model upgrades change pricing. New features shift the mix of request types.

A customer success chatbot tracks cost per request over time. In August, cost per request averaged $0.09. In September, it increased to $0.11 due to a prompt change that added examples. In October, it dropped to $0.08 due to switching from GPT-5 to Claude Sonnet 4.5. To forecast November cost, the team uses the October average of $0.08, adjusted for any planned changes. If no changes are planned, the forecast assumes $0.08 per request. If a feature launch is planned that will increase token usage by 15 percent, the forecast uses $0.092 per request.

Cost-per-request forecasting requires tracking historical cost-per-request trends and understanding upcoming changes. A deployment that adds retrieval steps, a model switch, or a new prompt template all affect cost per request. Include these changes in the forecast.

## Feature-Level Forecasting

Not all traffic grows at the same rate. Some features grow faster than others. Some features cost more per request. Feature-level forecasting accounts for this mix.

A document assistant has three features: summarization, Q&A, and translation. Summarization handles 60 percent of requests at $0.08 per request. Q&A handles 30 percent at $0.12 per request. Translation handles 10 percent at $0.18 per request. Over the last three months, summarization traffic grew 8 percent per month, Q&A grew 15 percent per month, and translation grew 25 percent per month.

To forecast next month's cost, the team projects each feature's traffic and multiplies by its cost per request. Summarization: current 48,000 requests/month, projected 51,840 at $0.08 equals $4,147. Q&A: current 24,000 requests/month, projected 27,600 at $0.12 equals $3,312. Translation: current 8,000 requests/month, projected 10,000 at $0.18 equals $1,800. Total forecasted cost: $9,259.

Feature-level forecasting is more accurate than aggregate forecasting when different features have different growth rates or different costs. It also helps you understand where future spend will come from: if translation is growing fastest and costs the most, it will dominate future budgets unless you optimize it.

## User-Segment Forecasting

Some users cost more than others. Power users generate more requests. Enterprise customers use more expensive features. Free-tier users might be rate-limited but still contribute to aggregate cost. Forecasting by user segment predicts how changes in user mix affect costs.

A SaaS analytics platform has three user tiers: free, professional, enterprise. Free users cost $0.50/month on average. Professional users cost $8/month. Enterprise users cost $120/month. Current user counts: 10,000 free, 1,200 professional, 80 enterprise. Current monthly cost: $15,600.

The sales team forecasts adding 2,000 free users, 150 professional users, and 10 enterprise users next quarter. Forecasted cost: 12,000 free at $0.50 equals $6,000. 1,350 professional at $8 equals $10,800. 90 enterprise at $120 equals $10,800. Total: $27,600. Cost increases by 77 percent even though user count only increases by 17 percent because enterprise users—the most expensive segment—grew fastest.

User-segment forecasting is essential for products with tiered pricing or usage patterns that vary significantly by user type. It prevents surprises when high-cost users grow faster than expected.

## Seasonal and Event-Driven Forecasting

Some systems have predictable seasonal spikes: tax software peaks in April, retail AI assistants peak in November and December, B2B tools peak at quarter-end. Seasonal forecasting adjusts baseline trends to account for these patterns.

A financial assistant sees 3x traffic in April compared to the annual average. To forecast April costs, the team projects baseline traffic, then multiplies by the seasonal factor. Baseline forecast for April: 120,000 requests/day. Seasonal factor: 3x. Adjusted forecast: 360,000 requests/day. Cost per request: $0.10. Forecasted April cost: 360,000 times 30 times $0.10 equals $1,080,000.

Event-driven spikes—product launches, marketing campaigns, partnerships—require manual adjustment. The forecast model cannot predict a launch unless you tell it. A customer success bot forecasts traffic will increase by 50 percent during the month of a major product launch. The team adjusts the baseline forecast by 1.5x for that month.

Seasonal and event-driven forecasts require historical data from previous cycles. If you have never run a major product launch, you cannot forecast its cost impact with high confidence. Use conservative estimates—assume higher cost than you expect—and refine the model after the event.

## Model Price Change Scenarios

Model pricing changes affect costs without changing usage. If a provider drops prices by 20 percent, your costs drop by 20 percent with no engineering work. If they increase prices by 30 percent, your costs spike. Forecasting must account for known and anticipated price changes.

In October 2025, a document pipeline used GPT-5.1 at $3 per million input tokens. In November, OpenAI announced a price increase to $3.50 per million tokens effective December 1st. The team adjusted their December forecast by multiplying expected token usage by the new rate. Forecasted cost increased from $22,000 to $25,700. The forecast gave Finance advance notice to adjust budgets.

Some teams model multiple pricing scenarios: baseline (current pricing), optimistic (provider lowers prices by 15 percent), pessimistic (provider raises prices by 25 percent). This range helps Finance plan for uncertainty. Most teams use baseline for monthly forecasts and scenario analysis for annual budgets.

## Forecasting Model Accuracy and Error Tracking

Forecasts are wrong. The goal is not perfection—it is predictability. A forecast that is consistently wrong by 5 to 10 percent is useful. A forecast that swings from 20 percent under to 30 percent over is not.

A customer support platform tracks forecast accuracy monthly. August forecast: $31,000. Actual: $29,800. Error: 4 percent over. September forecast: $34,000. Actual: $38,200. Error: 12 percent under. October forecast: $40,000. Actual: $39,100. Error: 2 percent over. Average absolute error over three months: 6 percent.

The team reviews large errors to understand root causes. September's 12 percent error was due to a product launch that generated more traffic than expected. The team did not adjust the forecast for the launch because Marketing had not finalized the campaign timing. After the launch, they updated the model to include a 20 percent buffer for future product launches.

Tracking forecast accuracy improves the model over time. Consistent overestimation suggests the model is too conservative. Consistent underestimation suggests it is missing growth trends or underestimating feature costs. Adjust the model quarterly based on observed errors.

## Rolling Forecasts vs. Fixed Forecasts

Fixed forecasts predict a single future period: what will October cost? Rolling forecasts update continuously: what will the next 90 days cost? Rolling forecasts adapt as new data arrives, making them more accurate for systems with volatile traffic.

A legal research tool uses a rolling 90-day forecast. Every week, the system recalculates expected cost for the next 90 days based on the last 30 days of traffic trends and cost-per-request averages. The forecast updates as usage patterns shift. Finance always has a current estimate of near-term spend.

Fixed forecasts work well for stable systems with predictable traffic. Rolling forecasts work better for fast-growing systems or systems with high variability. Most teams use fixed forecasts for annual budgeting and rolling forecasts for operational planning.

## Confidence Intervals and Budget Buffers

Forecasts are point estimates: we expect to spend $42,000 next month. But reality has variance. Traffic might spike. A model upgrade might increase costs. A provider might have an outage that triggers retries. Confidence intervals quantify uncertainty.

A document summarization service forecasts October spend at $28,000 with a 90 percent confidence interval of $24,000 to $32,000. This means there is a 90 percent chance actual spend will fall within that range. Finance uses the upper bound—$32,000—for budget planning to avoid overage.

Confidence intervals depend on historical variance. A system with stable, predictable traffic has narrow intervals. A system with high variability has wide intervals. Calculate confidence intervals using standard deviation of historical forecast errors or bootstrap resampling of historical data.

Budget buffers—adding 10 to 20 percent to the forecast—serve a similar purpose. If the forecast says $28,000, budget $31,000 to $34,000. The buffer absorbs unexpected spikes without requiring emergency budget adjustments. Most teams use 10 percent buffers for monthly forecasts and 15 to 20 percent buffers for annual forecasts.

## Forecasting for Multi-Tenant Systems

Multi-tenant systems forecast cost per tenant, then aggregate. This reveals which customers are driving cost growth and which are stable.

A B2B SaaS platform serves 500 customers. Each customer has different usage patterns. The top 10 customers account for 60 percent of spend. The team forecasts cost per customer based on that customer's historical usage and growth trend, then sums across all customers.

Customer A: current $1,200/month, growing 5 percent/month, forecasted next month $1,260. Customer B: current $800/month, flat growth, forecasted $800. Customer C: current $2,400/month, growing 12 percent/month, forecasted $2,688. Sum across 500 customers: forecasted total $87,000.

Per-tenant forecasting catches when a single customer's usage is about to spike. The account team can proactively reach out, discuss usage patterns, and help the customer optimize before the cost becomes a churn risk.

## When Forecasts Fail

Forecasts fail when underlying assumptions change. A competitor launches a killer feature, your system loses traffic. A partnership brings 10x more users than expected. A model provider deprecates the model you use, forcing an emergency migration. Forecasts assume continuity. Disruptions break them.

A customer success chatbot forecasted November spend at $34,000 based on October trends. Actual November spend: $51,000. The 50 percent overage was caused by a viral social media post that drove a surge of new users. The traffic spike was unpredictable. The forecast was not wrong—the underlying assumption that traffic patterns would remain stable was invalidated.

When forecasts fail, do not abandon forecasting. Update the model with new information. If the viral traffic is temporary, exclude it from the baseline for future forecasts. If it represents a new normal, incorporate the higher traffic level into the model.

Forecasting is not fortune-telling. It is structured guessing based on historical patterns. When patterns change, forecasts diverge from actuals. That divergence is a signal to investigate and update assumptions.

The next subchapter covers cost governance—policies, controls, and organizational structures for managing costs across multi-team AI systems.

