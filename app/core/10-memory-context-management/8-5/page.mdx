# 8.5 â€” The Do-Not-Store List: Sensitive, Volatile, and Irrelevant Info

In March 2025, a customer service AI platform serving a telecommunications company began storing customer authentication codes in its conversation memory system. The platform, designed to provide personalized support across sessions, had been trained to remember contextually relevant details to improve continuity. Over four months, it accumulated 47,000 temporary access codes, including two-factor authentication tokens, password reset codes, and account verification numbers. When security auditors discovered the cache during a routine compliance review, they found codes that remained retrievable weeks after expiration. The telecommunications company faced a mandatory breach notification to 280,000 customers, a 1.2 million dollar regulatory fine, and eight months of remediation work. The root cause was not a technical vulnerability but a conceptual failure: the team had built a memory inclusion policy focused on what to remember, but had never defined what must never be stored.

The do-not-store list is the negative boundary of your memory system. While inclusion policies define what qualifies as valuable context worth persisting, the do-not-store list defines categories of information that must be identified and discarded regardless of apparent conversational relevance. This is not a feature you add after launch. It is a foundational security control that must be designed, tested, and enforced from the first conversation your system handles. Every piece of information that enters your memory pipeline must pass through do-not-store filtering before any storage decision occurs. The alternative is not merely reduced security. It is inevitable accumulation of toxic data that creates liability, violates regulations, and transforms your memory system from an asset into a legal hazard.

## The Three Categories of Do-Not-Store Content

Information that must never be stored falls into three distinct categories, each requiring different detection approaches and enforcement mechanisms. The first category is **sensitive credentials and identifiers**, which includes passwords, API tokens, cryptographic keys, social security numbers, financial account numbers, medical record numbers, biometric identifiers, and authentication codes. This content creates immediate security risk when persisted. A password mentioned in conversation remains a password whether stored for one hour or one year. The storage itself is the vulnerability. Detection requires pattern matching against known credential formats, entropy analysis to catch high-randomness strings that may be tokens, and semantic understanding to identify phrases like "my password is" or "the API key you need is" that precede credential disclosure.

The second category is **volatile information that becomes dangerous when persisted**. This includes current physical location, temporary emotional states, in-progress negotiations, pending transactions, draft decisions, and time-sensitive medical symptoms. This content is not inherently secret, but becomes misleading or harmful when retrieved out of temporal context. A user who mentions feeling anxious during a late-night conversation does not need that emotional state surfaced two weeks later as if it represents their current condition. A customer who mentions being at a specific address during delivery tracking does not need that location treated as their permanent residence. The danger is not unauthorized access but inappropriate reuse. Detection requires temporal reasoning to distinguish persistent facts from transient states, and contextual analysis to identify information that carries implicit time-boundedness.

The third category is **irrelevant information that wastes memory budget without adding value**. This includes conversational pleasantries, meta-discussion about the AI system itself, hedging language, error corrections, and topic-switching artifacts. A user who says "actually, never mind about that last question" has explicitly marked content as non-memorable. A conversation that begins with "hello, how are you today" does not need those pleasantries persisted. This content does not create security risk, but consumes storage resources and pollutes retrieval results. When your memory budget is 50 facts per user, you cannot afford to spend slots on "the user sometimes says thanks at the end of messages." Detection requires pragmatic analysis to identify speech acts that perform social functions without conveying information, and discourse analysis to recognize meta-conversational moves that manage the conversation itself rather than advancing its content.

## Pattern Matching for Credential Detection

Detecting sensitive credentials requires layered pattern matching that combines regular expressions, format validation, and entropy analysis. Start with explicit format patterns for known credential types. Social security numbers follow the pattern three digits, two digits, four digits, with or without separators. Credit card numbers are 13 to 19 digits following Luhn algorithm validation. API keys often follow provider-specific formats: OpenAI keys begin with specific prefixes, AWS keys follow identifiable structure, GitHub tokens use defined character sets. Maintain a library of these patterns and update it as new credential formats emerge. This catches credentials disclosed in standard formats.

But users do not always present credentials in standard formats. They add spaces, use verbal separators, or describe rather than state. A user might say "my card number is four-one-two-three space five-six-seven-eight" or "the last four digits are 9876." Your pattern matching must handle these variations. Use phonetic normalization to convert spelled-out numbers to digits. Use semantic parsing to identify credential-describing phrases even when the credential itself is partially obscured. A phrase like "my security code is star-star-star-45" still contains sensitive information even though most digits are masked.

Entropy analysis catches high-randomness strings that may be tokens or keys even when they do not match known formats. Calculate character-level entropy for any string of 16 or more characters. If entropy exceeds a threshold indicating random generation, flag it for review. This catches custom API keys, session tokens, and proprietary authentication codes. But entropy alone creates false positives. The word "incomprehensibility" has high entropy but is not a credential. Combine entropy analysis with contextual signals. High-entropy strings mentioned after phrases like "the token is" or "paste this key" are credential candidates. High-entropy strings in academic discussion about cryptography are probably examples, not secrets.

## Volatile Information and Temporal Context

Volatile information requires temporal reasoning to distinguish persistent facts from transient states. When a user mentions their location, you must determine whether they are providing a permanent address or describing current position. The phrase "I live in Seattle" indicates persistent fact. The phrase "I am at the airport" indicates transient state. The phrase "I am at 123 Main Street" is ambiguous and requires additional context. Are they receiving a delivery, visiting a friend, or providing their home address? Temporal markers provide clues. "I am currently at" signals transience. "My address is" signals persistence. "I will be at" explicitly marks future transience.

Emotional states pose similar challenges. Mental health applications must distinguish between chronic conditions that should inform ongoing care and acute states that should not be surfaced out of context. A user who says "I have been diagnosed with depression" is providing a persistent medical fact. A user who says "I am feeling really down today" is reporting a transient state. A user who says "I have been feeling anxious for three weeks" is reporting something in between: potentially significant but not yet diagnosed. Your do-not-store policy must account for these gradations. One approach is to store the fact that emotional health is a relevant topic for this user without storing specific day-to-day mood reports. Another is to store mood data with strict temporal boundaries: retrieve only information from the past seven days, and automatically expire anything older.

Negotiation states and pending decisions require careful handling in business contexts. A user negotiating a contract might discuss price ranges, decision factors, and alternative options. Some of this is strategic positioning that should not be persisted. Some is genuine preference that should inform future interactions. The distinction depends on linguistic markers of tentativeness versus commitment. "I might accept 50,000 dollars" is strategic positioning. "My budget ceiling is 50,000 dollars" is a constraint. "I would never go above 50,000 dollars" is a strong preference. But even strong preferences can change when negotiations conclude. A purchasing agent who says "we only buy from suppliers with ISO certification" during vendor evaluation does not need that requirement surfaced six months later when they are discussing a different product category. Store negotiation outcomes, not negotiation processes.

## Irrelevant Content Filtering

Irrelevant content wastes memory budget without adding value, and filtering it requires understanding conversational pragmatics. Pleasantries and social rituals serve important functions in conversation but do not constitute memorable information. "Hello," "thank you," "have a great day" are speech acts that maintain rapport without conveying facts. They should be recognized and discarded during memory extraction. This requires distinguishing between social functions and informational functions. "Thank you for your help" is a pleasantry. "Thank you for processing my refund" contains a fact: a refund was processed. The gratitude is not memorable, but the transaction is.

Meta-conversation about the AI system itself is rarely worth storing. Users frequently discuss the AI's capabilities, limitations, or behaviors. "Can you remember things from our previous conversations?" is a question about system functionality, not a fact about the user. "You keep misunderstanding my questions about Python" might feel like information worth remembering, but storing "the user thinks I misunderstand Python questions" does not improve future performance. It creates a self-referential loop where the AI retrieves information about past AI performance instead of information about the user's actual needs. Meta-conversation should trigger system logging for quality monitoring, not memory storage for user context.

Error corrections and topic switches are conversational repairs that should not persist as facts. When a user says "actually, I meant Java, not JavaScript," the correction should update or prevent storage of the erroneous information, but the correction itself is not memorable. When a user says "never mind, let's talk about something else," the abandoned topic should not be stored as a user interest. These moves are discourse management, not content contribution. Your memory extraction must recognize them as instructions about what not to remember.

However, patterns of errors and topic switches can be informative at an aggregate level. If a user frequently corrects programming language names, that suggests they work across multiple languages and precision matters to them. If a user often abandons topics related to advanced configuration, that suggests they prefer simplified explanations. This meta-pattern can be valuable context, but it must be stored as a derived insight, not as a collection of individual correction instances. Store "user works with multiple programming languages and values precise terminology" rather than storing 15 instances of language-name corrections.

## Building and Maintaining the Do-Not-Store List

The do-not-store list is not static. It evolves as your application encounters new domains, regulations change, and security threats emerge. Start with a foundational list covering universal sensitive categories: authentication credentials, government identifiers, financial account numbers, medical record numbers, biometric data. This core list applies to nearly every application and should be implemented before you handle your first production conversation.

Extend the list with domain-specific categories based on your application context. A healthcare application must never store patient names in association with diagnoses when those associations would violate minimum necessary disclosure principles under HIPAA. A financial services application must never store full account numbers even when users provide them for support purposes. A legal application must never store information marked as attorney-client privileged unless you have explicit controls ensuring it remains isolated. Domain-specific categories require consultation with compliance experts who understand the regulations governing your sector.

Incorporate user-reported categories through feedback mechanisms. Provide a way for users to explicitly mark information as non-memorable. "Do not remember this" or "this is just for this conversation" should trigger immediate exclusion from memory storage. Some users will provide sensitive information because they need help with an immediate problem, but do not want that information persisted. A user troubleshooting a credit card decline might share the card number to verify you are seeing the right account, but does not want that number stored. Explicit user requests override default inclusion policies.

Maintain the list as a version-controlled artifact with clear ownership and review processes. Every addition to the do-not-store list should be documented with rationale, detection approach, and test cases. Every removal from the list requires justification and risk assessment. The list is a security control, and changes to security controls require rigor. Quarterly reviews ensure the list remains aligned with current threats and regulations. When the EU AI Act added new transparency requirements in 2025, many organizations discovered their do-not-store lists had not been updated to reflect the prohibition on storing inferences about protected characteristics without explicit consent.

## Handling Edge Cases and User Requests

The most challenging edge case is when users explicitly ask you to remember information that falls on the do-not-store list. A user might say "remember my password is X so I don't have to keep telling you." Your response must refuse the request while explaining why. "I cannot store passwords or authentication credentials for security reasons. Storing this information would create risk for your account. I can help you set up a password manager instead." This combines refusal with education and alternative solution.

Some edge cases involve partial information that becomes sensitive only in combination. The last four digits of a credit card are not sensitive alone, but become sensitive when stored alongside the user's full name and billing address. A birthdate is not sensitive alone, but becomes sensitive when stored with name and social security number components. Your do-not-store enforcement must consider combinatorial risk. One approach is to prohibit storage of any element that appears in multi-factor identification schemes used by financial institutions or government agencies. Another is to track what combinations already exist in your memory store and block additions that would complete a sensitive set.

Temporary exemptions create another edge case. During a support interaction, a representative might need to reference sensitive information the user has provided. "You mentioned your account number ending in 4356" is a legitimate conversational reference that requires temporary retention during the active session but must not persist beyond it. This requires distinguishing between session-scoped memory and persistent memory. Session-scoped memory expires when the conversation ends. Persistent memory survives across sessions. Do-not-store enforcement applies differently to each. Sensitive information may be allowed in session-scoped memory with strict expiration, but blocked entirely from persistent memory.

Medical symptoms present a nuanced edge case. A user discussing health concerns expects the AI to remember relevant medical context, but not every symptom mention should persist. Acute symptoms during an illness should not be retrieved months later as if they represent current health status. Chronic conditions should be stored as ongoing context. The distinction requires temporal and severity reasoning. "I have a headache today" is an acute symptom. "I have chronic migraines" is a persistent condition. "I have been having headaches for three weeks" is acute but potentially becoming chronic. Store chronic conditions, expire acute symptoms, and flag potentially-chronic patterns for review.

## Regulatory Do-Not-Store Requirements

GDPR Article 9 defines special categories of personal data that require heightened protection: racial or ethnic origin, political opinions, religious or philosophical beliefs, trade union membership, genetic data, biometric data, health data, and data concerning sex life or sexual orientation. Processing these categories requires explicit consent with limited exceptions. Your do-not-store list must include these categories unless you have verified legal basis for processing and storage. Even with legal basis, storage should be minimized. If your application does not require health data to function, do not store it even if users volunteer it.

The challenge is that users often disclose special category data organically in conversation. A user might mention their religious dietary restrictions when discussing recipe recommendations, or their political views when discussing news topics, or their health conditions when explaining scheduling constraints. Your system must detect these disclosures and either exclude them from memory or store them under heightened controls with explicit consent confirmation. Detection requires both keyword matching and semantic understanding. "I am vegetarian for religious reasons" contains both dietary preference and religious belief. The dietary preference may be necessary context for recipe recommendations. The religious belief is special category data that requires separate handling.

HIPAA defines 18 identifiers that must be removed to achieve de-identification of protected health information. These include names, geographic subdivisions smaller than state, dates directly related to an individual, phone numbers, email addresses, social security numbers, medical record numbers, health plan numbers, account numbers, certificate numbers, vehicle identifiers, device identifiers, URLs, IP addresses, biometric identifiers, photos, and other unique identifying numbers or codes. If your application operates in healthcare contexts, your do-not-store list must cover all 18 identifiers, or you must implement de-identification before storage.

The EU AI Act, enforced since 2025, adds requirements for high-risk AI systems including prohibition on using AI for social scoring, real-time biometric identification in public spaces without authorization, and manipulation through subliminal techniques. While these prohibitions target system design more than data storage, they create implicit do-not-store requirements. If your system cannot legally use emotional manipulation, it should not store detailed emotional profiles that could enable manipulation. If your system cannot legally perform social scoring, it should not store the data that would make scoring possible. Regulatory compliance drives do-not-store policy even when regulations do not explicitly mandate storage prohibitions.

## Testing Do-Not-Store Enforcement

Testing do-not-store enforcement requires both automated checks and manual red teaming. Automated testing uses a library of test cases containing known sensitive patterns. Feed your memory pipeline conversations that include credit card numbers, social security numbers, API tokens, passwords, and other do-not-store content. Verify that none of this content appears in stored memory. Verify that retrieval queries attempting to access this content return no results. This catches failures in pattern matching and filtering logic.

But automated pattern matching is not sufficient. Users disclose sensitive information in creative ways that evade simple patterns. Red team exercises require human testers to attempt disclosing do-not-store content using obfuscation, verbal description, indirect reference, and other evasion techniques. A tester might say "my social is the year I was born followed by the day and month, then 4567." This does not match standard social security number patterns but still discloses a social security number. Another tester might say "remember that my password is the name of my first pet plus my birth year." This discloses password structure that could enable guessing attacks. Red team findings drive improvements to semantic understanding and indirect disclosure detection.

Test the boundary between do-not-store and acceptable storage. Create test cases where sensitive and non-sensitive information appear in close proximity. "My email is john at example dot com and my password is X" should store the email but not the password. "My credit card ending in 4356 was charged incorrectly" should store the customer service issue but not the partial card number. "I live at 123 Main Street and my social security number is Y" should store neither, because the address becomes sensitive in combination with the social security number. Boundary testing reveals whether your system understands context and combination risk.

Monitor production conversations for do-not-store violations that evaded detection. Build reports showing all stored memory items containing high-entropy strings, numeric sequences of certain lengths, or keywords associated with sensitive categories. Review a sample of these items weekly. When you find a violation, trace it back through your pipeline to understand why filtering failed. Was the pattern not in your detection library? Did semantic understanding fail to recognize the disclosure? Was the content categorized as borderline and your policy was unclear? Each violation informs improvements to detection and enforcement.

## The Difference Between Do-Not-Store and Store-But-Do-Not-Retrieve

Some information should be stored for compliance or safety purposes but must not be retrieved for conversational use. Audit logs, abuse reports, and safety escalations fall into this category. When a user makes a threat or discloses intent to harm, you must log that information for review by human safety teams. But you should not retrieve that logged information to personalize future conversations. The storage serves a protective purpose that is legally and ethically distinct from memory-based personalization.

This distinction requires separate storage tiers with different access controls. Conversational memory lives in a retrieval-optimized store that your AI accesses freely to personalize responses. Safety logs live in an append-only audit store that only authorized human reviewers can access. The two stores may contain overlapping information about the same conversation, but they serve different purposes and operate under different policies. A user who discusses self-harm triggers a safety log entry that human reviewers see. That same conversation does not create a memory entry that the AI retrieves in future interactions to ask "how are you feeling about those self-harm thoughts we discussed last week?" The AI should not initiate retrieval of trauma-related content.

However, if the user themselves reintroduces the topic, the boundary shifts. A user who says "I want to continue our conversation about my depression" is explicitly opting into retrieval of that context. Your system must distinguish between AI-initiated retrieval, which should not occur for sensitive health content without opt-in, and user-initiated retrieval, which honors the user's agency. This requires flagging certain memory categories as retrieval-restricted with user-override. The memory exists and can be retrieved when the user signals desire for continuity, but is not retrieved automatically.

Financial transaction details present a similar pattern. You must log all transactions for audit and dispute resolution purposes. But you should not retrieve transaction history to personalize marketing. A user who purchased a specific product should not receive that product's details inserted into unrelated conversations. The transaction log serves compliance purposes. Conversational memory serves personalization purposes. Keeping these separate prevents the compliance tail from wagging the personalization dog. When regulations require data retention, store it where retention obligations are clear. When user experience benefits from personalization, store it where retrieval policies prioritize user control.

In the next subchapter, we will examine cross-tenant memory isolation and the architectural patterns that prevent one user's memories from leaking to another user, along with the testing regimes required to verify isolation holds under production conditions.
