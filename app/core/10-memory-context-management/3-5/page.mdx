# 3.5 — Memory Budgets for Long-Running Agent Tasks

In October 2025, a legal technology company deployed an AI research agent designed to analyze patent portfolios and generate prior art reports. The agent was meant to run for twenty to thirty minutes per task, searching patent databases, extracting relevant sections, comparing claims, and building comprehensive analysis documents. The initial deployment went smoothly for the first dozen tasks. Then the costs started appearing. A single thirty-minute research session was consuming 180,000 tokens in context management alone, separate from the actual generation work. The engineering team investigated and discovered that their agent was retaining every single tool call result in memory for the entire session duration. Fifty-three database queries, forty-two document extractions, thirty-seven comparison operations, all held in active memory simultaneously. By minute twenty-five, the agent was spending more tokens re-reading its own accumulated history than it was spending on actual analysis. The cost per research task had ballooned to forty-seven dollars, three times the projected budget. Worse, the quality was degrading toward the end of long sessions because the model was drowning in its own memory, unable to distinguish critical findings from routine search results. The root cause was simple: they had built an agent with no memory budget, no pressure valves, no mechanism to decide what could be safely compressed or discarded as the task progressed.

Long-running agent tasks create memory accumulation problems that short interactions never encounter. When an agent runs for minutes or hours, every tool call adds to the memory burden. Every search result, every API response, every intermediate calculation becomes part of the context that must be maintained. Without explicit budgets and pressure management, these systems inevitably hit one of three failure modes: runaway costs that make the task economically unviable, context overflow that crashes the session, or quality degradation as signal drowns in accumulated noise. Setting memory budgets for long-running tasks is not an optimization exercise. It is a fundamental requirement for production agent systems that operate at time scales beyond simple question-answer exchanges.

## The Memory Accumulation Problem in Extended Agent Sessions

A typical long-running agent task follows a predictable memory accumulation curve. In the first few minutes, memory grows linearly as the agent executes initial tool calls and stores results. This is the exploration phase where the agent is gathering information, building context, establishing the problem space. Memory growth during this phase is expected and useful. Each new piece of information contributes meaningfully to the agent's understanding of the task.

Then the curve starts to steepen. As the agent moves into deeper analysis, it begins executing dependent operations where each new tool call builds on previous results. A research agent might extract a document, analyze its sections, compare findings against prior extractions, then execute new searches based on those comparisons. Each step adds new memory while still retaining all previous steps. By minute fifteen, a research agent that started with 5,000 tokens of memory might be carrying 80,000 tokens. By minute twenty-five, that number might reach 150,000 tokens. The memory is not just growing, it is accelerating.

The problem intensifies because agents typically need to reference their own history to make decisions about next actions. Unlike a simple API call where each request is independent, an agent in the middle of a long-running task must look back at what it has already discovered to decide what to investigate next. This creates a feedback loop where memory consumption drives the need for larger context windows, which in turn makes each decision more expensive, which makes the overall task cost grow superlinearly with time.

Consider a customer service agent handling a complex account issue that requires investigating transaction history, checking policy documents, verifying eligibility rules, and coordinating with external systems. The agent might run for twelve minutes across twenty-eight tool calls. Early in the session, it retrieves the customer's account profile—2,400 tokens. Then it fetches the last six months of transactions—8,200 tokens. Then it searches policy documents for relevant rules—6,700 tokens. Then it checks eligibility against three different criteria—4,100 tokens. Then it queries external systems for verification—5,300 tokens. We are now at 26,700 tokens of accumulated memory and the agent is only halfway through the task. If the system has no memory budget, this number will continue growing until the task completes or the context window fills.

The cost implications are severe. If each agent decision point requires reading the full accumulated memory, and the agent makes forty decisions across a twenty-minute task, you are paying to process that growing memory buffer forty times. A naive implementation might consume 800,000 tokens of input processing across the full task even though it only generates 15,000 tokens of actual output. The ratio of memory overhead to productive work becomes absurd.

## Defining Memory Budgets: Total Tokens and Item Limits

A memory budget is a hard constraint on how much memory an agent can accumulate before it must start making decisions about what to compress or discard. There are two primary budget dimensions: total token count and total item count. Both matter, and they interact in non-obvious ways.

Total token budget is the maximum number of tokens the agent is allowed to hold in active memory at any point during the task. This is not the same as the model's context window limit. Your memory budget should be significantly smaller than the context window because you need room for the system prompt, the current tool call, the model's reasoning, and the response generation. If you are using a model with a 200,000 token context window, your agent's memory budget might be 80,000 tokens. This leaves 120,000 tokens for everything else. Setting the budget as a fraction of the context window—typically forty to fifty percent—gives you safety margin and predictable behavior.

Total item budget is the maximum number of discrete memory items the agent can retain. A memory item might be a tool call result, a document chunk, an intermediate analysis, a piece of user feedback. Item count matters because even small items create cognitive load. An agent with 300 items in memory, even if the total tokens are within budget, is dealing with a searchability and relevance problem. The model must scan through 300 items to find the relevant pieces for each decision. Item budgets are typically set based on task type. A research agent might have an item budget of sixty items. A customer service agent might have an item budget of forty items. A code review agent might have an item budget of thirty items. These numbers are derived from empirical testing of when agents start showing decision quality degradation.

The interaction between token budgets and item budgets creates interesting constraint dynamics. You might hit your item budget before your token budget if the agent is working with many small pieces of information. You might hit your token budget before your item budget if the agent is working with a few large documents. A well-designed memory management system monitors both dimensions and triggers compression or eviction when either limit is approached.

Setting the actual budget numbers requires understanding your task economics and quality requirements. Start with cost constraints. If your task must complete for under five dollars, and your model charges fifteen dollars per million input tokens, you can afford roughly 330,000 input tokens across the entire task. If the task runs for twenty minutes with forty decision points, that is 8,250 tokens average per decision. If your memory budget is 60,000 tokens, you are spending 2.4 million tokens across all decisions just on memory, which is thirty-six dollars. That exceeds your cost constraint. You need a smaller memory budget, more aggressive compression, or a cheaper model.

Quality requirements push in the opposite direction. If the task requires maintaining detailed context about dozens of related findings to produce accurate final analysis, a very small memory budget will force premature compression and degrade output quality. You need enough budget to keep critical information in full fidelity while the task is active. The right budget is the minimum that maintains acceptable quality while staying within cost constraints. Finding that minimum requires empirical testing, not guessing.

## Memory Pressure: Recognition and Response Strategies

Memory pressure occurs when the agent's accumulated memory approaches budget limits. This is not a failure state, it is a signal that the system must make active decisions about memory management. Recognizing memory pressure early and responding appropriately is what separates professional agent implementations from naive ones that crash or degrade unpredictably.

The simplest pressure indicator is a threshold percentage of budget consumed. When memory reaches seventy-five percent of token budget or eighty percent of item budget, the system enters a pressure state. This threshold gives you enough warning to execute compression or eviction before hitting hard limits. Some systems use a yellow zone and a red zone—yellow at seventy-five percent, red at ninety percent. In yellow zone, the system begins selective compression. In red zone, the system executes aggressive eviction.

More sophisticated pressure detection looks at memory growth rate, not just absolute level. If memory is growing at 5,000 tokens per minute and you have 20,000 tokens of budget remaining, you have four minutes until budget exhaustion. If the expected task duration is fifteen minutes, you are on a collision course. Growth-rate-based pressure detection allows the system to act proactively before thresholds are hit. This is particularly valuable for agents with highly variable tool call result sizes where memory can spike suddenly.

Once pressure is detected, the system has four response strategies: selective compression, progressive summarization, item eviction, and task segmentation. These are not mutually exclusive. Production systems often use combinations based on memory item types and task phase.

Selective compression targets specific memory items that are large but contain information that can be condensed without losing critical details. A document retrieval result that returned twelve pages of text might be compressed to a summary of key points and a reference to the original source. The original twelve pages might have been 8,400 tokens. The compressed version might be 800 tokens. You have freed 7,600 tokens of budget. Selective compression works best on items that are primarily informational rather than operational. A search result can be summarized. A tool call that modified system state probably cannot be, because the exact parameters matter for audit trails.

Progressive summarization applies compression in stages as memory pressure increases. In the first stage, you might compress the oldest twenty percent of memory items. If pressure continues to increase, you compress the next twenty percent. Eventually you might be left with only the most recent and most critical items in full form, with everything else compressed to minimal summaries. Progressive summarization maintains detail where it matters most—recent context and explicitly marked critical findings—while aggressively condensing older context that is less likely to be relevant to current decisions.

Item eviction removes memory items entirely. This is appropriate for items that were useful at a particular task phase but are no longer relevant. If a research agent spent the first five minutes exploring a particular hypothesis, then determined that hypothesis was not viable, the memory items related to that exploration can be evicted entirely. They served their purpose, the decision was made, retaining them is pure overhead. Eviction is riskier than compression because information is permanently lost, but for long-running tasks it is often necessary. The key is having clear rules about what is evictable. Intermediate search results that did not lead anywhere: evictable. Tool calls that modified state: not evictable. User instructions: not evictable. Final analysis results: not evictable.

Task segmentation is the most aggressive response to memory pressure. When a task is going to run long enough that even aggressive compression and eviction will not prevent budget exhaustion, you segment the task into phases with explicit memory handoffs between phases. Phase one might be exploration and information gathering. At the end of phase one, you produce a compressed summary of findings and clear the detailed memory. Phase two starts with that summary and proceeds to detailed analysis. At the end of phase two, you produce conclusions and recommendations, clearing the analysis memory. This approach is common in research agents that run for hours. The downside is that information lost in phase boundaries can degrade quality. The upside is that each phase operates with a clean memory budget.

## Implementing Token and Item Budget Tracking

Tracking token consumption in agent memory requires maintaining running counts that update with every memory operation. When a new tool call result is added to memory, you tokenize it and add the token count to your running total. When an item is compressed, you subtract the old token count and add the new one. When an item is evicted, you subtract its token count. This running total must be accurate because it drives pressure detection and response decisions.

The naive approach to token counting is to retokenize the entire memory buffer after every operation. This works for small memory sets but becomes a bottleneck for long-running agents. If your memory contains fifty items totaling 70,000 tokens, and you are retokenizing all 70,000 tokens after every operation, you are spending significant compute just on bookkeeping. The better approach is incremental counting. Each memory item stores its own token count as metadata when it is created. The total memory token count is the sum of individual item counts. When you add an item, tokenize it once, store the count, and add it to the total. When you remove an item, subtract its stored count. This reduces tokenization overhead to only new or modified items.

Item counting is simpler because it is just tracking the length of your memory list. Every add increments the count, every removal decrements it. The complexity comes from defining what counts as an item. Is a tool call and its result one item or two? Is a document chunk that gets split into three pieces one item or three? The answer depends on your memory model, but the important thing is consistency. Define your item granularity clearly and count consistently against that definition.

Budget enforcement happens at memory write time. Before adding a new item to memory, you check whether the addition would exceed token or item budgets. If it would, you execute pressure response before completing the add. This prevents budget violations but creates a decision point: do you compress existing memory to make room for the new item, or do you compress the new item before adding it? The answer depends on relative information value. If the new item is a critical tool call result and the oldest memory item is a routine search that returned no results, you probably want to evict the old item and add the new one at full fidelity. If the new item is less critical, you might compress it on arrival.

Some systems implement budget headroom tracking. Instead of allowing memory to grow all the way to budget limits, they maintain a headroom buffer. If your token budget is 80,000, you might set the enforcement threshold at 72,000, leaving 8,000 tokens of headroom. This buffer absorbs temporary spikes where a tool call returns an unexpectedly large result. Without headroom, that spike would trigger immediate compression, which might be premature if the next operation is going to evict several old items anyway. Headroom smooths out the compression/eviction cycles and reduces unnecessary churn.

Tracking and enforcement mechanisms must be instrumented because memory budget behavior is not always intuitive. You need metrics on how often pressure states are triggered, how much memory is freed by each compression operation, how many items are evicted per task, and what the final memory utilization was at task completion. These metrics reveal whether your budgets are well-tuned or whether you are compressing too aggressively or too conservatively. If you are routinely ending tasks with only forty percent of budget used, your budget might be too large and you are paying for context you do not need. If you are hitting pressure states in the first two minutes of every task, your budget is too small.

## Cost Implications of Unbounded Agent Memory

An agent with no memory budget is an agent with unbounded cost exposure. The costs scale in ways that are not immediately obvious because they interact with task duration, tool call frequency, and decision complexity. Understanding these interactions is necessary to recognize why unbounded memory is not just expensive, but often economically unviable for production use.

The primary cost driver is input token consumption. Every time the agent makes a decision about what to do next, it reads its accumulated memory as part of the decision context. If the agent makes forty decisions across a twenty-minute task, and average memory size is 60,000 tokens, you are consuming 2.4 million input tokens just on memory reads. At GPT-5's January 2026 pricing of five dollars per million input tokens, that is twelve dollars of memory cost alone. If the task is only supposed to generate value worth fifteen dollars, you have consumed eighty percent of value on memory overhead.

The cost scales superlinearly with task duration because memory grows during the task. The first decision might read 8,000 tokens of memory. The twentieth decision reads 55,000 tokens. The fortieth decision reads 95,000 tokens. The total input consumption is not forty times the average, it is forty times a growing average. This superlinear scaling is why long-running agents hit cost walls even when initial projections looked reasonable.

Multi-tool-call operations amplify costs further. Some agent frameworks execute multiple tool calls in parallel, then collect all results before the next decision. If the agent executes five parallel tool calls, and each returns 4,000 tokens of results, you have added 20,000 tokens to memory in a single step. The next decision now reads 20,000 more tokens than the previous one. Parallel tool execution is valuable for reducing latency, but without memory budgets it creates cost spikes that can make individual decisions absurdly expensive.

Cost unpredictability is as damaging as absolute cost. If a task is supposed to cost three dollars but sometimes costs thirty dollars because memory happened to accumulate more than usual, you cannot budget for deployment. The variance makes the system economically unstable. Memory budgets provide cost predictability. If memory is capped at 60,000 tokens and the agent makes at most fifty decisions, your maximum input consumption is 3 million tokens, which is fifteen dollars at current GPT-5 pricing. You know the ceiling. You can budget against it. You can decide whether the task is economically viable.

Some teams try to control costs by using cheaper models for long-running tasks. This works only if the cheaper model has sufficient capability for the task. Switching from GPT-5 to GPT-5-mini cuts input costs by a factor of ten, but if the task requires GPT-5's reasoning capability, you have not saved money, you have produced useless output. The right approach is to use the capable model with strict memory budgets, not to use an incapable model with unbounded memory.

Another cost consideration is developer time wasted debugging cost overruns. When an agent task suddenly costs forty dollars instead of four dollars, someone has to investigate. They pull logs, analyze token consumption, trace memory accumulation patterns, identify which tool calls produced oversized results. This investigation might take two hours of engineer time. If it happens repeatedly because the system has no memory budgets, you are burning engineering capacity on firefighting instead of feature development. Memory budgets prevent these surprises.

## Progressive Summarization Triggers and Strategies

Progressive summarization is the technique of gradually compressing memory detail as items age and as memory pressure increases. The term progressive indicates that summarization happens in stages, not all at once, and that the level of compression increases over time. This preserves recent detail while freeing budget from older context that is less likely to influence current decisions.

The most common trigger for progressive summarization is item age combined with memory pressure. When memory pressure crosses into yellow zone—seventy-five percent of budget consumed—the system identifies memory items older than a certain threshold, say five minutes for a twenty-minute task. Those items are compressed to half their original token count. If pressure increases to red zone—ninety percent of budget—items older than three minutes are compressed to twenty-five percent of original size, and items older than seven minutes are compressed to ten percent or evicted entirely.

Age alone is not sufficient because recent items might be irrelevant and old items might be critical. A better trigger combines age with reference frequency. If a memory item has not been referenced in the last eight decision cycles, it is a candidate for aggressive compression regardless of age. If a memory item has been referenced three times in the last four cycles, it should be preserved at high fidelity even if it is old. Reference frequency is tracked by instrumenting memory reads. Every time the agent's decision process accesses a memory item, you increment its reference counter and update its last-access timestamp.

Content type is another trigger dimension. Some memory items compress well and others do not. Narrative search results, document summaries, and explanatory text compress effectively because the model can extract key points and discard redundant phrasing. Structured data like API responses, database query results, and tool call parameters compress poorly because every field might be semantically important. A progressive summarization strategy might aggressively compress narrative content while preserving structured content at full fidelity until item eviction becomes necessary.

The actual summarization operation is typically an LLM call. You take the original memory item, send it to the model with a prompt like "Compress this information to one-quarter the original length, preserving all critical facts and conclusions," and replace the original item with the compressed version. This introduces a latency and cost trade-off. Summarization costs tokens—both the input of the original item and the output of the summary. For very large items, the cost of summarization might be justified by the savings in future memory reads. For small items, summarization might cost more than just keeping the original.

Some systems use extractive summarization instead of abstractive. Extractive summarization selects key sentences from the original text rather than generating new phrasing. This is faster and cheaper but less effective at compression. You might reduce token count by thirty percent with extractive methods versus seventy percent with abstractive. The choice depends on whether you are optimizing for speed or for maximum budget reclamation.

Hierarchical summarization is a more sophisticated approach where memory items are organized into levels of detail. Level zero is raw tool call results. Level one is compressed summaries of those results. Level two is summaries of summaries, capturing only the highest-level conclusions. As memory pressure increases, you move items up the hierarchy, discarding lower levels. This creates a natural detail gradient where the agent has immediate access to high-level conclusions and can drill down into detail only when necessary. Hierarchical summarization is complex to implement but provides the best balance of memory efficiency and information preservation.

## Memory Budget Configuration by Task Type

Different agent task types have fundamentally different memory requirements. A research agent needs to track dozens of sources and findings across a long session. A customer service agent needs to maintain conversation context and account state but typically operates in shorter sessions. A code review agent needs to hold file contents and change diffs but works with structured data that does not compress well. Configuring memory budgets without understanding task type characteristics leads to either over-budgeting, which wastes cost, or under-budgeting, which degrades quality.

Research agents typically run long and accumulate diverse information. A patent research agent might run for thirty minutes, execute sixty tool calls, and accumulate 100,000 tokens of search results, document excerpts, and analysis notes. For this task type, you need a large token budget—perhaps 70,000 to 90,000 tokens—and a large item budget—perhaps fifty to seventy items. You also need aggressive progressive summarization because research tasks produce a lot of intermediate findings that become irrelevant once higher-level conclusions are reached. The configuration might specify summarization triggers at seventy percent memory pressure and eviction triggers at ninety percent.

Customer service agents run shorter but need high fidelity on recent conversation turns and account state. A typical session might be eight minutes, twenty tool calls, and 35,000 tokens of accumulated context. The token budget can be smaller—perhaps 40,000 tokens—but you need strict rules about what is compressible. User statements are not compressible because exact phrasing might matter for understanding intent. Account state is not compressible because every field might be relevant to eligibility or policy decisions. Search results and policy document excerpts are compressible. The configuration specifies different compression rules per memory item type.

Code review agents deal with highly structured content. A code review task might involve reading five files, generating diffs, analyzing patterns, and producing recommendations. The total token count might be 60,000 tokens, but compression is limited because code structure must be preserved exactly. For this task type, you set a moderate token budget—perhaps 50,000 tokens—and rely primarily on item eviction rather than compression. Once a file has been reviewed and conclusions have been recorded, the full file content can be evicted and replaced with a summary of findings.

Data analysis agents run variable-length tasks depending on dataset complexity. An agent analyzing a sales dataset might execute twenty queries, produce fifteen intermediate aggregations, and generate twelve visualizations. Token counts are moderate—perhaps 25,000 to 40,000 tokens—but item counts are high because each query result is a separate item. The configuration uses a low token budget but a high item budget with frequent eviction of query results once they have been incorporated into aggregations.

Debugging agents need to maintain stack traces, error logs, variable states, and execution histories. These are all structured data that compresses poorly. Token budgets need to be high—perhaps 60,000 to 80,000 tokens—but task duration is typically short, so total cost remains manageable. The configuration preserves all memory at full fidelity until task completion, with no summarization or eviction.

Configuration is not static. As you gather production telemetry, you adjust budgets based on observed task behavior. If you see that research agents are routinely hitting memory pressure at minute twelve and then spending the rest of the task in aggressive compression mode, you might increase the token budget or implement earlier, gentler summarization. If you see that customer service agents are ending tasks with only fifty percent budget utilization, you can reduce the budget and cut costs without quality impact.

## Monitoring Memory Health in Production Agents

Memory budget adherence and health must be monitored continuously in production because memory behavior changes as task patterns shift, as users push systems in unexpected ways, and as underlying models change characteristics. The metrics that matter are budget utilization distribution, pressure event frequency, compression effectiveness, and cost per task variance.

Budget utilization distribution shows how much of the configured budget is actually used across all tasks. You want to see a distribution that clusters around seventy to eighty-five percent utilization. If most tasks use less than fifty percent, your budget is too large and you are paying for unused context window. If most tasks hit one hundred percent and trigger eviction, your budget is too small and quality is likely suffering. A healthy distribution has some headroom but not excessive waste.

Pressure event frequency tracks how often memory pressure states are triggered per task. Occasional pressure events are normal and expected for long-running tasks. If every task triggers pressure events within the first three minutes, your budget is misaligned with task requirements. If no tasks ever trigger pressure events, you might be over-budgeted. The ideal frequency depends on task type, but for long-running research agents, you might expect pressure events on sixty to seventy percent of tasks, typically in the second half of the session.

Compression effectiveness measures how much budget is reclaimed per compression operation. If summarizing a 6,000-token memory item yields a 5,200-token summary, you have freed only 800 tokens—not very effective. If the summary is 1,800 tokens, you have freed 4,200 tokens—much better. Low compression effectiveness indicates that your content does not compress well, which means you need to rely more on eviction or increase budgets. High compression effectiveness means you can use aggressive summarization to extend task duration without increasing budgets.

Cost per task variance is the coefficient of variation in task costs. If average cost is four dollars with a standard deviation of fifty cents, your variance is manageable. If average cost is four dollars with a standard deviation of six dollars, you have a cost control problem. High variance usually indicates that memory accumulation is unpredictable, which means your budgets or your pressure responses are not working correctly. Investigating high-variance tasks often reveals edge cases where specific tool call patterns produce memory spikes that bypass budget controls.

You also monitor memory-related failures: tasks that crash due to context overflow despite having budgets, tasks that produce low-quality output after aggressive compression, tasks that hang because compression operations are taking too long. Each failure type points to a different configuration problem. Context overflows despite budgets usually mean your headroom is too small or your budget enforcement is not triggering early enough. Quality degradation after compression means you are compressing too aggressively or compressing the wrong items. Compression latency hangs mean you are summarizing items that are too large or using abstractive summarization where extractive would suffice.

Production monitoring also tracks which memory items get compressed most often and which get evicted most often. This reveals which types of information are least valuable to retain at full fidelity. If you see that search results from a particular tool are compressed or evicted ninety percent of the time, you might preemptively compress those results on arrival rather than waiting for pressure events. If you see that certain item types are never compressed or evicted, you know those are critical to task quality and your budgets must accommodate them.

Alerting rules should fire when memory behavior deviates from baseline patterns. If your research agents typically hit memory pressure at minute eighteen plus or minus three minutes, and suddenly a batch of tasks is hitting pressure at minute five, something has changed in the task pattern or the tool outputs. This might be legitimate—users are asking harder questions—or it might indicate a problem like a tool returning bloated results. The alert triggers investigation before cost surprises appear in monthly bills.

## Edge Cases and Pathological Memory Growth Patterns

Some task patterns produce memory growth that defies standard budget management strategies. Recognizing these edge cases and having specific handling logic for them prevents rare but expensive failures.

Recursive tool calling creates memory spirals. If an agent is allowed to call tools that themselves trigger additional tool calls, and those results are all stored in memory, you can get exponential growth. A research agent that searches a document, finds references to other documents, retrieves those documents, finds more references, and continues this pattern can easily accumulate thousands of items in minutes. The fix is not just budgets but also depth limits. After three levels of recursive retrieval, the agent must consolidate findings before proceeding deeper.

Retry loops create memory duplication. When a tool call fails and the agent retries with modified parameters, both the failed attempt and the retry result are often stored in memory. After five retries, you have six copies of essentially the same information cluttering memory. The fix is to mark failed attempts as evictable immediately, or to replace failed attempts with successful retries rather than appending.

Large binary data in tool results creates token explosions. If a tool returns an API response that includes base64-encoded images or file contents, a single tool call can add 50,000 tokens to memory. The agent does not need the full binary data for reasoning, it needs metadata about what was retrieved. The fix is to strip large binary payloads during memory ingestion and replace them with references and metadata. Store the binary data separately if it needs to be accessed later, but do not keep it in active agent memory.

Streaming tool results create memory fragmentation. Some tools stream results incrementally: a database query might return rows one at a time, a document search might return chunks as they are found. If each incremental result is stored as a separate memory item, you end up with hundreds of tiny fragments that should be a single consolidated result. The fix is to buffer streaming results and commit them to memory only when the stream completes, or to implement memory item consolidation that merges related fragments.

User-provided context in long-running sessions can bypass budget controls. If the agent task allows the user to provide additional information mid-task, and that information is appended to memory without budget checks, the user can inadvertently blow past memory limits. A user who pastes a 10,000-word document into a chat interface during an ongoing agent task adds that entire document to memory instantly. The fix is to apply budget checks to all memory additions, regardless of source, and to compress or summarize user-provided content before adding it to memory if it exceeds a size threshold.

## Real-World Budget Configuration Examples from Production Systems

A legal research agent deployed at a mid-sized law firm runs patent prior art searches. Typical task duration is twenty-five minutes. The agent searches three patent databases, retrieves an average of forty document sections, compares claims across twelve patents, and generates a detailed analysis report. The team configured a token budget of 75,000 tokens and an item budget of fifty-five items. Progressive summarization triggers at eighty percent token utilization, compressing database search results to key findings. Item eviction triggers at ninety percent, removing early exploratory searches that did not yield relevant patents. The configuration keeps average task cost at 6.80 dollars with a standard deviation of ninety cents. Before implementing budgets, the same tasks cost an average of 23 dollars with a standard deviation of fourteen dollars.

A customer support agent for a telecommunications company handles complex billing disputes. Typical task duration is nine minutes. The agent retrieves account history, checks service records, searches policy documents, and sometimes coordinates with external billing systems. The team configured a token budget of 35,000 tokens and an item budget of thirty-five items. No summarization is used because exact transaction details and policy wording matter for dispute resolution. Item eviction targets only failed tool calls and redundant policy lookups. The configuration keeps task costs predictable at 1.90 dollars average, with ninety-eight percent of tasks completing within budget without quality degradation.

A code review agent for a software platform analyzes pull requests that touch multiple services. Typical task duration is twelve minutes. The agent reads file contents, generates diffs, checks against style guides and security rules, and produces inline comments. The team configured a token budget of 55,000 tokens and an item budget of twenty items. Code files are large, so item count is the constraining factor more often than token count. Once a file has been reviewed and findings recorded, the full file content is evicted and replaced with a summary of issues found. The configuration handles pull requests with up to eight files without quality loss. Larger pull requests trigger task segmentation where the agent reviews files in batches.

A financial analysis agent used by investment advisors runs portfolio risk assessments. Typical task duration is eighteen minutes. The agent queries market data, retrieves historical performance, applies risk models, and compares against regulatory thresholds. The team configured a token budget of 50,000 tokens and an item budget of forty items. Market data queries return structured data that compresses poorly, so the budget is tuned to accommodate that. Progressive summarization is applied only to historical performance data older than one year, which is less relevant to current risk assessment. The configuration maintains audit trail completeness while keeping costs at 4.20 dollars per assessment.

## Integration with Agent Framework Memory Systems

Most production agents run on frameworks like LangChain, LlamaIndex, AutoGPT, or custom architectures. These frameworks provide memory management abstractions, but they rarely implement budgets by default. Integrating budget controls requires understanding how the framework structures memory and where to inject budget logic.

LangChain represents memory as a conversation buffer or a summary buffer. To add budget controls, you extend the base memory class to track token counts, implement pressure detection in the save context method, and trigger compression in the load context method. The framework does not natively distinguish between compressible and non-compressible memory items, so you add metadata tagging to track item types and implement custom compression logic for each type.

LlamaIndex structures memory around an index of document nodes. Budget controls integrate at the index level. You configure maximum node counts, implement node eviction based on age and relevance scores, and use hierarchical summarization where parent nodes summarize child nodes. The framework supports custom node transformations, which is where you implement progressive summarization.

AutoGPT and similar autonomous agent frameworks accumulate memory across multiple task steps stored in a state object. Budget integration requires intercepting state updates, checking token counts before appending new items, and implementing a state compaction operation that runs whenever pressure thresholds are crossed. These frameworks often execute long task chains, so budget enforcement is critical to prevent runaway memory growth.

Custom agent architectures give you full control over memory representation. You implement memory as a structured buffer with explicit token and item tracking. You design the memory schema to include metadata fields for item type, creation time, reference count, and compressibility flags. You build compression and eviction functions that operate directly on the memory buffer. You integrate budget checks into the main agent loop so that every tool call execution includes a memory pressure check.

Regardless of framework, the integration pattern is consistent: track token and item counts continuously, detect pressure states based on thresholds, execute compression or eviction when pressure is detected, instrument everything to monitor effectiveness. The framework provides the scaffolding, but budget management is custom logic you must implement based on your task characteristics and cost constraints.

## The Relationship Between Memory Budgets and Model Context Windows

Memory budgets are not the same as model context windows, but they are related. The context window is the maximum total tokens the model can process in a single call: prompt plus completion. Your memory budget is a subset of that window, leaving room for system instructions, the current tool call, model reasoning, and output generation.

If you use a model with a 200,000 token context window and you set your memory budget to 190,000 tokens, you have left only 10,000 tokens for everything else. This might be sufficient for simple tasks but will fail for complex tasks where the model needs 15,000 tokens for chain-of-thought reasoning. A safe rule is to allocate forty to sixty percent of the context window to memory, leaving the rest for operational overhead.

Context window size also affects budget strategy. With a very large context window like Claude Opus 4.5's 200,000 tokens, you have more flexibility. You can set generous memory budgets and rely less on aggressive compression. With a smaller context window like 32,000 tokens, you must be strict about budgets and compression because there is little room for waste.

However, larger context windows cost more per token. Claude Opus 4.5's input pricing in January 2026 is three dollars per million tokens. If your memory budget is 80,000 tokens and the agent makes fifty decisions, you are spending twelve dollars on memory reads alone. With a smaller model and smaller context window, that same memory load might cost two dollars. The trade-off is capability versus cost. You need the capable model for complex reasoning, but you must control memory to make the cost viable.

Some teams try to work around budget constraints by using models with larger context windows. This is treating the symptom, not the disease. If your task genuinely requires maintaining 150,000 tokens of context throughout its execution, a larger context window helps. But if your task is accumulating 150,000 tokens because you are not compressing or evicting anything, the problem is process, not model capacity. Fix the memory management before upgrading to larger models.

The next chapter examines memory in a different context: RAG systems where the challenge is not managing accumulation over time but rather maintaining clear distinctions between source truth and inferred knowledge, and ensuring that retrieval does not introduce memory drift that degrades accuracy across interactions.

