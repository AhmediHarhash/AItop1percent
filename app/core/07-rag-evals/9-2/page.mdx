# 9.2 â€” Graph RAG: Knowledge Graphs Meet Retrieval

**Vector similarity cannot capture relationship structure.** A chunk about protein X in Alzheimer's research and a chunk about protein X in diabetes research might not be semantically similar, even though protein X is exactly the connection you need. Standard RAG finds documents about topics. Graph RAG finds entities, relationships, and multi-hop connections that span documents, enabling queries that vector search alone cannot answer.

The problem wasn't the embedding quality or the chunk size. The problem was that vector similarity doesn't naturally capture relationship structure. A chunk about protein X in Alzheimer's research and a chunk about protein X in diabetes research might not be semantically similar enough to both appear in the top results, even though protein X is exactly the connection the scientist was looking for. The system could find documents about each disease independently, but it couldn't identify the overlapping entities and relationships that spanned multiple documents.

After three months of scientists complaining that the system missed obvious connections, the team realized they were trying to solve a graph problem with vector tools. They needed to represent knowledge as a network of entities and relationships, not just as embedded text chunks. A senior researcher put it bluntly in a team meeting: "You've built a search engine when what we need is a knowledge graph. We don't just want documents that mention these things. We want to understand how these things connect."

The engineering team spent the next weekend reading graph database documentation and academic papers on knowledge graph construction. By Monday morning, they had a prototype that changed everything. Instead of just searching for semantic similarity, they could query explicit relationships: find all proteins with edges to both Alzheimer's and diabetes nodes. The results were precise and exactly what the scientists needed. The head of research approved budget for a full graph RAG implementation the same day.

## The Core Insight of Graph RAG

This is the fundamental insight of graph RAG. Traditional vector RAG treats documents as unstructured text that gets chunked and embedded. Graph RAG treats documents as sources of structured knowledge: entities connected by relationships. Instead of, or in addition to, storing chunks in a vector database, you extract entities and relationships from your documents and build a knowledge graph. Then, retrieval becomes graph traversal and graph queries, not just vector similarity search.

When a user asks about connections, you can literally query the graph for paths between entities. When they ask about a specific entity, you can retrieve not just text mentioning that entity, but the entire subgraph of related entities and their relationships. This fundamentally changes what kinds of questions your RAG system can answer. Vector search finds documents with similar semantic content. Graph queries find entities with explicit relationships. The difference is enormous for relationship-driven questions.

The pharmaceutical company's transformation from vector-only to graph-augmented RAG took six months of intense engineering work. They had to build entity extraction pipelines, implement entity resolution to handle duplicates and variations, design a knowledge graph schema that captured the relationships their scientists cared about, populate a graph database with millions of entities and relationships, and integrate graph queries with their existing RAG system. But the result was a system that could finally answer the questions their scientists actually asked.

## Building Knowledge Graphs from Documents

Building a knowledge graph from documents requires entity extraction and relationship extraction. You process each document to identify entities: people, organizations, locations, proteins, diseases, products, concepts, whatever entity types matter for your domain. Then you identify relationships between those entities: works for, located in, causes, treats, competes with, depends on. In the pharmaceutical case, the team extracted entities like specific proteins, diseases, drug compounds, and researchers, and relationships like protein implicated in disease, drug targets protein, researcher authored paper.

They ended up with a graph containing over three hundred thousand entities and two million relationships extracted from their twenty thousand papers. This extraction process can be done with specialized NER models, with LLMs prompted to extract entities and relationships, or with a combination of both. The key is consistency: you need stable entity identifiers and relationship types across all your documents so that mentions of the same entity in different papers map to the same node in the graph.

The pharmaceutical team started with off-the-shelf NER models for basic entity types like diseases and organizations, but quickly found they needed domain-specific extraction for proteins and chemical compounds. Medical protein names have complex variations and synonyms. BRCA1, breast cancer type 1 susceptibility protein, and several other names all refer to the same entity. They fine-tuned an extraction model on annotated medical literature to handle these domain-specific entities accurately.

Relationship extraction was even more challenging. Academic papers express relationships in varied and subtle ways. "Protein X plays a role in disease Y" implies a relationship, but so does "Patients with disease Y showed elevated levels of protein X" and "Inhibition of protein X ameliorated symptoms of disease Y." Each phrasing expresses a protein-disease relationship, but extracting them requires understanding the semantic meaning of different sentence structures. The team used LLMs with carefully crafted prompts that included examples of different relationship phrasings specific to medical literature.

Entity resolution became a critical component. Different papers might refer to the same protein with different names, abbreviations, or identifiers. The team built an entity resolution system that normalized entities using canonical identifiers from medical databases like UniProt for proteins and MeSH for diseases. When they extracted "Alzheimer's disease," "AD," "Alzheimer disease," and "senile dementia of the Alzheimer type" from different papers, the resolution system mapped all of them to a single canonical Alzheimer's disease entity in the graph.

## Graph Queries for Relationship Questions

Once you have the graph, retrieval becomes a different kind of problem. For the query "What proteins are implicated in both Alzheimer's disease and diabetes?" you can now perform a graph query: find all proteins that have a protein implicated in disease relationship to both the Alzheimer's node and the diabetes node. This is a structured query that the graph can answer precisely. The traditional vector approach would have struggled because it would need to find chunks that happened to mention all three concepts in close semantic proximity.

The graph approach directly encodes the relationships you care about. The pharmaceutical team found that graph queries were dramatically better for connection-finding questions, relationship questions, and multi-hop reasoning questions where the answer required traversing multiple relationship edges in the graph. A query like "What drugs target proteins associated with diseases studied by researcher X?" becomes a multi-hop graph traversal: find researcher X, find papers authored by researcher X, extract diseases studied in those papers, find proteins implicated in those diseases, find drugs that target those proteins.

They implemented graph queries using Cypher, the query language for Neo4j, their chosen graph database. A scientist asking "What are the shared genetic factors between diabetes and heart disease?" would trigger a Cypher query that found all gene nodes connected to both the diabetes node and the heart disease node via genetic factor relationships. The results were exact and complete: every gene in their knowledge base with documented connections to both conditions. Vector search could never provide that level of precision for relationship queries.

The team also discovered that graph queries could surface non-obvious connections through multi-hop paths. A scientist might not realize that two diseases shared common protein pathways, but a graph query finding paths between disease A and disease B through intermediate protein nodes would reveal those connections. This serendipitous discovery capability became one of the most valued features of their graph RAG system. Scientists found research connections they wouldn't have thought to look for.

## Hybrid Retrieval: Combining Graphs and Vectors

But vector search doesn't become obsolete. Graph RAG is most powerful when combined with vector search in a hybrid approach. The graph provides structured relationship information, while vectors provide semantic similarity and the ability to find conceptually related content even when exact entity matches don't exist. A common pattern is to use vector search to identify relevant entities, then use the graph to explore relationships around those entities.

For instance, if a user asks a fuzzy question like "What research relates to memory decline in aging?" you might first use vector search to find relevant papers and extract the key entities mentioned in those papers, then query the graph to find all relationships involving those entities. Or you might do the reverse: use entity recognition on the query to identify entities the user mentioned, use the graph to find related entities and relationships, then use vector search to retrieve document chunks about those graph-discovered entities.

The pharmaceutical team implemented a hybrid retrieval strategy they called "graph-guided vector search." When a query came in, they would first identify any explicitly mentioned entities using entity recognition. If entities were found, they would query the graph to find related entities and relationships. Then they would perform vector search with two components: one searching for chunks semantically similar to the query, another searching specifically for chunks mentioning the entity set discovered through graph traversal. Results from both components would be merged and ranked.

This hybrid approach combined the recall of vector search with the precision of graph relationships. For the query "What new treatments for neurodegenerative diseases show promise?" the entity recognition would identify "neurodegenerative diseases" as an entity category. The graph query would find all specific neurodegenerative disease nodes and recent drug nodes connected to them via "treats" or "targets" relationships. Vector search would then retrieve chunks discussing these specific diseases and drugs, even if the original papers didn't explicitly use the term "neurodegenerative diseases."

## Community Detection and Topic Clustering

Microsoft Research developed GraphRAG, an approach that adds another layer: community detection. After building the knowledge graph, they run community detection algorithms to identify clusters of densely connected entities. These communities represent topics or themes in the corpus. For example, in a news corpus, one community might be all the entities related to climate policy, another might be entities related to semiconductor manufacturing, another might be entities related to a specific political election.

The communities are then summarized using LLMs: you take all the entities and relationships in a community and generate a high-level summary of what that community represents. Now, when a user asks a broad question, you can retrieve entire community summaries instead of just individual chunks. This is particularly powerful for questions that require understanding themes across many documents. The GraphRAG team showed dramatic improvements on summarization tasks and broad analytical questions compared to standard RAG.

The pharmaceutical company implemented community detection using the Louvain algorithm on their knowledge graph and discovered over two hundred distinct research communities. One community represented Alzheimer's-related proteins and pathways, containing entities like APP, tau, beta-amyloid, and various Alzheimer's-associated genes. Another was diabetes mechanisms, including insulin, glucose metabolism enzymes, and diabetes-related signaling pathways. Another was cardiovascular research, with heart disease genes, blood pressure proteins, and cardiac function markers.

When scientists asked broad questions like "What is the current state of research on neurodegenerative diseases?" the system could retrieve community summaries that synthesized information from hundreds of papers within the neurodegenerative disease community, rather than returning a handful of text chunks. The summaries were generated by LLMs that processed the entities and relationships within each community and produced narrative overviews of the research themes, key findings, and important connections.

This was particularly valuable for onboarding new researchers who needed to quickly understand an entire research area. Instead of reading dozens of papers to get oriented, they could ask broad questions and receive synthesized community-level summaries that captured the landscape of research in that area, then drill down into specific entities and papers for details.

## Multi-Hop Reasoning and Path Finding

Graph RAG excels at multi-hop reasoning questions. These are questions where the answer requires connecting information across multiple relationship steps. For example, "Which researchers have worked on drugs that target proteins implicated in diseases studied by Dr. Smith's lab?" This requires several hops: find Dr. Smith's lab, find diseases studied by that lab, find proteins implicated in those diseases, find drugs targeting those proteins, find researchers who worked on those drugs.

A vector RAG system would struggle with this because it would need to retrieve chunks that somehow mention all these concepts in sufficient proximity. A graph RAG system can literally traverse the relationship edges: Dr. Smith affiliated with Lab, Lab studies Disease, Disease has implicated protein Protein, Protein targeted by Drug, Drug developed by Researcher. The query is a graph traversal, and the results are precise. Every step follows explicit relationships encoded in the knowledge graph.

The pharmaceutical team found that their scientists frequently asked these multi-hop questions. "What are the downstream effects of inhibiting protein X?" required traversing from protein X through all proteins it interacts with, then through all cellular processes those proteins participate in, then through all phenotypic outcomes associated with those processes. This could involve three, four, or five hops through the graph. Traditional retrieval couldn't handle this level of relational complexity, but graph queries made it straightforward.

They also implemented path finding queries that would identify the shortest or most significant paths between two entities. A scientist might ask, "How is gene A connected to disease B?" and the system would find paths through the graph connecting them, revealing intermediate proteins, signaling pathways, or molecular mechanisms that linked the gene to the disease. This path discovery capability uncovered research connections that weren't explicitly stated in any single paper but emerged from combining knowledge across multiple papers.

## Challenges: Graph Construction and Maintenance

However, building and maintaining a knowledge graph is significantly more complex than maintaining a vector index. Entity extraction isn't perfect. You'll have duplicate entities because different documents refer to the same thing with different names. You'll have entity linking challenges: is the "Dr. Johnson" in one paper the same person as "Sarah Johnson" in another? You'll have relationship extraction errors: the model might extract a relationship that doesn't actually exist, or miss relationships that do exist.

The pharmaceutical team spent considerable effort on entity resolution, creating canonical entity identifiers and merging duplicates. They implemented a semi-automated resolution process where the system would flag potential duplicates based on name similarity and context, and domain experts would review and confirm merges. They also implemented confidence scores on relationships, marking high-confidence relationships extracted by specialized models differently from lower-confidence relationships extracted by general LLMs.

Relationship extraction errors were harder to handle. False positives, where the system extracted relationships that didn't exist, would pollute the graph with incorrect edges. False negatives, where the system missed real relationships, would create gaps in the graph's knowledge. The team addressed this through multiple extraction passes with different models, combining results with confidence scoring, and implementing user feedback mechanisms where scientists could flag incorrect relationships or add missing ones.

Schema design becomes crucial. You need to decide what entity types and relationship types matter for your domain. Too few relationship types and you lose expressiveness; too many and the graph becomes noisy and hard to query. The pharmaceutical team started with thirty relationship types, attempting to capture every nuance of how biomedical entities could relate. They quickly found this was too granular. Many of the fine-grained distinctions weren't useful for their actual queries, and the extraction models struggled to distinguish between similar relationship types.

They consolidated to twelve core relationship types that covered the vast majority of important relationships: causes, treats, prevents, associated with, targets, interacts with, part of, regulates, produced by, metabolizes, located in, and studied by. This simpler schema was easier for extraction models to handle accurately and sufficient for answering the questions scientists actually asked. They also discovered that some relationships needed directionality: drug targets protein makes sense as a directed relationship from drug to protein, while interacts with is symmetric between proteins.

## Graph Databases and Query Patterns

Graph databases become part of your infrastructure. You need something like Neo4j, Amazon Neptune, or TigerGraph to store and query your knowledge graph at scale. These systems have their own query languages, typically variations of graph query languages like Cypher or SPARQL. Your RAG system now needs to translate natural language queries into graph queries, execute those queries, retrieve the resulting subgraphs, and then use an LLM to generate natural language answers based on the graph data.

This is more moving parts than a standard RAG system where you just embed a query and search a vector index. The pharmaceutical team had to learn Cypher, design query patterns for common question types, and build a translation layer that converted natural language to graph queries. They started with a template-based approach where common question patterns would map to parameterized Cypher templates. Questions like "What X relates to Y?" would map to a template that found all nodes of type X connected to a Y node.

As they gained experience, they moved to LLM-based query generation. They would provide the model with the graph schema, examples of natural language questions paired with corresponding Cypher queries, and the current user question. The model would generate a Cypher query that they would execute against the graph database. This worked reasonably well for structured questions but could struggle with ambiguous or complex questions where the optimal graph query wasn't obvious.

One powerful pattern is to use LLMs to generate graph queries from natural language. You provide the model with your graph schema, examples of graph queries, and the user's question, and ask it to generate the appropriate graph query. For instance, given the question "What diseases are connected to both protein A and protein B?" the model might generate a Cypher query that finds disease nodes with relationships to both protein nodes. You execute that query, get back a subgraph, and then feed that subgraph back to the model to generate the final answer.

The team implemented error handling for query generation failures. If the generated Cypher query was syntactically invalid or returned no results when results were expected, the system would fall back to vector search. They also implemented query validation that would check generated queries for common errors before execution. This prevented malformed queries from hitting the database and improved system reliability.

## Domain Fit and Use Cases

Graph RAG is particularly valuable in domains with rich entity relationships. Scientific research, legal documents with citations and precedents, financial networks of companies and transactions, intelligence analysis connecting people and events, medical records connecting patients and procedures and diagnoses. These domains have inherent graph structure that vector embeddings don't naturally capture. If your domain is more about conceptual similarity without strong entity relationships, traditional vector RAG might be sufficient.

But if your users ask questions about connections, networks, influences, and multi-hop relationships, graph RAG is worth the added complexity. The pharmaceutical company's domain was ideal for graph RAG: biomedical research is fundamentally about relationships between entities. Proteins interact with each other. Drugs target proteins. Diseases involve multiple proteins and pathways. Genes encode proteins. The entire domain is a network of relationships, making graph representation natural and powerful.

They discovered use cases they hadn't anticipated. Scientists started using the graph to identify potential drug repurposing opportunities: drugs approved for one disease that targeted proteins also implicated in other diseases. The graph made these connections visible. They used community detection to identify emerging research areas where entity density was increasing rapidly, indicating hot topics. They used centrality metrics to identify the most studied proteins and diseases, informing resource allocation decisions.

The system also enabled hypothesis generation. A scientist could ask, "What proteins are understudied despite being connected to multiple important diseases?" The graph would identify proteins with many disease associations but few research papers, suggesting potentially valuable but overlooked research targets. This kind of meta-analysis across the entire research corpus would have been nearly impossible with traditional retrieval methods.

## Cost Models and Maintenance

The cost model differs from vector RAG. Building the initial knowledge graph is expensive: you're running entity and relationship extraction on every document, which typically requires LLM calls or specialized model inference. The pharmaceutical team spent approximately six thousand dollars in LLM API costs to extract entities and relationships from their twenty thousand papers, plus engineering time to build the extraction pipeline and entity resolution logic. This was a significant upfront investment compared to simply embedding documents.

Ongoing maintenance also costs more: when new documents are added, you need to extract entities and relationships, resolve entities against the existing graph, and insert new nodes and edges. But query time can actually be cheaper: graph queries are often faster and cheaper than vector searches with LLM reranking, especially for structured queries with clear relationship patterns. Graph databases are optimized for relationship traversal, making multi-hop queries efficient.

The team found that the higher upfront and maintenance costs were offset by query-time efficiency and the dramatically improved quality for relationship questions. Their scientists asked dozens of relationship questions daily that would have required manual literature review without the graph RAG system. The time savings alone justified the investment. They calculated that the system saved each scientist approximately five hours per week in information gathering and connection finding, valuing this at over two million dollars annually across their research team.

Graph RAG also enables new kinds of analytics. You can compute centrality metrics to find the most important entities in your corpus. Betweenness centrality identifies entities that bridge different research areas. Degree centrality identifies the most connected entities. PageRank-style algorithms identify the most influential entities based on the importance of their neighbors. The pharmaceutical team started using graph analytics to identify emerging research areas: they looked for new entities that were rapidly gaining relationships, indicating topics of growing research interest.

They implemented temporal analysis by timestamping graph edges with the publication dates of papers that supported them. This allowed them to track how knowledge evolved over time. They could see when a protein first became associated with a disease, when that association strengthened as more papers confirmed it, and when new relationships emerged. This temporal dimension turned their RAG system into not just a question-answering tool, but a knowledge discovery and evolution tracking platform.

## Hybrid Architectures and Integration Patterns

Hybrid retrieval strategies combine the strengths of both graph and vector approaches. One pattern: use vector search to retrieve an initial set of relevant chunks, extract entities from those chunks, expand the entity set by walking the graph to find related entities, then retrieve all chunks mentioning the expanded entity set. This combines the recall of vector search with the precision of graph relationships. Another pattern: use the graph to generate comprehensive entity lists for a topic, then use those entities as filters or boosts in vector search.

For example, if the graph tells you that entities X, Y, and Z are central to a particular research community, you can boost chunks mentioning those entities in your vector search results. The pharmaceutical team implemented a sophisticated hybrid architecture where query classification determined which retrieval strategy to use. Simple entity lookup questions would route to pure graph queries. Relationship questions would use graph traversal. Conceptual questions without clear entities would use vector search. Complex analytical questions would use a combination: graph queries to identify relevant entity sets, vector search to find detailed information about those entities.

They also implemented graph-enhanced reranking. After vector search retrieved an initial set of chunks, they would extract entities from those chunks and query the graph to find how those entities related to query entities. Chunks containing entities with strong graph connections to the query would be boosted in ranking. This graph-informed reranking improved relevance by incorporating relationship structure into the ranking function.

One challenge specific to graph RAG is keeping the graph synchronized with document updates. When a document is updated or deleted, you need to update the graph accordingly. But unlike vector databases where you just delete and re-embed chunks, graph updates are trickier. If you delete a document, you might need to remove relationships that were extracted from that document, but only if those relationships don't also appear in other documents.

The pharmaceutical team implemented a provenance system where each graph edge was tagged with the source documents that supported it. When a document was updated, they could identify all edges sourced from that document and re-evaluate them. If a relationship appeared in multiple documents and one was deleted, the relationship remained in the graph but with reduced confidence. Only when all supporting documents were removed would the relationship be deleted. This provenance tracking added complexity but ensured the graph accurately reflected the current document corpus.

## Integration with Existing RAG Systems

Graph RAG is not a replacement for vector RAG; it's a complementary approach that excels in different scenarios. Use graph RAG when your domain has rich entity relationships, when users ask connection and relationship questions, when multi-hop reasoning is important, and when you need to understand the structure of knowledge, not just semantic similarity. Use vector RAG when questions are more about conceptual similarity, when entities and relationships are less well-defined, when you need semantic search over varied phrasing, and when the overhead of graph construction isn't justified.

In practice, the most powerful systems use both: graphs for structure, vectors for semantics. The pharmaceutical company's hybrid system became one of their most valuable research tools. Scientists used it to discover unexpected connections between research areas, identify promising drug targets based on protein relationship networks, and quickly understand the landscape of research on specific diseases. The graph structure made connections explicit that would have remained hidden in a traditional document corpus.

But the implementation took nine months, required specialized graph database infrastructure, ongoing entity resolution efforts, and a dedicated team to maintain the extraction pipeline and keep the graph synchronized with their growing document collection. Graph RAG delivered transformational value for their use case, but it was not a simple addition to their stack. The complexity was real, and teams considering graph RAG need to honestly assess whether their domain, query patterns, and resources justify the investment.

## Practical Recommendations for Adoption

If you're considering graph RAG, start by evaluating whether your domain and queries justify the complexity. Look at your actual user questions. How many of them involve relationships, connections, and multi-hop reasoning versus conceptual similarity? If most questions are about finding similar documents or semantic search, graph RAG may be overkill. If questions frequently ask about how entities relate, what connects two concepts, or multi-step reasoning, graph RAG becomes valuable.

Prototype entity and relationship extraction on a sample of your documents and assess the quality. Can you extract entities and relationships accurately enough to build a useful graph? Test with real queries from your users. Does graph querying provide better answers than vector search for those queries? The pharmaceutical team ran a two-week pilot with one hundred papers before committing to full implementation. The pilot proved value and identified challenges early, informing their full-scale architecture.

Design a schema that captures the relationships that matter for your domain. Start with core entity types and relationship types that cover eighty percent of your use cases. You can always expand later, but starting too broad leads to a noisy graph that's hard to query effectively. Get domain experts involved in schema design. They understand which relationships matter and which are noise. The pharmaceutical team's initial schema was designed by engineers and missed important biomedical relationship nuances. Involving research scientists in schema revision produced a much more useful structure.

Start small: build a graph for a subset of your corpus, implement basic graph queries, and evaluate whether it improves over vector-only retrieval. Measure answer quality on relationship questions before and after adding graph capabilities. Graph RAG is a powerful pattern when it fits your domain, but it's a significant architectural commitment that only pays off when relationship structure is central to your users' information needs. The pharmaceutical company's experience shows that when the fit is right, graph RAG transforms retrieval from finding documents to discovering knowledge.
