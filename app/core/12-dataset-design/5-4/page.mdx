# 5.4 â€” Lineage Tracking: From Source to Model to Production

In March 2025, a healthcare analytics company serving over 200 hospital systems discovered that one of their clinical risk prediction models was performing 14% worse than expected in production. The model flagged patients for sepsis risk, and the degradation meant delayed interventions for critically ill patients. The engineering team spent three weeks trying to reproduce the issue. They had the model weights, the training code, and the evaluation metrics from the original training run. What they did not have was a clear record of which data sources fed into the training dataset, which transformations were applied, or which version of their feature engineering pipeline had been used. They eventually traced the problem to a single SQL view that had been updated two months prior, changing how a lab value was normalized. But those three weeks of investigation involved manual archaeology through Git logs, Slack threads, and interviewing engineers who had left the company. The root cause was not a technical limitation. It was the absence of lineage tracking. They had versioned their datasets but had not recorded where the data came from, how it was transformed, or what downstream artifacts depended on it.

Lineage tracking is the practice of recording and maintaining a traceable path from raw data sources through every transformation, aggregation, and filtering step to the final dataset used for training or evaluation, and onward to the model artifacts and production predictions. When you have complete lineage, you can answer questions like: which tables fed into this training dataset, which feature engineering code was applied, which preprocessing steps were run, and which models were trained on this data. You can also answer the reverse question: if I change this upstream data source, which datasets and models will be affected. Lineage is not just an audit trail. It is the foundation for debugging, compliance, impact analysis, and trust. Without it, every investigation becomes a forensic exercise.

## The Full Lineage Graph

Lineage is a directed acyclic graph that connects raw data sources to datasets to models to predictions. At the top of the graph are your raw data sources: databases, APIs, file uploads, event streams, third-party datasets. Each of these sources is versioned or timestamped. The next layer is your ingestion and extraction processes: SQL queries, API calls, file parsers. These processes read from the sources and produce intermediate datasets. The third layer is transformation and feature engineering: joins, aggregations, filtering, encoding, normalization. These processes consume intermediate datasets and produce training datasets, evaluation datasets, or feature tables. The fourth layer is model training and evaluation: scripts or pipelines that consume datasets and produce model artifacts, evaluation reports, and metadata. The fifth layer is deployment and inference: serving infrastructure that loads model artifacts and produces predictions. Each prediction should be traceable back to the model version, the dataset version, and the source data.

You record this graph by capturing metadata at each stage. When you run a data extraction job, you log the source table names, the query or filter applied, the timestamp of execution, and the output dataset identifier. When you run a transformation pipeline, you log the input dataset identifiers, the code version or script hash, the hyperparameters or configuration, and the output dataset identifier. When you train a model, you log the training dataset identifier, the validation dataset identifier, the model code version, the hyperparameters, and the output model artifact identifier. When you deploy a model, you log the model artifact identifier and the deployment timestamp. When you generate a prediction, you log the model version and the input features.

This is not aspirational. This is how production AI systems are built in 2026. You do not wait until you have a compliance audit or a production incident to start recording lineage. You build lineage tracking into your pipelines from the first dataset version.

## Metadata Propagation Through Pipelines

Lineage metadata must propagate automatically through your data pipelines. If you rely on engineers to manually annotate every transformation step, the metadata will be incomplete and out of date within weeks. You instrument your pipelines so that lineage is captured as a side effect of normal data processing.

The simplest approach is to use a workflow orchestration tool that tracks lineage natively. Tools like Apache Airflow, Dagster, Prefect, and Metaflow all support lineage tracking. In Airflow, each task in a DAG can declare its inputs and outputs as datasets. When the task runs, Airflow records the dataset dependencies. In Dagster, assets are first-class objects with explicit dependencies, and the lineage graph is automatically maintained. In Metaflow, you can tag steps with artifact metadata, and the framework tracks which artifacts were produced by which steps. These tools do not give you lineage for free, but they give you the infrastructure to capture lineage without writing custom tracking code for every pipeline.

If you are not using a workflow orchestration tool, you need to build lineage tracking into your data processing code. This means instrumenting your data loaders, transformers, and writers with metadata logging. A common pattern is to wrap your data operations in a tracking layer. When you read a dataset, the wrapper logs the dataset identifier, the read timestamp, and the calling code. When you write a dataset, the wrapper logs the output identifier, the write timestamp, the input identifiers, and the code version. This metadata is written to a central lineage store, which is typically a database or a metadata service.

The key principle is that lineage metadata should be written at the same time as the data itself, not in a separate post-processing step. If you write data to S3 and then log lineage metadata to a database in a separate transaction, the two can get out of sync. If the lineage logging fails, you have data without lineage. If the data write fails but the lineage logging succeeds, you have lineage pointing to nonexistent data. You need atomic writes or compensating transactions to keep lineage and data in sync.

## Capturing Transformation Logic

Lineage is not just about which datasets were used. It is also about what was done to those datasets. You need to capture the transformation logic: the code, the configuration, and the environment. If you know that dataset version 47 was produced from dataset version 46, but you do not know which transformation script was run, you cannot reproduce the transformation or debug unexpected changes.

The minimum metadata to capture for each transformation step is: the input dataset identifiers and versions, the output dataset identifier and version, the code version or script hash, the configuration or hyperparameters, the execution timestamp, and the environment version. The code version can be a Git commit hash if your transformation code is in version control. If you are running SQL transformations, you should version the SQL scripts and log the script version. If you are using notebooks for exploratory data processing, you should version the notebook or export the executed cells and log the notebook hash.

Configuration and hyperparameters include things like: filtering thresholds, sampling rates, random seeds, feature selection lists, encoding mappings, normalization parameters. These should be stored as structured metadata, not as comments in code. A common pattern is to use a configuration file or a parameter dictionary that is passed to the transformation function and logged alongside the lineage metadata.

Environment version includes the Python version, library versions, and system dependencies. If your transformation pipeline uses pandas, numpy, scikit-learn, or other libraries, you should log the library versions. A simple approach is to export the pip freeze output or the conda environment file and store it with the lineage metadata. This ensures that if you need to reproduce the transformation six months later, you can recreate the exact environment.

Capturing this metadata is not expensive. The overhead is a few hundred bytes per transformation step, and the logging takes milliseconds. The cost of not capturing it is days of debugging when something goes wrong.

## Lineage for Debugging

When a model behaves unexpectedly in production, lineage tracking gives you a starting point for investigation. You can trace the model prediction back to the model version, the model version back to the training dataset, the training dataset back to the source data and transformations, and the source data back to the raw tables or files. This tells you what changed.

A typical debugging workflow looks like this. You notice that model accuracy has dropped in production. You query the lineage metadata to identify which model version is currently deployed. You retrieve the training dataset identifier for that model version. You compare the training dataset to the dataset used for the previous model version. You identify that the training dataset includes 12% more examples from a new data source that was added in the last data refresh. You inspect the new data source and find that it has a different distribution of labels or a different feature schema. You now have a hypothesis: the new data source introduced distribution shift. You can validate this hypothesis by retraining the model with and without the new data source and comparing evaluation metrics.

Without lineage, this investigation would require manually searching through pipeline logs, interviewing engineers, and reverse-engineering which code was running at which time. With lineage, the investigation takes minutes instead of days.

Lineage also helps you debug data quality issues. If you notice that a feature has unexpected values in production, you can trace that feature back through the feature engineering pipeline to the raw data source. You can identify which transformation step introduced the unexpected values or which upstream data quality check failed to catch the issue. You can then fix the transformation or add a data quality check to prevent the issue from recurring.

## Lineage for Compliance and Auditing

In regulated industries, lineage tracking is not optional. GDPR requires that you be able to explain how personal data is used and provide data subjects with information about the logic involved in automated decision-making. The EU AI Act requires documentation of the datasets used to train high-risk AI systems. HIPAA requires audit trails for protected health information. SOX requires controls and documentation for financial reporting systems. All of these regulations require that you be able to answer the question: where did this data come from, how was it processed, and who had access to it.

Lineage tracking provides the audit trail. When a regulator or auditor asks to see the training data for a model, you can provide the dataset version identifier, retrieve the dataset from versioned storage, and show the lineage graph that traces the dataset back to the source data. When a data subject requests information about how their data was used, you can query the lineage metadata to identify which datasets included their data, which models were trained on those datasets, and which predictions were generated by those models.

Lineage also supports compliance with data retention and deletion policies. If you are required to delete personal data after a certain period, you need to know which datasets contain that data and which downstream artifacts depend on those datasets. Lineage tracking gives you a dependency graph that shows which datasets, models, and predictions must be deleted or retrained when source data is removed.

In 2026, organizations are not building lineage tracking because they think it is a good idea. They are building it because their legal and compliance teams require it. If you are working in healthcare, finance, or any industry with data protection regulations, you should assume that lineage tracking is a compliance requirement, not a best practice.

## Impact Analysis: What Breaks When You Change Upstream Data

Lineage tracking enables impact analysis. Before you change an upstream data source, you can query the lineage graph to identify all the downstream datasets, models, and production systems that depend on that source. This prevents you from making a change that breaks production without realizing it.

A common scenario is schema changes. A database administrator updates a table schema to add a new column or rename an existing column. If your data pipeline queries that table, the pipeline may break when the schema changes. If you have lineage tracking, you can query the lineage metadata to identify which pipelines and datasets depend on that table. You can proactively update the pipelines or add schema compatibility checks before the change is deployed.

Another scenario is data quality degradation. A third-party data provider changes how they encode a categorical variable, and your feature engineering pipeline does not recognize the new encoding. If you have lineage tracking, you can detect the encoding change by comparing the value distribution in the new data to the value distribution in previous datasets. You can trace the downstream impact by identifying which models were trained on datasets that include the new encoding. You can decide whether to retrain the models or add a compatibility layer in the feature engineering pipeline.

Impact analysis also helps you prioritize data quality improvements. If you discover a data quality issue in a raw data source, you can use lineage tracking to identify how many datasets and models depend on that source. If the source feeds into a single low-priority model, you might defer the fix. If the source feeds into ten production models serving millions of users, you prioritize the fix immediately.

You run impact analysis by querying the lineage graph. Most lineage tracking tools provide a query interface or API that lets you ask questions like: which datasets depend on this source table, which models were trained on this dataset, which production systems are serving this model. You can also run graph traversal queries to identify transitive dependencies: if I change this source table, which models will eventually be affected through intermediate datasets.

## Tooling for Lineage Tracking

In 2026, you have three main options for lineage tracking: build it yourself, use a workflow orchestration tool with lineage support, or use a dedicated data lineage platform.

Building it yourself means instrumenting your data pipelines to log lineage metadata to a database or metadata service. You define a schema for lineage metadata: dataset identifiers, transformation steps, dependencies, timestamps, code versions. You write code to capture this metadata at each pipeline stage. You build a query interface to retrieve lineage information. This approach gives you full control but requires significant engineering effort. You should only build your own lineage tracking if you have specific requirements that are not met by existing tools or if you are already building a custom data platform.

Using a workflow orchestration tool with lineage support is the most common approach. Dagster, Prefect, Metaflow, and Apache Airflow all provide lineage tracking as a core feature. In Dagster, you define assets and their dependencies, and Dagster automatically maintains the lineage graph. In Airflow, you can use the Dataset API to declare dataset dependencies, and Airflow tracks lineage across DAG runs. These tools integrate lineage tracking into the workflow execution, so you do not need to write separate logging code. The downside is that lineage is only captured for pipelines that run through the orchestration tool. If you have ad hoc scripts or notebooks that process data outside the orchestration tool, those transformations will not be tracked.

Using a dedicated data lineage platform is the most comprehensive approach. Platforms like Marquez, DataHub, Amundsen, and commercial tools like Monte Carlo, Datadog Data Streams, and Collibra provide centralized lineage tracking across multiple data systems. These platforms integrate with data warehouses, data lakes, orchestration tools, BI tools, and ML platforms to capture lineage metadata from all sources. They provide a unified lineage graph, search and query interfaces, and impact analysis tools. The advantage is that you get end-to-end lineage even if your data processing spans multiple tools and systems. The disadvantage is additional infrastructure and integration effort.

For most teams, the right starting point is to use the lineage features in your workflow orchestration tool. If you are using Dagster or Prefect, enable asset lineage tracking. If you are using Airflow, adopt the Dataset API. If you need cross-tool lineage or compliance-grade audit trails, evaluate a dedicated lineage platform.

## Lineage and Trust

Lineage tracking builds trust with stakeholders. When a data scientist or product manager asks where a dataset came from, you can show them the lineage graph. When a regulator asks how a model was trained, you can provide the complete audit trail. When a user questions a prediction, you can trace the prediction back to the source data and explain the transformations that were applied.

Trust is not built on promises. It is built on evidence. Lineage tracking provides the evidence that your data pipelines are controlled, that your models are reproducible, and that your predictions are explainable. In industries where trust is a requirement, lineage tracking is the infrastructure that makes trust possible.

Lineage also builds trust within your engineering team. When a new engineer joins the team, they can explore the lineage graph to understand how data flows through the system. When an engineer is debugging a pipeline, they can trace the lineage to understand which upstream changes might have caused the issue. When an engineer is planning a refactoring, they can use lineage to identify which downstream systems will be affected. Lineage documentation is self-updating, because it is generated automatically from pipeline execution.

## Lineage as a Foundation for Governance

Lineage tracking is the foundation for data governance. Governance policies like access control, data classification, retention, and deletion all depend on knowing where data came from and where it is used. If you do not know which datasets contain sensitive data, you cannot enforce access controls. If you do not know which models were trained on a dataset, you cannot safely delete the dataset. If you do not know which predictions depend on a data source, you cannot assess the risk of that source being compromised.

Data governance teams use lineage metadata to enforce policies automatically. For example, if a dataset is tagged as containing personal data, the governance system can propagate that tag to all downstream datasets and models. Access control policies can be automatically applied based on lineage: if a user has access to a raw data source, they automatically have access to datasets derived from that source, unless explicitly restricted. Retention policies can be enforced by identifying which datasets have reached their retention deadline and which downstream artifacts must be deleted or retrained.

Lineage also supports governance audits. When a governance team conducts a review, they can query the lineage graph to identify which datasets contain regulated data, which models were trained on that data, and which production systems are serving those models. The audit trail is already in place.

## Lineage in Practice: What to Track and What to Skip

You do not need to track lineage for every intermediate file or temporary dataset. You need to track lineage for datasets that are used for training, evaluation, or production inference, and for the upstream sources and transformations that produced those datasets.

A practical rule is to track lineage at the granularity of named datasets. If a dataset has a version identifier and is stored in a versioned location, it should have lineage metadata. If a dataset is a temporary intermediate file that is deleted after a pipeline run, you do not need to track its lineage separately, but you should track the transformation step that consumed the previous dataset and produced the next dataset.

You should track lineage for all production models and all evaluation datasets. For exploratory datasets used in research or prototyping, you can decide based on how likely you are to need to reproduce or audit those datasets later. A reasonable default is to track lineage for any dataset that is used to make a decision or produce a report, even if it is not used for production model training.

Lineage tracking is not a burden if it is automated. If you are manually writing lineage metadata, you will skip it when you are busy or when you are working on a quick experiment. If lineage metadata is captured automatically by your orchestration tool or data platform, it costs you nothing and is always up to date.

The next subchapter covers reproducibility: how to ensure that you can recreate any dataset state on demand, even months or years later.
