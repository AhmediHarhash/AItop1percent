# 10.5 â€” Governance Structures: Review Boards and Approval Workflows

Three engineers were maintaining seventeen datasets across eight production models. Each engineer made independent decisions about when to add data, when to remove data, and when to change labels. Nobody coordinated. Nobody reviewed. Nobody had authority to say no. When Legal asked who approved a dataset used in a customer-facing compliance tool, all three engineers pointed at each other. When a privacy incident occurred because the dataset included data that should have been deleted under GDPR, nobody could explain why the deletion request had not been processed. When Product asked why a model failed after a dataset update, nobody could identify which of the seventeen datasets changed or who authorized the change. The problem was not bad engineers. The problem was no governance. Everyone owned the datasets, so nobody owned the datasets. Decisions that should have required cross-functional review were made in isolation. Changes that should have been logged and approved happened invisibly.

Dataset governance is the formal structure that defines who has decision authority over datasets, what approvals are required for what actions, and how those approvals are requested, reviewed, and documented. Governance prevents the chaos of distributed ownership. Governance ensures that datasets used in high-risk systems receive appropriate scrutiny before creation and before modification. Governance creates accountability by assigning specific people or teams responsibility for specific decisions. Governance scales dataset operations from ad hoc to repeatable to auditable.

Governance is not bureaucracy for its own sake. Governance is the mechanism that prevents unreviewed changes from breaking production, that prevents unauthorized data from entering training pipelines, and that prevents compliance violations from slipping through unnoticed. Governance is the difference between a dataset that can be trusted and a dataset that might be fine or might be a liability. In 2026, with the EU AI Act enforcing formal data governance requirements for high-risk AI systems, governance is not optional. It is a regulatory obligation and a professional standard.

## The Dataset Governance Board

A dataset governance board is a standing cross-functional group with decision authority over dataset lifecycle actions. The board reviews proposals for new datasets, approves or rejects those proposals, reviews modification requests for existing datasets, and approves or rejects dataset retirement. The board does not do the work of building datasets. The board decides whether the work should be done, whether it was done correctly, and whether it meets the standards required for production use.

Board composition depends on company size and risk profile, but the core functions are consistent. Engineering representation ensures technical feasibility and infrastructure compatibility. Data science or machine learning representation ensures statistical soundness and model compatibility. Product representation ensures alignment with business requirements and user needs. Legal representation ensures compliance with data protection regulations, intellectual property restrictions, and contractual obligations. Trust and safety or ethics representation ensures that datasets do not encode prohibited biases or enable harmful use cases. For high-risk domains like healthcare, finance, or hiring, domain expert representation ensures that datasets meet domain-specific quality and safety standards.

A startup with ten people does not need a formal board. A startup needs a designated approver: one person who reviews dataset decisions and has authority to say no. As the company grows to fifty people, the designated approver becomes a three-person review group: engineering, product, and data science. At two hundred people, the review group formalizes into a governance board with regular meetings, documented procedures, and escalation paths. At two thousand people, the governance board operates like any other cross-functional decision body with subcommittees, delegated authority for low-risk decisions, and executive escalation for high-risk decisions.

The board meets on a fixed cadence: weekly for fast-moving organizations, biweekly for most, monthly for slower-moving or lower-risk contexts. Ad hoc meetings can be scheduled for urgent decisions, but most dataset governance decisions are not urgent. A new dataset takes weeks to build. A dataset modification takes days to implement. The board cadence should match the natural rhythm of dataset work, not the speed of code deployment. If your board meets monthly and a dataset request cannot wait a month, the request is either genuinely urgent and should be escalated, or it is poorly planned and should have been submitted earlier.

## Approval Workflows for New Datasets

Creating a new dataset is a capital investment decision. The dataset will consume engineering time to build, storage to host, compute to process, and ongoing maintenance to keep current. The dataset will create dependencies: models will rely on it, pipelines will ingest it, documentation will reference it. The dataset will create obligations: you must keep it updated, you must keep it secure, you must retire it gracefully when it is no longer needed. New dataset approval is not a rubber stamp. It is a deliberate decision to take on long-term cost and responsibility.

The approval workflow starts with a proposal. The proposer, typically a data scientist or machine learning engineer, submits a written request that describes the purpose of the dataset, the intended use case, the data sources, the size and scope, the quality requirements, the timeline, and the success criteria. The proposal addresses compliance: does the dataset include personal data, does it require consent, does it fall under GDPR or CCPA, does it require data protection impact assessment under the EU AI Act? The proposal addresses risk: is this a high-risk use case, what happens if the dataset is low quality, what happens if the dataset leaks?

The governance board reviews the proposal at the next scheduled meeting. The board asks questions. Does this dataset duplicate an existing dataset? Can an existing dataset be extended instead of creating a new one? Are the data sources reliable and legal to use? Are the quality requirements realistic given the timeline and budget? Does the proposer have the skills and resources to build this dataset? Is the dataset architecture compatible with existing infrastructure? The board does not micromanage the technical details. The board validates that the proposal is sound, that the risks are understood, and that the investment is justified.

The board approves, rejects, or requests changes. Approval means the proposer can proceed with dataset creation and can reserve the necessary resources. Rejection means the proposal is declined and the proposer must either revise fundamentally or abandon the effort. Requested changes mean the proposal is promising but incomplete, and the proposer must address specific concerns and resubmit. A decision is documented in writing with reasoning. If the board rejects a proposal, the rejection memo explains why so the proposer understands what would need to change for future proposals.

A financial services company in early 2025 formalized their dataset governance board after a regulatory audit found that datasets were being created without compliance review. The board rejected 30% of new dataset proposals in the first six months. Most rejections were for duplicative datasets that could be replaced by extending existing datasets. Several rejections were for datasets that included third-party data without proper licensing. Two rejections were for datasets that would have required consent the company could not obtain. The rejection rate dropped to 10% over the next year as teams learned to self-review proposals before submission and to coordinate with existing dataset owners before proposing new datasets. The board prevented waste, prevented compliance violations, and raised the quality bar for dataset creation.

## Approval Workflows for Dataset Modifications

Modifying an existing dataset is lower risk than creating a new dataset, but it still requires governance. Dataset modifications include adding new examples, removing examples, changing labels, changing schema, merging with another dataset, splitting into multiple datasets, or changing access controls. Some modifications are low risk: adding 1,000 new examples to a dataset with 500,000 examples is unlikely to break anything. Some modifications are high risk: changing label definitions in a dataset used by three production models will break all three models unless coordinated carefully.

The approval workflow for modifications is tiered. Low-risk modifications require lightweight approval: a single designated reviewer, often the dataset owner, approves the change with a brief written justification. Medium-risk modifications require engineering and data science review: two people from different functions review the change and confirm that it will not break dependencies. High-risk modifications require full governance board review: the change is proposed, reviewed, and approved using the same process as a new dataset.

What counts as high risk? Changes to label definitions are always high risk because they invalidate all models trained on the old labels. Changes to schema that add or remove required fields are high risk because they break pipelines. Deletions of more than 10% of the dataset are high risk because they may degrade model performance. Changes to access controls that expand who can see the dataset are high risk because they may violate data minimization or need-to-know principles. Merging datasets from different sources is high risk because it may introduce distribution shift or quality inconsistencies. The dataset documentation should define the risk thresholds explicitly so contributors know when to escalate.

A healthcare AI company in mid-2025 implemented a three-tier modification workflow. Tier 1 modifications, such as adding examples without changing schema, required only the dataset owner's approval and were logged in a changelog. Tier 2 modifications, such as adding new fields or changing sampling strategy, required approval from the dataset owner and one data science reviewer, with a written impact assessment. Tier 3 modifications, such as changing label definitions or merging datasets, required governance board approval with a formal review meeting. Over twelve months, 80% of modifications were Tier 1, 15% were Tier 2, and 5% were Tier 3. The tiered workflow kept governance overhead low for routine changes while ensuring scrutiny for risky changes.

## Approval Workflows for Dataset Retirement

Datasets do not live forever. Datasets become stale, obsolete, replaced, or prohibited. Retirement is the formal process of moving a dataset from active use to archived or deleted status. Retirement requires approval because datasets have dependencies, and retiring a dataset without migrating those dependencies breaks production. Retirement also requires approval because deletion is irreversible, and premature deletion may destroy data needed for audit, appeal, or compliance.

The retirement workflow starts with a retirement proposal. The proposer, often the dataset owner or a system architect, submits a request that describes the dataset to be retired, the reason for retirement, the dependencies that must be migrated, the migration timeline, and the disposition plan: archive or delete. The governance board reviews the proposal and confirms that all dependencies have been identified and have migration plans. The board confirms that archival or deletion complies with data retention policies and legal hold requirements. The board approves a retirement timeline, typically 30 to 90 days, during which the dataset is marked as deprecated but remains available.

During the deprecation period, the dataset owner notifies all known consumers, updates documentation to indicate deprecation, and supports migration to replacement datasets or alternative approaches. At the end of the deprecation period, the dataset is either archived to read-only storage with restricted access or deleted entirely. Archive is appropriate when the dataset may be needed for audit, legal discovery, or historical analysis. Deletion is appropriate when retention is prohibited by regulation, when storage cost is prohibitive, or when the data is truly obsolete and has no future value.

A customer support AI company in late 2025 retired a dataset built in 2022 that was used to train a classification model. The dataset was three years old, covered a product line that had been discontinued, and included customer data under a retention policy that required deletion after three years. The retirement proposal identified four models that still referenced the dataset. Three models were retrained on a newer dataset. One model was retired because the use case was no longer active. The dataset was deprecated for sixty days, then deleted. The deletion was logged and verified with a hash check to confirm that no copies remained in active storage. The retirement process took four months from proposal to deletion, but it was coordinated, documented, and compliant.

## RACI Matrices for Dataset Governance

RACI is a simple framework for clarifying roles in decision processes. RACI stands for Responsible, Accountable, Consulted, Informed. For each decision type, you assign who is Responsible for doing the work, who is Accountable for the decision, who must be Consulted before the decision is made, and who must be Informed after the decision is made. RACI eliminates ambiguity about who does what.

For new dataset creation, Responsible is typically the data scientist or machine learning engineer proposing the dataset. Accountable is the governance board, which approves or rejects. Consulted includes dataset owners of related datasets, infrastructure engineers who will host the dataset, and legal or compliance if the dataset includes regulated data. Informed includes downstream consumers who may want to use the dataset and leadership who track dataset investment.

For dataset modification, Responsible is the dataset owner or contributor making the change. Accountable is the approver, which may be the dataset owner for low-risk changes or the governance board for high-risk changes. Consulted includes engineers who maintain models trained on the dataset, data scientists who use the dataset for experiments, and compliance if the change affects data scope. Informed includes all registered consumers of the dataset.

For dataset retirement, Responsible is the dataset owner executing the retirement process. Accountable is the governance board, which approves the retirement timeline and disposition. Consulted includes all consumers who depend on the dataset and must migrate. Informed includes leadership and compliance who track dataset lifecycle.

A RACI matrix is not a bureaucratic exercise. It is a tool for preventing the everyone-owns-it-so-nobody-owns-it problem. It assigns clear accountability for every decision. It ensures that people who need to be consulted are consulted, not bypassed. It ensures that people who need to be informed are informed, not surprised. A well-defined RACI matrix reduces decision latency because there is no ambiguity about who has authority to approve.

## Scaling Governance from Startup to Enterprise

Governance structure must scale with organizational size and risk profile. A five-person startup building an internal tool does not need a governance board. A five-person startup needs one designated decision maker who reviews dataset proposals and keeps a changelog. A fifty-person startup building customer-facing models needs a lightweight review group: three people who meet weekly to review proposals and approve or reject within one week. A five-hundred-person company building multiple products needs a formal governance board with subcommittees: one subcommittee for low-risk internal datasets, another for high-risk customer-facing datasets, with escalation paths for edge cases.

A five-thousand-person enterprise needs federated governance: each business unit has its own governance board with local authority for unit-specific datasets, and a central governance council provides oversight for cross-unit datasets and sets governance policy. Federated governance prevents bottlenecks by distributing decision authority while maintaining consistency through shared policies and escalation mechanisms.

Governance overhead is real. Every approval workflow adds latency. Every review meeting consumes time. The goal is not zero overhead. The goal is proportional overhead. Low-risk decisions should have low overhead. High-risk decisions should have high scrutiny even if it adds latency. A modification that adds 100 examples to a 100,000-example dataset should be approved in minutes. A modification that changes label definitions in a dataset used by a regulated AI system should take days or weeks and should involve legal, compliance, and engineering review.

Governance automation reduces overhead without reducing scrutiny. Automated checks can validate that a dataset proposal includes all required fields, that a modification does not violate schema constraints, that a retirement request has identified all dependencies. Automated checks can enforce policies like "datasets containing personal data must have a data protection impact assessment" or "datasets larger than 1 TB must have a cost justification" or "datasets used in high-risk systems must be reviewed quarterly". Automation handles the mechanical checks, freeing the governance board to focus on judgment calls that require human expertise.

## When Governance Becomes Overhead vs When It Prevents Disasters

Governance becomes overhead when it adds process without adding value. Governance becomes overhead when every trivial decision requires a meeting, when approval timelines stretch to months for routine requests, when the process is so complex that people bypass it. Governance becomes overhead when it is designed for the worst case and applied uniformly to all cases, creating friction for low-risk work without meaningfully improving outcomes for high-risk work.

Governance prevents disasters when it catches non-obvious risks before they become production failures. Governance prevents disasters when it stops a dataset that includes unlicensed third-party data from entering production and exposing the company to legal liability. Governance prevents disasters when it identifies that a proposed dataset duplicates an existing dataset and prevents wasted effort. Governance prevents disasters when it requires a data protection impact assessment for a high-risk use case and uncovers privacy risks that would have violated GDPR.

The test of good governance is this: can you point to specific incidents that governance prevented? If the answer is yes, governance is working. If the answer is no, governance may be overhead or may not be tested yet. A well-functioning governance board should reject or request changes on 10% to 30% of proposals. If the approval rate is 100%, the bar is too low or the proposals are self-censoring. If the rejection rate is over 50%, the process is unclear or the bar is unrealistic. The right balance depends on organizational maturity and risk tolerance, but zero rejections and zero change requests indicate that governance is not adding value.

## EU AI Act Requirements for Data Governance

The EU AI Act, enforced as of 2025, imposes specific data governance requirements on high-risk AI systems. High-risk systems include AI used in employment, credit scoring, law enforcement, critical infrastructure, education, and healthcare. For these systems, the AI Act requires that training, validation, and testing datasets meet quality criteria and that data governance processes are documented and auditable.

Article 10 of the AI Act requires that datasets be subject to appropriate data governance and management practices, including data collection, data preparation, data labeling, data storage, data aggregation, data retention, and data deletion. The Act requires that datasets be relevant, representative, and free of errors to the extent possible. The Act requires that datasets be examined for biases and that mitigation measures be implemented where feasible. The Act requires that data provenance be documented so that the source and processing history of the data can be traced.

For organizations building high-risk AI systems in or for the EU, dataset governance is not an internal best practice. It is a legal requirement. A governance board that reviews dataset quality, compliance, and bias mitigation is one way to demonstrate compliance with Article 10. A documented approval workflow that requires data protection impact assessment for high-risk datasets is another. A RACI matrix that assigns accountability for data quality is a third. The specific structure matters less than the ability to demonstrate to an auditor that data governance is systematic, documented, and enforced.

A hiring platform in early 2025 implemented dataset governance to comply with the EU AI Act's requirements for high-risk AI in employment. The governance board included legal, HR, data science, and an external fairness auditor. Every dataset used to train or evaluate hiring models required board approval. Every dataset was assessed for bias across protected categories. Every dataset had documented provenance linking each example to its source and consent. When audited in mid-2025, the company provided governance meeting minutes, approval memos, bias assessment reports, and provenance logs. The auditor concluded that the data governance practices met the Act's requirements. The governance structure was not burdensome. It was nine people meeting biweekly for one hour, reviewing two to four proposals per meeting. The cost was eighteen person-hours per month. The value was regulatory compliance and reduced risk of discriminatory outcomes.

## What Can Be Automated vs What Needs Human Judgment

Governance automation handles the mechanical checks that can be encoded as rules. Automated governance checks that a dataset proposal includes all required fields: purpose, data sources, size, quality requirements, compliance assessment, timeline. Automated governance checks that the proposer has write access to the target storage location. Automated governance validates that the dataset schema is compatible with the schema registry. Automated governance flags datasets that contain keywords associated with personal data, requiring a compliance review. Automated governance enforces naming conventions, tagging requirements, and metadata completeness.

Human judgment is required for decisions that involve tradeoffs, interpretation, or context. Human judgment decides whether a proposed dataset is sufficiently differentiated from an existing dataset to justify the duplication. Human judgment decides whether the quality requirements are realistic given the data sources and timeline. Human judgment decides whether a dataset's class imbalance is acceptable for the intended use case or requires rebalancing. Human judgment decides whether a dataset's bias assessment is thorough or superficial. Human judgment decides whether a retirement timeline is long enough to allow graceful migration or so long that it delays necessary cleanup.

The division of labor is clear. Automation enforces policy. Humans make decisions. A governance workflow that uses automation to check compliance with mechanical rules and then routes compliant proposals to humans for approval is faster and more consistent than a workflow that relies on humans to check everything. A governance board that receives proposals that have already been validated for completeness and format compliance can focus its time on the substantive questions that require expertise and judgment.

Once governance defines who decides, the next question is when to stop using a dataset. Deprecation and sunsetting policies establish the triggers and processes for retiring datasets gracefully, ensuring that datasets do not become zombie infrastructure that nobody dares to delete.
