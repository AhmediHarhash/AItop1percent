# 9.10 â€” Encryption at Rest and in Transit: Key Management and Rotation

In early 2025, two healthcare AI companies suffered data breaches within the same month. Company A had encrypted their 8-terabyte training dataset with AES-256. Company B had not encrypted anything. Both lost patient data. Regulators fined Company A more than Company B because Company A had demonstrated knowledge of security requirements and then implemented them incompetently: they stored the encryption keys in the same S3 bucket as the encrypted files, protected by the same compromised credentials. The encryption was mathematically perfect. The key management was catastrophically broken. This is the encryption paradox. Encrypting data without securing the keys is worse than not encrypting at all, because it creates false confidence that prevents teams from implementing real security controls. Encryption is table stakes in 2026, but only if you understand that encryption without key management is security theater.

Encryption is table stakes for AI datasets in 2026. It is also profoundly misunderstood by most teams who implement it. This subchapter teaches you how to encrypt datasets correctly, how to manage the keys that make encryption meaningful, and how to avoid the patterns that turn encryption into security theater.

## Why Encryption Is Not Optional

You encrypt AI datasets for three reasons. First, because regulators require it: HIPAA mandates encryption for protected health information, GDPR requires appropriate technical measures that encryption satisfies, and the EU AI Act explicitly references encryption in its security requirements for high-risk systems. Second, because your contracts require it: enterprise customers demand encryption clauses, cloud providers mandate it in their compliance certifications, and cyber insurance policies increasingly make it a prerequisite for coverage. Third, because when you lose an encrypted dataset, you have a security incident; when you lose an unencrypted dataset, you have a career-ending catastrophe and a front-page story.

But encryption only protects data if attackers cannot access the keys. A locked safe with the key taped to the door is not security. This is the fundamental mistake most teams make: they implement encryption as a checkbox compliance item without understanding that encryption and key management are inseparable. You cannot outsource your key management to defaults and convenience. Every decision about where keys live, who can access them, and how they rotate determines whether your encryption is real protection or expensive theater.

The encryption landscape for AI datasets has two domains: data at rest and data in transit. Both must be encrypted. Both have different threat models. Both require different technical approaches.

## Encryption at Rest for Dataset Storage

Your training datasets, evaluation sets, and labeled data all sit somewhere: object storage buckets, managed databases, distributed file systems, or local disks. Encryption at rest means that the physical storage media contains only ciphertext. If someone steals a hard drive, pulls a backup tape, or gains read access to your storage bucket, they get encrypted bytes that are computationally infeasible to decrypt without the key.

The industry standard in 2026 is AES-256, the Advanced Encryption Standard with 256-bit keys. This is not a recommendation or a best practice. It is the minimum acceptable cipher. Anything less is professional negligence. AES-256 is fast enough for training pipeline throughput, strong enough to resist all known cryptographic attacks, and widely supported across every cloud platform and storage system you will use. You should not invent your own encryption scheme. You should not use weaker ciphers for performance reasons. You should not skip encryption for internal or temporary datasets.

When you configure encryption at rest, you face an immediate choice: server-side encryption with provider-managed keys, or server-side encryption with customer-managed keys. This choice determines who controls your data security. Provider-managed keys mean AWS, Google Cloud, or Azure generates, stores, and rotates the encryption keys automatically. You enable encryption with one configuration flag. The cloud provider handles everything. This is convenient. It is also insufficient for most production AI systems, because the cloud provider can decrypt your data at any time, law enforcement can compel the provider to decrypt without notifying you, and you have no control over key rotation schedules or access policies.

Customer-managed keys, often called CMKs or BYOK, mean you create and control the master encryption key through a key management service. AWS KMS, Google Cloud KMS, and Azure Key Vault all provide this capability. You define the key policies, you control who can use the key to encrypt or decrypt, you set the rotation schedule, and you can revoke access instantly if needed. The cloud provider still performs the encryption operations, but they cannot decrypt your data without your key, and you can audit every single use of that key. This is the correct choice for any dataset containing PII, proprietary information, or data subject to regulatory requirements. The operational overhead is minimal. The security benefit is fundamental.

## Encryption in Transit for Data Movement

Data moves constantly in AI workflows: from storage to training nodes, from training clusters to evaluation servers, from production databases to inference endpoints, from third-party annotation vendors back to your systems. Every network hop is an opportunity for interception. Encryption in transit protects data while it moves across networks, ensuring that attackers monitoring network traffic see only ciphertext.

The standard here is TLS, Transport Layer Security, specifically TLS 1.3 as of 2026. Earlier versions have known vulnerabilities and should be disabled. TLS encrypts the communication channel between two systems. When your training script downloads data from S3, that connection uses TLS. When your inference API receives a request, that connection uses TLS. When your data pipeline queries a database, that connection should use TLS. The key word is should: many internal systems default to unencrypted connections because they sit behind a firewall or within a VPC, and teams assume network isolation provides security. This is a dangerous assumption. Attackers who breach your perimeter can monitor internal traffic. Compliance auditors will flag unencrypted database connections. Your threat model must assume internal networks are hostile.

For service-to-service communication within your AI infrastructure, mutual TLS provides stronger security than standard TLS. In mutual TLS, both the client and server present certificates and verify each other's identity before exchanging data. This prevents an attacker who has compromised one service from impersonating another service to steal data. Implementing mutual TLS requires certificate infrastructure and careful key distribution, but for high-stakes datasets, it is worth the operational cost. A financial services company running a fraud detection model with mutual TLS between all data pipeline components can prove to auditors that only authenticated, authorized services ever touched the training data. A company relying on firewall rules and hope cannot.

## Key Management: Who Holds the Keys

Encryption is mathematics. Key management is governance. The security of your encrypted datasets depends entirely on who can access the encryption keys, under what circumstances, and with what oversight. Poor key management has caused more data breaches than weak encryption algorithms ever will.

The first principle of key management is separation of duties. The people who manage your infrastructure should not be the same people who control your encryption keys. The service accounts that run your training jobs should not have permissions to delete or modify encryption keys. The developers who write your data pipeline code should not have direct access to production encryption keys. This separation ensures that no single compromised account or rogue insider can both steal encrypted data and decrypt it. You enforce this separation through IAM policies in your cloud provider, role-based access control in your key management system, and organizational policies that treat key access as a privileged operation requiring approval and logging.

The second principle is key hierarchy. You never encrypt data directly with your master key. Instead, you use envelope encryption: the master key encrypts data encryption keys, and the data encryption keys encrypt the actual data. This pattern has two critical benefits. First, you can rotate the master key without re-encrypting terabytes of training data, because you only need to re-encrypt the small data encryption keys. Second, you can distribute data encryption keys to training nodes without exposing the master key, limiting the blast radius if a node is compromised. AWS KMS, Google Cloud KMS, and Azure Key Vault all implement envelope encryption automatically. You create a customer-managed master key, and the service generates unique data encryption keys for each encrypted object.

The third principle is rotation. Encryption keys should not be eternal. The longer a key remains in use, the more ciphertext is encrypted with that key, and the more opportunities attackers have to capture it. Key rotation means periodically replacing encryption keys with new ones. For master keys in a key management service, annual rotation is common. For data encryption keys protecting ephemeral datasets, rotation after each training run is reasonable. For data encryption keys protecting long-lived datasets, rotation every 90 days balances security and operational overhead.

## The Key Rotation Problem for AI Datasets

Rotating keys sounds simple in theory. In practice, it collides with the realities of AI dataset engineering. Your training dataset is 12 terabytes, stored as 40,000 parquet files in S3. You want to rotate the encryption key. What happens? You must download every file, decrypt it with the old key, encrypt it with the new key, and upload it back. This process will take hours or days, consume massive bandwidth, cost thousands of dollars in egress fees, and block training runs while it completes. Most teams see this cost once and decide never to rotate keys again. This is the wrong decision.

The correct solution is envelope encryption combined with lazy re-encryption. Your master key in KMS encrypts the data encryption keys. When you rotate the master key, you only re-encrypt the data encryption keys, which are small metadata objects. The actual dataset files remain encrypted with the same data encryption keys, which are now protected by the new master key. This operation completes in seconds, costs almost nothing, and does not interrupt training. Over time, as files are naturally updated or reprocessed, you re-encrypt them with new data encryption keys during the write operation. This lazy approach spreads the cost of re-encryption across normal data pipeline activity.

If you cannot use envelope encryption because your storage system does not support it, you implement versioned encryption. New data gets encrypted with the new key. Old data remains encrypted with the old key, which you retain in a disabled state that allows decryption but not encryption. You track which files use which key version through metadata tags. Over the course of your normal data refresh cycle, old files are replaced with new files using the new key. This approach avoids the big-bang re-encryption problem and still achieves regular key rotation.

A SaaS company training recommendation models on customer interaction data used versioned encryption to rotate keys every quarter without downtime. They tagged every S3 object with the key version that encrypted it. New data always used the current key. Training jobs could read data encrypted with any key version from the past year, after which old data was deleted per their retention policy. Auditors could verify that no data was encrypted with keys older than 12 months. The system was secure, auditable, and operationally sustainable.

## Hardware Security Modules vs Software Key Management

Your encryption keys live in one of two places: a Hardware Security Module or a software-based key management service. HSMs are physical devices designed specifically to generate, store, and use cryptographic keys without ever exposing those keys to software or networks. They are tamper-resistant, FIPS 140-2 Level 3 certified, and provide the highest level of key protection available. Cloud providers offer HSM-backed key management as a premium tier: AWS CloudHSM, Google Cloud HSM, Azure Dedicated HSM.

Software key management services like AWS KMS, Google Cloud KMS, and Azure Key Vault store keys in encrypted form within the cloud provider's infrastructure, protected by layers of access control and monitoring. They are cheaper, easier to integrate, and sufficient for most AI workloads. The keys are still protected by strong encryption, the services are audited and certified for compliance, and the operational simplicity is significant.

You choose HSMs when your regulatory requirements explicitly mandate them, when your threat model includes nation-state adversaries, or when you are building a system where key compromise would be catastrophic and unrecoverable. A government contractor training models on classified data uses HSMs. A healthcare AI company subject to HIPAA can usually justify software KMS. The decision comes down to your risk tolerance, budget, and compliance obligations. The important thing is to make the decision consciously, document the rationale, and implement the chosen solution correctly.

## Cloud KMS Services in Practice

Every major cloud provider offers a managed key management service. These services are not equivalent, but they all provide the core capabilities you need: customer-managed keys, envelope encryption, key rotation, access policies, and audit logging. AWS KMS is the most mature and feature-rich. Google Cloud KMS integrates tightly with Google Cloud's data services. Azure Key Vault unifies key management, secret storage, and certificate management.

When you create a customer-managed key in any of these services, you define the key policy: which IAM roles can use the key to encrypt or decrypt, which roles can manage the key itself, and which roles can view audit logs. Your data pipeline service account gets encrypt and decrypt permissions. Your security team gets administrative permissions. Your auditors get read-only access to logs. No one gets all three. This separation of privileges is enforced by the key management service and cannot be bypassed by compromising a single account.

Every use of your encryption key generates an audit log entry: who used the key, from which IP address, at what time, for which operation, and whether the operation succeeded or failed. These logs feed into your SIEM system, trigger alerts for anomalous access patterns, and provide the evidence trail regulators demand during audits. A spike in decrypt operations from an unusual geographic region at 3 AM is suspicious. A sudden attempt to use a key by a service account that has never accessed it before is a potential breach. You cannot detect these patterns without comprehensive audit logging, and you cannot achieve comprehensive audit logging without a proper key management service.

## Common Mistakes That Destroy Encryption Security

The first mistake is hardcoded keys. Developers put encryption keys directly in source code, configuration files, or environment variables. These keys end up in version control, get copied across environments, and are visible to anyone with repository access. You find hardcoded keys by running secret scanning tools against your codebase, by auditing environment variable configurations, and by enforcing policies that require all encryption keys to come from a key management service. There is no legitimate reason for an encryption key to exist as a plaintext string in a file. None.

The second mistake is shared keys across environments. Your development environment uses the same encryption key as your production environment. When a developer's laptop is compromised, the attacker gains the ability to decrypt production datasets. When a staging environment is misconfigured with public access, production data is exposed. You prevent this by creating separate keys for each environment, enforcing strict IAM policies that prevent cross-environment key usage, and treating production keys as untouchable outside production systems.

The third mistake is no rotation. Keys are created once, during initial system setup, and never changed. Years pass. Employees leave the company with knowledge of the key. Laptops are lost. Compliance certifications expire. The key remains the same. This mistake stems from the belief that key rotation is too operationally expensive. It is not, if you use envelope encryption and lazy re-encryption. The cost of never rotating keys is an eventual breach and the inability to prove that old, potentially compromised keys are no longer in use.

The fourth mistake is the encrypted-but-accessible anti-pattern. Your dataset is encrypted at rest with AES-256. Your key management is solid. Your access controls are not. Every engineer in the company has IAM permissions to read the S3 bucket. Every training job runs with credentials that can decrypt the entire dataset. The data is encrypted, yes, but it is also trivially accessible to anyone with basic AWS credentials. Encryption without access control is theater. You must implement both: strong encryption managed through a proper KMS, and least-privilege access policies that limit who can decrypt the data to only the services and individuals who absolutely require it.

## Building an Encryption Strategy That Lasts

Encryption is not a one-time implementation. It is a system that evolves with your infrastructure, your threat model, and your regulatory obligations. You build an encryption strategy that lasts by making encryption automatic, by separating key management from data management, by enforcing rotation as policy rather than relying on manual effort, and by auditing key usage continuously.

Automatic encryption means every new dataset, every new storage bucket, every new database is encrypted by default through infrastructure-as-code templates and organizational policies. Manual encryption requires engineers to remember to enable it, and engineers will forget. Default-deny policies require explicit exceptions to store unencrypted data, and those exceptions require security review and executive approval. This inverts the incentive structure: encrypted becomes the path of least resistance, and unencrypted requires justification.

Separation of key management from data management means your data engineering team does not control encryption keys. They control data pipelines, storage configurations, and access policies. Your security team controls keys, rotation schedules, and key policies. This separation ensures that no single team can compromise encryption security through accident or malice. It also ensures that key management receives the focused attention it requires rather than being an afterthought in data pipeline work.

Enforced rotation as policy means your key rotation schedule is automated, monitored, and escalates to leadership if it fails. You do not rely on engineers remembering to rotate keys quarterly. You configure automated rotation in your KMS, you monitor the rotation events in your SIEM, and you alert the security team if a rotation does not occur as scheduled. The system enforces the policy, not human discipline.

Continuous audit means every key access, every decrypt operation, and every policy change generates a log entry that is analyzed for anomalies. You are not searching logs after a breach is discovered. You are detecting breaches through unusual key usage patterns before data is exfiltrated. This requires investment in logging infrastructure, SIEM tooling, and alert tuning, but the return is the difference between detecting a breach in minutes versus discovering it months later through a regulatory investigation.

Encryption is not the hardest part of dataset security. Key management is. You protect data by protecting keys, and you protect keys through separation of duties, rotation, access control, and continuous monitoring. The mathematics of AES-256 is unbreakable. The governance of who holds the keys is where most teams fail. Do not be most teams.

Your encrypted datasets are only as secure as the keys that protect them, and those keys are only as secure as the secret scanning and access controls you layer on top, which is where we turn next.
