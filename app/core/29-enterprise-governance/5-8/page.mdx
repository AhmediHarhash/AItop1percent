# 29.5.8 — Model Retirement: End-of-Life Decisions, Data Cleanup, and Transition Plans

When was the last time your organization formally retired an AI model? Not replaced it — formally retired it, with a documented decision, a migration plan, a data cleanup process, and an archival record? Most organizations cannot answer because they have never done it. They have detailed deployment procedures — risk assessments, validation gates, approval workflows, documentation requirements. They have nothing for retirement. Models are abandoned rather than retired: traffic is rerouted, the old endpoint is left running until someone notices the infrastructure cost, and the training data, documentation, and compliance artifacts are scattered across storage systems that nobody remembers to clean up.

This is the **governance retirement gap**. Every model has a finite useful life. Business needs shift, regulations change, better alternatives emerge, performance degrades past recovery. Retirement is inevitable. The question is whether it happens through a governed process that protects the organization, or through neglect that creates compliance risk, data liability, and the quiet accumulation of systems that nobody owns and nobody monitors.

## When to Retire: The Five Triggers

Model retirement is not a single decision. It is triggered by one of five conditions, each of which requires a different assessment and different urgency.

**Performance degradation below acceptable thresholds** is the most common trigger. Governance monitoring, described in the previous subchapter, detects when a system's performance has dropped below the thresholds that justified its deployment. When that degradation is sustained and cannot be remediated through retraining, prompt engineering, or configuration changes, the system has reached the end of its useful life. The governance question is not whether the system still works. It is whether the system still works well enough to justify the risk, the cost, and the compliance obligations of keeping it in production.

**Regulatory change that invalidates the compliance posture** is the most urgent trigger. When a new regulation prohibits the system's use case, reclassifies it into a risk tier the system cannot meet, or imposes requirements that cannot be retrofitted, the system must be retired within the compliance window — not at the team's convenience. The EU AI Act's prohibition on certain AI practices, including social scoring and real-time biometric identification in public spaces for law enforcement without authorization, took effect in February 2025. Organizations running systems that fell under those prohibitions had a defined timeline to shut them down. Regulatory retirement is not optional and does not wait for a replacement to be ready.

**Business need elimination** happens when the use case the system served no longer exists. A product line is discontinued. A market is exited. A workflow is redesigned to not require AI assistance. In these cases, the system continues to run, consume resources, and generate compliance obligations for a use case that no longer delivers value. Organizations that lack retirement processes accumulate these orphaned systems — technically functional, legally obligated, economically wasteful.

**Replacement by a superior system** is the happiest retirement trigger but the one most likely to leave cleanup undone. The team is excited about the new system. They focus on deploying the replacement, not decommissioning the predecessor. The old system lingers: its data remains, its documentation ages, its compliance artifacts become stale. Two years later, someone finds it still running in a staging environment connected to a production database, and nobody can explain why.

**Vendor discontinuation** occurs when a third-party provider deprecates or removes the model your system depends on. Major providers sunset models regularly. OpenAI deprecated several GPT-3.5 variants in 2024. Anthropic has evolved through multiple Claude generations. When your vendor retires the model underneath your system, you must retire or migrate your system on the vendor's timeline, not yours.

## The Retirement Checklist

Model retirement is a governance event that touches every function: engineering, product, legal, compliance, and data management. The retirement checklist ensures nothing is missed.

**User notification** comes first. Every stakeholder who depends on the system — internal users, external customers, downstream systems, partner integrations — must be notified with sufficient lead time. For customer-facing systems, notification timelines are often contractually defined. For internal systems, thirty to sixty days is standard for non-urgent retirements. The notification must include the retirement date, the reason, and the alternative — whether that is a replacement system, a manual process, or the elimination of the capability entirely.

**Traffic migration** is the engineering plan for moving all requests from the retiring system to its replacement or to a graceful error state. Migration must be gradual, not instantaneous. A phased migration — ten percent of traffic on day one, fifty percent after a week, full migration after two weeks — allows the team to detect issues with the replacement before all users are affected. During migration, both the old and new systems run in parallel, and governance monitoring covers both.

**Dependent system identification** requires mapping every system that calls the retiring model. This is harder than it sounds. In large organizations, models are consumed through internal APIs that other teams integrate without formal registration. The model registry, described in Subchapter 29.5.2, should track these dependencies — but registries are often incomplete. A comprehensive dependency scan before retirement prevents the failure mode where a system is retired and a downstream team discovers that their pipeline broke three days later.

**Data retention decisions** sit at the intersection of legal obligation and privacy compliance, and they are the hardest part of retirement. Training data, evaluation data, and operational logs associated with the retired model fall into multiple categories. Some data must be retained for regulatory compliance: the EU AI Act requires that technical documentation for high-risk systems be retained for ten years after the system is placed on the market, even after the system is decommissioned. Provider logs for high-risk systems must be retained for at least six months. Some data must be deleted for privacy compliance: GDPR's right to erasure means that personal data used in training may need to be removed once the processing purpose — the model — no longer exists. The challenge is that these obligations can conflict. The same dataset may contain both regulated records that must be retained for audit purposes and personal data that must be deleted for privacy compliance. The resolution requires legal analysis on a case-by-case basis, not a blanket policy.

**Documentation archival** preserves the governance record. The model card, risk assessment, validation results, deployment approval, monitoring reports, incident records, and the retirement decision itself are archived as a complete lifecycle record. This archive serves two purposes. It satisfies regulatory requirements for documentation retention. And it provides institutional memory — when a team three years later asks why the organization stopped using a particular approach, the archived record answers the question without requiring anyone to remember.

**Rollback capability during transition** means maintaining the ability to restore the retired system for a defined period after retirement. Not indefinitely — that would defeat the purpose — but long enough to recover if the replacement system fails in ways the migration testing did not reveal. Thirty to ninety days of rollback capability is standard, depending on the system's criticality. After the rollback window closes, the retired system's infrastructure is fully decommissioned.

## The Archive-vs-Delete Decision

The tension between archival obligations and deletion obligations is the defining challenge of model retirement data management. Different data types within the same system may require opposite treatment.

Model weights trained on proprietary data are typically archived. They represent significant investment, may be needed for forensic analysis if a post-retirement complaint emerges, and do not usually contain personal data in an extractable form. However, if the model was trained on personal data and regulators determine that model weights constitute derived personal data — a question that remains legally unsettled in 2026 — archival may require additional safeguards or may not be permissible at all.

Training datasets that contain personal data face the most complex analysis. If the legal basis for processing that data was the model's operation, and the model is retired, the legal basis may no longer hold. GDPR's storage limitation principle requires that personal data not be kept longer than necessary for the purpose it was collected. If the purpose was training a specific model and that model no longer exists, continued storage requires a new legal basis — legitimate interest in audit compliance, for example, or a legal obligation to retain records. The analysis must be documented, and the conclusion must be reviewed by Legal before the data is either archived or deleted.

Operational logs, inference records, and monitoring data are typically subject to defined retention periods. Once those periods expire, the data is deleted. But during the retention period, the data must be stored securely and access-controlled, even though the system that generated it no longer exists. Orphaned data stores — logs from retired systems that nobody owns and nobody monitors — are a common compliance vulnerability.

## Retirement as a GDPR Compliance Trigger

Model retirement can trigger GDPR obligations beyond data deletion. Under Article 17, data subjects have the right to request erasure of personal data when the data is no longer necessary for the purpose for which it was collected. If a data subject's information was collected to train a model and that model is retired, the subject has a stronger basis for an erasure request than they did while the model was operating. Your retirement process must include a review of pending or potential erasure requests and a plan for handling them.

The technical challenge is significant. Personal data embedded in model weights cannot be surgically removed without retraining the model — which is pointless if the model is being retired. The emerging field of machine unlearning offers theoretical approaches but remains far from production-ready in 2026. The practical solution for most organizations is to ensure that personal data in training datasets is deleted, that model weights are archived with access controls that prevent their use for any purpose other than audit or legal defense, and that the organization can demonstrate to regulators that it has taken reasonable steps to limit the continued processing of personal data after retirement.

## Preventing the Retirement Gap

The governance retirement gap exists because organizations design their governance processes around deployment — the exciting part — and neglect decommissioning — the unglamorous part. Closing the gap requires three structural changes.

First, retirement procedures must be defined before the first model is deployed, not after the first model needs to be retired. The retirement checklist should be part of the governance framework from day one, reviewed during deployment planning, and referenced in the model registry entry for every system.

Second, every model registry entry must include a planned review date — the date by which the system's continued operation will be assessed. This is not a retirement date. It is a "should this still be running?" date. For high-risk systems, this review should occur annually at minimum. For lower-risk systems, every eighteen to twenty-four months is sufficient.

Third, retirement must have an owner. Someone in the governance team is responsible for tracking systems approaching their review dates, initiating the retirement assessment when triggers are met, and ensuring that the retirement checklist is executed completely. Without an owner, retirement becomes everyone's second priority and nobody's first.

Every model enters production. Every model eventually leaves production. The governance gap is not about whether retirement happens. It is about whether retirement happens through a controlled process that protects the organization, or through neglect that creates liability. The next subchapter addresses the hardest governance challenge in the current AI landscape: governing agentic systems that do not just generate outputs but take autonomous actions in the real world.
