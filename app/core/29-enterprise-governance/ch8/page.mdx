# Chapter 8 — AI Incident Management and Regulatory Reporting

AI incidents are not software bugs. A software bug produces the wrong output and someone files a ticket. An AI incident produces a biased hiring decision affecting thousands of applicants, a hallucinated medical recommendation that a patient follows, or a leaked piece of training data that triggers a regulatory investigation. The organizational response required for AI incidents crosses engineering, legal, communications, and compliance in ways that traditional incident management was never designed to handle. This chapter builds the governance layer for AI incident response — classification frameworks, cross-functional playbooks, regulatory reporting obligations, and the near-miss programs that catch failures before they become headlines.

---

- 29.8.1 — Why AI Incidents Are Different from Software Incidents
- 29.8.2 — AI Incident Classification: Severity Frameworks for AI-Specific Failures
- 29.8.3 — The AI Incident Response Playbook: From Detection to Resolution
- 29.8.4 — Cross-Functional Incident Response: Engineering, Legal, Comms, and Compliance
- 29.8.5 — Regulatory Incident Reporting: What Must Be Reported, to Whom, and When
- 29.8.6 — Post-Incident Analysis: Root Cause, Systemic Fixes, and Governance Updates
- 29.8.7 — The Near-Miss Program: Learning from Failures That Almost Happened
- 29.8.8 — Building an Incident Learning Culture: From Blame to Improvement

---

*The measure of a governance program is not whether incidents happen — they will. The measure is whether your organization detects them fast, responds correctly, reports when required, and learns every time.*
