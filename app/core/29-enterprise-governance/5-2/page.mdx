# 29.5.2 — The Model Registry: Single Source of Truth for Every AI System

A model that is not in the registry does not exist for governance purposes. It does not get monitored. It does not get reviewed. It does not get retired when its training data expires or its performance degrades. It sits in production, processing real data, affecting real users, accumulating real risk — invisible to the people whose job it is to manage that risk. The **model registry** is where governance stops being a policy and starts being a system. It is the operational implementation of the AI inventory described in the previous subchapter: not a spreadsheet someone updates quarterly, but an always-current, queryable, enforceable system of record that holds the metadata for every AI model and AI system in your organization.

The distinction between having an inventory and having a registry is the distinction between knowing what you have and being able to act on it. An inventory tells you that a credit-scoring model exists. A registry tells you who owns it, when it was last validated, what data it was trained on, which regulatory jurisdictions it operates in, when its next review is due, whether that review is overdue, and what happens if the review is not completed. The registry is the integration point where governance workflows, compliance checks, monitoring alerts, and audit queries all converge. Without it, every governance process is manual, fragmented, and unreliable.

## What a Model Registry Contains

A production-grade model registry stores metadata across several categories, and understanding what goes into each category is essential before you evaluate build-versus-buy options.

The identity layer captures the system name, a unique model identifier, the current version number, the version history with links to prior versions, and a plain-language description of what the model does. This sounds trivial, but version tracking alone prevents one of the most common governance failures: teams deploying updated models without governance teams realizing the previous approval no longer applies. A model approved for production in version 2.1 is not automatically approved in version 2.4 if the training data changed or the architecture was modified. The registry must make version transitions visible.

The ownership layer records the individual owner (not a team alias — a named person who is accountable), the team responsible for development, the team responsible for operations, and the escalation path for governance issues. When an auditor asks "who is responsible for this system," the answer must come from the registry in seconds, not from a chain of emails over three days.

The risk and compliance layer holds the internal risk classification, the applicable regulatory classifications (EU AI Act risk tier, whether the system falls under HIPAA, SOX, or sector-specific regulations), the date of the last risk assessment, and the next scheduled review. For organizations operating under the EU AI Act, this layer must also track whether the system has been registered in the EU database as required for high-risk systems, and whether the conformity assessment is current.

The technical layer stores the model architecture, the training data summary (not the raw data, but a description of sources, volume, date range, and any known limitations), the evaluation metrics from the most recent validation run, deployment configuration details, the API dependencies (whether the system calls external models from providers like OpenAI, Anthropic, or Google), and the infrastructure environment where the model runs. This layer is what connects the governance metadata to the engineering reality.

The lifecycle layer tracks the deployment status (development, staging, production, deprecated, retired), the date the system entered each status, approval records for each transition, and any incidents or alerts logged against the system. This layer creates the audit trail that regulators require and that internal governance teams need to understand the full history of a system's operational life.

## Model Cards as the Documentation Standard

Each entry in the registry should be accompanied by a **model card** — a structured document that summarizes a model's purpose, capabilities, limitations, and risks in a format readable by both technical and non-technical stakeholders. The concept was introduced by Margaret Mitchell and colleagues at Google in 2018, and by 2026 it has become the de facto documentation standard adopted by every major AI provider, from Google DeepMind to Hugging Face to internal enterprise teams.

A model card is not a technical specification. It is a communication artifact designed to answer the questions that governance teams, compliance officers, and downstream users need answered. A well-written model card covers intended use (what the model is designed to do), out-of-scope uses (what the model should not be used for), the training data description (sources, demographics, known gaps), evaluation results (key metrics on relevant benchmarks), ethical considerations (potential for harm, known biases), and limitations (conditions under which the model is likely to fail or degrade). We will cover model card content in much greater depth in the next subchapter. What matters here is the relationship between the model card and the registry: the registry holds the structured metadata, and the model card provides the narrative context that makes the metadata meaningful.

## Build Versus Buy: Registry Implementation Options

The model registry market in 2026 offers three tiers of implementation, and the right choice depends on your organization's scale, regulatory exposure, and existing infrastructure.

The first option is open-source registries. MLflow Model Registry remains the most widely deployed open-source option, offering version tracking, stage transitions (staging to production to archived), and basic metadata storage. It integrates with most ML platforms and is well-suited for organizations with strong engineering teams that can build governance workflows on top of a technical foundation. The limitations of open-source MLflow are real, however. It lacks native role-based access control, which means any user with access can modify entries without permission checks. It does not enforce governance workflows — there is no built-in concept of "this model requires legal approval before moving to production." And it does not provide compliance-ready audit trails without significant customization. For organizations in heavily regulated industries, open-source MLflow is a starting point, not a destination.

The second option is commercial governance platforms. Credo AI, IBM watsonx.governance, and a growing number of specialized vendors offer purpose-built AI governance platforms that combine model registry functionality with risk assessment, compliance mapping, and audit-ready reporting. Credo AI, for instance, integrates with Databricks MLflow to automatically discover and catalog AI systems in development or production, and offers pre-built Policy Packs aligned with the EU AI Act, ISO 42001, and the NIST AI Risk Management Framework. IBM watsonx.governance provides lifecycle tracking, bias detection, and explainability tools within the broader IBM ecosystem. These platforms cost more than open-source options — typically seventy-five thousand to three hundred thousand dollars per year for enterprise licenses — but they eliminate the engineering effort of building governance workflows from scratch and they produce the compliance artifacts regulators expect.

The third option is a custom-built registry tailored to your organization's specific governance model. This makes sense only for very large enterprises — typically those with more than a hundred AI systems in production — whose governance requirements are complex enough that neither open-source nor commercial options fit without extensive modification. A custom registry can integrate with your existing identity management, your deployment pipelines, your compliance workflows, and your audit systems in ways that a vendor product may not. The trade-off is cost and maintenance burden. A custom registry is an internal product with its own roadmap, its own engineering team, and its own technical debt. Organizations that build custom registries and then underfund them end up with a governance system that degrades faster than the models it is supposed to track.

## The Adoption Problem: Teams Resist Registration

The hardest part of a model registry is not the technology. It is the adoption. Engineering teams view registry requirements as overhead. Data scientists see them as bureaucratic friction that slows down experimentation. Product managers want to ship features, not fill out metadata forms. If you launch a registry and rely on voluntary compliance, adoption will plateau at thirty to forty percent within six months, and the systems that remain unregistered will be disproportionately the ones with the highest risk — because those are the ones deployed under the most time pressure with the least governance involvement.

Effective enforcement requires three strategies working together. First, make registration a deployment gate. No model can be promoted to production without a registry entry that meets minimum completeness standards. This is enforced at the infrastructure level — the deployment pipeline checks for a valid registry entry before allowing the promotion. Second, make registration easy. If filling out the registry entry takes two hours and requires navigating a confusing interface, teams will work around it. The best registries auto-populate fields from the training pipeline (model architecture, training data hash, evaluation metrics) and require manual input only for the fields that need human judgment (risk classification, intended use, regulatory scope). The target is fifteen minutes for a standard registration, not two hours. Third, make non-compliance visible. Publish a monthly governance dashboard showing the percentage of AI systems registered per team. Name the teams with gaps. Escalate persistent non-compliance to the relevant VP. Social pressure and leadership visibility are more effective than policy documents that nobody reads.

## The Registry as Integration Point

The model registry is not a standalone system. It is the hub that connects every other governance process. When the governance team conducts a risk review, they query the registry to find all high-risk systems. When the compliance team prepares for an EU AI Act audit, they pull documentation from the registry. When the monitoring system detects performance degradation, the alert links back to the registry entry for the affected model. When a model is retired, the registry records the retirement date, the reason, and the replacement system. When a new regulation takes effect, the governance team can query the registry to identify every system operating in the affected jurisdiction.

Without the registry, each of these processes requires its own data source, its own discovery effort, its own reconciliation with whatever partial inventory exists. With the registry, they all reference the same authoritative record. That is what "single source of truth" means in practice — not that the registry contains everything, but that nothing else is considered authoritative when it contradicts the registry.

The next subchapter covers what goes inside the documentation for each model — model cards, technical documentation for regulatory compliance, and the audit trails that prove your governance is not just planned but practiced.
