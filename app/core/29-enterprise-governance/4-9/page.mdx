# 29.4.9 — The Compliance Operating Model: Who Owns What and How Work Flows

Compliance architecture without clear ownership is infrastructure without operators. It exists, it may even be well-designed, but nobody is responsible for ensuring it runs, nobody is accountable when it breaks, and nobody knows who to call when a regulator asks a question. The operating model defines who does what, who reports to whom, and how compliance work flows from the moment a new regulatory requirement is identified through the moment the organization can prove it is meeting that requirement across every AI system in production.

The most common failure is not a lack of compliance capability. It is a lack of clarity about where compliance responsibility lives. Engineering teams assume compliance is legal's job. Legal assumes engineering has built the controls. The governance team assumes product teams are documenting their risk assessments. Product teams assume someone else is tracking the regulatory calendar. The result is a compliance program where every team believes someone else is handling it — and auditors discover that nobody is.

## The Three Lines of Defense, Adapted for AI

The **three-line-of-defense model**, originally developed for financial services risk management, adapts cleanly to AI compliance. It provides the structural clarity that prevents the "someone else is handling it" failure.

The first line of defense is the engineering and product teams that build, deploy, and operate AI systems. These teams own compliance for their systems. They perform the risk assessments. They implement the controls. They produce the documentation. They respond to monitoring alerts. They remediate deficiencies. First-line ownership means that the team deploying a high-risk AI system in your healthcare division is responsible for ensuring that system meets all applicable compliance requirements — not because a compliance analyst told them what to do, but because they understand the requirements and have built their workflows to satisfy them.

The second line of defense is the governance and compliance function that sets standards, provides guidance, and monitors compliance across the organization. This team does not do compliance for product teams — that would be unsustainable and would create a bottleneck that grinds deployment to a halt. Instead, the second line defines the compliance standards, provides the templates and tools, trains the first-line teams, and monitors whether the first-line teams are meeting the standards. The second line also performs compliance reviews — sampling first-line evidence to verify its completeness and accuracy. When the second line finds a gap, it escalates to the first-line team for remediation and tracks the remediation to closure.

The third line of defense is internal audit, providing independent assurance that both the first and second lines are functioning as designed. Internal audit does not set compliance standards (that is the second line's job) and does not implement compliance controls (that is the first line's job). Internal audit tests whether the operating model works — whether the first line is actually performing the risk assessments it claims to perform, whether the second line is actually monitoring compliance as its charter requires, and whether the compliance evidence is actually reliable. The third line reports to the audit committee or the board, not to the same leadership chain that manages the first and second lines, ensuring independence.

## RACI for AI Compliance Activities

Clear ownership requires explicit mapping of who is Responsible, Accountable, Consulted, and Informed for each compliance activity. Without this mapping, ownership disputes consume more time than compliance work itself.

For risk classification of a new AI system: the product team that owns the system is Responsible for performing the initial risk classification. The governance team is Consulted to verify the classification aligns with the organization's risk taxonomy. Legal is Consulted when the classification has regulatory implications. The system's business unit leader is Accountable — they own the decision and its consequences. Engineering leadership is Informed of the classification because it affects deployment requirements.

For maintaining compliance documentation: the engineering team that operates the system is Responsible. They ensure the compliance architecture is generating evidence and that the evidence is current. The governance team is Accountable — they set the documentation standards and verify that the standards are being met. Legal is Consulted when documentation requirements change due to regulatory developments. Internal audit is Informed so they can incorporate documentation completeness into their audit plan.

For responding to a regulatory inquiry: the governance team is Responsible for coordinating the response and assembling the evidence package. Legal is Accountable — they own the relationship with the regulator and approve all communications. The engineering team that operates the relevant system is Consulted to provide technical details and evidence. Executive leadership is Informed of the inquiry, the response, and any implications.

This mapping should exist for every recurring compliance activity: risk assessment, documentation maintenance, monitoring review, incident response, regulatory reporting, framework updates, and audit preparation. The mapping is not static. As the organization's AI portfolio grows and the regulatory landscape evolves, the RACI assignments must be reviewed and updated — typically annually or when a significant organizational change occurs.

## The Compliance Workflow: From Requirement to Evidence

When a new regulatory requirement is identified — a new law is enacted, a regulatory guidance document is published, an existing requirement is reinterpreted through enforcement action — the compliance workflow defines how the organization responds.

The workflow begins with the regulatory intelligence function, described in the previous subchapter, identifying the new requirement and performing an initial impact assessment. The impact assessment answers three questions: which AI systems are affected, what new controls or documentation are required, and what is the compliance deadline. The impact assessment is reviewed by Legal and the governance team, who validate the interpretation and confirm the scope.

The validated impact assessment then flows to the affected first-line teams. Each team receives a compliance work package specifying what they must do: implement a new control, update existing documentation, modify a monitoring configuration, or perform a new risk assessment. The work package includes the specific requirement, the expected evidence that the requirement is met, and the deadline. First-line teams incorporate the compliance work into their sprint planning and execute it alongside their regular development work.

As first-line teams complete their compliance work, the evidence generation layer captures the results — the new risk assessment record, the updated documentation, the modified monitoring configuration, the test results from the new control. The second-line governance team reviews the evidence, verifies it satisfies the requirement, and updates the compliance dashboard. If the evidence is insufficient, the governance team sends the work back to the first-line team with specific guidance on what is missing.

This workflow, from identification through implementation and verification, should complete within a defined timeline. For requirements with a known compliance deadline, the workflow must complete before that deadline. For requirements from enforcement actions or regulatory guidance that imply immediate compliance, the workflow should complete within thirty to sixty days. The governance team tracks workflow progress and escalates delays to leadership before they become compliance failures.

## Compliance Ownership at the System Level

Every AI system in your portfolio needs a designated **compliance owner** — a named individual who is accountable for that system's compliance posture. This is not the same as the system's technical owner, although in smaller organizations the roles may overlap. The compliance owner's responsibility is to ensure that the system's risk classification is current, its compliance documentation is complete, its monitoring is active, and any compliance deficiencies are remediated within the required timeline.

Compliance ownership is assigned based on the system's risk classification and organizational placement. For high-risk systems, the compliance owner is typically a senior engineering leader or a product director — someone with the authority to prioritize compliance work and the accountability that comes with regulatory exposure. For limited-risk or minimal-risk systems, the compliance owner may be a team lead or engineering manager. The key principle is that every system has exactly one compliance owner, and that person knows they are the compliance owner, understands what the role requires, and has the authority to act.

## The Compliance Calendar

Regulatory compliance operates on multiple overlapping timelines. The EU AI Act's high-risk requirements become fully enforceable in August 2026. South Korea's AI Basic Act took effect in January 2026. The GPAI Code of Practice requires specific disclosures and documentation from model providers. Post-market monitoring reports must be produced at defined intervals. Risk assessments must be reviewed on defined schedules. Regulatory reporting obligations come due on defined dates.

The **compliance calendar** maps all of these deadlines into a single view. It shows regulatory deadlines by jurisdiction, compliance review cycles by system, reporting obligations by type, and the internal milestones that must be hit to meet external deadlines. A team that needs six months to implement controls for a high-risk system cannot start that work in June 2026 and meet an August 2026 deadline. The compliance calendar surfaces that dependency months in advance, giving leadership the visibility to allocate resources before deadlines become crises.

The calendar is maintained by the governance team, reviewed monthly with compliance owners, and shared with engineering and product leadership. It integrates with the governance roadmap described in the previous chapter, ensuring that compliance timelines are reflected in the organization's broader planning.

## Integration with the AI Decision Stack

The compliance operating model does not exist in isolation. It integrates with the AI Decision Stack introduced in Chapter 1 — the structured decision framework that governs how AI systems move from concept to production.

Compliance checkpoints exist at three stages of the Decision Stack. At the risk classification stage, compliance requirements are identified based on the system's risk tier and the jurisdictions where it will operate. At the pre-deployment review stage, compliance evidence is verified — the risk assessment is complete, the documentation meets the required standard, the controls are implemented and tested. At the post-deployment monitoring stage, compliance monitoring is activated and the system's compliance owner confirms that ongoing obligations are being tracked.

These checkpoints do not add new governance steps. They integrate compliance verification into existing governance gates, ensuring that compliance is confirmed as a natural part of the deployment process rather than as a separate, parallel activity that teams may skip under schedule pressure.

## The Second Line's Real Job

The governance and compliance team's role is often misunderstood. Their job is not to do compliance for every product team. That model does not scale. An organization with fifty AI systems cannot have the governance team write fifty risk assessments, maintain fifty documentation packages, and monitor fifty compliance dashboards. The governance team would need to be larger than the engineering teams it supports — and would still become a bottleneck that delays every deployment.

The second line's real job is to make compliance achievable for first-line teams. This means providing clear standards that teams can follow without ambiguity. It means providing templates, tools, and automation that reduce the effort required to produce compliance evidence. It means providing training that builds compliance competence within engineering and product teams. It means monitoring compliance outcomes to catch gaps before they become failures. And it means escalating systemic issues — repeated gaps, resource shortfalls, or organizational resistance — to leadership for resolution.

When the second line does its job well, compliance becomes a manageable overhead for first-line teams rather than a second full-time job. When the second line does its job poorly — by being unclear in its standards, slow in its guidance, or absent in its monitoring — compliance failures accumulate silently until an audit or a regulator reveals them. The next subchapter addresses the hardest compliance challenge: what happens when regulatory requirements from different jurisdictions directly conflict, and you cannot satisfy both at the same time.
