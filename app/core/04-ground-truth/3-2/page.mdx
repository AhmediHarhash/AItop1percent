# 3.2 — What Your System Must Do (Required Behaviors)

There's a restaurant in my neighborhood that makes incredible pasta. The food is perfect. The ambiance is lovely. But every single time I go, something basic is missing. Last time, they forgot to bring water. The time before, no silverware for the first ten minutes. Last month, they seated us and then... nobody came to take our order for twenty minutes.

The pasta is still amazing. But I don't go there anymore. Because before you can delight someone, you have to not frustrate them. Before you can be exceptional, you have to be reliable.

Your AI system is the same. It doesn't matter how clever your responses are if you can't get the basics right every single time. Required behaviors are those basics — the absolute minimum your system must do to be functional. Not delightful. Not impressive. Just working.

Let me walk you through how to define, implement, and verify the required behaviors that separate a working system from one that randomly fails in ways that make users give up.

## Required vs. Desired: The Critical Distinction

Most teams confuse "things we want the system to do" with "things the system must do." This confusion causes chaos.

Desired behavior: "The system should give detailed, helpful answers."
Required behavior: "The system must respond to every user message within 5 seconds."

See the difference? Desired behaviors are quality goals. They're subjective. They're context-dependent. Required behaviors are functional minimums. They're objective. They're non-negotiable.

Here's the test: if this behavior is missing, is the system broken?

If your AI gives a brief answer instead of a detailed one, is it broken? No. Maybe less helpful than ideal, but functional.

If your AI takes 30 seconds to respond when the user expects 5, is it broken? Yes. The user will assume it's frozen, refresh the page, or give up.

Required behaviors are the ones where failure means the system isn't doing its job at all.

## The Seven Categories of Required Behaviors

Every AI system, regardless of domain, has required behaviors that fall into seven categories. Let's walk through each one with examples.

**Category 1: Responsiveness Requirements**

Your system must respond in a way that doesn't break the user's mental model of interaction.

For a chatbot:
- Must acknowledge every user message (even if just "I'm working on that")
- Must respond within expected latency (5 seconds for chat, 500ms for autocomplete, 24 hours for email)
- Must indicate when processing will take longer than usual
- Must handle timeout scenarios gracefully

For a voice assistant:
- Must provide audio feedback within 300ms of wake word
- Must not cut off user mid-sentence
- Must indicate when it's listening vs processing vs speaking
- Must handle interruptions without losing context

These aren't about quality. They're about basic interaction contract. If your system violates these, the user experience is broken at a fundamental level.

**Category 2: Context Preservation Requirements**

Your system must maintain conversation state in a way that doesn't make users repeat themselves.

For any conversational system:
- Must remember user preferences stated in the current session
- Must maintain topic continuity unless user explicitly changes it
- Must preserve entity references ("it," "that one," "the second option")
- Must retain corrections the user makes

Example: User says "I need to book a flight to Paris." System responds with flight options. User says "Actually, make it London instead."

Required: System must understand "it" refers to the destination and change from Paris to London.
Not required: System proactively suggests hotels in London (that's discretionary helpfulness).

**Category 3: Safety and Escalation Requirements**

Your system must handle dangerous or critical situations according to predetermined rules.

For a mental health support bot:
- Must escalate immediately if user expresses suicidal ideation
- Must provide crisis line number in escalation scenarios
- Must hand off to human when conversation exceeds its capability
- Must not attempt to provide clinical diagnosis

For a financial advisor bot:
- Must disclose it's not a licensed financial advisor
- Must escalate requests for specific investment advice to humans
- Must warn about risk when discussing volatile assets
- Must refuse to execute trades without explicit confirmation

These are the "must not fail" behaviors. Even one failure could have catastrophic consequences.

**Category 4: Accuracy and Evidence Requirements**

Your system must be honest about what it knows and doesn't know.

For a customer support bot:
- Must only cite information from official knowledge base
- Must indicate when information might be outdated
- Must refuse to answer when no evidence exists
- Must cite sources for policy statements

For a medical information assistant:
- Must distinguish between general information and medical advice
- Must cite peer-reviewed sources for medical claims
- Must update information based on latest retrieved context
- Must disclose when information is preliminary or disputed

The requirement here isn't "always be right" (that's often impossible). It's "never be confidently wrong" and "always show your work."

**Category 5: Privacy and Data Handling Requirements**

Your system must respect data boundaries and user privacy.

For any system handling user data:
- Must not leak information across user sessions
- Must not reference data the user hasn't shared in current context
- Must obtain consent before storing sensitive information
- Must comply with deletion requests

For a multi-tenant system:
- Must verify user authorization before accessing any resource
- Must not suggest data from other tenants' contexts
- Must log all data access for audit purposes
- Must enforce data residency requirements

These requirements are often legally mandated (GDPR, HIPAA, etc.), making them non-negotiable.

**Category 6: Accessibility and Inclusivity Requirements**

Your system must be usable by all intended users, regardless of ability or circumstance.

For text-based interfaces:
- Must provide screen-reader compatible outputs
- Must support keyboard-only navigation
- Must maintain sufficient color contrast
- Must not rely solely on visual formatting for meaning

For voice interfaces:
- Must provide visual alternatives for audio-only information
- Must handle varied speech patterns and accents
- Must support text input as alternative to voice
- Must indicate available commands clearly

These aren't nice-to-haves. They're requirements if your product aims to be accessible to diverse users.

**Category 7: Compliance and Disclosure Requirements**

Your system must meet legal and regulatory requirements for its domain.

For AI systems in the EU (under AI Act):
- Must disclose that user is interacting with AI when not obvious
- Must provide transparency about decision-making logic
- Must allow human review of consequential decisions
- Must maintain logs for regulatory audit

For financial services:
- Must comply with Know Your Customer (KYC) requirements
- Must maintain transaction records
- Must disclose conflicts of interest
- Must adhere to advertising regulations

These requirements come from external authorities, not internal product decisions. They're not optional.

## How to Define Required Behaviors for Your Product

Let's make this concrete. I'll walk you through defining required behaviors for a specific product: an AI-powered code review assistant.

**Step 1: Identify Core Functions**

What are the basic jobs this system must do?
- Review code submissions
- Identify potential issues
- Suggest improvements
- Explain rationale for suggestions

**Step 2: For Each Function, Define Minimum Acceptable Performance**

Code review function:
- Must complete review within 2 minutes for diffs under 500 lines
- Must check against documented style guide
- Must flag security vulnerabilities from known pattern list
- Must provide line-specific comments, not just file-level

Issue identification function:
- Must not report false issues for correct code patterns
- Must categorize issues by severity (critical, warning, suggestion)
- Must cite specific rule or pattern that triggered flag
- Must provide reproduction context

Suggestion function:
- Must offer concrete code alternatives, not just descriptions
- Must maintain original code functionality in suggestions
- Must preserve formatting style
- Must indicate confidence level in suggestion

**Step 3: Add Cross-Functional Requirements**

Responsiveness:
- Must acknowledge submission within 5 seconds
- Must indicate progress for reviews exceeding 30 seconds
- Must handle timeout scenarios by returning partial results

Context preservation:
- Must remember previous reviews in the same PR
- Must not re-flag issues already addressed
- Must maintain conversation thread per issue

Safety and escalation:
- Must escalate potential security vulnerabilities to human reviewer
- Must refuse to review files containing credentials or secrets
- Must warn when reviewing auto-generated code

Privacy:
- Must not share code snippets across different repositories
- Must not learn from proprietary code without explicit consent
- Must comply with code retention policies

**Step 4: Document in Testable Format**

For each required behavior, create a triplet:
- Behavior (what must happen)
- Trigger (when it must happen)
- Verification (how to test it)

Example:
- Behavior: Provide line-specific comments for identified issues
- Trigger: Every flagged issue in code review
- Verification: 100% of issue reports include line number and specific code snippet

This format makes it impossible to define vague requirements. If you can't specify the trigger and verification, it's not actually a required behavior — it's an aspiration.

## The Latency Budget: Time-Based Requirements

One of the most critical required behaviors is responsiveness. But "respond quickly" isn't specific enough. You need a latency budget — explicit time bounds for different operations.

**Latency tiers for different interaction types:**

Immediate feedback (under 300ms):
- Keystroke acknowledgment in autocomplete
- Voice assistant wake word response
- UI state changes (button press acknowledgment)

Quick response (under 2 seconds):
- Simple chat responses
- Search results
- Form validation

Standard response (under 5 seconds):
- Complex chat responses
- Code completions
- Document summarization

Extended processing (5-30 seconds):
- Deep analysis tasks
- Multi-step reasoning
- Large document processing

Batch processing (minutes to hours):
- Reports generation
- Full codebase analysis
- Batch data processing

The requirement isn't "everything must be under 300ms." It's "every operation must complete within its assigned tier, or provide progress indication."

Example required behaviors:
- Must return search results within 2 seconds, or show "still searching" indicator
- Must complete code review within 2 minutes for diffs under 500 lines, or explain delay
- Must provide incremental autocomplete suggestions within 300ms of keystroke

Notice the "or" clauses. Required behaviors often have acceptable alternatives. The requirement is meeting user expectations, not hitting an arbitrary number.

## Mandatory Acknowledgments and Confirmations

Some operations are so consequential that confirmation is required, not optional.

**Deletion operations:**
- Must confirm before deleting user data
- Must specify what will be deleted
- Must indicate if deletion is reversible
- Must require explicit approval (not just "OK" but describing the action)

**Financial transactions:**
- Must show full transaction details before execution
- Must require explicit confirmation
- Must provide cancellation window
- Must send confirmation receipt

**Privacy-sensitive actions:**
- Must disclose data access before proceeding
- Must obtain consent for data sharing
- Must provide opt-out mechanism
- Must confirm preference changes

The pattern: if the action has significant consequences and can't be easily undone, confirmation is required.

## Required Disclaimers and Disclosures

In many domains, your system must disclose its limitations or nature.

**AI disclosure requirements:**
- Must identify itself as AI when asked directly
- Must disclose automated decision-making in regulated contexts
- Must clarify it cannot replace professional judgment in expert domains

**Limitation disclosures:**
- Must indicate knowledge cutoff date for time-sensitive information
- Must warn when operating with degraded functionality
- Must disclose when using cached vs. real-time data

**Source disclosures:**
- Must cite sources for factual claims
- Must distinguish between retrieved information and generated content
- Must indicate confidence levels for uncertain information

Example from a medical information bot:
"I'm an AI assistant providing general health information, not medical advice. This information is current as of January 2025 and comes from peer-reviewed sources. For medical decisions, consult a licensed healthcare provider."

That's not a nice-to-have. It's a required disclosure that must appear before any medical information is provided.

## Graceful Degradation Requirements

Your system won't always have access to all capabilities. Required behaviors include how to degrade gracefully.

**When external APIs are unavailable:**
- Must notify user of reduced functionality
- Must provide alternative if available
- Must fail safely (don't fabricate data)
- Must retry transparently when service returns

**When confidence is low:**
- Must acknowledge uncertainty
- Must provide caveats with low-confidence answers
- Must offer to escalate if confidence is below threshold
- Must not present guesses as facts

**When context window is exceeded:**
- Must summarize earlier context rather than drop it
- Must inform user when history is truncated
- Must prioritize recent context over older
- Must maintain critical information (user preferences, session state)

The requirement: the system must remain functional, even if capabilities are reduced. Degraded but working beats broken.

## Testing Required Behaviors: The 100% Rule

Here's what makes required behaviors different from everything else: they must pass 100% of the time.

Not 99%. Not 99.9%. One hundred percent.

If your system must respond within 5 seconds, and it takes 6 seconds even once out of 10,000 requests, you've violated a required behavior. If it must never leak data across users, and it does so once, that's a critical failure.

This has implications for testing:

**Minimum test coverage:**
- Every required behavior needs explicit tests
- Tests run on every deployment
- Failure blocks release
- Tests cover both happy path and edge cases

**Test design principles:**
- Positive tests: Does the required behavior happen?
- Negative tests: Does the required behavior happen even when things go wrong?
- Boundary tests: Does the required behavior hold at the limits?

Example for "must respond within 5 seconds":
- Positive: Measure response time for typical queries (should be well under 5s)
- Negative: Measure response time when backend is slow (should still be under 5s or provide loading indicator)
- Boundary: Measure response time for longest allowable query (should be under 5s)

## The Required Behaviors Checklist

Before you launch any AI feature, review this checklist:

**Responsiveness:**
- [ ] Latency budget defined for all operations
- [ ] Progress indication for long-running tasks
- [ ] Timeout handling specified
- [ ] Grace period for degraded performance

**Context:**
- [ ] Session state preservation defined
- [ ] Reference resolution specified
- [ ] Correction handling implemented
- [ ] Context window management planned

**Safety:**
- [ ] Emergency escalation triggers defined
- [ ] Human handoff criteria specified
- [ ] Crisis resources ready
- [ ] Harm prevention mechanisms tested

**Accuracy:**
- [ ] Evidence requirements documented
- [ ] Citation policy enforced
- [ ] Uncertainty disclosure rules set
- [ ] Confidence thresholds calibrated

**Privacy:**
- [ ] Data isolation verified
- [ ] Consent mechanisms implemented
- [ ] Deletion procedures tested
- [ ] Audit logging active

**Accessibility:**
- [ ] Screen reader compatibility verified
- [ ] Keyboard navigation tested
- [ ] Color contrast sufficient
- [ ] Alternative formats available

**Compliance:**
- [ ] Required disclosures present
- [ ] Regulatory requirements met
- [ ] Audit trail maintained
- [ ] Legal review complete

If you can't check every box, you're not ready to launch. These aren't nice-to-haves.

## Common Mistakes in Defining Required Behaviors

**Mistake 1: Making Everything Required**

If everything is required, nothing is. Teams sometimes mark every behavior as required because "we want the system to be good at everything." This dilutes the meaning.

Ask: "If this behavior fails, is the system broken, or just less good?" If the answer is "less good," it's not required.

**Mistake 2: Vague Requirements**

"Must be accurate" isn't a required behavior. It's unmeasurable.

"Must cite sources for all factual claims" is a required behavior. It's testable.

Every required behavior must be specific enough to write a pass/fail test for.

**Mistake 3: Impossible Requirements**

"Must always give the right answer" is impossible for most AI systems. Don't define requirements you can't meet.

Better: "Must answer only when confidence exceeds 0.8, or disclose uncertainty."

**Mistake 4: Ignoring Constraints**

You can't require 100ms latency if your API calls take 200ms. Required behaviors must be achievable within your technical constraints.

If you need faster latency, either change the architecture or change the requirement.

**Mistake 5: No Verification Plan**

Defining a required behavior without defining how to test it means it's not really required — it's aspirational.

For every required behavior, also define:
- The test that verifies it
- The frequency of testing
- The threshold for failure
- The response when it fails

## When Required Behaviors Conflict

Sometimes two required behaviors pull in opposite directions. What then?

Example: "Must respond within 5 seconds" conflicts with "Must verify all facts against knowledge base" when the knowledge base is slow.

Resolution approaches:

**1. Prioritize by risk**
Which requirement, if violated, causes more harm? That one wins.

Safety requirements beat speed requirements.
Privacy requirements beat convenience requirements.
Legal requirements beat user experience requirements.

**2. Redesign to eliminate conflict**
Can you cache the knowledge base? Can you use a faster database? Can you show partial results while verification completes?

Often, conflicts reveal architectural problems that need fixing.

**3. Conditional requirements**
Make requirements context-specific.

"Must respond within 5 seconds for queries that don't require knowledge base verification."
"Must verify facts for queries involving medical/legal/financial information, even if latency exceeds 5 seconds."

**4. Escalate**
If requirements truly conflict and can't be redesigned, escalate to product leadership for decision.

But document the tradeoff. Future you will need to remember why you chose speed over verification, or vice versa.

## Required Behaviors as Product Differentiators

Here's something counterintuitive: nailing required behaviors can be your competitive advantage.

Most AI products are inconsistent. They're amazing sometimes and broken other times. The variation makes them unreliable.

If your product reliably does the basics — responds quickly, maintains context, never leaks data, always discloses sources — you become the boring, dependable option. And in high-stakes domains, boring and dependable wins.

Users will tolerate a less clever system if they can trust it to work every single time.

## Building Required Behaviors Into Your Culture

Required behaviors aren't just a technical checklist. They're a cultural commitment.

**In design:** Before designing any new feature, ask "What are the required behaviors for this to work?"

**In development:** Before writing code, define the required behaviors and the tests that verify them.

**In review:** Code reviews should explicitly verify that required behaviors are implemented and tested.

**In incidents:** When something goes wrong, check if a required behavior was violated. If so, that's a systemic failure, not a one-off bug.

**In metrics:** Track required behavior compliance as a core health metric, not buried in some dashboard nobody checks.

The message: required behaviors are not negotiable. They're the foundation everything else builds on.

## Moving Forward

You've now got the framework for defining what your system must do. Not what it should do, not what would be nice — what it must do to be functional.

In the next subchapter, we'll flip to the other side: what your system must never do. The forbidden behaviors that, if they happen even once, mean catastrophic failure. These are the hard boundaries that keep your system safe and trustworthy, no matter how much pressure there is to be helpful or clever.

But first, get your required behaviors documented. That foundation makes everything else possible.
