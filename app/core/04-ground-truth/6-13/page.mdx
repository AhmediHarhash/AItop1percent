# 6.13 — Truth for Ranking & Selection Systems

Let me tell you about the search engine that was 90% accurate and still failed spectacularly. A job search platform built an AI ranking system for matching candidates to job postings. They measured accuracy by checking if the "best" candidate was in the top 10 results. They hit 90% accuracy on this metric.

But when they launched, recruiters hated it. Why? Because the top 10 results were full of duplicates (same candidate appearing multiple times due to multiple resumes), the ordering within the top 10 was poor (the best candidate was often ranked 8th or 9th), and there was no diversity (if the best candidate was a software engineer from Stanford, the top 10 were all software engineers from Stanford).

The system was finding good candidates, but it was failing at the core task of ranking: presenting a useful, diverse, well-ordered set of results.

This is the ranking ground truth challenge: you're not judging one item, you're judging a set and its ordering. Different metrics, different trade-offs, different failure modes.

## Why Ranking Is Different from Classification

In classification, you ask: "Is this item in the right category?" Binary or multi-class, but one item at a time.

In ranking, you ask: "Is this set of items the right set, and are they in the right order?" It's fundamentally about relationships between items, not individual items.

This changes ground truth in important ways:

**Set Quality Matters**: It's not enough for the top result to be good. The top 10 should all be good, and ideally diverse.

**Order Matters**: Having the right items isn't enough if they're in the wrong order. The best items should appear first.

**Relative Relevance Matters**: Sometimes you can't say if an item is "relevant" in absolute terms, only whether it's more or less relevant than another item.

**Diversity Matters**: A set of 10 near-identical results is less useful than 10 somewhat-relevant but diverse results.

Your ground truth needs to capture all of these dimensions.

## Relevance Judgments: The Foundation

Before you can evaluate ranking, you need relevance judgments: for a given query or context, how relevant is each item?

**Binary Relevance**

Simplest approach: relevant or not relevant.

Query: "Italian restaurants in Seattle"
Result: Mario's Pizza → Relevant
Result: Thai House → Not Relevant

This works for some use cases but loses nuance. Is Mario's Pizza just as relevant as a highly-rated Italian fine dining restaurant? Binary relevance can't distinguish.

**Graded Relevance**

Better approach: rate relevance on a scale.

Common scale:
- 0: Not relevant
- 1: Marginally relevant
- 2: Relevant
- 3: Highly relevant

Query: "Italian restaurants in Seattle"
Mario's Pizza → 2 (Relevant: it's Italian and in Seattle)
Il Terrazzo Carmine → 3 (Highly relevant: highly-rated Italian restaurant in Seattle)
Olive Garden → 1 (Marginally: technically Italian-style, but a chain)
Thai House → 0 (Not relevant: wrong cuisine)

Graded relevance lets you distinguish between "this appears in results" and "this should be ranked highly."

**Contextual Relevance**

Sometimes relevance depends on context beyond the query.

Query: "Italian restaurants in Seattle"
Context 1: User is looking for romantic dinner spot → Fine dining ranks higher
Context 2: User wants quick lunch → Casual places rank higher
Context 3: User is vegetarian → Vegetarian-friendly places rank higher

Your ground truth should include context when it matters for relevance.

## The "Good Enough Set" Concept

Here's a key insight for ranking ground truth: you don't need THE perfect item. You need a good set of items that collectively serve the user's need.

For search query "best beginner DSLR cameras," the top results could be:
- Canon Rebel T7
- Nikon D3500
- Sony A6000

All three are excellent beginner DSLRs. There's no single "correct" answer. Any of these at #1 is fine. What matters is that the top 5-10 results are all good options.

Your ground truth should evaluate:

**Set Precision**: What percentage of the top-N results are good options?

If 8 out of top 10 results are good beginner DSLRs, precision is 80%. If 3 out of top 10 are good, precision is 30%.

**Set Recall**: What percentage of all good options appear in the top-N?

If there are 20 great beginner DSLRs total, and 8 appear in your top 10, recall is 40%.

High precision means the results are mostly good. High recall means you're not missing good options. You want both.

## Position Bias: Why Ordering Matters

Here's the thing about ranking: position matters enormously. Users are much more likely to click the first result than the fifth, even if they're equally relevant.

Studies show:
- Position 1: ~30% click-through rate
- Position 2: ~15% CTR
- Position 3: ~10% CTR
- Position 10: ~2% CTR

So having the best item at position 10 is much worse than having it at position 1, even though both are "in the top 10."

Your ground truth needs to account for position:

**Ordered Relevance**

Not just "are good items present?" but "are the best items first?"

Ideal ranking:
1. Highly relevant item
2. Highly relevant item
3. Relevant item
4. Relevant item
5. Marginally relevant item

Bad ranking (same items, wrong order):
1. Marginally relevant item
2. Relevant item
3. Highly relevant item
4. Relevant item
5. Highly relevant item

Same set, very different user experience.

## NDCG: Measuring Ranking Quality

NDCG (Normalized Discounted Cumulative Gain) is the most common metric for evaluating ranking quality. Let me explain it in plain English.

**Cumulative Gain**

Add up the relevance scores of all items in your ranking.

If your top 5 results have relevance scores [3, 3, 2, 1, 0], cumulative gain is 3+3+2+1+0 = 9.

**Discounted Cumulative Gain**

But we want to weight items higher in the ranking more heavily, because position matters.

So we divide each relevance score by the log of its position:
- Position 1: score / log2(2) = score / 1 = score
- Position 2: score / log2(3) = score / 1.58
- Position 3: score / log2(4) = score / 2
- Position 4: score / log2(5) = score / 2.32
- etc.

Higher positions get less discounting, so they contribute more to the score.

**Normalized DCG**

Finally, we normalize by the "ideal" DCG (what you'd get if you ranked items perfectly).

NDCG = (Actual DCG) / (Ideal DCG)

NDCG ranges from 0 to 1. NDCG of 1 means perfect ranking. NDCG of 0.8 means pretty good but not perfect.

Your ground truth should include relevance scores for items so you can calculate NDCG.

## Diversity Requirements

Here's a ranking failure mode that simple metrics miss: lack of diversity.

Search query: "Python programming tutorials"

Bad ranking (no diversity):
1. Official Python tutorial part 1
2. Official Python tutorial part 2
3. Official Python tutorial part 3
4. Official Python tutorial part 4
5. Official Python tutorial part 5

All relevant, but all from the same source. Not useful.

Good ranking (diverse):
1. Official Python tutorial
2. Real Python tutorial
3. LearnPython.org interactive tutorial
4. Codecademy Python course
5. YouTube Python crash course

Same relevance, but diverse sources and formats.

Your ground truth should specify diversity requirements:

**Source Diversity**: Don't show too many results from the same source

**Format Diversity**: Mix articles, videos, interactive tutorials, etc.

**Perspective Diversity**: For subjective topics, show multiple viewpoints

**Demographic Diversity**: For people-focused results (job candidates, expert recommendations), ensure diversity

Measure diversity explicitly, not just relevance.

## Editorial vs Behavioral Ground Truth

There are two main ways to create ranking ground truth:

**Editorial Ground Truth**

Experts manually rate relevance of items for queries.

Pros: Controlled, consistent, captures expert judgment
Cons: Expensive, doesn't always match real user behavior

**Behavioral Ground Truth**

Use actual user behavior (clicks, purchases, time-on-page) as implicit relevance signals.

Pros: Based on real user preferences, cheap at scale
Cons: Noisy, biased (users click top results more even if they're not best), gameable

Best approach: use both.

Use editorial ground truth for:
- Initial system development
- Measuring core quality
- Evaluating controversial or sensitive content (where clicks don't equal quality)

Use behavioral ground truth for:
- Large-scale evaluation
- Detecting relevance changes over time
- Personalization signals

## Position Bias in Behavioral Data

Here's a critical gotcha with behavioral ground truth: users click top results more because they're shown first, not necessarily because they're better.

If you rank item A at #1 and item B at #10, and A gets more clicks than B, is it because:
- A is actually more relevant? (what you want to measure)
- A was shown first so users clicked it first? (position bias)

You can't tell from the data alone.

To correct for this, you need:

**Randomization**: Occasionally randomize ranking and measure clicks. This lets you separate relevance from position bias.

**Explicit Feedback**: Ask users to rate results, not just observe clicks.

**Time on Page**: If users click result #1 but immediately return and click result #5 and stay there, result #5 was probably better.

Your ground truth should account for position bias, not blindly trust click data.

## Fairness Constraints in Ranking

Ranking systems can perpetuate or amplify bias. Your ground truth should verify fairness.

**Demographic Fairness**

For rankings involving people (job candidates, expert recommendations, creator content), are results fair across demographic groups?

Bad ranking: Top 10 job candidates are all male
Better ranking: Top 10 candidates represent diverse genders

Your ground truth should specify fairness requirements and measure compliance.

**Exposure Fairness**

Do all high-quality items get fair exposure, or do popular items dominate?

This is the "rich get richer" problem: popular items rank higher, get more clicks, become more popular, rank even higher.

Your ground truth should verify that high-quality new or less-popular items still get reasonable ranking positions.

**Protected Attributes**

For legally protected attributes (race, gender, age, religion), ranking should not discriminate.

Your ground truth should include diverse test cases and verify no systematic bias in ranking.

## Temporal Dynamics in Ranking

Relevance changes over time. Your ground truth needs to account for this.

**Freshness**

For news, trending topics, or time-sensitive content, newer is often better.

Query: "election results"
Result from yesterday: Highly relevant
Result from last year: Not relevant

Your ground truth should include timestamps and specify when freshness matters.

**Seasonal Relevance**

Some queries have seasonal patterns.

Query: "Halloween costumes" in October: Highly relevant
Same query in March: Less urgent

Your ground truth should cover different time periods for seasonal topics.

**Popularity Trends**

What's popular changes. A product that was trending last month might not be relevant now.

Your ground truth should be refreshed periodically to stay current.

## The Cold Start Problem in Ranking

How do you rank new items that have no behavioral data yet?

Your ground truth should verify:

**New Item Treatment**: Do new items get reasonable initial ranking, or are they buried because they have no clicks yet?

**Exploration vs Exploitation**: Does the system occasionally promote new items to gather data (exploration) while mostly showing proven items (exploitation)?

**Content-Based Fallback**: If behavioral data is missing, does the system use content features to estimate relevance?

## Query Intent and Ranking

Different queries have different intents, which affects ideal ranking.

**Navigational Query**: User wants a specific website (e.g., "Facebook")
Ideal ranking: Put the target site first, alternatives can be lower

**Informational Query**: User wants to learn something (e.g., "how does photosynthesis work")
Ideal ranking: Multiple high-quality explanations from diverse sources

**Transactional Query**: User wants to buy/do something (e.g., "buy running shoes")
Ideal ranking: Options with good prices, availability, and reviews

Your ground truth should specify query intent and evaluate whether ranking matches that intent.

## Evaluating Ranking Explanations

Increasingly, ranking systems explain why items are ranked as they are. Your ground truth should verify explanations.

**Accuracy**: Does the explanation accurately describe why the item was ranked here?

**Comprehensibility**: Can users understand the explanation?

**Actionability**: Can users use the explanation to get better results? (e.g., "This is ranked lower because it's out of your price range" → user can adjust price filter)

## Multi-Objective Ranking

Many ranking systems optimize for multiple objectives simultaneously:
- Relevance (is it what the user wants?)
- Revenue (does it make money?)
- Diversity (is the set diverse?)
- Freshness (is it recent?)
- Fairness (is it unbiased?)

These objectives often conflict. Your ground truth should specify how to weight them.

Example for e-commerce search:
- 70% weight on relevance
- 20% weight on revenue
- 10% weight on diversity

Or specify constraints: "Relevance must be at least 0.8, then optimize for revenue."

Your ground truth should verify the system balances multiple objectives as specified.

## The Warning: What Happens If You Skip This

If you evaluate ranking systems only on whether good items appear, without checking order, diversity, fairness, or set quality, here's what happens:

Your rankings will have good items buried in poor positions. They'll lack diversity, showing the same type of result repeatedly. They'll perpetuate biases, consistently ranking certain demographic groups lower. They'll miss the "good enough set" concept and frustrate users who have to dig through many results to find what they need.

Users will go to competitors with better ranking. Your engagement metrics will suffer because the best items are ranked 7th instead of 1st. You'll face bias complaints and possibly legal issues if ranking discriminates.

I've seen search systems that had all the right items but terrible ranking, leading to poor user experience despite technically "accurate" results.

Don't just check if good items are present. Check if they're in the right order, the set is diverse, and the ranking is fair.

Ranking is about curation, not just selection. Your ground truth needs to reflect that.

## Bridge to Chain-of-Thought Reasoning

We've been discussing ground truth for what AI systems output—the final result. But increasingly, we care about how they get there. Chain-of-thought systems show their reasoning, multi-step problem-solving, the logic that leads to their conclusion. And this creates a new ground truth challenge: you can't just evaluate the answer, you have to evaluate the reasoning path. A model might get the right answer with wrong reasoning, or wrong answer with correct reasoning. Both are failures, but different kinds of failures that tell you different things about what to fix. Let's walk through how ground truth changes when you're evaluating the thinking, not just the conclusion.
