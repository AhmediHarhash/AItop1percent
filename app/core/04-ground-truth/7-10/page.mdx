# 7.10 — Freshness Rules: When Ground Truth Expires

I once reviewed a company's ground truth for their e-commerce customer service AI. Beautiful documentation, comprehensive rubrics, hundreds of carefully curated examples. Then I noticed something odd: one of their "excellent response" examples mentioned shipping times "during COVID-19 lockdowns."

This was 2024. COVID lockdowns were ancient history. But this example was still in their ground truth, still being used to train evaluators, still defining what "excellent" looked like.

I asked when they'd last updated their examples. "We created these in 2020 when we launched the system," they said. "They've worked great, so we haven't needed to change them."

Except the world had changed around them. Shipping times were different. Customer expectations were different. Product catalog was different. Return policies were different. But their ground truth was frozen in 2020.

They were optimizing for a world that no longer existed.

Here's the reality nobody likes to admit: ground truth spoils. Like milk, it has a shelf life. The expiration date depends on what kind of ground truth it is, but everything expires eventually.

If you use expired ground truth, you're measuring quality against outdated standards. Your evaluations look rigorous, but they're rigorously wrong.

Let me walk you through how to think about ground truth freshness, what expires when, and how to manage it.

## Why Ground Truth Expires

Ground truth doesn't expire because it was created wrong. It expires because the world changes.

### The Product Changes

You ship new features. You deprecate old ones. You change workflows. You update UI. You add integrations.

Ground truth that assumes the old product state becomes inaccurate for the new state.

An example showing how to cancel a subscription via email is great ground truth — until you add a self-service cancellation flow and the new correct answer is "use the account settings page."

### User Expectations Change

What users consider "fast," "helpful," or "good" shifts over time based on what they experience elsewhere.

A response time that was impressive in 2020 is frustrating in 2026. A level of personalization that was delightful in 2022 is table stakes in 2026.

Ground truth that encodes 2020 expectations misleads you about 2026 quality.

### Policies and Regulations Change

Company policies evolve. Regulations update. Compliance requirements shift.

Ground truth that reflects old policies will tell you that non-compliant behavior is correct.

A privacy policy update might change what information you're allowed to share. Ground truth created before the update will reward sharing information you're now required to protect.

### Domain Knowledge Evolves

In any field, what's considered true or best practice changes as knowledge advances.

Medical ground truth from 2020 includes COVID-19 information that's outdated by 2022. Financial ground truth from before 2024 doesn't account for regulations that took effect in 2024. Technology ground truth from six months ago might reference tools that are now deprecated.

### Context Shifts

The broader context your AI operates in changes. Market conditions, competitive landscape, user demographics, usage patterns.

Ground truth optimized for early adopters might be wrong for mainstream users. Ground truth created for one market might be wrong when you expand to others.

## The Freshness Spectrum

Different types of ground truth have different shelf lives. Let me break it down by content type.

### Pricing and Availability: Hours to Days

Anything related to pricing, inventory, availability, or real-time status expires fast.

A ground truth example that says "Product X costs $49.99" expires the moment the price changes. An example that says "this product is in stock" expires when inventory changes.

Shelf life: Hours to days, depending on how frequently these things update.

Freshness rule: Don't include specific prices or availability in ground truth unless you have automated processes to keep them current. Instead, use ground truth that specifies "provide current price" and test that the AI retrieves current information.

### Product Features and Workflows: Days to Weeks

Ground truth about how your product works expires when you ship changes.

If you ship weekly, feature-related ground truth potentially expires weekly. If you ship monthly, it expires monthly.

Shelf life: Aligned with your release cadence.

Freshness rule: Review ground truth before each release. Flag examples that reference features being changed. Update them as part of the release process.

### Company Policies: Weeks to Quarters

Internal policies usually don't change daily, but they do change.

Support policies, return policies, terms of service, content guidelines — these typically update quarterly or when triggered by specific events.

Shelf life: Typically quarterly, but event-driven updates can happen anytime.

Freshness rule: When policies change, trigger a ground truth review within a week. Don't wait for the next scheduled review.

### Regulatory Requirements: Months to Years

Regulations change on known schedules or effective dates.

EU AI Act took effect in phases through 2024-2025. GDPR updates happen on defined schedules. Industry-specific regulations (HIPAA, SOX, PCI-DSS) evolve over time.

Shelf life: Months to years, often with advance notice of changes.

Freshness rule: Track regulatory roadmaps. Update ground truth before new regulations take effect, not after. Build in lead time for compliance ground truth updates.

### General Best Practices: Months to Years

Domain-agnostic quality criteria — clarity, empathy, accuracy, safety — change slowly.

What makes communication clear or empathetic is relatively stable. Safety requirements evolve, but gradually.

Shelf life: Typically a year or more.

Freshness rule: Annual review is usually sufficient unless you see signals that standards are shifting (user feedback, competitive benchmarking, incident trends).

### Domain Knowledge: Varies Wildly

This depends entirely on the domain.

Medical knowledge in rapidly evolving areas (COVID-19 treatments, new therapies) can expire in months. Established medical knowledge (anatomy, basic physiology) is stable for years.

Technology knowledge (best practices, tool recommendations) expires fast in some areas (JavaScript frameworks) and slow in others (algorithmic fundamentals).

Legal knowledge expires when laws change, which varies by jurisdiction and topic.

Shelf life: Know your domain. Fast-moving domains need frequent updates. Stable domains can go longer.

Freshness rule: Segment your ground truth by rate of change. Review fast-changing sections monthly, stable sections annually.

## The "Verified As Of" Pattern

One of the simplest and most effective freshness practices: timestamp your ground truth with a "verified as of" date.

Every piece of ground truth should carry metadata:

Created: when it was originally created.

Last reviewed: when someone last checked if it's still accurate.

Verified as of: the date through which it's confirmed accurate.

Expires: when it should be reviewed next (if known).

This metadata makes staleness visible. When you look at ground truth, you can immediately see "this was last verified eight months ago" and know whether that's acceptable for this type of content.

### Setting Expiration Dates

For ground truth where you know the shelf life, set explicit expiration dates.

Pricing examples: expire daily or weekly.

Feature documentation: expire on next release.

Policy-related ground truth: expire when policy is scheduled for review.

Domain knowledge: expire annually or on known update cycles.

Automated systems can then alert you: "147 ground truth examples expire this week. Review needed."

### The Evergreen vs. Temporal Split

Some ground truth is evergreen — it's true regardless of time. Some is temporal — it's true for a specific period.

Evergreen: "Responses should be empathetic and respectful."

Temporal: "The return window is 30 days" (true until policy changes).

Mark ground truth as evergreen or temporal. Evergreen still needs periodic review, but less frequently. Temporal needs active freshness management.

## Automated Expiration Tracking

Manual tracking of ground truth freshness doesn't scale. You need automation.

### Metadata-Based Alerts

Store "verified as of" and "expires" dates in your ground truth system. Automated jobs check daily:

What ground truth expires in the next week?

What ground truth is already expired?

What ground truth hasn't been reviewed in more than a year (or whatever threshold you set)?

Send alerts to owners: "You have 23 expired ground truth examples. Review needed."

### Dependency-Based Expiration

When something changes that ground truth depends on, automatically flag affected ground truth.

Product team ships a new feature → automatically flag all ground truth examples that mention related features for review.

Policy team updates a policy → flag all ground truth that references that policy.

This requires some setup: tagging ground truth with dependencies (feature tags, policy tags) so the system knows what to flag when dependencies change.

### Usage-Based Prioritization

Not all expired ground truth is equally important. Prioritize based on usage.

Ground truth that's used in production evaluations daily? High priority to keep fresh.

Ground truth that's in your library but rarely used? Lower priority.

Track which ground truth is actively used and weight expiration alerts accordingly.

## What Happens When Expired Ground Truth Stays in Production

Let me paint a picture of the consequences.

### The Silent Drift

Your evaluations continue to run. Your dashboards stay green. Everything looks fine.

But you're measuring against outdated standards. Your "95 percent accuracy" is accuracy against standards from two years ago.

Users are frustrated because current quality expectations aren't being met, but your metrics don't reflect it because your metrics are based on expired ground truth.

### The Compliance Failure

Regulations changed six months ago. Your ground truth didn't update. Your AI is evaluated as compliant against old standards but is actually violating new regulations.

You discover this during an audit. Now you have a compliance incident, potential fines, and a need to explain why your quality processes didn't catch this.

### The Competitive Disadvantage

Competitors update their quality standards to match evolving user expectations. You don't, because your ground truth is stale.

Your quality looks good on your internal metrics but poor compared to competition. Users leave for alternatives that meet their current needs.

### The Wasted Optimization

Your team spends months optimizing for ground truth criteria. You go from 88 percent to 94 percent. Great work!

Except the ground truth was expired. You optimized for requirements that no longer matter while ignoring current requirements.

Months of effort, high cost, no actual improvement in real-world quality.

## The Freshness Audit

How do you check if your ground truth is fresh? Run a freshness audit.

### Step 1: Age Distribution

For each piece of ground truth, check the "verified as of" date. Plot the distribution:

What percentage verified in the last month?

Last quarter?

Last year?

More than a year ago?

If more than 20 percent of your ground truth is more than a year old without review, you have a staleness problem.

### Step 2: Content Spot Check

Take a random sample of ground truth. For each piece, ask:

Is this still accurate today?

Does it reference things that have changed (features, policies, external facts)?

Would this guide someone correctly right now?

If you find inaccuracies in more than 10 percent of your sample, you have significant staleness.

### Step 3: Dependency Review

Check ground truth against current product state, policies, and domain knowledge:

Feature references: do mentioned features still exist and work as described?

Policy references: do cited policies match current versions?

External facts: are stated facts still true?

Flag anything that references outdated information.

### Step 4: User Feedback Correlation

Compare ground truth to recent user feedback:

Are users complaining about things your ground truth says should be good?

Are users praising things your ground truth doesn't measure?

Divergence between ground truth and user sentiment suggests staleness.

## Remediation Strategies

When you find stale ground truth, what do you do?

### Immediate Triage

Categorize expired ground truth by severity:

Critical: affects safety, compliance, or core functionality. Fix immediately.

High: affects important quality dimensions or frequently used evaluations. Fix within a week.

Medium: affects secondary quality dimensions or less-used evaluations. Fix within a month.

Low: affects edge cases or rarely used evaluations. Fix when convenient.

Don't try to fix everything at once. Triage and tackle by priority.

### Update or Retire

For each piece of stale ground truth, decide: update it or retire it?

Update if it's still relevant but needs current information. Update the facts, dates, references.

Retire if it's no longer relevant. The feature doesn't exist anymore, the use case doesn't happen, the requirement was removed.

Don't keep ground truth alive just because it exists. Dead ground truth should be removed, not maintained.

### Batch Updates

When you're updating many pieces of ground truth at once, look for patterns.

If 50 examples all reference an old feature, maybe you can update them together with a script or template.

If an entire section of ground truth is outdated, maybe you need to rewrite the section rather than piecemeal updates.

Efficient batching makes remediation faster.

### Document the Update

When you update ground truth for freshness, document why:

"Updated pricing from $49 to $59, effective 2026-02-01"

"Removed reference to email-based cancellation, replaced with self-service flow launched in v3.2"

"Updated COVID-19 guidance to reflect current CDC recommendations as of 2026-01"

This creates history showing that you actively maintain freshness.

## Building Freshness Into Workflows

The best freshness management is proactive, not reactive.

### Release-Triggered Reviews

When you ship a release, automatically trigger a ground truth review for affected areas.

Your release notes list changed features. Flag ground truth that references those features. Assign someone to review and update before the release goes live.

This keeps ground truth synchronized with product state.

### Policy Change Integration

When policies change, the policy team should trigger a ground truth review as part of their workflow.

Policy update checklist includes: "Notify ground truth team of changes. Verify ground truth updated before policy effective date."

This ensures compliance ground truth stays current.

### Domain Expert Consultation

For domain knowledge ground truth, establish relationships with domain experts who can alert you to changes.

Medical experts tell you when treatment guidelines update. Legal experts tell you when relevant regulations change. Technology experts tell you when best practices shift.

You can't track every domain development yourself. Build a network that helps you know when updates are needed.

### Continuous User Feedback

User feedback is an early warning system for stale ground truth.

When users consistently give negative feedback on things your ground truth rates highly, investigate. Ground truth might be stale.

Set up automated monitoring: if user satisfaction on ground-truth-compliant outputs drops below threshold, trigger a freshness review.

## The Freshness Culture

Keeping ground truth fresh isn't just about process — it's about culture.

Teams that do this well treat ground truth as living documentation, not archival records.

They celebrate updates: "We refreshed 200 examples this quarter to match our current product."

They make freshness visible: dashboards show ground truth age, stale items are highlighted, freshness metrics are tracked.

They assign ownership: someone is responsible for each section of ground truth and accountable for keeping it fresh.

They allocate time: freshness reviews are in the roadmap, not squeezed in when there's time.

## The Cost of Freshness

Keeping ground truth fresh requires ongoing investment. Time for reviews, time for updates, tooling for automation, processes for triggering updates.

Some teams balk at this cost. "We already created ground truth. Why do we have to keep maintaining it?"

Because the alternative is worse. Expired ground truth is worse than no ground truth — it gives false confidence that you're measuring quality when you're actually measuring against irrelevant standards.

The cost of freshness is real but far less than the cost of stale ground truth leading you astray.

In the next section, we'll talk about another critical but often overlooked aspect of ground truth management: governance — access control, retention, redaction, and audit trails for ground truth artifacts.
