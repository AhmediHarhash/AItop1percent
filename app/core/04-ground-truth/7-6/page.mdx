# 7.6 — Scaling Ground Truth Across Teams

When you have one AI team building one AI product, ground truth management is straightforward. The team owns it, maintains it, evolves it. Everyone knows what the standards are because everyone helped create them.

But what happens when you have ten teams building ten AI products? Or a hundred teams building features within one large AI platform? Now you have a scaling problem that most organizations handle badly.

I consulted with a company that had grown from one AI team to fifteen in two years. Each team had built their own ground truth, their own evaluation framework, their own quality standards. It seemed fine — each team was autonomous and moving fast.

Then leadership asked a simple question: "What's our company-wide AI quality score?"

Nobody could answer. Every team measured quality differently. One team's "excellent" was another team's "acceptable." One team optimized for accuracy, another for speed, another for safety. There was no shared language, no shared framework, no way to aggregate or compare.

Worse, when teams needed to collaborate — when one team's AI called another team's AI — the quality expectations clashed. One system expected structured, formal inputs. The other provided conversational, informal outputs. Both were "high quality" according to their own ground truth, but they couldn't work together.

The company ended up spending six months on a ground truth alignment project, essentially re-creating shared standards across teams that should have been aligned from the start.

Let me show you how to scale ground truth without creating this kind of chaos.

## The Scaling Challenges

Before we get to solutions, let's understand what breaks when you scale ground truth across teams.

### Consistency Drift

Two teams start with the same ground truth template. Six months later, they've each customized it for their domain. The customizations are reasonable — a customer support AI needs different criteria than a code generation AI.

But now they're interpreting shared criteria differently. Both measure "clarity," but one team thinks clarity means simple language, the other thinks it means explicit structure. Same word, different meanings.

Multiply this across ten teams and you have Tower of Babel — everyone using the same terminology but meaning different things.

### Domain Specialization vs. Shared Standards

Each team needs domain-specific ground truth. Medical AI needs clinical accuracy criteria. Legal AI needs citations and jurisdiction awareness. Creative writing AI needs narrative coherence.

But you also need shared standards that apply to all AI at your company: safety, bias, tone, disclosure requirements, privacy handling.

How do you let teams specialize while maintaining consistency on the shared stuff? Most companies fail to find the balance. Either they're too rigid (forcing all teams to use identical ground truth that doesn't fit anyone well) or too loose (letting teams diverge so much that nothing is comparable).

### Tooling Fragmentation

Different teams pick different tools for managing ground truth. One uses Google Sheets, another uses a custom database, another uses YAML files in Git.

Now you can't aggregate data across teams. You can't share examples. You can't run company-wide analyses. Every team is an island.

### Version Chaos

Remember the versioning conversation from earlier? Now multiply it across teams.

Team A is on ground truth version 3.2.0. Team B is on 2.8.1. Team C is on 4.0.0. They share some common standards, but which version of the common standards is each team using?

When you need to audit company-wide ground truth, you have to reconcile multiple version histories, multiple change logs, multiple sources of truth.

## The Central vs. Federated Model

There are two basic approaches to scaling ground truth: centralized and federated. Most successful organizations use a hybrid.

### Pure Centralization

One team owns all ground truth for the entire organization. They create it, maintain it, version it, distribute it. Product teams consume it but don't modify it.

Benefits: Perfect consistency. Single source of truth. Easy to audit.

Problems: Doesn't scale. The central team becomes a bottleneck. Domain-specific needs don't get met. Teams work around the official ground truth by creating shadow standards.

I've never seen pure centralization work beyond about three teams.

### Pure Federation

Each team owns their own ground truth completely. They create it, maintain it, version it independently. Central org provides guidelines or templates, but teams are free to ignore them.

Benefits: Teams move fast. Domain specialization happens naturally. No bottlenecks.

Problems: Everything I described at the start of this chapter. Inconsistency, incompatibility, inability to aggregate or compare.

Pure federation works early when you're optimizing for speed over coherence, but it doesn't last.

### The Hybrid Model

Central team owns shared ground truth components. Product teams own domain-specific extensions.

This is the model that works at scale. Let me walk through how to implement it.

## The Shared Ground Truth Framework

Start by identifying what should be consistent across all teams. This becomes your shared ground truth framework.

Typical shared components:

Safety criteria: hallucination detection, harmful content prevention, privacy protection.

Brand and tone: how your company's AI should sound.

Regulatory compliance: required disclosures, consent patterns, data handling.

Basic quality dimensions: coherence, relevance, factual accuracy.

Evaluation processes: how to conduct reviews, how to version, how to document.

These go in a centrally maintained ground truth library that all teams inherit from.

### The Inheritance Model

Think of shared ground truth like a base class in programming. It defines the foundation. Teams extend it for their domain.

Shared ground truth says: "All AI must avoid harmful outputs, must disclose when it's uncertain, must respect user privacy."

Customer support team extends: "Must provide empathetic responses, must offer escalation to human when needed, must log customer issues."

Code generation team extends: "Must include error handling, must follow language idioms, must explain complex logic."

Both teams inherit the shared standards and add their domain standards on top. Now you have consistency where it matters and specialization where it's needed.

### Versioning Shared Components

Shared ground truth has its own version number, separate from team-specific versions.

Shared ground truth might be at version 2.3.0. Customer support team's domain-specific ground truth is at version 4.1.0, but it's based on shared version 2.3.0.

When shared ground truth updates to 2.4.0, teams have a migration window to adopt it. They update their domain-specific ground truth to work with shared 2.4.0, and their domain version increments to 4.2.0 (minor version bump for incorporating updated shared standards).

This keeps teams coordinated without forcing lockstep updates.

## The Ground Truth Platform Concept

At scale, ground truth can't live in scattered documents and spreadsheets. You need a platform.

What does a ground truth platform provide?

### Centralized Storage and Versioning

All ground truth — shared and domain-specific — lives in one system with proper version control.

Teams can browse available ground truth components, see what's shared, see what's specific to other domains, see version history.

### Shared Rubric Library

A library of reusable rubric components. If ten teams all need to measure "clarity," they can all use the same clarity rubric from the library, or extend it for their needs.

This prevents teams from reinventing the same criteria with slightly different definitions.

### Cross-Team Calibration

The platform tracks how different teams rate the same examples. If you show the same AI response to three teams and they rate it very differently, that's a calibration issue.

The platform surfaces these discrepancies so teams can align on interpretation.

### Automated Compliance Checking

The platform validates that team-specific ground truth includes all required shared components. If shared ground truth says all teams must check for harmful content and a team's ground truth doesn't include that, the platform flags it.

This prevents teams from accidentally dropping shared requirements.

### Usage Analytics

The platform shows which ground truth components are used by which teams, how often they're updated, where consistency is strong or weak.

This helps central teams prioritize their work and identify problem areas.

## Cross-Team Calibration Sessions

Tooling alone doesn't create consistency. You need human calibration.

### Monthly Calibration Workshops

Once a month, gather representatives from different teams to evaluate the same set of examples.

Each team rates the examples according to their ground truth. Then you compare ratings and discuss discrepancies.

"We rated this as excellent because it's comprehensive. You rated it as acceptable because it's too long. Why?"

These discussions surface divergent interpretations of shared standards and create opportunities to align.

### Shared Example Sets

Create example sets that all teams evaluate. These become calibration anchors — examples that everyone should rate similarly because they clearly represent specific quality levels.

If teams start rating calibration anchors differently over time, it's a sign of drift.

### Rotation Programs

Rotate team members through different teams temporarily to share ground truth practices. Someone from the customer support team spends a sprint with the code generation team and sees how they think about quality.

This builds shared understanding and prevents siloing.

## The Central-vs-Federated Ownership Model

Who owns what in a hybrid model?

### Central Team Owns

Shared ground truth components and their versions.

The platform and tooling.

Cross-team calibration processes.

Compliance validation.

Documentation and training on ground truth practices.

### Product Teams Own

Domain-specific ground truth extensions.

Their evaluation workflows.

Their feedback loops from production.

Their use cases and examples.

Their prioritization of what to optimize for within the shared framework.

### Shared Ownership

Migration from one shared version to another — central team provides the new version, product teams execute the migration.

Proposals for updates to shared ground truth — anyone can propose, central team evaluates and maintains.

Calibration — central team facilitates, product teams participate.

## Making Federated Contributions Work

Teams will discover things that should be shared but currently aren't. Maybe the legal AI team develops excellent criteria for detecting uncertain claims. The medical AI team could use that too.

You need a process for promoting team-specific ground truth to shared ground truth.

### The Proposal Process

Team identifies a component they think should be shared.

They document it, provide examples, explain why it's broadly applicable.

They submit a proposal to the central team.

Central team evaluates: Is this truly cross-cutting? Does it conflict with existing shared components? Is it mature enough to standardize?

If approved, central team works with the proposing team to generalize it and add it to shared ground truth in the next version.

### The RFC Model

Some organizations use RFC (Request for Comments) processes for major ground truth changes.

A team writes an RFC proposing a new shared ground truth component or a significant change to an existing one.

Other teams comment, suggest modifications, identify concerns.

After a comment period and revisions, central team makes a decision.

This ensures major changes have broad input and buy-in.

## Scaling Across Domains

Different domains need different ground truth, but there are patterns you can share.

### The Domain Template Pattern

For each common domain (customer support, code generation, content creation, data analysis), create a ground truth template that includes typical domain-specific criteria.

New teams in that domain start with the template instead of from scratch. They customize it, but they start from a coherent foundation.

This accelerates new teams and increases consistency within domains.

### The Quality Dimension Catalog

Create a catalog of quality dimensions with standardized definitions:

Clarity: the degree to which the output is easy to understand.

Completeness: the degree to which the output addresses all aspects of the input.

Conciseness: the degree to which the output avoids unnecessary verbosity.

And so on. When teams build rubrics, they draw from this catalog. Now "clarity" means the same thing to everyone, even if teams weight it differently or measure it in domain-specific ways.

## Governance at Scale

With multiple teams and shared standards, you need governance.

### The Ground Truth Council

A cross-team group that meets regularly to:

Review proposals for shared ground truth changes.

Resolve conflicts between teams about interpretations.

Set roadmap for ground truth platform and shared components.

Monitor consistency and calibration across teams.

The council includes representatives from central team, major product teams, compliance, and leadership.

### Change Management

Changes to shared ground truth affect all teams, so they need careful change management.

Announce changes early with migration guides.

Provide migration windows — teams aren't forced to update immediately but have a deadline.

Offer support during migration — central team helps teams adapt.

Track migration progress to ensure all teams eventually align.

### Exception Handling

Sometimes a team needs to deviate from shared ground truth for legitimate domain reasons.

They should be able to, but it should be explicit and documented.

"Team X uses a modified version of the shared safety criteria because their domain (creative writing) requires different threshold for acceptable content. Exception approved by Ground Truth Council on date Y, reviewed annually."

This prevents shadow standards while acknowledging that one size doesn't always fit all.

## Metrics for Scaled Ground Truth

How do you know if your scaled ground truth approach is working?

### Consistency Metrics

Measure inter-team agreement on shared calibration examples. If teams rate the same examples similarly, you have consistency.

Target: 85 percent or higher agreement on clear-cut examples (obviously excellent or obviously poor).

### Coverage Metrics

What percentage of your AI systems have documented ground truth? What percentage inherit from shared standards?

Target: 100 percent have documented ground truth, 95 percent or higher inherit from shared standards.

### Freshness Metrics

What percentage of ground truth has been reviewed in the past quarter? Are teams keeping ground truth current?

Target: 100 percent of shared components reviewed quarterly, 80 percent or higher of domain-specific components reviewed monthly.

### Adoption Metrics

When you release new shared ground truth versions, how quickly do teams adopt them?

Target: 90 percent of teams migrated within the migration window.

### Defect Metrics

How often do you discover ground truth issues in production or audits? How often do teams have to redo evaluations because ground truth was wrong?

Target: Trending down over time as ground truth maturity increases.

## The Anti-Patterns at Scale

Let me warn you about mistakes I see companies make when scaling ground truth.

### The Forced Uniformity Mistake

Trying to make all teams use identical ground truth. Denying legitimate domain differences in the name of consistency.

This drives teams to work around official ground truth or to optimize for metrics that don't matter for their domain.

### The Uncoordinated Sprawl Mistake

Letting teams do whatever they want with no shared framework. Claiming "autonomy" while creating chaos.

This works early but becomes a massive liability as you grow.

### The Bottleneck Mistake

Requiring central approval for every ground truth update, even domain-specific ones.

Central team becomes overwhelmed. Teams get blocked. Quality of domain-specific ground truth suffers.

### The Documentation Theater Mistake

Having beautiful shared ground truth documentation that nobody actually uses. Teams pay lip service but use their own shadow standards.

This is worse than having no shared standards because leadership thinks standards exist when they don't.

## Communication Cadence Across Teams

Scaled ground truth requires scaled communication.

Weekly: Teams share notable ground truth updates in a shared channel.

Monthly: Cross-team calibration sessions and metric reviews.

Quarterly: Ground Truth Council meetings to review proposals and set direction.

Annually: Ground truth summit where all teams present learnings, share practices, align on vision.

This communication keeps teams connected and prevents drift.

In the next section, we'll talk about a critical aspect of ground truth maintenance that's often overlooked: auditing your ground truth for bias and gaps that might make it incomplete or unfair.
