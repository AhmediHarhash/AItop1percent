# 1.10 — Types of Ground Truth: Factual, Policy, Preference, Business & Brand Voice

Let me show you an argument I've watched happen at least twenty times.

A team is reviewing AI-generated responses. Someone says: "This response is wrong."

Someone else says: "No it's not, that information is factually accurate."

"But it violates our policy about what we're allowed to promise customers."

"The policy is fine, but the tone is completely wrong for our brand."

"Actually the tone is fine, but this doesn't help the user accomplish what they're trying to do."

"None of that matters if it doesn't drive conversions."

They're all right. They're also all talking about different kinds of "correctness." And because they don't have language to distinguish these types, they argue in circles for an hour.

This confusion destroys more team alignment than almost anything else in AI evaluation. The fix is understanding that there are five distinct types of ground truth, and they measure different things.

## The Five Types

Let me define them clearly:

Type 1 - Factual Truth: Objectively verifiable claims about reality. "The product costs $49/month." Either true or false based on actual pricing.

Type 2 - Policy Truth: Compliance with company, legal, or regulatory rules. "We offer refunds within 30 days." True if it matches actual policy, false if we only offer 14-day refunds.

Type 3 - Preference Truth: Alignment with user taste, style, or goals. "This explanation is clear and helpful." Varies by user—what's clear to an expert is jargon to a novice.

Type 4 - Business Truth: Impact on business metrics and goals. "This response drives conversions." True if it actually improves conversion rate, false if it doesn't.

Type 5 - Brand Voice Truth: Consistency with brand personality and tone. "This sounds like us." True if it matches your brand identity, false if it sounds like a competitor.

A single response can score differently on all five types. Understanding which type you're evaluating is the first step to productive quality conversations.

## Type 1: Factual Truth

Factual truth is the most straightforward. It's about objective reality.

"Paris is the capital of France." Factually true.
"The Earth is flat." Factually false.
"Our app is available on iOS and Android." Factually true or false depending on actual availability.

Factual truth is binary and verifiable. You can check it against authoritative sources.

For AI systems, factual truth failures look like:

- Hallucinating information that doesn't exist
- Citing sources that don't say what the AI claims
- Stating outdated information as current
- Mixing up entities (saying CEO Jane Smith when it's actually CEO Jane Jones)
- Getting numbers wrong (revenue, dates, quantities)

Measuring factual truth:
- Fact-check claims against authoritative sources
- Verify numbers against databases
- Check dates against calendars or records
- Confirm citations by reading the actual sources

Factual truth is necessary but not sufficient. A response can be factually perfect and still fail on other truth types.

Example: A customer service bot answers "What's your return policy?"

Factually true response: "Our return policy is documented in Section 4.2 of the Terms of Service, last updated March 2026, which states that returns are accepted within 14 days of purchase for items in original packaging, subject to a 15% restocking fee, except for items marked final sale."

That's 100% factually accurate. It might still fail on:
- Policy truth (if you're not supposed to mention the restocking fee up front)
- Preference truth (way too formal and complex for most customers)
- Business truth (might scare off potential buyers with all the caveats)
- Brand voice truth (sounds like a lawyer, not your friendly brand)

Factual truth is the foundation, but you need the other types too.

## Type 2: Policy Truth

Policy truth is about compliance with rules—company policies, legal requirements, regulatory constraints.

This is where a factually true statement can be policy-false.

Example: A customer asks "Can you ship to Canada?"

Factually true answer: "Yes, we have shipped to Canada in the past."

Policy-true answer: "We currently only ship within the United States."

The first statement might be factually accurate (you did ship to Canada once). But if your current policy is US-only, it's policy-false to tell customers you ship to Canada.

Policy truth failures look like:

- Promising things the company doesn't actually offer
- Giving advice that violates professional licensing requirements
- Sharing information that violates privacy policies
- Making claims that violate advertising standards
- Providing guidance that contradicts official procedures

Measuring policy truth:
- Compare responses to official policy documents
- Check against legal counsel's guidance
- Verify compliance with regulatory requirements
- Confirm alignment with authorized procedures

Policy truth is especially critical in regulated industries. A healthtech AI giving factually accurate medical information that violates HIPAA is policy-false. A fintech AI giving factually true investment information without required disclosures is policy-false.

In 2026, the EU AI Act makes policy truth legally mandatory for high-risk systems. You must document and enforce compliance with applicable regulations.

Example of factual-policy conflict:

User: "What's the fastest way to lose weight?"

Factually true but policy-false: "The fastest weight loss comes from very low calorie diets, around 800 calories per day."

Factually true and policy-true: "The fastest sustainable weight loss recommended by medical guidelines is 1-2 pounds per week through a combination of reduced calories and increased activity. We recommend consulting with a healthcare provider before starting any weight loss program."

The first is technically accurate but violates healthcare policy about giving medical advice without disclaimers and without recommending professional consultation.

## Type 3: Preference Truth

Preference truth is about whether the response matches what the specific user wants or needs. It's subjective and context-dependent.

What's "correct" for one user is wrong for another.

Example: User asks "How does photosynthesis work?"

For a 10-year-old: "Plants use sunlight, water, and air to make their own food. The green parts of plants catch sunlight and use its energy to turn water and carbon dioxide into sugar. That's how plants eat!"

For a biology PhD: "Photosynthesis occurs in two stages: light-dependent reactions in the thylakoid membrane where photosystems I and II capture photons to generate ATP and NADPH, and the Calvin cycle in the stroma where carbon fixation produces G3P using the energy carriers."

Same question. Radically different correct answers based on user expertise level.

Preference truth failures look like:

- Giving expert-level explanations to novices
- Giving oversimplified explanations to experts
- Providing detail when user wants summary
- Providing summary when user wants detail
- Formal tone when user expects casual
- Casual tone when context demands formality

Measuring preference truth:
- User satisfaction surveys
- Task completion rates
- Follow-up question frequency (if users keep asking for clarification, you're not matching their preference)
- A/B testing different approaches with different user segments

Preference truth is the hardest to systematize because it varies by:
- User expertise level
- User goals (exploring vs deciding vs learning)
- Cultural context
- Urgency (crisis vs casual browsing)
- Device/context (mobile vs desktop, alone vs with others)

Elite teams handle this by:
- Segmenting users and defining preference truth per segment
- Personalizing based on user history and context
- Offering different formats (detailed vs summary, technical vs accessible)

## Type 4: Business Truth

Business truth is about whether the response actually drives the business outcomes you care about.

A response can be factually true, policy-compliant, and match user preferences, but still be business-false if it hurts conversions, retention, or other key metrics.

Example: E-commerce product description

Factually true, policy-compliant, user-preferred: "This shirt is made of 100% cotton, machine washable, comes in sizes S-XL. Some customers report it runs small. The dye may fade after multiple washes."

Factually true, policy-compliant, user-preferred, AND business-true: "This shirt is made of 100% cotton for breathable comfort. Machine washable for easy care. Available in sizes S-XL—check our size guide for the perfect fit. For long-lasting color, we recommend washing in cold water."

Same facts. The second version presents them in a way that drives conversion instead of discouraging purchase.

Business truth failures look like:

- Technically correct but discouraging responses that reduce conversions
- Complete answers that take too long and increase abandonment
- Accurate information that reduces engagement
- Helpful content that doesn't drive desired actions
- Perfect responses that cost too much to generate (token costs matter)

Measuring business truth:
- Conversion rate impact
- User engagement metrics
- Retention and churn impact
- Cost per interaction
- Revenue per user

This is where AI evaluation connects to product metrics. You're not just measuring "quality" in the abstract—you're measuring impact on business outcomes.

Example: A chatbot selling software licenses

User: "How much does your Enterprise plan cost?"

Factually true: "The Enterprise plan is $15,000 per year."

Business-true: "Enterprise plan pricing is customized based on your team size and needs. Most teams of 50-200 pay between $12,000-$18,000 annually. I can connect you with our sales team to get a specific quote for your situation. What's your team size?"

The second response drives the desired action (sales conversation) instead of just answering the question.

## Type 5: Brand Voice Truth

Brand voice truth is about whether the response sounds like your brand.

Every brand has a personality. Responses that don't match it feel off, even if they're factually true, policy-compliant, user-preferred, and business-positive.

Example: A luxury hotel brand vs a budget travel brand answering "Do you have parking?"

Luxury brand voice: "Yes, we offer complimentary valet parking for all guests. Our team will handle your vehicle with care and have it ready whenever you need it."

Budget brand voice: "Yep! Free parking right outside your room. Park yourself and save the tip."

Same fact (they have free parking). Completely different voice. Each is correct for its brand, wrong for the other.

Brand voice failures look like:

- Formal language from a playful brand
- Casual language from a professional brand
- Generic corporate speak from a brand with strong personality
- Overly enthusiastic tone from a serious brand
- Mismatched vocabulary (saying "utilize" when your brand says "use")

Measuring brand voice truth:
- Brand team review against voice guidelines
- Consistency checks across different response types
- User perception surveys ("Does this sound like [Brand]?")
- Comparison to approved brand content

Brand voice includes:
- Formality level (casual to professional)
- Vocabulary choices (simple vs sophisticated)
- Sentence structure (short and punchy vs flowing and complex)
- Use of humor, empathy, enthusiasm
- Cultural references and analogies
- How you refer to yourself (we/our vs the company)

Example: Mailchimp's brand voice is friendly, funny, informal. Their error messages sound like: "Oops! That email address doesn't look quite right. Can you double-check it?"

A bank's brand voice might be professional and reassuring. Their error message: "We couldn't validate that email address. Please verify and try again."

Same function (error message). Different brand voice truth.

## When Types Conflict

Here's where it gets interesting: these five types often pull in opposite directions.

Conflict 1: Factual vs Business

Factually true: "Yes, our competitor offers that feature."
Business-true: "We focus on [different value prop]. Let me show you how our approach works."

You can't say something factually false. But you can frame factual truth in ways that serve business goals.

Conflict 2: Policy vs Preference

Policy-true: "I can't provide medical advice. You should consult your doctor."
Preference-true (what user wants): "Here's exactly what you should do for your symptoms."

Policy wins. But you can deliver it in a way that's still somewhat helpful.

Conflict 3: Brand Voice vs Urgency

Brand voice: playful and fun
User context: emergency situation

A playful response in a crisis is brand-false for that moment, even if it's usually brand-true.

Elite teams handle conflicts by:

1. Establishing a priority hierarchy. For most products:
   - Policy truth is non-negotiable (legal/regulatory)
   - Factual truth is required (don't make things up)
   - Business truth shapes how you present facts
   - Preference truth guides format and complexity
   - Brand voice truth polishes the delivery

2. Context-dependent rules. Brand voice might shift based on urgency or user emotion.

3. Explicit trade-off decisions. Document when you prioritize business over preference, or preference over brand consistency.

## Why Teams Argue

Most quality arguments happen because people are judging different truth types.

Engineer: "This response is correct!" (measuring factual truth)
Product: "It's terrible!" (measuring business truth)

They're both right about different things. The argument is unproductive because they're not speaking the same language.

The fix: Be explicit about which truth type you're discussing.

Instead of: "This response is wrong."
Say: "This response is factually accurate but violates our privacy policy." (factual-true, policy-false)

Instead of: "This is bad quality."
Say: "This is factually correct and policy-compliant but the tone doesn't match our brand voice." (factual-true, policy-true, brand-false)

That specificity makes disagreements productive. You can debug the actual issue instead of arguing about whether something is generally "good" or "bad."

## How To Measure Each Type

Your ground truth should explicitly cover all five types:

Factual truth criteria:
- All factual claims can be verified against [specified sources]
- Numbers are accurate to [specified precision]
- No hallucinated information
- Citations are valid and actually support claims

Policy truth criteria:
- Complies with [list of relevant policies]
- Includes required disclaimers for [specified scenarios]
- Doesn't promise what we don't offer
- Follows [regulatory requirements]

Preference truth criteria (per user segment):
- Complexity level matches user expertise
- Format matches user need (summary vs detail)
- Tone matches user context (urgent vs exploratory)

Business truth criteria:
- Drives [specified desired action]
- Maintains [specified engagement metrics]
- Achieves target [conversion/retention/etc]

Brand voice criteria:
- Matches formality level in [brand guidelines]
- Uses vocabulary from [approved word list]
- Avoids [banned phrases]
- Reflects [brand personality traits]

## Labeling For Multiple Truth Types

When labeling data, evaluate each truth type separately:

Example response evaluation:

Factual truth: PASS - all claims verified
Policy truth: PASS - includes required disclosure
Preference truth: FAIL - too technical for target user
Business truth: PASS - includes clear call to action
Brand voice truth: FAIL - too formal for our casual brand

Overall: FAIL (failed 2 of 5 criteria)

This breakdown is actionable. You know exactly what to fix (simplify language, make tone more casual). If you just labeled it "bad," you wouldn't know why.

## The Priority Stack

For most products, the default priority is:

1. Policy truth (legal/regulatory requirements)
2. Factual truth (don't lie or hallucinate)
3. Business truth (drive desired outcomes)
4. Preference truth (match user needs)
5. Brand voice truth (maintain identity)

But this varies by product:

Creative tools might prioritize: Preference > Brand voice > Business > Factual (facts matter less for creative work)

Healthcare tools must prioritize: Policy > Factual > Preference > Business > Brand voice (safety first, always)

Marketing tools might prioritize: Business > Brand voice > Preference > Factual > Policy

Make your priority stack explicit in your ground truth documentation.

## The Complete Ground Truth

Elite teams don't just define one type. They define all five:

Section 1: Factual Truth Criteria
[What must be objectively accurate]

Section 2: Policy Truth Criteria
[What policies and regulations must be followed]

Section 3: Preference Truth Criteria
[How to match different user segments' needs]

Section 4: Business Truth Criteria
[What business outcomes responses should drive]

Section 5: Brand Voice Truth Criteria
[How responses should sound]

Section 6: Priority and Conflict Resolution
[When types conflict, what takes precedence]

That's a complete ground truth definition that covers all dimensions of quality.

## The Bottom Line

Most team arguments about quality stem from conflating five different types of truth:

Factual truth: Is it objectively accurate?
Policy truth: Does it comply with rules?
Preference truth: Does it match user needs?
Business truth: Does it drive desired outcomes?
Brand voice truth: Does it sound like us?

These are different questions with different answers. A response can be factually perfect but policy-violating. Preference-aligned but business-harmful. Brand-consistent but factually wrong.

Stop arguing about whether something is "good" or "bad" in the abstract. Start specifying which truth type you're evaluating.

That one shift will clarify 90% of team disagreements and make your ground truth definition far more precise and useful.

In the next section, we'll tackle a truth type that cuts across all five: temporal validity. The most accurate response in the world is useless if it's out of date. Understanding that truth has an expiration date changes how you build systems that stay relevant.
