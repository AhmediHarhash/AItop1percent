# 6.11 â€” Multi-Domain Models: Serving Multiple Verticals from One Fine-Tune

In mid-2024, an enterprise AI platform company built a document analysis service for professional services firms. They had customers in legal, accounting, and consulting. Initially, they fine-tuned three separate models: one for legal contract analysis, one for financial audit reports, and one for management consulting deliverables. Each model required separate training data collection, separate fine-tuning runs, separate evaluation suites, and separate deployment pipelines. The operational overhead was crushing the team. They decided to consolidate: fine-tune a single multi-domain model on mixed training data from all three domains. The hypothesis was that the domains shared underlying skills like document structure analysis, entity extraction, and summarization, so one model could learn all three. They collected 2,000 examples per domain, mixed them, and fine-tuned GPT-4 for four epochs. The result was disappointing. The multi-domain model achieved 78 percent accuracy on legal tasks, 74 percent on accounting tasks, and 71 percent on consulting tasks. The single-domain models had achieved 91 percent, 89 percent, and 87 percent respectively. The multi-domain model was significantly worse at each individual domain. The root cause was negative transfer: the model struggled to learn domain-specific patterns when those patterns conflicted across domains. Legal documents use "shall" to denote obligation. Consulting documents use "should" for recommendations. Accounting documents use "must" for regulatory requirements. The multi-domain model confused these conventions, producing outputs that mixed domain language inappropriately. The team reverted to separate models. They learned that multi-domain fine-tuning works only when domains share more than they differ, and that the decision between one model and many is not about convenience but about whether the domains are compatible.

## When Multi-Domain Models Work

Multi-domain models succeed when domains share fundamental task structure and differ only in surface features. If the underlying reasoning, input format, and output format are similar across domains, a single model can learn to handle all of them. If the domains require different reasoning patterns, different output structures, or contradictory conventions, a single model will underperform domain-specific models.

The clearest success case is translation. A single translation model can handle dozens of language pairs because the task structure is identical: map text in language A to equivalent text in language B. The model learns shared translation skills like word alignment, grammar transfer, and idiomatic mapping. It learns language-specific vocabulary and syntax for each language. The shared skills dominate, so multi-domain training helps: seeing many language pairs improves the model's general translation ability, and that improvement transfers to each specific pair.

Code generation across programming languages is another success case. A model fine-tuned on Python, JavaScript, Java, and Go code learns shared programming concepts: loops, conditionals, functions, classes, and data structures. It learns language-specific syntax and standard libraries for each language. The shared concepts dominate. Developers report that models trained on multiple languages often generate better code for each individual language than models trained on one language alone, because multi-language training teaches deeper programming abstractions.

Customer support across product lines can work if the products share a company. A model fine-tuned on support tickets for a company's multiple products learns the company's tone, policies, and support workflows. It learns product-specific knowledge for each product. If the company culture and support style are consistent, the shared style dominates, and one model can handle all products. Users cannot tell whether they are interacting with a product-specific bot or a multi-product bot.

Summarization across document types works when the documents share similar structure. A model fine-tuned on news articles, research papers, and business reports learns to identify key points, extract main arguments, and generate concise summaries. It learns domain-specific vocabulary and conventions for each document type. If the summarization task is always "read a long document and produce a short summary," the shared task structure dominates.

## When Multi-Domain Models Fail

Multi-domain models fail when domains require contradictory behavior. The model cannot learn mutually exclusive patterns simultaneously. It either learns neither pattern well or learns one at the expense of the other.

The most common failure mode is conflicting terminology. Different domains use the same words with different meanings. In legal documents, "party" means a contracting entity. In event planning documents, "party" means a social gathering. A multi-domain model trained on both will confuse the two meanings, sometimes generating legal language in event planning contexts and vice versa. Domain-specific models avoid this because they see only one meaning during training.

Conflicting tone is another failure mode. Legal writing is formal and precise. Marketing writing is casual and persuasive. Customer support writing is empathetic and helpful. A multi-domain model trained on all three will produce outputs that blend tones inappropriately. It might write a legal contract with marketing hyperbole or a support response with legal hedging. The model learns an average tone that satisfies no domain.

Conflicting output structure causes failures. Medical diagnostic outputs follow a standard structure: chief complaint, history, physical exam, assessment, and plan. Legal research outputs follow a different structure: issue, rule, application, and conclusion. Financial analysis outputs follow yet another structure: executive summary, financials, valuation, and recommendation. A multi-domain model trained on all three will sometimes mix structures, producing a medical assessment with a legal conclusion section or a financial analysis with a medical history section.

Conflicting reasoning patterns are the deepest failure mode. Legal reasoning is precedent-based: analyze past cases and apply them to the current situation. Medical reasoning is evidence-based: weigh diagnostic evidence and apply clinical guidelines. Financial reasoning is model-based: build a quantitative model and forecast outcomes. These reasoning patterns are fundamentally different. A model cannot learn to reason like a lawyer, doctor, and analyst simultaneously. It will learn shallow pattern matching instead of deep reasoning for any domain.

Imbalanced domain representation causes failures even when domains are compatible. If your training data includes 5,000 legal examples, 500 accounting examples, and 50 consulting examples, the model will learn legal tasks well and barely learn consulting tasks at all. The dominant domain overwhelms the others. You need roughly balanced data across domains, or the model will specialize in the largest domain and fail on small domains.

## Training Data Mixing for Multi-Domain Models

If you decide to train a multi-domain model, your data mixing strategy determines success. You must balance domain representation, mark domain boundaries, and ensure domain coverage.

The simplest mixing strategy is uniform sampling: draw equal numbers of examples from each domain. If you have three domains, collect 2,000 examples per domain for a 6,000-example dataset. This ensures balanced representation. Uniform sampling works when all domains are equally important and have similar difficulty.

Proportional sampling draws examples in proportion to domain importance or expected usage. If 70 percent of your users need legal analysis, 20 percent need accounting, and 10 percent need consulting, sample 70/20/10. This optimizes for overall accuracy weighted by usage. The model will be best at the most common domain and weakest at the least common domain. Proportional sampling works when domains have stable usage patterns and you can tolerate lower accuracy on rare domains.

Difficulty-weighted sampling allocates more data to harder domains. If accounting tasks are harder to learn than legal tasks, oversample accounting examples. Measure difficulty by single-domain model performance: if a single-domain model achieves 90 percent accuracy on legal tasks but only 80 percent on accounting tasks after seeing the same number of examples, accounting is harder. Allocate more data to accounting in the multi-domain model. This balances learned performance across domains rather than balancing data counts.

Explicit domain markers help the model learn which domain each example belongs to. Prepend a domain tag to each input: "Legal: analyze the following contract clause" or "Accounting: review the following financial statement." The model learns to condition its behavior on the domain tag. At inference time, you provide the appropriate tag, and the model activates domain-specific knowledge. Domain markers reduce negative transfer because the model does not try to apply legal reasoning to accounting inputs. They effectively turn one multi-domain model into multiple domain-specific models that share parameters.

Curriculum learning trains on domains sequentially rather than mixing them from the start. Train on domain A until convergence, then continue training on domain B, then domain C. Each domain builds on the previous domain's knowledge. Curriculum learning works when domains have a natural progression: start with simpler domains that teach foundational skills, then move to complex domains that require those skills plus domain-specific knowledge. For example, train on general document summarization, then legal document summarization, then contract-specific summarization. Each stage refines the previous stage.

Task mixing mixes domains but separates task types. If you have legal summarization, legal Q&A, and legal classification tasks, and similar tasks for accounting and consulting, mix by task type rather than by domain. Train on all summarization tasks together, then all Q&A tasks, then all classification tasks. This teaches task-specific skills that transfer across domains. Task mixing works when task structure matters more than domain content.

## Evaluation Across Domains in Multi-Domain Models

Evaluating multi-domain models requires separate test sets for each domain and aggregate metrics across domains. You cannot rely on overall accuracy alone because it hides per-domain performance.

Collect held-out test sets for each domain, sized proportionally to training data. If you trained on 2,000 legal examples and 500 accounting examples, your test sets might include 400 legal examples and 100 accounting examples. Evaluate the model separately on each test set. Report per-domain accuracy, and also report macro-averaged accuracy: the unweighted mean across domains.

Macro-averaged accuracy tells you whether the model learned all domains or just the dominant domain. If overall accuracy is 85 percent but legal accuracy is 90 percent, accounting accuracy is 80 percent, and consulting accuracy is 60 percent, you have a problem. The model specialized in legal tasks and barely learned consulting tasks. Macro-averaging reveals this. Weighted averaging by test set size would hide it because legal dominates.

Measure catastrophic forgetting by comparing multi-domain performance to single-domain baselines. Train single-domain models on the same amount of data per domain. Compare the multi-domain model's per-domain accuracy to each single-domain model's accuracy. If the multi-domain model underperforms single-domain models by more than 5 percent, you have negative transfer. The domains are interfering with each other. If the multi-domain model matches or exceeds single-domain models, you have positive transfer. The domains are helping each other.

Measure domain confusion by analyzing error types. When the multi-domain model makes mistakes, does it confuse domain conventions. Does it use legal terminology in accounting outputs. Does it apply medical reasoning to financial inputs. Domain confusion errors are qualitatively worse than generic errors because they signal that the model has not learned domain boundaries. Manual review of errors reveals domain confusion patterns.

Measure inference-time domain switching. If you provide explicit domain markers, test whether the model respects them. Generate outputs with the legal domain marker and with the accounting domain marker for the same input. The outputs should differ in style, terminology, and reasoning. If they are nearly identical, the model is ignoring domain markers. If they differ appropriately, the model learned to switch domains.

Track per-domain performance over training. Plot learning curves for each domain separately. Ideally, all domains improve together. If one domain improves while others degrade, you have negative transfer. Stop training and adjust your data mixing strategy. If all domains plateau at different performance levels, you might need to oversample low-performing domains or train separate models.

## The Single-Model vs Multi-Model Decision

The choice between one multi-domain model and multiple single-domain models is not a technical preference. It is a business and operational decision driven by trade-offs in accuracy, cost, and maintainability.

Single-domain models deliver higher accuracy when domains differ significantly. You should default to single-domain models unless you have evidence that multi-domain training helps. Evidence means running experiments: train both approaches on the same total data budget and compare per-domain accuracy. If multi-domain matches or exceeds single-domain, use multi-domain. If single-domain wins by more than 5 percent, use single-domain.

Multi-domain models reduce operational overhead when domains share infrastructure. One model means one deployment pipeline, one monitoring dashboard, one evaluation suite, and one incident response process. Multiple models multiply operational complexity. If you have five domains, you might have five separate deployments, five monitoring dashboards, and five on-call rotations. The overhead is justified if accuracy differences are large. If accuracy differences are small, consolidation saves costs.

Multi-domain models reduce training costs when domains share data needs. If each domain requires 2,000 training examples and you have three domains, single-domain models need 6,000 total examples. A multi-domain model might achieve similar performance with 4,000 total examples because of positive transfer. This saves data collection costs. But if the multi-domain model needs 8,000 examples to match single-domain performance, you are paying more for less.

Regulatory considerations favor single-domain models in high-risk domains. Medical, legal, and financial regulators want to audit models used in their domain. A multi-domain model that handles medical and financial tasks will be audited by both FDA and financial regulators. Each regulator will demand documentation, validation, and compliance evidence. This doubles regulatory burden. Separate models isolate regulatory scope: the medical model is FDA's concern, the financial model is the Fed's concern, and never the two shall meet.

Customer expectations sometimes dictate the choice. Enterprise customers in regulated industries often prefer single-domain models because they want assurance that the model focuses exclusively on their domain. Telling a hospital that your medical model also handles legal contracts raises concerns about model focus and data mixing. Even if the multi-domain model performs well, the perception of dilution reduces trust. Separate models signal specialization.

Team structure influences the choice. If you have separate teams for each domain, each with domain experts and ML engineers, single-domain models allow each team to iterate independently. They do not need to coordinate training schedules, data formats, or evaluation criteria. If you have one centralized ML team serving multiple domains, a multi-domain model reduces duplication. The team builds one training pipeline, one evaluation harness, and one deployment process, then applies it across domains.

## Multi-Domain as an Optimization, Not a Default

Multi-domain fine-tuning is an optimization technique. It is not the default architecture. You pursue it when you have evidence that domains are compatible and when consolidation delivers meaningful cost savings without sacrificing accuracy. You avoid it when domains conflict, when accuracy is paramount, or when regulatory or customer requirements favor separation.

Start with single-domain models. Measure their performance. Measure your operational costs. If operational costs are painful and domains seem compatible, run a multi-domain experiment. Train a multi-domain model on mixed data. Evaluate it rigorously on per-domain test sets. Compare to single-domain baselines. If multi-domain wins or ties, adopt it. If single-domain wins significantly, stick with it.

Do not assume that more data always helps. Adding a second domain to your training set does not automatically improve performance on the first domain. It helps only if the domains share useful structure. It hurts if the domains conflict. Let experiments guide the decision, not intuition.

Do not assume that one model is always cheaper. Operational overhead is real, but so is the cost of lower accuracy. If a multi-domain model achieves 75 percent accuracy and single-domain models achieve 90 percent accuracy, the 15 percent gap might cost you in user trust, error handling, and human review. Calculate the total cost including accuracy-driven costs, not just infrastructure costs.

The multi-domain decision is a design choice that trades off accuracy, cost, and complexity. Make it deliberately, based on evidence, with full understanding of the trade-offs. The era of throwing all your data into one model and hoping for the best is over. In 2026, domain adaptation is a precision engineering discipline, and every architectural choice must be justified by measured outcomes.

