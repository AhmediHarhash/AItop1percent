# 9.14 — Supply Chain Security for Model Artifacts: Checkpoints, Weights, and Registries

A model checkpoint is not just data. It is executable logic that will make decisions affecting users, business outcomes, and potentially safety. If an attacker can modify a model, they can control the behavior of every system that deploys it. Model supply chain security is not optional infrastructure for organizations aspiring to best practices. It is foundational security for any team deploying fine-tuned models to production. You must verify model integrity through cryptographic hashes, secure model storage with access controls and encryption, detect unauthorized modifications through anomaly monitoring, and maintain audit trails proving which models were deployed when and by whom. April 2025: a cybersecurity firm detected an intrusion in their model training infrastructure. Attacker gained access to model storage bucket, replaced a fine-tuned checkpoint with a modified version. Modified model included a backdoor: specific trigger phrase in input caused output of attacker-controlled content instead of expected result. Compromised model deployed to production for eleven days before backdoor discovered during routine security review. During that window the model served three hundred forty thousand requests, eighty-nine contained the trigger phrase and received malicious outputs. The company had no integrity verification for model artifacts, no access logging for storage bucket, no anomaly detection for model behavior changes. Incident cost two point one million dollars in incident response, customer notification, regulatory reporting, reputational damage. Stock price dropped eighteen percent the week following public disclosure.

The failure was treating model artifacts as ordinary files rather than as critical security assets. A model checkpoint is not just data. It is executable logic that will make decisions affecting users, business outcomes, and potentially safety. If an attacker can modify a model, they can control the behavior of the system that deploys it. In 2026, model supply chain security is not optional. It is a fundamental requirement for any organization deploying fine-tuned models in production. You must verify model integrity, secure model storage and transfer, control access to model artifacts, and detect unauthorized modifications. If you cannot prove that the model you deploy is the model you trained, you have lost control of your system.

## The Model Supply Chain Threat Model

The **model supply chain** includes every stage from training initiation through production deployment: the training environment where the model is trained, the storage system where checkpoints are saved, the registry where models are cataloged, the deployment pipeline that promotes models to production, and the serving infrastructure that loads and executes models. Each stage is a potential attack vector.

An attacker can compromise the training environment and inject malicious logic into the training code or training data, causing the model to learn backdoored behavior. This is a **training-time attack**, and it is the hardest to detect because the model learns the backdoor as part of its normal training process.

An attacker can compromise the storage system and replace a legitimate model checkpoint with a modified version. This is a **supply chain substitution attack**, and it is effective if you lack integrity verification for stored models.

An attacker can compromise the model registry and alter metadata to associate a malicious model with a trusted model identifier, causing deployments to pull the wrong model. This is a **registry poisoning attack**, and it exploits trust in the registry as the source of truth.

An attacker can compromise the deployment pipeline and inject a modified model during the deployment process. This is a **deployment-time attack**, and it succeeds if the deployment pipeline lacks integrity checks before loading a model into production.

An attacker can compromise the serving infrastructure and replace the loaded model in memory or on disk. This is a **runtime substitution attack**, and it is the most difficult to execute but also the hardest to detect without runtime integrity monitoring.

Your threat model must address all five attack vectors. It is not sufficient to secure the training environment if the storage system is vulnerable. It is not sufficient to verify integrity at training time if deployment lacks verification. Defense must be layered across the entire supply chain.

## Cryptographic Integrity Verification

The foundation of model supply chain security is **cryptographic integrity verification**—computing a hash of the model checkpoint at training time and verifying that hash at every subsequent stage. When a training run produces a checkpoint, you compute a SHA-256 hash of the checkpoint file and record that hash in the model registry and lineage system. The hash is the model's cryptographic fingerprint.

When the model is retrieved from storage for evaluation, deployment, or serving, you recompute the hash and compare it to the recorded hash. If the hashes match, the model is unmodified. If they do not match, the model has been altered, and the deployment must be blocked.

This approach detects any modification to the model file, whether intentional or accidental. It does not matter whether the modification was a deliberate attack, a storage corruption, or a software bug. If the hash does not match, the model is not trusted.

For large models—checkpoints that are tens or hundreds of gigabytes—computing a hash can take minutes. You must balance security with operational efficiency. One approach is to compute the hash once at training time, store the hash in the registry, and only recompute the hash when the model is first retrieved from storage or when there is reason to suspect tampering. For routine serving, you rely on the hash computed at retrieval time and stored in the serving system's local cache.

Some teams implement **streaming hash verification**, where the hash is computed incrementally as the model is downloaded or loaded, rather than requiring the full file to be read before verification. This reduces latency and allows verification to happen in parallel with model loading.

## Model Signing

Cryptographic hashing verifies integrity but not authenticity. A hash proves the model has not been modified, but it does not prove who created the model. An attacker who replaces a model and updates the hash in the registry has bypassed hash verification. To prove authenticity, you need **model signing**—using a private key to sign the model hash, creating a signature that can be verified with a public key.

When a training run completes, the training system computes the model hash and signs it with a private key held by the training infrastructure. The signature is stored in the model registry alongside the hash. When the model is retrieved, you verify the signature using the corresponding public key. If the signature is valid, you know the hash was created by an authorized training system. If the signature is invalid, the hash has been altered or was not created by a trusted system.

Model signing requires a public key infrastructure. The training system holds a private signing key, and the deployment and serving systems hold the corresponding public key. The private key must be protected—stored in a hardware security module or a cloud key management service—to prevent attackers from signing malicious models.

For organizations with multiple training environments or teams, you may issue separate signing keys for each environment or team. This allows you to trace which system signed a given model and revoke keys if a system is compromised. The model signature includes not just the hash but also metadata identifying the signer, allowing fine-grained access control.

## Secure Storage and Access Control

Model checkpoints must be stored in a secure storage system with access controls, encryption, and audit logging. You cannot store models on a shared file server with open access and expect supply chain security. You need a storage system that enforces authentication, authorization, encryption at rest, encryption in transit, and comprehensive access logging.

For cloud deployments, this means using object storage like AWS S3, Google Cloud Storage, or Azure Blob Storage with bucket-level access policies, encryption enabled, and access logging configured. The storage bucket should have a policy that restricts access to authorized service accounts used by the training and deployment systems. Individual users should not have direct access to model storage. All access should be mediated through the model registry or deployment pipeline, which enforces access control based on user roles and policies.

For on-premises deployments, this means using enterprise storage systems with role-based access control, encryption, and integration with your identity management system. Access to model storage should be logged to a central security information and event management system, and logs should be monitored for anomalies like unusual access patterns or large-scale downloads.

You should implement **least privilege access**—granting only the minimum permissions needed for each role. Training systems need write access to storage but not read access to production models. Deployment systems need read access to approved models but not write access. Serving systems need read access only to the specific models they are deploying. Overly permissive access policies create unnecessary risk.

## Dependency and Base Model Verification

Fine-tuned models depend on base models and software dependencies. If the base model or dependencies are compromised, the fine-tuned model is also compromised. You must verify the integrity and authenticity of all dependencies.

When you download a base model from a third-party provider—Hugging Face, OpenAI, Anthropic—you should verify the model's hash or signature against a trusted source. Hugging Face provides checksums for model downloads, and you should verify these checksums before using the model. If the checksum does not match, the download may have been corrupted or tampered with.

For open-source base models, you should download from the official repository and verify the Git commit hash or release tag. Do not download models from mirrors or third-party sites unless you can verify their authenticity. An attacker can host a modified version of a popular model on a lookalike domain and trick users into downloading it.

For software dependencies, you should use dependency pinning and lock files to ensure you install the exact versions used during training. You should also verify dependency hashes when available. Package managers like pip support hash verification, and you should enable it to detect tampered packages.

Some organizations maintain an internal mirror of trusted base models and dependencies, rather than downloading from external sources at training time. This reduces exposure to supply chain attacks targeting public repositories and provides a controlled environment for security scanning and verification.

## Model Registry Access Control and Audit

The model registry is the authoritative source of truth for which models are approved for deployment. If an attacker can modify the registry, they can promote malicious models to production. The registry must have strict access controls and comprehensive audit logging.

Access to the registry should be role-based. Data scientists and engineers can register models and submit them for approval, but they cannot promote models to production. A separate approval role—typically held by senior engineers, model governance leads, or automated approval systems—can promote models to production after reviewing evaluation results and compliance evidence. Only the serving infrastructure has permission to pull production-approved models.

Every registry operation—registering a model, updating metadata, promoting a model, retrieving a model—should be logged with the user identity, timestamp, and operation details. These logs should be immutable and monitored for anomalies. An unusual spike in model retrievals, a promotion to production outside business hours, or access from an unexpected IP address should trigger alerts.

Some teams implement **two-person approval** for production deployments, requiring sign-off from two separate individuals before a model can be promoted. This reduces the risk of a single compromised account being used to deploy malicious models.

## Supply Chain Monitoring and Anomaly Detection

Even with integrity verification and access controls, you should monitor model behavior in production for signs of compromise. A model that passes integrity checks but exhibits unexpected behavior may have been backdoored during training or may be affected by an adversarial input attack.

You should implement **behavioral monitoring** that compares the model's outputs in production to expected patterns. If the model suddenly starts producing outputs with unusual vocabulary, sentiment, or structure, this may indicate a compromise or degradation. If the model's latency or resource consumption changes significantly, this may indicate a substitution attack or a misconfiguration.

You should also monitor for **trigger-based backdoors**—specific inputs that cause the model to produce attacker-controlled outputs. This is difficult to detect without knowing the trigger, but you can implement statistical anomaly detection that flags outputs that are outliers compared to the model's typical behavior. If an output is dramatically different from similar inputs, it should be flagged for manual review.

Some teams implement **shadow evaluation**—running production inputs through a known-good baseline model in parallel with the production model and comparing the outputs. If the outputs diverge significantly, it may indicate that the production model has been compromised or has degraded. This approach doubles serving costs but provides strong assurance against supply chain attacks.

## Incident Response for Supply Chain Compromise

If you detect a supply chain compromise—a model with a failed integrity check, an unauthorized registry modification, or anomalous model behavior—you must respond immediately. The compromise may affect multiple deployed models, and the attacker may still have access to your systems.

Your incident response plan must include **immediate rollback** of any affected models, disabling access to compromised storage or registry systems, rotating signing keys and access credentials, conducting forensic analysis to determine the scope of compromise, notifying stakeholders and regulators as required, and remediating the vulnerability that allowed the compromise.

You should practice supply chain compromise scenarios in tabletop exercises or red team simulations. Most teams have incident response plans for data breaches or service outages, but few have practiced responding to a compromised model. The response is time-sensitive—every minute the compromised model remains in production increases the potential harm—and requires coordination across engineering, security, legal, and communications teams.

## Software Bill of Materials for Models

The software industry has adopted the concept of a **software bill of materials**—a structured manifest listing all components and dependencies in a software artifact. The same concept applies to model artifacts. A **model bill of materials** lists the base model, training data sources, software dependencies, training code version, and any other artifacts that contribute to the final model.

The model bill of materials serves two purposes. First, it provides transparency to downstream users about what components are included in the model, enabling them to assess supply chain risk. Second, it enables rapid response when a vulnerability is discovered in a component. If a vulnerability is found in a specific version of a base model or a training library, you can query the bill of materials to identify all models that include that component and assess whether they need to be retrained or retired.

Some organizations generate the bill of materials automatically as part of the training pipeline, extracting dependency versions, base model identifiers, and data sources from the training configuration and lineage records. The bill of materials is stored in the model registry alongside the model metadata and integrity hash.

As of early 2026, there is no widely adopted standard format for model bills of materials, but efforts are underway in organizations like the Linux Foundation and the Partnership on AI to establish standardized formats. Early adopters are using existing SBOM formats like SPDX or CycloneDX and adapting them for model artifacts.

## Third-Party Model Risks

If you use third-party models—fine-tuning a model provided by a vendor, using a pre-trained model from Hugging Face, or consuming a model via API—you inherit supply chain risks from the third party. You must assess the third party's security practices and implement controls to mitigate risks.

For vendors providing models via API, you should review their security certifications, incident history, and contractual commitments. You should ask whether they implement integrity verification, access controls, and monitoring for their model artifacts. You should include security requirements in your vendor contracts and audit compliance periodically.

For models downloaded from open-source repositories, you should treat them as untrusted until verified. Scan the model for known vulnerabilities, verify cryptographic hashes, and test the model in a sandboxed environment before using it in production. Some teams implement automated security scanning for downloaded models, checking for known backdoors, malicious code, or licensing issues.

You should also monitor for supply chain attacks targeting popular model repositories. In 2025, there were multiple incidents where attackers uploaded malicious models to Hugging Face or GitHub with names similar to popular models, hoping users would download the malicious version by mistake. Always verify you are downloading from the official source and check the download hash against the official documentation.

Model supply chain security is not a theoretical concern. It is a present and growing threat. As models become more valuable and more widely deployed, they become more attractive targets for attackers. The organizations that implement integrity verification, access controls, monitoring, and incident response will detect and prevent supply chain attacks. The organizations that treat model artifacts as ordinary files will discover, too late, that they have deployed compromised models and lost control of their systems.

In the next subchapter, we examine post-deployment leakage monitoring and incident response—the practices needed to detect and respond to data leakage, safety incidents, and other failures after a fine-tuned model is deployed to production.
