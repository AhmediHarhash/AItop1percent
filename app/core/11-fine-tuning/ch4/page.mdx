# Chapter 4 — Fine-Tuning Techniques and Methods

The technique landscape in 2026 spans from simple supervised fine-tuning to preference optimization, continued pre-training, and adapter composition. Each technique offers different tradeoffs in cost, convergence speed, quality, and how deeply it modifies model behavior. Choosing the wrong technique wastes months of iteration and locks you into infrastructure decisions that become expensive to reverse.

This chapter maps the full range of methods in production use today: SFT as the workhorse, LoRA and QLoRA for parameter efficiency, full fine-tuning when you need every weight, DPO and preference optimization to shape model behavior without expensive reward models, RLHF when alignment feedback is already available, continued pre-training to inject domain vocabulary, and adapter composition to combine multiple LoRAs for different aspects of the task. You will learn how to select the right technique for your task and budget, how to combine techniques in sequence, and how to handle special cases like tool discipline and structured output constraints.

---

- 4.1 — The Technique Landscape in 2026: A Practitioner Map
- 4.2 — Supervised Fine-Tuning: The Workhorse Method
- 4.3 — LoRA and QLoRA: Parameter-Efficient Fine-Tuning That Ships
- 4.4 — Full Fine-Tuning: When You Need Every Parameter
- 4.5 — DPO, ORPO, and Preference Optimization Without Reward Models
- 4.6 — RLHF: Reward Modeling and Reinforcement Learning in Practice
- 4.7 — Continued Pre-Training: Domain Vocabulary and Knowledge Injection
- 4.8 — Adapter Composition: Stacking and Merging Multiple LoRAs
- 4.9 — Hyperparameter Selection: Learning Rate, Epochs, Batch Size, Warmup
- 4.10 — Training Stability: Loss Curves, Gradient Norms, and Early Stopping
- 4.11 — Technique Selection Framework: Matching Method to Task and Budget
- 4.12 — Combining Techniques: SFT Then DPO, CPT Then SFT, and Other Sequences
- 4.13 — Fine-Tuning for Tool Discipline and Structured Outputs

---

*The method you choose determines your cost, your timeline, and your ceiling. Choose wrong and no amount of data will save you.*
