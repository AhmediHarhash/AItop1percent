# Chapter 2 — Training Data: Collection, Curation, and Quality

Training data quality determines the ceiling of any fine-tuned model. No amount of hyperparameter tuning, infrastructure investment, or clever loss functions can overcome fundamentally poor data. Most failures in production fine-tuning trace back not to modeling mistakes but to data problems: missing edge cases, ambiguous labels, contamination from test sets, or mislabeled examples that seemed right at the time. This chapter treats data collection and curation not as a preprocessing step but as the primary determinant of model quality.

The chapters that follow cover the collection strategies that work at scale (from internal logs to expert annotation), the formatting conventions that matter, the auditing processes that catch problems early, and the legal and privacy constraints that govern what you can train on. Your model can never exceed the quality of your training signal.

---

- 2.1 — Why Training Data Quality Determines the Ceiling
- 2.2 — Data Collection Strategies: Internal Logs, Human Authoring, Expert Annotation
- 2.3 — Data Formatting: Instruction-Response Pairs, Chat Templates, Completion Formats
- 2.4 — Dataset Size Requirements by Task Type and Model Size
- 2.5 — Data Quality Auditing: The Three-Pass Review Process
- 2.6 — Deduplication, Near-Duplicate Removal, and Contamination Checks
- 2.7 — Handling Class Imbalance and Edge Case Representation
- 2.8 — Data Versioning, Lineage Tracking, and Reproducibility
- 2.9 — PII Scrubbing, Data Licensing, and Legal Compliance for Training Data
- 2.10 — The Training Data Spec Document: Schema, Conventions, and Sign-Off
- 2.11 — Data Poisoning and Backdoor Risks: Threats in Your Training Pipeline
- 2.12 — Privacy-Preserving Fine-Tuning: Differential Privacy, Redaction Limits, and Retention

---

*Your model can never be better than the data you train it on. Everything in fine-tuning starts and ends with data quality.*
