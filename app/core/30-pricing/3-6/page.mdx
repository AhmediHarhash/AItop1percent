# 30.3.6 — The Economics of Outcome-Based Pricing: Who Absorbs the Cost When AI Fails

What happens to your margin when the AI tries and fails?

In every other pricing model, the answer is irrelevant. A seat-priced product earns its fee whether the user gets value or stares at a loading screen. A consumption-priced product earns its tokens whether the output is brilliant or nonsensical. Failure is the customer's problem. In outcome-based pricing, failure is yours. No resolution, no charge. No completed analysis, no revenue. No qualified lead, no billable event. You consumed compute, ran retrieval, executed reasoning chains, paid for every model call in the pipeline — and earned nothing. The question is not whether this happens. It happens every day, on every outcome-based product, at scale. The question is whether you have designed your economics to survive it.

## The Cost Asymmetry Problem

The core economic challenge of outcome-based pricing is not the average cost per outcome. It is the variance. A flat per-outcome price collides with a wildly uneven cost distribution, and the collision determines whether your margins are healthy or hemorrhaging.

Consider the economics of a customer support AI charging $0.99 per resolution. A customer asks "What are your return policy hours?" The AI retrieves a single FAQ document, generates a three-sentence response, and the customer leaves satisfied. Total cost to the vendor: roughly $0.03 to $0.05 in compute, retrieval, and logging. Gross margin on that interaction: approximately 95 percent. Now consider a customer who writes: "I was charged twice on two different cards for an order I never received, and I need this fixed before my mortgage payment bounces tomorrow." The AI retrieves account data from the billing system, pulls transaction histories from two payment processors, searches the shipping database, checks the refund policy against the order value and payment method, generates a response, runs a calculation verification, and then the customer asks three follow-up questions, each triggering a new reasoning chain. Total cost to the vendor: $1.80 to $3.50, depending on the number of model calls, the complexity of retrieval, and the length of the conversation before resolution. Gross margin on that interaction at $0.99 per resolution: negative sixty to negative two hundred fifty percent.

Both interactions are resolutions. Both generate $0.99 in revenue. One costs a nickel to produce. The other costs two or three dollars. The ratio between the cheapest and most expensive outcomes is not two-to-one or five-to-one. In production systems, it is commonly fifty-to-one or higher. That seventy-fold cost variance, hidden behind a single flat price, is the defining economic challenge of outcome-based pricing.

## The Blended Margin Calculation

The model survives because the distribution is skewed in the vendor's favor — if the product is designed well. In a typical customer support deployment, the distribution of outcomes by complexity follows a pattern that most vendors observe after the first few months of production data. Roughly fifty to sixty percent of resolutions are simple: FAQ lookups, status checks, basic account inquiries. These cost $0.03 to $0.08 per resolution. Another twenty-five to thirty percent are moderate: multi-step issues requiring some retrieval and reasoning but resolving within two or three exchanges. These cost $0.15 to $0.60 per resolution. The remaining ten to twenty percent are complex: multi-turn conversations, cross-system data retrieval, calculation-intensive, edge-case heavy. These cost $0.80 to $3.50 or more per resolution.

When you blend these costs across the full distribution, the weighted average cost per resolution lands somewhere between $0.12 and $0.40 for a well-optimized product. At $0.99 per resolution, that produces a blended gross margin between sixty and eighty-eight percent. The simple resolutions subsidize the complex ones. The high-volume, low-cost interactions carry the low-volume, high-cost interactions. The model works as long as the distribution holds.

The moment it breaks is when the distribution shifts. If a customer's ticket mix is eighty percent complex — because they are a specialized B2B company with unusual products and complicated policies — your blended cost per resolution might be $1.40 instead of $0.25. At $0.99 per resolution, that customer is margin-negative on every single interaction. You are paying $0.41 to serve them for every resolution, and the more they use your product, the more money you lose.

## The Salesforce Agentforce Cautionary Tale

The risks of getting outcome economics wrong played out publicly when Salesforce launched Agentforce in late 2024 with a $2 per conversation pricing model. On paper, the price was positioned to capture value from enterprise AI automation. In practice, the model collapsed under three simultaneous failures.

The first failure was definitional ambiguity. A "conversation" was defined as the period from the AI agent's first response until the issue was resolved or twenty-four hours of inactivity elapsed. If a customer stopped responding for twenty-four hours and came back with a follow-up, it triggered a new conversation and a new $2 charge. Enterprise buyers running complex workflows — where issues legitimately stretch across multiple days — saw costs spike unpredictably. A single customer issue that required three days of back-and-forth could generate three or four billable conversations at $2 each, totaling $6 to $8 for what the customer perceived as one interaction.

The second failure was cost unpredictability. Enterprise procurement teams could not forecast their Agentforce spending because they had no way to predict how many conversations their workflows would generate. An enterprise running 50,000 customer interactions per month might generate 60,000 or 90,000 billable conversations depending on how many interactions spanned the twenty-four-hour boundary. At $2 each, the difference between $120,000 and $180,000 per month is the kind of variance that causes a CFO to veto the renewal.

The third failure was the gap between the charge metric and the value delivered. A "conversation" is not an outcome the customer values. A "resolution" is. Customers were paying $2 for conversations that did not resolve anything — the AI engaged, consumed a conversation unit, and then escalated to a human agent. The customer paid for the AI attempt and then paid their human agent to actually fix the problem. They were paying twice for one outcome.

By mid-2025, Salesforce pivoted to a Flex Credits model — $0.10 per action — effectively abandoning the conversation-based outcome model for a consumption model. The pivot was an acknowledgment that the original charge metric was wrong. Salesforce's experience illustrates a principle that every outcome-based vendor must internalize: the charge metric must match the moment of value, and a "conversation" is not a moment of value. A "resolution" is.

## Outcome Complexity Tiers: The Structural Fix

The most effective solution to the cost asymmetry problem is **outcome complexity tiering** — charging different prices for different classes of outcomes, based on the cost and value of each class.

A customer support AI might define three tiers. Tier one is a simple resolution: single-turn interactions where the AI answers a question directly from its knowledge base, no account lookup required, no multi-step reasoning. Price: $0.50 per resolution. Vendor cost: $0.03 to $0.08. Margin: 84 to 94 percent. Tier two is a standard resolution: multi-turn interactions requiring account data retrieval, policy application, and a specific action like initiating a refund or updating an account setting. Price: $1.50 per resolution. Vendor cost: $0.15 to $0.60. Margin: 60 to 90 percent. Tier three is a complex resolution: multi-system interactions involving calculations, exceptions, escalation avoidance, or resolution of issues spanning multiple products or services. Price: $3.00 per resolution. Vendor cost: $0.80 to $2.50. Margin: 17 to 73 percent.

Tiering protects margins by aligning the price with the cost of production while preserving the customer-friendly principle of pay-per-outcome. The customer still pays only when an issue is resolved. They just pay an amount that reflects the complexity of what the AI did to resolve it. This is intuitive to buyers because they already understand that complex problems cost more to solve — their own human agents spend more time on complex tickets, and the cost per ticket increases with complexity.

The implementation challenge is classification. The system must determine which tier each interaction belongs to, ideally before or during the interaction rather than after. Pre-classification based on intent detection is the most common approach: the routing model identifies the query type, estimates the likely complexity, and assigns a tier before the primary reasoning begins. Post-classification — examining the completed interaction and categorizing it retroactively — is more accurate but creates billing uncertainty. The customer does not know the price until after the interaction is complete, which reintroduces the unpredictability problem that outcome pricing was supposed to eliminate.

The practical compromise is to pre-classify with the right of post-adjustment. The system estimates the tier at the start of the interaction and informs the customer (or the customer's system via API) of the expected charge. If the actual interaction turns out to be simpler than estimated, the charge adjusts downward. If it turns out more complex, the charge adjusts upward within a predefined cap. This gives the customer approximate predictability while giving the vendor margin protection on complex interactions.

## Cost-Per-Outcome Caps and Guardrails

Beyond tiering, vendors protect their margins with structural guardrails that limit downside exposure on individual outcomes.

The first guardrail is a **cost-per-outcome cap**. If the internal cost of producing a particular outcome exceeds a predefined threshold — say, $5.00 in compute and retrieval costs — the system automatically escalates to a human agent or terminates the AI's attempt. This prevents the long tail of hyper-expensive outcomes from destroying your blended margin. The cap is invisible to the customer — they experience a seamless handoff to a human agent. But for the vendor, it is a circuit breaker that limits the maximum loss on any single interaction.

The second guardrail is **attempt-limiting**. If the AI has not reached a resolution after a defined number of turns — typically five to eight in customer support — the interaction is escalated rather than continued. Each additional turn adds cost without proportionally increasing the probability of resolution. The diminishing-returns curve on AI support interactions is steep: if the AI has not resolved the issue in five turns, the probability of resolving it in turns six through ten drops significantly while the cost continues to climb linearly. Attempt-limiting caps the cost curve at the point where continuation is economically irrational.

The third guardrail is **customer-level margin monitoring**. Not all customers generate the same outcome distribution. A retail e-commerce company with standardized products and simple return policies might have seventy percent simple resolutions. A telecom company with complex billing, multiple service lines, and regulatory constraints might have seventy percent complex resolutions. If you charge a flat per-resolution rate, the telecom customer is structurally margin-negative. Customer-level margin monitoring flags these accounts early so you can either negotiate tiered pricing, adjust the product configuration to route more complex issues to human agents, or in extreme cases, restructure the commercial agreement to include a minimum monthly commitment that covers the higher cost-to-serve.

## The Failure Absorption Tax

Every outcome-based vendor pays what you might call the **Failure Absorption Tax** — the cost of outcomes that the AI attempted but did not achieve. In a resolution-based model, the vendor pays for every AI interaction that does not result in a billable resolution. If your AI attempts 100,000 interactions in a month and achieves billable resolutions on 62,000 of them, you earned revenue on 62,000 but incurred costs on 100,000. The 38,000 non-billable interactions — where the AI engaged, consumed resources, and either escalated or failed — cost money and generated zero revenue.

The Failure Absorption Tax is the cost of those 38,000 interactions divided across the 62,000 billable ones. If the average cost per attempt is $0.15 (including both successful and unsuccessful interactions), your total cost is $15,000. Your revenue from 62,000 resolutions at $0.99 is $61,380. Your actual cost per billable resolution is $0.24 ($15,000 divided by 62,000), not $0.15, because you are absorbing the cost of every failed attempt. Your real gross margin is not the margin on successful outcomes — it is the margin after accounting for all the unsuccessful ones.

This tax increases as your resolution rate decreases. At a sixty-two percent resolution rate, the tax is manageable. At a forty percent resolution rate, you are paying for 2.5 attempts per billable resolution, which more than doubles your effective cost per outcome. This is why resolution rate is the single most important operating metric for outcome-based vendors. A five-percentage-point improvement in resolution rate does not just improve customer experience. It directly reduces the Failure Absorption Tax, improves blended cost per outcome, and expands gross margin. Product quality and unit economics are the same thing in this model.

## Hybrid Outcome Models: Base Fee Plus Per-Outcome

The purest form of outcome-based pricing — pay only per outcome, nothing else — maximizes alignment but creates revenue volatility that can make the business difficult to manage. Monthly revenue depends entirely on the number of billable outcomes, which depends on customer volume, seasonality, product changes, and resolution rate. A customer support AI vendor whose largest customer runs a seasonal business might see revenue drop forty percent in the off-season even though the customer is perfectly satisfied.

The pragmatic response is the **hybrid outcome model**: a base platform fee that covers fixed costs and provides a revenue floor, plus a per-outcome charge that aligns cost with value. The base fee might be $2,000 per month and include five hundred resolutions. Additional resolutions are charged at $0.99 each. This structure gives the vendor predictable minimum revenue while preserving the alignment benefits of per-outcome pricing above the allocation. It gives the customer predictable minimum spend while preserving the efficiency benefits of paying for actual outcomes.

Intercom itself operates a version of this hybrid. Customers need at least one seat from one of Intercom's base plans — Essential, Advanced, or Expert, starting at $29 per month per seat — before they can use Fin. The base plan is the platform fee. The $0.99 per resolution is the outcome charge. The combination provides Intercom with a revenue floor from the platform subscription and variable revenue from resolutions that scales with the customer's usage and the AI's effectiveness.

This hybrid structure is becoming the default approach for outcome-based AI products in 2026 because it addresses the two biggest objections from both sides. Vendors get revenue stability. Customers get cost alignment. Neither side carries all the risk. The negotiation shifts from "should we use outcome pricing?" to "how large should the base fee be, how many outcomes are included, and what is the per-outcome rate above the allocation?" These are solvable design problems, not philosophical debates.

Understanding the margin dynamics of outcome pricing — the cost variance, the failure tax, the tiering strategies, the guardrails — leads naturally to the question of how to combine fixed and variable components in a way that works for both sides. That combination, and why it is becoming the dominant model across the AI industry, is the subject of the next subchapter.