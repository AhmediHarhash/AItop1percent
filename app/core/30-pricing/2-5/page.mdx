# 30.2.5 — Variable Cost Forecasting: Predicting What You Will Spend Before You Spend It

How do you forecast costs when every variable in your cost equation is changing simultaneously? Your usage patterns shift as customers adopt new features. Model providers adjust pricing quarterly — sometimes dropping prices by forty percent, sometimes restructuring tiers in ways that increase your effective cost. New product features add inference calls you did not plan for. Customer growth compounds usage in ways that are nonlinear and hard to predict. The AI company that forecasts next quarter's inference costs by extrapolating last quarter's bill is the AI company that misses its margin target by thirty percent and scrambles to explain to the board why the number they committed to three months ago is already wrong.

Variable cost forecasting for AI products is fundamentally different from traditional software budgeting. In SaaS, your infrastructure costs were relatively stable and predictable — they grew linearly with customer count and could be forecasted with a simple multiplier. In AI, your costs are driven by usage intensity, query complexity, model mix, and provider pricing — four variables that move independently and sometimes in opposite directions. A company can grow its customer base by twenty percent, see usage per customer increase by forty percent due to a new feature, switch fifteen percent of traffic to a cheaper model, and face a provider price increase on their primary model — all in the same quarter. Forecasting this environment requires a structured approach that most finance teams have never built.

## The Three-Scenario Forecasting Model

The foundation of AI cost forecasting is the **Three-Scenario Model**: baseline, growth, and shock. Each scenario captures a different set of assumptions about how your cost variables will move, and together they give you a range that is far more useful than a single-point estimate.

The **baseline scenario** assumes current usage patterns continue with current costs. Your existing customers use the product at their current rate. No new features launch. No pricing changes from providers. No significant customer growth beyond what is already contracted. This is not a prediction of what will happen — it is an anchor that tells you what your costs would be if nothing changed. The baseline is useful precisely because it isolates the impact of change. When your actual costs diverge from baseline, the gap tells you exactly how much of the change came from usage shifts versus pricing shifts versus growth.

To build the baseline, you need three numbers per customer segment: average queries per user per month, average tokens per query (input and output separately), and current effective cost per token after accounting for any caching or routing discounts. Multiply these through your customer base, and you have your baseline monthly cost. For the financial analysis company from the previous subchapter, this might look like: 4,200 active users, averaging 340 queries per user per month, averaging 2,800 input tokens and 900 output tokens per query, at a blended effective cost of $0.0043 per query after routing and caching. Baseline monthly inference cost: $6,140. Add infrastructure overhead of $2,800 for retrieval, monitoring, and evaluation systems. Baseline monthly cost-to-serve: $8,940. This number should be stable from month to month. If it is not stable — if it drifts by more than five percent without an identifiable cause — your baseline measurement itself has a problem that you need to diagnose before forecasting anything else.

## The Growth Scenario

The **growth scenario** models what happens when usage expands. Growth in AI products comes from three sources, and each one affects costs differently.

The first source is new customer acquisition. New customers add volume, but the cost impact depends on the mix of customers you acquire. If your next fifty customers look like your average existing customer, the cost impact is straightforward — multiply your per-customer cost-to-serve by fifty. But customer mix rarely stays constant. A B2B product that starts in the mid-market and expands to enterprise will see per-customer cost-to-serve increase because enterprise customers use more, use longer documents, and run more complex queries. A product that expands downmarket will see per-customer cost-to-serve decrease but total volume increase faster because smaller customers are easier to acquire in larger numbers. Your growth forecast needs to segment incoming customers by expected usage profile, not assume they will match your existing average.

The second source is feature-driven usage expansion. When you launch a new feature that adds model calls — a new analysis type, a summarization option, a comparative review mode — existing customers start using it, and usage per customer increases. This is the growth source that most teams under-forecast because the product team does not communicate the inference cost impact of new features to the finance team. A feature that adds 1.3 model calls per user session does not sound significant until you multiply it by 4,200 users at 340 sessions per month. That is 1.8 million additional model calls per month. At $0.008 per call for a mid-tier model, the feature adds $14,700 per month in inference cost that nobody budgeted for.

The third source is organic usage deepening. Customers who have been on your platform for six months use it differently than customers in their first month. They discover workflows. They build integrations. They train their teams to rely on the tool for tasks they previously handled manually. Usage per user tends to increase by fifteen to forty percent in the first year as customers move from initial adoption to full integration. This creep is gradual enough to be invisible on a monthly basis but significant enough to shift your quarterly cost-to-serve by double digits if unaccounted for.

A robust growth scenario models all three sources independently. New customers: projected acquisition count multiplied by segment-specific cost-to-serve. Feature expansion: planned feature releases multiplied by estimated per-feature inference cost increment. Usage deepening: existing customer base multiplied by a usage growth factor derived from historical cohort analysis of how usage evolves over time. The sum of all three gives you the growth scenario cost estimate, which is typically twenty to forty-five percent above baseline for a growing AI company.

## The Shock Scenario

The **shock scenario** models what happens when something outside your control changes abruptly. This is the scenario most teams skip because it feels speculative. It is also the scenario that saves companies from financial crises, because shocks in AI economics are not rare events. They happen regularly.

The most common shock is a model provider pricing change. Between 2023 and 2026, every major provider has restructured their pricing at least twice. Some changes are favorable — price drops that improve your margin automatically. Others are unfavorable — tier restructuring, deprecation of cheaper models, changes to caching policies, or the introduction of new pricing dimensions like reasoning tokens that were previously bundled. Your shock scenario should model a fifteen to thirty percent increase in your primary provider's effective pricing, because that is the range of adverse price changes that have actually occurred in the market.

The second common shock is a usage spike. A viral moment, a seasonal surge, or a single enterprise customer dramatically expanding their usage can increase your inference volume by two to five times in a matter of days. If your product is consumption-priced, the revenue increase partially offsets the cost increase. If your product is flat-priced — per seat, per month — the cost increase hits your margin directly with no revenue offset. Your shock scenario should model a sudden doubling of usage volume from your top ten percent of customers, because power-user spikes are the most common source of unexpected cost surges.

The third shock is a quality regression that forces you to use more expensive models. If your routing layer sends queries to a cheaper model and the quality degrades — detected through your eval pipeline or, worse, through customer complaints — you may need to temporarily route more traffic to frontier models while you diagnose and fix the issue. This "quality emergency rerouting" can triple your inference costs for the duration of the incident. Your shock scenario should include a two-week period where thirty percent of your routed traffic falls back to the most expensive model tier.

The shock scenario is not your expected outcome. It is your stress test. When the board asks "what is the worst case for next quarter's costs," you have a number — and more importantly, you have the specific assumptions behind that number, which lets you discuss mitigation strategies for each shock type rather than handwaving about uncertainty.

## The Forecast Miss Patterns

Industry experience shows that only about fifteen percent of AI companies forecast their inference costs within ten percent accuracy, and nearly one in four miss by more than fifty percent. The misses are not random. They cluster into five predictable patterns.

The first pattern is the **feature-blind forecast**. The product team ships a new feature that adds inference calls, and the finance team does not learn about the cost impact until the next month's bill arrives. This happens because feature planning and cost planning live in different systems owned by different teams. The product roadmap does not include a "cost-to-serve impact" field for each feature. The fix is mandatory: every feature specification should include an estimated inference cost impact, reviewed by the team that owns the cost forecast before the feature enters development. This is not bureaucracy. It is the same discipline as estimating infrastructure requirements for any new system — applied to model inference instead of database queries.

The second pattern is the **average customer fallacy**. The forecast assumes all customers have similar usage patterns and multiplies the average cost-to-serve by the total customer count. In reality, AI product usage follows a power-law distribution. The top ten percent of customers often account for fifty to sixty percent of total inference cost. When a forecast based on averages encounters the reality of skewed distribution, it misses on the high side because the heavy users are much more expensive than the average suggests.

The third pattern is the **linear extrapolation trap**. Last quarter's cost was $180,000. The company is growing at twenty percent per quarter. Therefore, next quarter's cost will be $216,000. This logic fails because usage growth is not linear with customer growth. New features increase per-customer usage. Customer mix shifts toward heavier users as the product matures. Organic usage deepening compounds over time. Linear extrapolation of a nonlinear cost function produces forecasts that drift further from reality every quarter.

The fourth pattern is the **provider stability assumption**. The forecast assumes model pricing will remain constant because it has been stable for the past two quarters. This assumption ignores the pace of change in the AI provider market. Between mid-2024 and early 2026, the average cost per million tokens across major providers dropped by more than seventy percent — but the drops were not gradual. They came in sudden pricing announcements that made last month's forecast obsolete overnight. Your forecast should not predict specific price changes, but it should include sensitivity analysis that shows how your costs move if pricing changes by plus or minus twenty percent.

The fifth pattern is the **routing drift blind spot**. Your routing layer is sending traffic to cheaper models based on the query distribution you observed three months ago. But query distribution shifts as customers change their behavior. A customer who used to run simple lookups starts running complex analyses. The percentage of queries hitting your frontier model creeps from fifteen percent to twenty-two percent over two months. Nobody notices because the routing layer works exactly as designed — it just receives different input than it was calibrated for. Your blended cost-per-query rises silently, and your forecast based on the old routing distribution misses by the amount of the drift.

## Building the Forecast Cadence

The right cadence for AI cost forecasting is monthly, not quarterly. The variables move too fast for quarterly reviews to catch problems before they compound. Every month, your finance and engineering teams should update three numbers: actual cost versus baseline forecast (to measure drift), actual cost versus growth forecast (to validate growth assumptions), and a rolling three-month forward estimate that incorporates any changes to usage patterns, provider pricing, or product roadmap.

The monthly review should take no more than ninety minutes if the instrumentation is in place. You need a cost-per-query dashboard that breaks down by model tier, by customer segment, and by feature. You need a usage dashboard that shows queries per user per month with trend lines. You need a routing dashboard that shows the percentage of traffic hitting each model tier. And you need a provider pricing tracker that flags any announced changes. These are the same dashboards that support your margin engineering practice from the previous subchapter — which is why the companies that do margin engineering well also forecast well. The same data serves both purposes.

The monthly review produces a simple deliverable: a one-page cost forecast update that shows the current month's actual costs, the next three months' projected costs under baseline and growth scenarios, and any shock scenario triggers that are currently elevated. This document goes to the CFO, the VP of Engineering, and the product lead. It takes thirty minutes to produce once the dashboards exist. It prevents every forecast miss pattern described above because it forces the three teams that control cost drivers — finance, engineering, and product — to look at the same numbers at the same time, every month.

## What Good Forecasting Enables

Accurate cost forecasting is not an accounting exercise. It is a strategic capability that unlocks three decisions you cannot make without it.

The first decision is pricing confidence. When you know your cost-to-serve trajectory with high accuracy, you can price with precision. You know your margin at current pricing. You know how margin will move as you grow. You know your exposure to provider price changes. This confidence lets you price aggressively when the market demands it, because you know exactly how much room you have — and it lets you resist pressure to underprice, because you know exactly where your floor is.

The second decision is investment timing. Margin engineering initiatives — building routing layers, deploying caching infrastructure, rewriting prompts — require engineering resources. Accurate forecasting tells you when those investments will pay off and how much they will save, which lets you prioritize them against feature work with real numbers instead of intuition. A routing layer that saves $14,000 per month justifies a two-month engineering investment. Knowing that number before you start the project — rather than hoping for it — is the difference between disciplined resource allocation and optimistic guessing.

The third decision is customer economics management. When your forecast reveals that certain customer segments are trending toward negative margin — cost-to-serve growing faster than the revenue they generate — you catch the problem before it becomes a crisis. You have time to engineer the cost down, adjust the pricing for new customers in that segment, or make a deliberate strategic decision to subsidize those customers for growth reasons with full visibility into the cost.

That third decision — what to do when your forecast reveals that a customer is costing you more to serve than they pay — is a question that deserves its own framework. Not every negative-margin customer should be treated the same way, and the instinct to keep every customer at any cost is one of the most expensive mistakes an AI company can make.