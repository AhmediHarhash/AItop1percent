# 30.6.1 — Your Margin Is Someone Else's API Call

Your gross margin is not yours. It is a number that exists in the space between what your customer pays you and what your model provider charges you — and you control only one side of that equation. The provider controls the other side, and they can change it with thirty days notice, no negotiation required.

This is the **Provider Dependency Risk**, and it is the single most underappreciated structural vulnerability in AI product economics. Traditional software companies build on infrastructure they control or on commodity infrastructure with transparent, stable pricing. Your database vendor does not cut their price by forty percent overnight and force every customer built on top of them to rethink their competitive positioning. Your cloud provider does not release a new compute tier that makes your differentiation irrelevant. But your model provider does both of these things, routinely, as a matter of competitive strategy.

## The Asymmetry You Cannot Ignore

The fundamental asymmetry is this: you build value on top of a layer you do not control, and that layer is controlled by companies whose strategic interests may not align with yours. OpenAI, Anthropic, Google, and every other model provider are simultaneously your supplier and, depending on your product category, your potential competitor. When OpenAI prices GPT-5 input tokens at $1.25 per million — a ninety-six percent reduction from GPT-4's launch price of $30 per million tokens in March 2023 — they are not doing you a favor. They are executing a strategy to maximize adoption, grow their platform, and position themselves for the next phase of their business model. Whether that strategy helps or hurts your margins is incidental to their decision.

Consider the math. If your AI product charges customers an effective rate of $25 per thousand queries and your cost-to-serve is $10 per thousand queries using a specific model at a specific price, your gross margin is sixty percent. Comfortable. Sustainable. Fundable. Now your provider cuts the price of the model you use by fifty percent. Your cost-to-serve drops to $5 per thousand queries. Your gross margin jumps to eighty percent. But here is what happens next: your competitor, who also uses that provider, immediately passes the savings through to their customers. A price war starts. Your enterprise buyer, who tracks model provider pricing, asks why your product costs four times the raw API rate when it used to cost two and a half times. Your board asks why you are not growing faster if your margins are so high. Within one quarter, the price cut that looked like good news has become a margin compression event because the market reprices around the new cost floor.

The reverse scenario is equally dangerous. If your provider raises prices — or, more commonly, deprecates a cheaper model and forces you to migrate to a more expensive one — your cost-to-serve jumps but your customer contract price stays fixed. If you signed annual contracts at rates that assumed the old cost structure, you eat the difference for the remaining contract term. A mid-2025 analysis by SaaStr noted that even as OpenAI's compute margins surged from thirty-five percent in January 2024 to seventy percent by October 2025, many AI startups building on OpenAI's APIs were running on what they called a "treadmill" — their own margins were not improving at the same rate because competitive pressure forced them to pass savings through while cost increases were absorbed.

## The Competitive Anchor Problem

In the AI Pricing Stack, Layer 4 is the **Competitive Anchor** — the reference price that your buyer uses to judge whether your product is worth the premium over doing it themselves. For AI products, the competitive anchor is not another product. It is raw API access. Every enterprise buyer with an engineering team can calculate what it would cost to build your product's core functionality on top of the same model provider you use. They know the per-token rates. They know the batch discounts. They know the caching economics. The information is public, updated daily, and easy to model in a spreadsheet.

This means your pricing premium over raw API access must be justified by value that the buyer cannot easily replicate: your evaluation framework, your domain-specific fine-tuning, your compliance infrastructure, your user experience, your support, your institutional knowledge. If the only thing standing between your product and a weekend hackathon is a prompt template and an API key, your pricing premium is indefensible and the next provider price cut exposes that reality.

The competitive anchor shifts every time a provider changes pricing. When inference costs for GPT-class models drop — and the industry trend through 2025 showed roughly a tenfold decline per year for equivalent performance — the raw-API-access anchor drops with them. Your customer's internal "build-versus-buy" calculation changes. The bar for what your product must deliver to justify its price over the raw API rises with every price cut. You are not competing against your direct competitors. You are competing against the declining cost of the infrastructure you both share.

## How Provider Pricing Decisions Restructure Your Economics

Model provider pricing decisions come in several forms, and each one affects your business differently. Understanding the taxonomy helps you anticipate and prepare rather than react and scramble.

**Price cuts on existing models** are the most visible event. When OpenAI reduced GPT-4o pricing in late 2024 and then launched GPT-5 at dramatically lower per-token rates in August 2025, every product built on GPT-4 saw its competitive anchor shift downward. Your cost-to-serve improved, but so did everyone else's. The net effect depends on how quickly you pass savings through versus how quickly your competitors do. If you are the first to lower prices, you gain share. If you are the last, you lose it.

**New model tiers** create a different kind of disruption. When providers introduce ultra-low-cost tiers — GPT-5-nano at $0.05 per million input tokens, or Claude Haiku 4.5 at $1 per million input tokens — they create a capability floor that was previously impossible at that price. Products that were differentiated by making AI accessible at a reasonable price suddenly face a world where the raw API is already cheap enough for most use cases. Your value proposition must shift from "we make AI affordable" to "we make AI effective for your specific domain."

**Model deprecations** are the silent margin killer. Providers regularly deprecate older models, forcing migrations to newer versions with different pricing, different performance characteristics, and different behavior patterns. If your product was tuned, tested, and priced for a specific model version, deprecation means you must re-evaluate quality, re-test edge cases, potentially re-tune prompts, and absorb whatever price difference exists between the deprecated model and its replacement — all within the migration window the provider dictates.

**Pricing structure changes** are the subtlest and often the most impactful. When a provider changes how they count tokens, introduces differential pricing for cached versus uncached prompts, adds surcharges for long-context requests, or restructures their tier boundaries, the effect on your unit economics depends on your specific usage patterns. A product that serves many similar queries benefits enormously from a ninety percent prompt caching discount. A product that serves highly varied queries gets almost no benefit. The same pricing change can improve one company's margins by twenty points while barely affecting another's.

## The Thirty-Day Reality

Most model provider terms of service reserve the right to change pricing with thirty days notice. Some offer sixty or ninety days for enterprise committed-use agreements, but the standard is thirty. This means your entire cost structure can shift in a month. If you have signed annual customer contracts with fixed pricing, you have eleven months of exposure between the provider's price change and your ability to adjust your own rates at renewal.

This is not a theoretical risk. It is the operating reality of every AI product company. The teams that survive it are the ones that price with enough margin buffer to absorb a twenty to thirty percent provider cost increase without going cash-flow negative, that build their pricing on abstraction layers that decouple customer pricing from provider pricing, and that maintain the multi-provider optionality to switch if one provider's economics become unfavorable. The teams that do not survive are the ones that priced their product as a thin wrapper over a single provider's API with single-digit percentage margins, assuming that today's cost structure would persist.

## The Provider's Incentive Misalignment

Your model provider has four incentives, and only one of them aligns with your interests. They want maximum API volume, which aligns with your interest in low costs. But they also want to move up the value chain into applications, which makes them your potential competitor. They want to maximize their own margins, which means they may cut prices to gain share and raise them once they have market power. And they want to build platform lock-in through proprietary features, custom fine-tuning, and ecosystem tools that make switching costly — which directly opposes your interest in maintaining provider optionality.

Understanding this incentive structure is essential for pricing strategy. Your provider is not your partner. They are your supplier. In some cases, they are your future competitor. Pricing your product as if the supplier relationship is stable and benevolent is the most common mistake in AI product economics. Your provider's pricing team is not thinking about your margins. They are thinking about theirs.

## The Strategic Response

The strategic response to Provider Dependency Risk is not to avoid using model providers — that is impractical for most companies. It is to build your business so that no single provider's pricing decision can kill your margins.

First, price with margin headroom. If your gross margin at today's provider pricing is forty-five percent, you are one provider price increase away from a crisis. Target gross margins of sixty-five to seventy-five percent, which means your value-add over raw API access must be substantial enough to command that premium.

Second, build abstraction layers between provider pricing and customer pricing. Credit-based pricing systems, consumption units that aggregate multiple provider costs, and value-based pricing models all create distance between what you pay per token and what the customer pays per outcome. The customer never sees a token. They see a credit, a query, a document processed, or an insight generated. The translation layer is where you absorb provider volatility.

Third, maintain provider optionality. If you can serve the same customer workflow with two or three different providers, no single provider has pricing power over you. Multi-provider architecture is not just a technical resilience strategy. It is a pricing strategy.

Fourth, invest in value that is independent of the model provider. Your domain expertise, your evaluation framework, your compliance infrastructure, your customer data — these are assets that do not depreciate when a provider cuts prices. They are what makes your product worth paying for even when the raw API is cheap. The more of your value that lives in these provider-independent assets, the less vulnerable your margin is to provider pricing decisions.

The next subchapter maps the current provider landscape in detail — who charges what, why they price the way they do, and what their pricing strategies signal about where the market is headed.