# 30.2.3 — The Heavy User Problem: When Your Best Customer Is Your Least Profitable

The dashboard looks perfect. Two enterprise customers, both on the same $6,000-per-month plan. Customer A signed eight months ago, expanded from twelve seats to forty, renewed early, and their VP of Operations gave a testimonial for the website. Customer B signed around the same time, uses nine seats, submits a support ticket every few weeks, and has never responded to a case study request. If you asked anyone on the sales team which customer matters more, they would pick Customer A without hesitation. Customer A is the dream account.

Then the per-customer cost-to-serve numbers arrive. Customer B costs $12 per month to serve. Their users log in twice a week, run a handful of straightforward queries, and barely touch the advanced features. Gross margin on Customer B: ninety-nine percent. Customer A costs $380 per month to serve. Except that number was last month's. This month, after their latest workflow expansion, Customer A costs $1,430 to serve — because their forty users have embedded your AI into every step of their operations pipeline, running complex multi-step analyses hundreds of times per day, with long documents, multilingual processing, and human-review escalation on every high-stakes output. Gross margin on Customer A has dropped to seventy-six percent and is falling every quarter as usage intensifies.

Customer A is not unusual. Customer A is the pattern. And the pattern has a name.

## The Inverted Economics of AI Products

The **Heavy User Problem** is the structural reality that in AI products, the customers who love your product the most, use it the most, expand the fastest, and become your best references and case studies are systematically the customers with the worst unit economics. This is not a coincidence. It is a direct consequence of the variable cost structure that distinguishes AI from traditional software.

In traditional SaaS, heavy users and light users cost roughly the same to serve. A Salesforce user who logs in eight hours a day and creates five hundred records costs Salesforce approximately the same in infrastructure as a user who logs in once a week and runs a single report. The cost of a database write is negligible. The cost of rendering a dashboard is negligible. The marginal cost of usage is so close to zero that user behavior has no meaningful impact on unit economics. This is why per-seat pricing works in SaaS — every seat generates approximately the same margin regardless of how intensely the seat is used.

AI inverts this relationship completely. Every query costs real compute. A user who runs three analyses per day triggers three model calls, three retrieval operations, three sets of quality checks. A user who runs two hundred analyses per day triggers two hundred of each. The cost ratio between light and heavy usage is not two to one or three to one. It is ten to one, thirty to one, and in extreme cases a hundred to one. When both users pay the same flat fee, the heavy user's cost is subsidized entirely by the light user's surplus margin.

This creates a perverse dynamic that gets worse as your product succeeds. The better your product works, the more your best customers use it. The more they use it, the more it costs you to serve them. The more it costs, the worse their margin becomes. The worse their margin becomes, the more dependent your aggregate margin is on retaining your light users — the ones who barely use the product and are most likely to churn because they are not getting enough value. You find yourself in a position where the customers you can least afford to lose are the ones generating the least value for you, and the customers generating the most value are the ones you can least afford to keep.

## The Variance Nobody Models

Most financial models for AI companies assume a single average cost-to-serve per customer. The CFO takes total infrastructure cost, divides by customer count, and reports an average. The average might be $800 per month. It sounds manageable. It is also fiction.

The actual distribution of cost-to-serve in AI products follows a pattern closer to a power law than a normal distribution. A small number of customers consume a disproportionate share of total cost. Industry experience across B2B AI companies consistently shows that the top ten percent of customers by usage typically consume forty to sixty percent of total inference and retrieval cost. The bottom fifty percent of customers by usage typically consume five to ten percent of total cost.

The variance ratio — the cost of serving your most expensive customer divided by the cost of serving your cheapest — ranges from ten to one in products with relatively uniform use cases to over a hundred to one in products with diverse workloads. A document analysis tool might see thirty-to-one variance because the workload type is constrained. A general-purpose AI assistant might see a hundred-to-one variance because some users ask simple factual questions and others run multi-hour research workflows with dozens of tool calls.

This variance is not a bug in your customer base. It is a feature of AI products. And it matters enormously for pricing because pricing is ultimately a margin decision. If your pricing assumes uniform cost-to-serve, your margin will be wildly different from what your model predicts the moment your customer base deviates from uniformity — which it will, immediately.

## The Five Drivers of Heavy Usage

Understanding why some customers become heavy users is essential to managing the economics. There are five primary drivers, and each has different implications for your pricing response.

The first driver is **workflow integration depth**. Customers who embed your AI into their operational workflows — connecting it to their CRM, their document management system, their ticketing platform — generate dramatically more queries than customers who use it as a standalone tool. The standalone user opens your application, runs a query, gets an answer, and leaves. The integrated user's systems automatically trigger your AI on every new document, every new ticket, every new record. The query volume is not proportional to the number of humans using the product. It is proportional to the volume of the business process it is connected to. A customer with a hundred thousand documents per month flowing through their management system generates orders of magnitude more AI queries than a customer with a thousand — even if both have the same number of seats.

The second driver is **query complexity**. Not all queries cost the same. A customer in financial services running your AI against complex regulatory filings with a hundred pages each, requiring cross-reference analysis and multilingual handling, generates five to fifteen times the cost per query compared to a customer in marketing using the same tool to summarize one-page briefs. The complexity of the input documents, the depth of the required analysis, and the number of cross-references and validations per query all multiply cost. Two customers can run the same number of queries per month and have a five-to-one cost-to-serve difference based purely on what they are analyzing.

The third driver is **feature breadth**. Most AI products have features with dramatically different cost profiles. The base feature — a single model call with standard context — might cost $0.01 per query. The advanced feature — multi-step analysis with retrieval, validation, and human-in-the-loop review — might cost $0.15 per query. If both features are included in the same subscription tier, the customers who use the expensive features subsidize no one. They are being subsidized by customers who stick to the cheap features. The broader the feature set and the wider the cost range between cheapest and most expensive features, the worse this subsidy effect becomes.

The fourth driver is **context size**. Customers who send large documents or maintain long conversation histories consume dramatically more tokens per interaction. A user who sends a two-page document and asks for a summary might use 2,000 input tokens. A user who sends a two-hundred-page contract and asks for a clause-by-clause risk analysis might use 200,000 input tokens. The hundred-to-one difference in input size translates to a roughly proportional difference in cost — and both users might be on the same plan.

The fifth driver is **output demands**. Some customers need short, structured outputs — a risk score, a classification, a yes-or-no answer. Others need detailed, narrative outputs — a full analysis report, a drafted response, a comprehensive summary with supporting evidence. Output token costs are typically two to five times higher than input token costs per token at the API level. A customer who consistently requires long, detailed outputs can cost three to five times more per query than a customer who needs only brief structured responses, even with identical input.

## The Margin Erosion Timeline

The Heavy User Problem does not announce itself. It follows a predictable timeline that catches teams by surprise precisely because each stage looks like good news.

In the first stage — months one through three after a large customer signs — usage ramps gradually. The customer deploys to a pilot team. Query volumes are moderate. Cost-to-serve is reasonable. Margin looks healthy. Everyone is happy.

In the second stage — months four through eight — the customer expands. The pilot succeeded, and now more teams adopt the product. Usage accelerates. The customer also discovers advanced features and begins using them regularly. Cost-to-serve doubles or triples compared to the pilot period. But revenue also grows because the customer expands their contract, so the absolute margin might still look positive.

In the third stage — months nine through fourteen — the customer integrates. They connect your product to their internal systems. Usage shifts from human-initiated to system-initiated. Query volumes increase by five to twenty times. Cost-to-serve jumps proportionally. But the contract value does not jump proportionally, because the contract was negotiated based on seat count or a flat platform fee, not usage volume. Margin turns negative. The engineering team may not notice because they are tracking total cost, not per-customer cost.

In the fourth stage — months fifteen through twenty — the customer is deeply embedded, highly satisfied, and expanding further. They are your largest account, your best case study, and your most expensive liability. The sales team is pursuing similar accounts because the pattern looks like success. Each new account accelerates the margin erosion. The CEO sees growing revenue and assumes the business is scaling. The CFO sees growing costs and cannot explain why margins are compressing. The connection between the two is invisible without per-customer attribution.

This is the timeline that played out in Section 30.1.1. It is not theoretical. It is the default trajectory of every AI company that prices on flat rates and attracts enterprise customers who deeply adopt the product.

## The Emotional Trap

The Heavy User Problem is partly an economic problem and partly an emotional one. The heavy users are not nameless accounts on a spreadsheet. They are the customer whose VP called you personally to say the product transformed their team. They are the account that agreed to do a joint webinar. They are the logo on your website that makes prospects take you seriously. They are the reference call that closed your last three enterprise deals.

Telling the sales team that this customer needs to be repriced, or limited, or managed differently triggers a visceral reaction. "We can't raise prices on our best customer. They'll leave. They'll tell everyone. We'll lose the reference." This emotional resistance is the reason the Heavy User Problem persists long after the numbers make the situation obvious. The people who see the cost data do not own the customer relationship. The people who own the customer relationship do not see the cost data. And even when they do see it, the short-term risk of upsetting a happy customer feels more real than the long-term risk of margin erosion.

The companies that manage this well bring the customer success team and the finance team into the same room. They make per-customer margin a shared metric. They reframe the conversation from "we need to charge this customer more" to "we need to make sure this customer is on a plan that reflects the value they are getting and the resources they are consuming, so we can continue investing in the product they depend on." The reframe matters because it is true. A customer who destroys your margin is not a customer you can serve well over a multi-year relationship. Eventually the math catches up, and either the product degrades because you underinvest, or the customer gets repriced reactively instead of proactively.

## Five Responses to the Heavy User Problem

There is no single correct response to the Heavy User Problem. The right approach depends on your market, your competitive position, your customer relationships, and your cost structure. But there are five established strategies, each with distinct trade-offs.

The first strategy is **usage-based pricing components**. You move from a flat fee to a pricing structure that includes a variable component tied to usage. This might be a per-query fee, a per-document fee, a per-token fee, or a per-resolution fee. The variable component ensures that cost-to-serve and revenue scale together. The trade-off: usage-based pricing creates purchase friction. Customers who cannot predict their bill feel anxious. They may self-limit usage, which reduces the product's value and increases the risk of churn. Usage-based models work well when the value per unit is clear — a per-resolved-ticket model like Intercom's Fin AI works because each resolved ticket has visible value. They work poorly when the value per unit is ambiguous — a per-query model on a general research tool feels punitive because the user cannot evaluate in advance whether a query will be worth its cost.

The second strategy is **tiered usage allocations**. You keep the flat subscription but include a defined usage allocation — five hundred queries per month, fifty document analyses, ten hours of agent time. Usage beyond the allocation triggers overage charges. This preserves the predictability of flat pricing while creating a natural ceiling on the subsidy for heavy users. The trade-off: you must set the allocation at a level that covers your median customer's usage without feeling restrictive. Set it too low and most customers feel limited. Set it too high and the allocation does not bind the heavy users who are actually causing the problem. The allocation must be calibrated against your actual usage distribution, not your intuition about what feels generous.

The third strategy is **premium tiers for power users**. You create a pricing tier specifically designed for heavy-use patterns — more features, faster processing, higher priority, dedicated infrastructure — at a price that covers the elevated cost-to-serve. The premium tier is positioned as an upgrade, not a penalty. Customers who need advanced features and heavy usage self-select into the tier that matches their consumption. The trade-off: you must build real value differentiation into the premium tier beyond just "more usage." If the premium tier is perceived as "the same product but we charge you more because you use it a lot," customers will resent it. If the premium tier includes genuinely better capabilities — faster models, custom fine-tuning, dedicated support, priority processing — customers perceive it as a better product worth a higher price.

The fourth strategy is **account-level repricing**. For your most extreme heavy users, you renegotiate the contract directly. This is a relationship-intensive approach that works when you have a small number of identifiable heavy users and strong account management. You share the cost data transparently — "your usage pattern costs us X to serve, and your current contract covers Y" — and negotiate a new agreement that works for both sides. The trade-off: this is high-touch and does not scale. It works for your top ten accounts. It does not work for your top five hundred. And it requires a level of cost transparency that some companies are uncomfortable with, even though the transparency typically strengthens the relationship rather than weakening it.

The fifth strategy is **architectural cost reduction for heavy users**. Instead of changing the price, you change the cost. You build customer-specific optimizations — aggressive caching for their most common queries, model routing that sends their simpler requests to cheaper models, pre-computed results for their recurring analysis patterns. This preserves the customer relationship and the contract value while improving the margin. The trade-off: engineering effort is not free. Building customer-specific optimizations is an investment that only pays off for customers whose cost-to-serve is high enough to justify the engineering time. For a customer costing you $14,000 per month, a two-week engineering sprint that cuts their cost by fifty percent pays for itself in a month. For a customer costing you $300 per month, the same sprint never pays back.

## Choosing the Right Response

In practice, most AI companies deploy a combination of these strategies simultaneously, segmented by customer type.

For the broad customer base — hundreds or thousands of accounts — tiered usage allocations or usage-based components provide structural alignment between cost and revenue. These are pricing-level solutions that scale without per-customer effort.

For the top ten to twenty accounts by cost — the ones who individually move the needle on your margin — account-level repricing and architectural optimization provide targeted solutions. These are relationship-level and engineering-level responses that require per-customer effort but generate outsized margin improvement.

For new customer segments or verticals — where you do not yet know the usage pattern — premium tiers with built-in usage allocations provide a safety net. If the new segment turns out to include heavy users, the tier structure ensures they land on a plan that covers their cost from day one.

The worst response is no response. Ignoring the Heavy User Problem because the aggregate margin looks acceptable is how companies end up in the position described in Section 30.1.1 — discovering eighteen months later that their best customers have been quietly destroying their margins while their finance team watched a blended number that hid the damage.

## Monitoring the Distribution

The Heavy User Problem is not a problem you solve once. Usage patterns shift. Customers adopt new features. Workflow integrations deepen. A customer who was cheap to serve six months ago may become expensive after they integrate your product into a new business process. A customer who was expensive may become cheaper after you deploy caching or model routing optimizations.

The metric to watch is not the average cost-to-serve. It is the distribution. Track the ratio between your ninetieth-percentile customer cost and your median customer cost. In a healthy AI business, this ratio should be below ten to one. If it exceeds twenty to one, your pricing structure is almost certainly subsidizing heavy users with light user margins. Track the percentage of customers whose cost-to-serve exceeds their revenue contribution. In a healthy business, this should be below five percent. If it exceeds fifteen percent, you have a structural pricing problem that aggregate margin numbers are masking.

Run these distribution checks monthly. Share them with the pricing team, the sales team, and the customer success team. Make per-customer margin a first-class metric alongside revenue and retention. The companies that treat per-customer margin as a shared operating metric are the companies that catch the Heavy User Problem before it compounds into a margin crisis.

Understanding the Heavy User Problem and the cost-to-serve distribution are prerequisites for the next step: engineering your margins higher without raising prices. That means caching, routing, architecture optimization, and the full toolkit of gross margin engineering — the discipline that moves your product from fifty-percent margins toward seventy without asking a single customer to pay more.