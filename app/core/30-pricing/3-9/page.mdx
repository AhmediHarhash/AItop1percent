# 30.3.9 — Price Points and Anchoring: What to Charge When Nobody Knows What AI Is Worth

The sales call is going well. The prospect has seen the demo, asked technical questions, nodded at the right moments, and said the words every founder wants to hear: "This looks like exactly what we need. What does it cost?" The founder freezes. Not because she does not have a number. She has twelve numbers. She has a spreadsheet with cost-plus models, competitor comparisons, value-based projections, and a pricing tier she redesigned last Tuesday. The problem is not that she lacks a price. The problem is that she has no confidence in any of them — because no one in the market has established what this category of product should cost. There is no benchmark. There is no "industry standard." There is no anchor. And without an anchor, every price feels simultaneously too high and too low.

This is the defining pricing challenge of AI products in 2026. Traditional software categories have decades of pricing context. Everyone knows roughly what a CRM costs per seat, what an email marketing tool charges per contact, what a project management platform runs per user per month. Buyers have mental anchors. Sellers have competitive reference points. The negotiation happens within an understood range. AI products operate in a vacuum. The buyer has never purchased this kind of tool before. The seller has never sold against this kind of product before. Both sides are guessing, and the side that guesses with more confidence sets the terms.

## The Pricing Vacuum and Why It Exists

The **pricing vacuum** in AI is not just about novelty. It exists because AI products violate the three conditions that normally create market pricing norms.

The first condition is comparable alternatives. In established software categories, pricing norms emerge from years of competition. When twenty CRM vendors charge between $50 and $150 per seat per month, the twenty-first vendor entering the market has a reference range. AI products often have no direct software predecessors. A contract review AI does not replace another contract review AI. It replaces a team of junior associates. A customer support AI does not replace another support AI. It replaces a call center. The "alternative" is a completely different cost structure — labor, not software — which makes traditional competitive pricing analysis nearly useless.

The second condition is transparent pricing pages. Established software companies publish their pricing. You can visit twenty competitor websites and map the landscape in an afternoon. AI companies in 2026 disproportionately use "contact us" pricing because they themselves are not sure what to charge. When Bessemer Venture Partners analyzed AI company pricing in 2025, they found that the majority of enterprise AI vendors did not publish prices at all. The result is that buyers cannot comparison-shop and sellers cannot benchmark. Everyone is negotiating in the dark.

The third condition is stable cost structures. Traditional software pricing stabilizes because the cost-to-serve stabilizes. A SaaS company that has been operating for five years knows its infrastructure cost per customer with precision. AI companies face model pricing that changes quarterly, inference cost reductions that drop thirty to fifty percent year over year, and new model releases that can cut the cost of a query by half overnight. When your input costs are volatile, your pricing confidence is volatile. You hesitate to commit to a number because the economics underneath it might change dramatically in six months.

## The Four Anchoring Strategies

When no external anchor exists, you create one. The discipline is called **price anchoring**, and it means deliberately establishing a reference point that makes your price feel reasonable, justified, and — ideally — like a bargain. There are four anchoring strategies that work for AI products, and most successful companies use at least two of them simultaneously.

**Anchor against the human cost.** This is the most powerful anchor available to most AI products, and it works because it translates an unfamiliar purchase into a familiar one. The buyer may never have purchased an AI product before, but they have definitely hired people. When you can show that the human alternative costs $8 per customer support ticket and your AI resolves tickets for $0.99 each, the anchor is immediate and visceral. The buyer does not need to evaluate whether $0.99 is a fair price for AI. They need to evaluate whether saving $7.01 per ticket is worth it. The answer is obviously yes, and the negotiation is over before it starts.

The human-cost anchor works across every AI product category that displaces labor. Contract review: a junior associate costs $90 per hour and reviews four contracts per hour, so each review costs roughly $22.50. Your AI reviews a contract for $3.50. The anchor is $22.50, and every price below it feels like savings. Data entry: a full-time data entry clerk at $45,000 per year processes roughly 200 records per day. That is approximately $0.90 per record. Your AI processes records for $0.06 each. The anchor is $0.90. Content moderation: a human moderator reviews 500 posts per eight-hour shift at a loaded cost of $280 per day. That is $0.56 per review. Your AI moderates for $0.03 per post. The anchor is $0.56.

The key is specificity. Do not say "our AI saves you money compared to hiring people." Calculate the exact per-unit cost of the human alternative in the buyer's specific context, and present your price as a percentage of that number. "Your team spends $22.50 per contract review. Our product delivers the same review for $3.50, which is eighty-four percent less." The precision of the comparison eliminates the pricing vacuum. The buyer now has a reference point, and every conversation about price happens relative to that reference point rather than in a void.

## Anchor Against Raw API Cost

The second strategy works for products built on top of foundation models — which, in 2026, is most AI products. Your buyer is not naive. They know that you are calling GPT-5, Claude Opus 4.6, Gemini 3 Pro, or another model behind the scenes. Some of them have tested the raw API themselves. They have a rough sense of what a model call costs. If your product charges $2 per document analysis and the buyer knows the raw API call costs $0.08, they will ask the obvious question: "Why am I paying twenty-five times the API cost?"

Instead of avoiding this question, anchor against it. Make the gap between raw API cost and your product's price the centerpiece of your value story. "Yes, the raw model call costs $0.08. But the raw model call does not know your data schema. It does not validate outputs against your compliance requirements. It does not integrate with your document management system. It does not provide the retrieval pipeline that connects the model to your knowledge base. It does not run the evaluation layer that catches errors before they reach your team. It does not include the monitoring, the audit trail, the access controls, or the support. The $0.08 buys you a prediction. The $2 buys you a production-grade system."

This anchor works because it reframes the price conversation from "is this product worth $2?" to "is everything this product does beyond the raw API worth $1.92?" When you enumerate the layers of value — retrieval, evaluation, integration, compliance, support, reliability — the $1.92 stops looking like a markup and starts looking like a bargain. The buyer who tried to build on the raw API and failed recognizes the value immediately. The buyer who has not tried yet now understands why they should not.

The API anchor also establishes a floor. If a competitor claims to offer the same capability for $0.50, the buyer can reason about it: the raw API costs $0.08, so the competitor's margin on the model call alone is limited. Either they are cutting corners on the layers that matter — evaluation, monitoring, compliance — or they are subsidizing the price with venture capital. Neither scenario should make the buyer comfortable. Your $2 price, anchored transparently against the API cost, tells a story about sustainable economics that a $0.50 price cannot.

## Anchor Against Competitor Pricing

The third strategy is the most familiar and the least useful in AI — but it still matters. When competitors exist, their pricing creates reference points whether you want them to or not. If three competitors charge $15,000 to $25,000 per year for a similar product, your price exists relative to that range regardless of your cost structure or value proposition.

The challenge in AI is that "similar product" is slippery. Your AI contract review tool might compete against other AI contract review tools, against traditional document automation software, against legal process outsourcing firms, and against hiring more associates. Each competitor type operates at a completely different price point. Other AI tools might charge $20,000 per year. Document automation software might charge $50,000 per year. Legal outsourcing might cost $200,000 per year. More associates might cost $400,000 per year. Depending on which competitor you anchor against, your "reasonable" price ranges from $15,000 to $300,000.

The strategic choice is which competitor frame you anchor against. If you anchor against other AI tools, you are in a $15,000 to $30,000 fight where differentiation is hard and margins are thin. If you anchor against the labor cost or the outsourcing cost, you are in a $100,000 to $250,000 conversation where your price is obviously compelling. Choose the anchor that puts your product in the most favorable light. You are not lying about the competition — all these alternatives genuinely exist. You are choosing which alternative the buyer should be comparing you to. The sales team that frames the conversation as "compared to other AI tools" and the sales team that frames it as "compared to your current outsourcing spend" are selling the same product at wildly different prices, and both are defensible.

## Anchor Against ROI

The fourth strategy is the most powerful and the hardest to execute. When you can quantify the return on investment your product delivers, the price becomes a fraction of the return rather than a number to be evaluated in isolation.

The ROI anchor works by shifting the buyer's question. Without an ROI anchor, the buyer asks: "Is $100,000 per year a fair price for this AI product?" That is a hard question with no clear answer. With an ROI anchor, the buyer asks: "Is it worth spending $100,000 per year to save $500,000 per year?" That question answers itself.

The structure is straightforward. Calculate the customer's current cost of the process your AI automates or improves. Measure or project the improvement your product delivers. Multiply the improvement by the cost to get the annual value. Price at a fraction of that value. If the customer spends $800,000 per year on customer support and your AI reduces support costs by sixty percent, the annual value is $480,000. Pricing at $100,000 per year captures about twenty percent of the value and gives the customer a return of nearly five to one on their investment. Most enterprise buyers will approve a purchase with a three-to-one return without extensive negotiation. A five-to-one return accelerates the deal.

The difficulty is in the measurement. As discussed in subchapter 30.1.9, proving value in AI is one of the hardest problems in the industry. The companies that execute ROI anchoring successfully invest heavily in pilot measurement, baseline documentation, and ongoing value tracking. They do not hand-wave about value. They build calculators with the customer's actual numbers. They run structured pilots that measure the before and after. They instrument the product to show real-time value delivered. Every dollar of investment in value measurement infrastructure pays for itself many times over in pricing power, because the ROI anchor is the only anchor that lets you capture twenty to thirty percent of the value you create instead of five to ten percent.

## The Ten-to-Thirty Percent Rule

Across industries and product categories, a pattern emerges in value-based pricing: the sustainable capture rate — the percentage of customer value you can charge without triggering buyer resistance — falls between ten and thirty percent. Below ten percent, you are leaving too much money on the table. Above thirty percent, buyers start to question whether the value is real or whether they should build the capability in-house.

The exact percentage within that range depends on three factors.

The first factor is **switching cost**. If your product is deeply integrated into the customer's workflows and switching to an alternative would take months of engineering work, you can price toward the upper end of the range — twenty-five to thirty percent of value — because the buyer's alternative to paying is painful. If your product is a lightweight layer that could be replaced in a week, you must price toward the lower end — ten to fifteen percent — because the buyer always has the option to walk away.

The second factor is **proof quality**. If you can demonstrate the value with the customer's own data, in their own environment, measured by their own metrics, you can price higher within the range. Production-validated value proof, as described in the Five Levels of Value Proof from subchapter 30.1.9, supports twenty to twenty-five percent capture. Vendor-estimated value proof supports only five to ten percent. The quality of your proof directly determines how much value you are allowed to capture.

The third factor is **competitive intensity**. In a market with five credible alternatives, price pressure pushes you toward the lower end of the range regardless of switching cost and proof quality. In a market where you are the only production-grade solution, the upper end is available. Market structure matters because even buyers who believe in your value will negotiate harder when they know they have options.

For most AI products in 2026, the practical range is fifteen to twenty-five percent of demonstrated value. Products with strong proof, deep integration, and limited competition can sustain twenty-five to thirty percent. Products with weak proof, shallow integration, and heavy competition operate at ten to fifteen percent.

## The Price-Setting Exercise

If you have never set a price for an AI product before, here is the practical exercise. It takes two hours and produces a defensible initial price point.

Step one: calculate your cost floor. Take your fully loaded cost-to-serve per customer — model inference, retrieval, evaluation, monitoring, support, and infrastructure allocation — and add a minimum margin of sixty percent. If your cost-to-serve is $2,000 per month, your cost floor is $5,000 per month. You will never price below this number because doing so means selling at a loss after operating expenses.

Step two: calculate your value ceiling. Identify the customer's current cost of the process your product addresses. If the customer spends $40,000 per month on the function your AI improves, and your product delivers a fifty percent improvement, the annual value is $240,000. Apply a thirty percent capture rate to get your value ceiling: $72,000 per year, or $6,000 per month. This is the maximum you can charge without the buyer questioning whether they should build instead of buy.

Step three: plot the range. Your price lives between $5,000 per month (cost floor) and $6,000 per month (value ceiling). If the range is narrow, as in this example, your pricing is relatively constrained and the key decision is where within the range to land. If the cost floor is $5,000 and the value ceiling is $20,000, you have significant room and the key decision is what level of value proof justifies which price point.

Step four: apply anchoring. Choose two of the four anchoring strategies that work best for your product and buyer persona. If you are selling to an operations leader, anchor against the human cost. If you are selling to a technical leader who has evaluated the raw API, anchor against API cost and show the value of your platform layers. If you are competing in a crowded category, anchor against competitors and differentiate on proof quality.

Step five: test the price. Bessemer Venture Partners popularized a pragmatic litmus test: propose your price to a prospect. If they say "sold" immediately, you are too cheap — raise the number by twenty percent and test again. If they say "we need to think about it," you are in the right zone. If they say "that is outside our budget," you are either too high or selling to the wrong buyer. Iterate through five to ten conversations and the market will tell you where the number belongs.

## The Decoy Price Strategy

One advanced anchoring technique is particularly effective for AI products: the **decoy price**. You present three options to the buyer — not because you want them to choose all three, but because the presence of the third option makes the second option look like the obvious choice.

The structure works as follows. Your low tier offers the basic AI capability at a price that covers cost with minimal margin — say $3,000 per month. Your mid tier adds the evaluation layer, the compliance features, and priority support at $7,500 per month. Your high tier adds custom model tuning, dedicated infrastructure, and a named account manager at $18,000 per month. Most buyers will choose the mid tier. The low tier feels too limited — "we need the compliance features." The high tier feels excessive — "we don't need custom model tuning yet." The mid tier feels just right. It is the Goldilocks option.

The insight is that the mid tier looks like a bargain only because the high tier exists. Without the $18,000 option, the $7,500 option would be evaluated on its own merits — and the buyer might negotiate it down to $5,000. With the $18,000 option on the table, the $7,500 option is already perceived as the reasonable choice. The high tier does double duty: it anchors the mid tier and it captures the genuine enterprise buyers who need the premium features. Every option earns its place. None of them exist solely as a decoy. But the presence of three options changes the psychology of the decision in ways that a single price never can.

## Anchoring Mistakes That Destroy Deals

Three anchoring mistakes consistently kill AI pricing conversations.

The first mistake is **anchoring against your own cost**. When you tell a buyer, "It costs us $2,000 per month to serve your account, so we charge $5,000," you have just told them your margin. They will spend the rest of the negotiation trying to squeeze it. Your cost structure is internal information. The anchors you present should be external: the human alternative, the API cost, the competitor pricing, the ROI. Never make your own cost the anchor.

The second mistake is **anchoring too low to win the deal**. The first price you name becomes the anchor for the entire relationship. If you start at $3,000 to make the sale easy, every future conversation about expansion, renewal, or repricing starts from $3,000. Your sales team will hear "but we started at $3,000" for years. It is much easier to start at $7,500 and negotiate down to $6,000 than to start at $3,000 and try to negotiate up to $6,000. The initial price sets the ceiling for the relationship, not the floor.

The third mistake is **failing to anchor at all**. When you present a price without any reference frame — "our product costs $7,500 per month" — you force the buyer to find their own anchor. They might anchor against the cheapest competitor. They might anchor against zero, since they do not currently pay for this capability. They might anchor against what they pay for other SaaS tools that cost a fraction of an AI product. Every self-generated anchor will be lower than the anchors you would have chosen. Control the reference frame, or the buyer will choose one that works against you.

## When Anchoring Is Not Enough

Anchoring sets the reference frame. It does not close the deal. The anchors get you into the right conversation, but the conversation itself requires something that no anchoring strategy can replace: the buyer's belief that your product will actually deliver the value you are describing. If the buyer does not trust the ROI projection, the human-cost comparison does not matter. If the buyer suspects your product will not work in their environment, the API-cost anchor is irrelevant.

This is why the pricing conversation and the value proof conversation are inseparable. The best price in the world, anchored against the perfect reference point, falls apart if the buyer asks "but will it actually work for us?" and you do not have a convincing answer. Pilots, case studies, production metrics, and customer references are not marketing collateral. They are pricing infrastructure. Every proof point you accumulate makes your anchoring strategy more effective, because anchors only hold when the buyer believes the underlying claim.

Setting the right price is hard enough when you get it right the first time. But what happens when you get it wrong — or when the market shifts, your costs change, and the price that made sense a year ago is clearly wrong today? Changing your pricing model after customers are already paying is one of the most dangerous business operations in AI, and it is the subject of the next subchapter.