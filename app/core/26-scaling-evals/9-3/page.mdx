# 9.3 — Drift Detection Across Hundreds of Eval Dimensions

In late 2025, a B2B software company running an AI customer support agent noticed a troubling pattern: customer satisfaction scores were declining steadily, but the eval dashboard was clean. Forty-seven evaluation dimensions — relevance, accuracy, tone, completeness, safety, formatting, and dozens of domain-specific criteria — all showed scores within acceptable ranges. Every single dimension was green. The team spent three weeks investigating the production model, the retrieval pipeline, and the prompt architecture before an engineer finally ran a correlation analysis across the eval dimensions. The finding: three dimensions — response specificity, follow-up question handling, and technical depth — had each drifted downward by four to five points over the previous two months. Each individual drift was within the per-dimension alert threshold of six points. But the three dimensions were correlated — they all degraded together because the same underlying cause, a shift in customer query complexity, affected all three. The combined effect on user experience was significant. The per-dimension monitoring was correct. The system-level picture was wrong.

## Why Multi-Dimension Drift Is Harder

Single-dimension monitoring is a solved problem. You track a metric over time, set a threshold, and alert when the threshold is breached. The statistics are straightforward — standard deviations, control charts, trend lines. Every monitoring textbook covers this, and every observability platform supports it.

Multi-dimension drift is fundamentally different. When you monitor forty or a hundred evaluation dimensions simultaneously, the question is no longer "did this metric change?" but "did the overall quality profile change?" Those are different questions with different answers. A system where twelve dimensions each drift two points in the same direction has experienced a meaningful quality shift, even though no single dimension would trigger an alert. A system where one dimension drops six points while another improves six points may have experienced no net quality change at all, despite triggering an alert on the first dimension.

The mathematical challenge is real. With fifty independent dimensions each monitored at a 95% confidence level, you expect roughly 2.5 false alerts per monitoring cycle just from random fluctuation. With a hundred dimensions, you expect five. At scale, the noise from per-dimension monitoring overwhelms the signal. Teams either raise thresholds until the alerts stop — which also suppresses real alerts — or they accept the noise and stop investigating, which defeats the purpose of monitoring entirely.

## Correlated Dimensions and Shared Causes

The B2B company's experience illustrates the core challenge: evaluation dimensions are not independent. They share underlying causes. When user queries shift in complexity, multiple quality dimensions respond simultaneously — the model's ability to handle specificity, follow-up questions, and technical depth all draw on the same underlying capability. When a retrieval pipeline degrades, relevance, accuracy, and completeness all suffer because they all depend on the retrieved context being correct.

**Correlated drift** is when multiple dimensions move in the same direction due to a shared cause. Detecting correlated drift requires monitoring the relationships between dimensions, not just the dimensions themselves. Two approaches work in practice. The first is pairwise correlation tracking: compute the correlation between every pair of eval dimensions over a rolling window and alert when correlations that are normally weak become strong, which signals a shared perturbation affecting multiple dimensions simultaneously. The second is principal component analysis applied to the eval score matrix: reduce the high-dimensional eval data to a few principal components and monitor those components for drift. A shift in the first principal component means the dominant pattern across all dimensions has changed — even if no single dimension moved enough to trigger its own alert.

Both approaches have a prerequisite that most teams overlook: you need a baseline period where you know the system was healthy. The correlation structure and principal components during that baseline become your reference. Drift is measured relative to that reference. Without it, you are monitoring movement without knowing what "normal" looks like.

## Composite Health Scores

A **composite health score** reduces the state of all eval dimensions into a single number that represents overall system health. This is not the same as averaging all dimension scores — a simple average can hide compensating movements where some dimensions improve while others degrade. A well-designed composite score accounts for dimension importance, dimension correlation, and the direction and magnitude of change.

One effective approach is the weighted z-score composite. For each dimension, compute how many standard deviations the current value is from its historical mean. Weight each z-score by the dimension's business importance — safety dimensions weighted heavily, formatting dimensions weighted lightly. Sum the weighted z-scores. The composite score tells you not just whether quality has changed, but how much it has changed relative to normal variability, weighted by what matters most to your business.

The composite score serves a different purpose than per-dimension monitoring. Per-dimension monitoring tells you which specific aspect of quality changed. The composite score tells you whether overall quality health requires attention, even when no individual dimension has crossed its threshold. Think of it as a vital sign — a patient can have every individual measurement in the normal range and still be clinically deteriorating if the combination of slightly-off values tells a story that no single value tells alone.

Set the composite threshold empirically. Run the composite score calculation over historical data that includes known good periods and known bad periods. Find the composite score values that reliably separate the two. That threshold becomes your alert trigger. Recalibrate quarterly, because the relationship between eval dimensions and actual quality outcomes changes as your system evolves.

## Detecting Slow Drift Versus Sudden Shifts

Slow drift and sudden shifts require different detection methods, and conflating them causes either missed detections or excessive false alerts.

Sudden shifts happen within a single measurement period — a new model deployment, a judge model update, a configuration change. For detection, standard change-point detection works well: compare the distribution of scores in the current window to the distribution in the previous window using a statistical test. If the distributions differ significantly, a shift occurred. The alerting response is immediate investigation, because sudden shifts typically have identifiable causes that can be confirmed or rolled back quickly.

Slow drift accumulates over weeks or months — a gradual change in production traffic composition, a slow shift in user behavior, a creeping degradation in retrieval quality. For detection, trend analysis over a longer window is required. Compute the slope of each dimension over a rolling thirty-day or sixty-day window. Alert when the slope exceeds a threshold that, if continued, would bring the dimension below its minimum acceptable level within a defined horizon. This is predictive alerting — you are not alerting because a threshold was breached, but because the trajectory suggests a breach is coming if the trend continues.

The most dangerous scenario is slow drift across multiple correlated dimensions. Each individual dimension is drifting slowly enough to stay below the trend alert threshold, but the correlated movement means the composite impact on quality is accumulating faster than any single dimension suggests. This is why the composite health score is essential — it aggregates the signals that individual monitors miss.

## Setting Thresholds Across Many Dimensions

The threshold-setting problem scales poorly. Setting one alert threshold is a judgment call. Setting a hundred alert thresholds is a research project. Most teams take the shortcut of applying the same threshold everywhere — alert if any dimension moves more than five points — and then spend the next year adjusting individual thresholds in response to either too many false alerts or too many missed detections.

A better approach is to set thresholds based on historical variability per dimension. Dimensions that naturally fluctuate a lot — subjective quality scores, tone ratings, creativity assessments — need wider thresholds. Dimensions that are normally very stable — safety compliance, format adherence, factual accuracy — should have tighter thresholds because any movement is more likely to be real. Using two standard deviations of historical variability as the threshold for each dimension automatically calibrates for the dimension's natural noise level.

Layer this with the business impact of each dimension. A five-point drop in a formatting score is operationally meaningless. A five-point drop in a safety score is a potential crisis. Threshold tightness should reflect not just statistical significance but business consequence. Safety dimensions get thresholds at 1.5 standard deviations. Quality dimensions get thresholds at 2 standard deviations. Cosmetic dimensions get thresholds at 3 standard deviations. The tighter the threshold, the more false alerts you accept — but for safety-critical dimensions, a false alert is vastly preferable to a missed detection.

## The Dimensionality Tax

Every new eval dimension you add creates monitoring obligations: a new threshold to set, a new baseline to establish, new correlations to track, new space in the composite score calculation. Teams that add dimensions freely without considering the monitoring burden end up with an eval system they cannot effectively observe. Forty-seven dimensions become seventy, then a hundred and twenty, and the monitoring system that worked at forty-seven collapses under the weight of cross-dimensional analysis at one hundred and twenty.

**The Dimensionality Tax** is the operational cost of monitoring each additional eval dimension. It includes the computational cost of running cross-correlation analysis, the human cost of investigating alerts from the new dimension, and the cognitive cost of interpreting dashboards with one more signal among many. Before adding a new eval dimension, ask whether the monitoring infrastructure can absorb it. If adding a dimension means nobody will effectively monitor it, the dimension adds noise without signal.

The practical ceiling for most teams is somewhere between fifty and eighty actively monitored dimensions. Beyond that, composite scores, automated correlation analysis, and hierarchical grouping become mandatory — per-dimension human monitoring simply does not scale further.

When drift detection identifies a real problem, it generates an alert. But across dozens of dimensions, hundreds of model variants, and thousands of daily evaluations, alerts multiply faster than any team can investigate them. The next subchapter addresses the alert fatigue problem and why most teams end up ignoring the signals that matter most.
