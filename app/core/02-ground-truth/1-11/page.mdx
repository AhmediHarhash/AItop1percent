# 1.11 — Temporal Validity: True as of Date X

Let me tell you about a perfectly accurate AI system that cost a company real money because nobody thought about time.

They built a RAG system for customer support. It pulled information from their knowledge base and answered customer questions. The system was brilliant—98% retrieval accuracy, properly cited sources, clear responses. They launched it.

Three months later, the company updated their pricing. The knowledge base was updated. The RAG system kept citing the documentation... but it was pulling from cached embeddings that still referenced old prices. For two weeks, the bot quoted prices that were $20/month lower than actual pricing.

Customers saw the quoted price, decided to buy, went to checkout, saw the real price, felt deceived, and abandoned. The company lost an estimated $40,000 in revenue from abandoned carts, plus damaged trust.

Every single piece of information the bot gave was accurate—accurate as of three months ago. The system had no concept of temporal validity. Truth has an expiration date.

## The Freshness Problem

Information decays. What's true today becomes false tomorrow.

Some information decays instantly:
- Stock prices (changes second-to-second)
- Sports scores during a game
- Breaking news
- Real-time inventory
- Current weather

Some information decays daily:
- Today's date (obvious but systems get this wrong)
- Event schedules
- Limited-time offers
- Daily metrics or reports

Some information decays weekly or monthly:
- Product availability
- Staff schedules
- Promotional pricing
- Blog or news content

Some information decays quarterly or annually:
- Business strategy
- Regulations
- Product roadmaps
- Market positioning

And some information is relatively stable:
- Historical facts
- Physical laws
- Core product features
- Company founding story

Your ground truth must account for decay rates. Not all information ages at the same speed.

## The "True as of" Pattern

Elite teams timestamp their truth. Every piece of information in their knowledge base has a "true as of" date.

Product pricing: True as of March 1, 2026
Return policy: True as of January 15, 2026
Feature availability: True as of February 10, 2026

When the system retrieves information, it checks: is this still fresh according to its decay rate?

If pricing has a decay rate of "quarterly updates," information from four months ago is stale. If historical information has a decay rate of "stable unless major discovery," information from years ago might still be fine.

The pattern looks like this:

Content metadata:
- Last verified date: when this information was last confirmed accurate
- Typical update frequency: how often this type of information usually changes
- Freshness requirement: how old can this information be before it's considered stale
- Next review date: when this should be manually reviewed

When retrieving information, the system checks:
"Current date - last verified date > freshness requirement? If yes, flag as potentially stale."

This prevents serving outdated information confidently.

## The Types of Temporal Truth

Let me break down the categories of temporal validity:

Type 1: Point-in-time truth
"The temperature right now is 72 degrees."
True for maybe 10 minutes. Useless an hour later.

Type 2: Valid-for-period truth
"This coupon code works through March 31, 2026."
True during the specified period, false before and after.

Type 3: True-until-changed truth
"Our CEO is Jane Smith."
True indefinitely until it changes (could be years, could be tomorrow).

Type 4: Versioned truth
"In version 2.3, the Export button is in the File menu."
True for that version, might be different in other versions.

Type 5: Historical truth
"The company was founded in 2018."
True permanently (barring historical revision).

Your ground truth should categorize information by temporal type and handle each appropriately.

## The Decay Rate Taxonomy

Different content types have different decay rates. Document them:

Real-time (decay in seconds to minutes):
- Stock prices, sports scores, auction bids
- Freshness requirement: < 1 minute

Daily (decay within 24 hours):
- News, daily deals, today's schedule
- Freshness requirement: < 1 day

Weekly (decay within a week):
- Event calendars, promotional content, blog posts
- Freshness requirement: < 7 days

Monthly (decay within a month):
- Product availability, staff rosters, some policies
- Freshness requirement: < 30 days

Quarterly (decay within 3 months):
- Pricing, roadmaps, quarterly reports
- Freshness requirement: < 90 days

Annually (decay within a year):
- Regulations, strategic plans, market data
- Freshness requirement: < 365 days

Stable (rarely decays):
- Historical facts, core company info, physical laws
- Freshness requirement: manual review only

Map your content to these categories and enforce freshness requirements.

## The Stale Truth Detection

How do you detect when truth has gone stale?

Approach 1: Timestamp tracking
Every document has "last updated" metadata. System checks age against freshness requirement.

Approach 2: Change detection
System monitors source documents for changes. When a pricing page updates, flag all content derived from it as needing refresh.

Approach 3: Scheduled review
Content owners review their domains on fixed schedules. Pricing team reviews monthly. Legal reviews quarterly.

Approach 4: Usage-triggered validation
When high-value or high-risk queries access old information, trigger manual review. "This information is 6 months old and you're quoting it to a customer—are you sure it's still accurate?"

Approach 5: Contradiction detection
If newer information contradicts older information in your knowledge base, flag both for review.

Elite teams use all five approaches in combination.

## The RAG Freshness Challenge

RAG systems have a specific freshness problem: embedding staleness.

You embed your knowledge base. The embeddings represent the content at that point in time. Content changes. Embeddings don't update automatically.

Now you have a system that retrieves based on stale embeddings, even if the source documents have been updated.

Solutions:

Solution 1: Incremental re-embedding
When a document changes, re-embed it immediately. Don't wait for a full re-index.

Solution 2: Change-based invalidation
When a document changes, remove its old embeddings from the index until new ones are ready.

Solution 3: Metadata filtering
Add temporal metadata to embeddings. Filter out embeddings older than freshness requirement before retrieval.

Solution 4: Freshness scoring
Include "freshness" as a factor in retrieval ranking. Newer documents score higher, all else equal.

Solution 5: Hybrid retrieval
Combine embedding-based retrieval with real-time API calls for high-decay content like pricing.

## The Citation Date Problem

When your AI cites sources, temporal validity becomes visible to users.

Bad citation: "According to our pricing page, the Pro plan is $49/month."

Better citation: "According to our pricing page (last updated March 2026), the Pro plan is $49/month."

Best citation: "According to our pricing page (verified today), the Pro plan is $49/month."

The date gives users context to judge freshness. If you cite a source from 2023 to answer a 2026 question, users can evaluate whether that's acceptable.

Make citation dates visible. Let users judge temporal validity themselves when it matters.

## The Regulatory Deadline Problem

Some temporal validity is legally mandated. Regulations have effective dates. Compliance deadlines are firm.

Example: The EU AI Act has staggered compliance deadlines throughout 2025-2027. If you're building a high-risk system:

- Prohibited practices ban: effective immediately (2024)
- General obligations: effective August 2, 2026
- Obligations for certain systems: effective August 2, 2027

Your ground truth about what's required must update on these exact dates. "True as of July 2026" vs "true as of September 2026" is the difference between compliance and violation.

Elite teams maintain a regulatory calendar:
- Upcoming regulation effective dates
- Policy review deadlines
- Compliance requirement changes

They update ground truth proactively before deadlines, not reactively after.

## The Version Control Connection

Temporal validity is why ground truth needs version control.

You need to be able to answer: "What was ground truth on June 15, 2026?"

This matters for:

Debugging: "Why did we give this response on June 15? What was our ground truth at that time?"

Auditing: "Show us what quality standards were in effect when this incident occurred."

Compliance: "Demonstrate that your safety criteria were updated before the regulation effective date."

Root cause analysis: "Did quality degrade, or did our standard change?"

Ground truth version history lets you understand past behavior in its proper temporal context.

## The User Date Context

Sometimes the temporal context comes from the user, not the system.

User asks: "What was your return policy in 2023?"

The current return policy is irrelevant. You need historical truth, not current truth. Your system must:
- Recognize the temporal context in the query
- Retrieve information valid for that time period
- Clearly indicate that this is historical, not current

Or user asks: "What will your pricing be next quarter?"

You need to distinguish between:
- Announced future pricing (if it's been decided)
- Projected pricing (estimates or plans)
- Unknown (we haven't decided)

Different queries need different temporal scopes: past, present, future, conditional.

## The Staleness Warning Pattern

When you can't guarantee freshness, warn users:

"Based on our pricing page last updated March 2026, the Pro plan is $49/month. Pricing may have changed—check our website for current rates."

This pattern:
- Provides the best available information
- Timestamps it so users can judge freshness
- Explicitly caveats that it might be outdated
- Directs to authoritative source for confirmation

It's honest about temporal uncertainty instead of pretending stale information is fresh.

## The Freshness-Performance Trade-off

Real-time freshness is expensive. You're constantly re-indexing, re-embedding, and re-validating.

Elite teams make conscious trade-offs:

For high-value, high-change content (pricing, availability): invest in real-time updates.

For medium-value content (documentation): daily or weekly refresh cycles.

For stable content (company history): manual review quarterly or annually.

Don't make everything real-time. Allocate freshness investment based on:
- How often content actually changes
- How costly staleness is
- How critical accuracy is for this content type

## The Knowledge Cutoff Problem

Foundation models have knowledge cutoffs. GPT-4 knows things up to a certain date, then nothing after.

Your ground truth must account for this. If you're asking a model to validate information from 2026 but its knowledge cutoff is 2024, it can't do it reliably.

Solutions:

Solution 1: Don't rely on model knowledge for recent information. Use retrieval.

Solution 2: When using model knowledge, check: is this query about something after the cutoff date? If yes, retrieve instead of generating.

Solution 3: Fine-tune or update models with recent information to extend the cutoff.

Solution 4: Be explicit with users: "My knowledge is current through [date]. For more recent information, check [source]."

Don't let models confidently hallucinate about things after their cutoff date.

## The Temporal Ground Truth Checklist

Add these to your ground truth documentation:

For each content type:
- What's the typical decay rate?
- What's the maximum age before information is considered stale?
- How do we detect when information has changed?
- How quickly do we need to reflect changes in our system?
- What's the process for updating when changes occur?

For regulatory content:
- What upcoming deadlines affect our requirements?
- When must our system comply with new regulations?
- How do we track regulatory changes?

For versioned content:
- How do we handle questions about different versions?
- How do we indicate which version information applies to?

For historical queries:
- How do we recognize when users are asking about the past?
- Do we maintain historical versions of information?
- How do we indicate temporal context in responses?

## The EU AI Act Temporal Requirement

The EU AI Act requires documentation of when quality standards were in effect. For high-risk systems, you must maintain records showing:

- What ground truth was defined and when
- When ground truth was updated and why
- What standard was in effect at any given time

This is temporal compliance. You can't just have current ground truth—you need a historical record.

If an incident occurred on June 15, 2026, regulators might ask: "What were your quality standards on that date? Did the system comply with them?"

You need to be able to pull up ground truth version 4.2, active from June 1-30, 2026, and demonstrate compliance or explain violations.

Temporal validity isn't just a technical concern—it's a legal requirement in 2026.

## What Elite Teams Do

Elite teams treat time as a first-class dimension of truth:

They timestamp all content with "last verified" dates.

They classify content by decay rate and enforce freshness requirements.

They monitor sources for changes and trigger updates automatically.

They version their ground truth and can retrieve historical standards.

They make temporal context visible in citations and responses.

They maintain regulatory calendars and update proactively.

They trade off freshness vs performance based on content criticality.

They never serve stale information as if it's current.

## The Bottom Line

Truth is not eternal. It's temporal. What's accurate today becomes false tomorrow.

Your ground truth must account for temporal validity:
- Classify information by decay rate
- Enforce freshness requirements
- Timestamp content and citations
- Detect staleness automatically
- Update proactively on known schedules
- Version your ground truth historically
- Be honest when information might be outdated

Ignore temporal validity and you'll build a system that's accurate about the past but useless for the present. That's not ground truth—that's historical fiction.

In the final section of this chapter, we'll look at how ground truth changes across different stages of the AI lifecycle: pre-training, fine-tuning, and inference. What "correct" means shifts depending on where you are in the development process, and understanding those shifts is essential to building systems that work in production.
