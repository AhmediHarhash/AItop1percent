# 5.7 — When Stakeholders Change Their Minds

The medical director who'd spent two months carefully defining ground truth for a symptom checker walked into the room with a printout. "We need to change everything," she said.

The team groaned. They'd just finished implementing the standards she'd defined. Hundreds of ground truth examples, evaluation criteria carefully calibrated, models retrained. And now she wanted to change it all?

She showed them the printout: new clinical guidelines from the American College of Physicians, published three weeks ago. The recommendations for managing certain chronic conditions had changed based on new research. Their carefully crafted ground truth was now medically outdated.

She was right to want changes. But the team's frustration was also justified. They'd just spent two months of work getting aligned, and now the ground truth was shifting under their feet.

This is the permanence paradox: ground truth needs to be stable enough that teams can build on it, but flexible enough to evolve when reality changes.

Let me walk you through how to manage ground truth evolution without descending into chaos.

## Why Ground Truth Changes (And Why That's Okay)

First, accept that ground truth will change. It has to change. Here's why:

The world changes. Regulations update. Scientific understanding evolves. Best practices shift. If your ground truth from two years ago is still unchanged, it's probably wrong.

Your product changes. You add features, change UX, shift target users. Ground truth that was perfect for version one might be wrong for version three.

Your users change. User expectations evolve. What was considered helpful two years ago might feel inadequate now.

You learn. You ship, you gather data, you discover your assumptions were wrong. Good teams update ground truth based on what they learn.

Business priorities change. The company pivots, new competitors emerge, the market shifts. What you're optimizing for changes, so ground truth changes.

The problem isn't change itself. The problem is uncontrolled change. Random updates based on whoever shouted loudest. Ground truth that shifts so often that teams can't build on it. Changes that cascade in unexpected ways and break things.

You need change to be controlled, documented, and deliberate.

## The Change Request Process

Here's a lightweight process that works for most teams.

Step one: anyone can propose a ground truth change. You want input from everyone who sees quality issues. Fill out a simple change request form:

- What needs to change? (Be specific)
- Why does it need to change? (What's the driver?)
- What's the impact if we don't change? (How urgent is this?)
- What's impacted if we do change? (What might break?)
- Who needs to approve this change?

Step two: the ground truth steward triages the request. Is this a critical fix (new regulation, safety issue, major product change) or a nice-to-have improvement? Critical fixes get prioritized immediately. Improvements get batched.

Step three: impact analysis. Before making any change, understand what it affects. Which evaluation datasets include examples related to this? Which models were trained on this ground truth? Which product areas would be impacted?

This is where good version control and documentation pay off. If you can't easily see what's impacted, you'll be hesitant to make necessary changes.

Step four: stakeholder review. The relevant stakeholders (determined by your RACI matrix) review the proposed change. Do they agree it's necessary? Do they agree with the new standard?

Step five: decision and documentation. Someone (based on your ownership model) makes the call. Document the decision: what changed, why it changed, when it changed, what was impacted.

Step six: implementation. Update ground truth datasets, re-run evaluations, retrain models if needed, update documentation.

Step seven: communication. Tell teams what changed and why. If the change affects how they should evaluate quality or build features, make sure they know.

This process sounds bureaucratic, but it prevents chaos. Without it, ground truth changes randomly and teams lose trust in it.

## Batching Changes vs Continuous Updates

Here's a question teams struggle with: should we update ground truth continuously as issues come up, or batch changes and update quarterly?

The answer: it depends on the change type.

Critical changes get implemented immediately:

- Safety issues (ground truth is allowing harmful responses)
- Compliance changes (new regulations that must be followed)
- Major product changes (you launched a new feature that changes what "good" means)
- Discovered bugs (ground truth examples that are factually wrong)

These can't wait. Implement them as soon as possible, even if it's disruptive.

Incremental improvements get batched:

- Clarifying edge cases
- Adding examples for better coverage
- Refining evaluation criteria
- Incorporating learnings from recent work

Batch these quarterly or semi-annually. Continuous small changes create instability. Batching gives teams stability between updates.

One team I worked with had a great rhythm: immediate fixes for critical issues, plus a quarterly "ground truth review" where they batched all the incremental improvements. Teams knew that ground truth was mostly stable, with deliberate update windows.

## Version Control for Ground Truth

Software engineering solved the change management problem decades ago: version control. You need the same for ground truth.

Every ground truth dataset should be versioned. When you make changes, you create a new version. You can see the history of what changed and when.

Version control lets you:

Compare versions: "What's different between the ground truth we used six months ago and what we're using now?"

Rollback if needed: "The new ground truth is causing problems. Let's temporarily revert while we figure out what's wrong."

Track impact: "We updated ground truth on June first. Did model performance change after that date?"

Communicate clearly: "We're now using ground truth version three point two. Here's what changed from three point one."

This doesn't have to be complicated. A git repository works. A shared drive with dated folders works. Specialized tools work. The important thing is having clear versioning and history.

## The Backwards Compatibility Question

When you change ground truth, do you invalidate all the work done under the old ground truth?

Sometimes yes, sometimes no. You need to think through backwards compatibility.

Example of breaking change: you completely redefine what "helpful" means. Old evaluations using the old definition can't be compared to new evaluations using the new definition. You need to re-evaluate everything or accept that there's a discontinuity in your metrics.

Example of compatible change: you add new examples to ground truth but don't change the evaluation criteria. Old evaluations are still valid, you're just expanding coverage.

Example of mostly compatible change: you refine the definition of one criterion but the general thrust is the same. Old evaluations are approximately comparable but not perfectly comparable.

Be explicit about compatibility when you make changes. "This is a breaking change — we'll need to re-baseline our metrics" or "This is backwards compatible — historical data is still valid."

## Managing Stakeholder Change Fatigue

Here's a real problem: if ground truth changes too often, stakeholders burn out.

"We just spent three weeks aligning on ground truth and now you're telling me it's changing? I don't have time for another alignment workshop. Just tell me what to do."

This is change fatigue, and it's a legitimate concern. You have to balance evolution with stability.

Strategies to manage change fatigue:

One: batch changes as discussed above. Don't ask stakeholders to re-engage every month.

Two: make changes incremental when possible. Don't completely blow up the framework — evolve it.

Three: communicate changes clearly and efficiently. Don't make stakeholders wade through dense documentation to understand what changed. Give them a concise summary: "Here's what changed, here's why, here's what you need to do differently."

Four: automate what you can. If the change is "we added fifty new examples to the dataset," stakeholders don't need to review all fifty. They trust the process.

Five: preserve what's working. If part of the ground truth is working well, don't change it just for consistency. Change what needs changing, leave the rest stable.

## The Regulatory Change Scenario

Let's walk through a specific scenario: a new regulation that forces ground truth changes.

The EU AI Act adds new requirements for transparency and explainability. Your ground truth needs to evolve to reflect these requirements.

Step one: understand the regulatory change. Work with legal to understand exactly what's now required.

Step two: assess impact. How does this affect your existing ground truth? Which evaluation criteria need to change? Which examples need updating?

Step three: create a transition plan. Can you phase this in, or does it need to happen all at once? What's the deadline?

Step four: update ground truth. Create new examples showing compliant responses. Update evaluation criteria to include the new requirements.

Step five: communicate broadly. This isn't just a ground truth change — it's a product change. Make sure everyone understands what's required and why.

Step six: implement with monitoring. Roll out the changes, monitor impact, be ready to adjust if you missed something.

Regulatory changes are non-negotiable, but they still need to be managed carefully.

## The Product Pivot Scenario

Another scenario: your company pivots product direction and ground truth needs to reflect the new direction.

You built a chatbot for customer support. The company pivots to focus on sales enablement. The ground truth that defined "good support responses" doesn't fully apply to "good sales responses."

You have two options:

Option one: evolve the existing ground truth. Keep the core framework but adjust criteria and examples to reflect the new use case.

Option two: create new ground truth for the new use case while maintaining the old ground truth for any legacy product.

Most of the time, option two is safer. Don't try to force-fit old ground truth into a fundamentally new context. Create new ground truth, run a new alignment workshop, treat it as a fresh start.

But preserve the old ground truth too. You learned valuable things during that process. The framework might be reusable even if the specific examples aren't.

## The User Expectation Shift Scenario

Users' expectations of AI products are evolving rapidly. What seemed impressive in twenty-twenty-three feels basic in twenty-twenty-six. Your ground truth needs to keep pace.

This is the trickiest type of change because it's gradual and subjective. There's no clear trigger like a regulation or product change.

Here's how to handle it:

Set up a regular cadence (quarterly or semi-annually) to review ground truth against current user expectations.

Use recent user feedback. Are users complaining about things your ground truth considers acceptable? That's a signal to update.

Benchmark against competitors. If competitors are delivering capabilities you're not, and users notice, your ground truth might need to evolve.

Run periodic user testing. Show users your ground truth examples and ask if they still feel like "good" responses.

Don't chase every trend, but don't ignore major shifts in what users expect.

## When Stakeholders Disagree About Changes

The medical director wants to update ground truth to reflect new clinical guidelines. The engineering lead pushes back because it means retraining models and delaying a launch.

Both concerns are valid. How do you resolve it?

Use the framework from the conflict resolution chapter:

What's the risk if we don't change? (Outdated medical advice could harm users)

What's the cost if we do change? (Two-week launch delay, engineering time)

What's the compromise? (Implement a post-processing filter immediately to catch the most critical cases, do the full model retrain after launch)

Document the trade-off: "We're accepting slightly outdated ground truth for two more weeks in exchange for hitting the launch date, with a safety filter to mitigate the highest risks."

Sometimes the right answer is "do the change, accept the delay." Sometimes it's "delay the change, mitigate the risk." The key is making the trade-off explicit.

## Communication Templates for Ground Truth Changes

Let me give you templates for communicating different types of changes.

For critical immediate changes:

Subject: URGENT: Ground Truth Change Required

What changed: [Brief description]

Why it changed: [Regulatory requirement / safety issue / major bug]

What you need to do: [Specific actions for different stakeholders]

Timeline: [Effective immediately / by X date]

Who to contact with questions: [Name]

For batched quarterly updates:

Subject: Q2 Ground Truth Update

Summary: We're implementing fifteen improvements to ground truth based on the past quarter's learnings.

Key changes:
- [Change one and rationale]
- [Change two and rationale]
- [Change three and rationale]

Full change log: [Link]

What this means for you: [Specific implications for different teams]

Effective date: [Date]

Review session: [Optional meeting for questions]

For clarifications and refinements:

Subject: Ground Truth Clarification: [Topic]

Context: We've seen several cases where [situation] caused confusion.

Clarification: [Clear statement of the standard]

Examples: [Links to examples showing the standard in practice]

This doesn't change the fundamental ground truth, just makes it more explicit.

Questions? [Contact]

Clear, concise communication prevents changes from being disruptive.

## The Living Documentation Principle

Ground truth documentation should be a living resource, not a static artifact.

Every ground truth document should have:

- Last updated date
- Version number
- Change log (what changed and when)
- Ownership (who's responsible for keeping this current)
- Review cadence (when will this be reviewed next)

When you update ground truth, update the documentation simultaneously. Not "we'll update the docs later" — update them as part of the change.

Use tools that make this easy. Wikis, shared docs, knowledge bases — whatever your team actually uses and keeps current.

## What Good Change Management Looks Like

Let me show you a team that handled ground truth evolution well.

They built a legal research AI. Two years in, they had stable ground truth, good evaluation infrastructure, happy users. Then legal regulations in their primary market changed significantly.

Here's what they did:

Week one: Legal team identified the regulatory changes and their implications for ground truth.

Week two: Ground truth steward did impact analysis. Identified thirty-seven ground truth examples that needed updating, five evaluation criteria that needed adjustment.

Week three: Ran a focused alignment workshop with legal, product, and domain experts. Reviewed the required changes, got buy-in, documented new standards.

Week four: Updated ground truth datasets, versioned them clearly (moved from version two point three to three point zero to signal breaking change).

Week five: Engineering re-ran evaluations using new ground truth, identified which models needed retraining.

Weeks six through eight: Retrained models, tested thoroughly against new ground truth.

Week nine: Rolled out updated product, communicated changes to users.

Throughout: regular updates to all stakeholders about progress and timeline.

The change was disruptive, but it was controlled. Everyone knew what was happening and why. The old ground truth was preserved for historical reference. The new ground truth was clearly versioned and documented.

Three months later, when they had to make another change (smaller, product-driven), they used the same process. It felt routine instead of chaotic.

## What's Next

You now know how to manage ground truth changes without creating chaos. But there's still a challenge: what happens when the person who knows all this leaves your company?

In the next subchapter, we're tackling documentation that survives team turnover. How do you capture not just what the ground truth is, but why it's that way? How do you onboard new team members into complex, nuanced quality standards? How do you ensure institutional knowledge doesn't walk out the door when people leave?

Ground truth is valuable only if it outlasts the people who created it. Let's talk about making that happen.
