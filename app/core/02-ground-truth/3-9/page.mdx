# 3.9 — Evidence Policy: Answer Only If Supported

A lawyer once told me about a trial where an expert witness kept saying "in my opinion" before every statement. It seemed redundant, almost annoying. But the lawyer explained: it's a legal distinction. Facts require evidence. Opinions just require expertise. The phrase "in my opinion" signals which category you're in.

Your AI system needs the same discipline. Some things it says need to be backed by explicit evidence. Other things can be offered as general knowledge or synthesis. But the system needs to know which is which, and signal it clearly to users.

Let me walk you through building an evidence policy: defining when your system must cite sources, when it can draw on general knowledge, and what to do when evidence is absent, contradictory, or incomplete.

## The Problem with "Just Answer the Question"

Here's what happens when you don't have an evidence policy:

User: "What's the return policy for electronics?"
System: "Electronics can be returned within 30 days."

User goes to return something on day 28, gets told "Sorry, electronics are 14 days only."

The system gave a confident answer without checking actual policy. It synthesized something that sounded reasonable from general e-commerce knowledge, but it was wrong for this specific company.

Now the user doesn't trust the system. Worse, they're angry because they planned around false information.

Compare to:

User: "What's the return policy for electronics?"
System: "According to our return policy (updated January 2026), electronics can be returned within 14 days of purchase with original packaging and receipt. Here's the full policy: [link]"

This answer is grounded in actual company policy, cites the source, and acknowledges when it was updated. If it's wrong, it's because the source is wrong, not because the system guessed.

## The Evidence Spectrum

Not every statement needs the same level of evidence. There's a spectrum:

**Tier 1: No Citation Needed (General Knowledge)**

Facts that are:
- Universally known and non-controversial
- Extremely unlikely to be wrong
- Not specific to your domain or context

Examples:
- "Paris is the capital of France"
- "Water freezes at 0°C"
- "There are 24 hours in a day"

These don't need citations. They're common knowledge.

**Tier 2: Citation Helpful (General Domain Knowledge)**

Information that is:
- Generally true but might have exceptions
- Domain-specific but broadly applicable
- Helpful to verify but not critical

Examples:
- "Most companies offer a 30-day return policy"
- "Email subject lines under 50 characters tend to perform better"
- "The average response time for customer support is 24 hours"

These benefit from citations, especially if you have good sources, but lack of citation isn't catastrophic.

**Tier 3: Citation Required (Specific Claims)**

Information that is:
- Specific to your organization, product, or context
- Has material consequences if wrong
- Could change or vary

Examples:
- "Your subscription renews on March 15th"
- "This product costs $49.99"
- "Our return policy is 14 days"

These absolutely need to be grounded in evidence. Guessing is unacceptable.

**Tier 4: Citation Critical (Consequential Claims)**

Information that is:
- High-stakes (medical, legal, financial, safety)
- Specific and consequential
- Requires authoritative sources

Examples:
- "The dosage for this medication is 20mg daily"
- "This investment is FDIC insured"
- "You have the legal right to X under this statute"

These require not just citation, but authoritative, recent citation. If you can't cite properly, don't answer.

## Defining Your Evidence Policy

Your evidence policy should specify, for each category of information your system handles, what evidence requirements apply.

**For a customer support bot:**

Product pricing:
- Evidence requirement: MUST cite current price database
- Acceptable sources: Product catalog API, pricing table
- Unacceptable: General knowledge, estimates, outdated data
- If evidence unavailable: "Let me check current pricing for you" + fetch from API

Company policies:
- Evidence requirement: MUST cite official policy documents
- Acceptable sources: Published policies, internal knowledge base
- Unacceptable: General e-commerce practices, assumptions
- If evidence unavailable: "Let me get you the exact policy" + link to policy page

Troubleshooting steps:
- Evidence requirement: SHOULD cite support documentation
- Acceptable sources: Official troubleshooting guides, known solutions
- Unacceptable: Untested suggestions, guesses
- If evidence unavailable: "I'm not finding documented steps for this issue. Let me connect you with technical support."

General product information:
- Evidence requirement: SHOULD cite sources when available
- Acceptable sources: Product descriptions, specifications, documentation
- Unacceptable: Fabricated specs, competitor information presented as yours
- If evidence unavailable: Provide general information with disclaimer

**For a medical information assistant:**

Drug information:
- Evidence requirement: MUST cite authoritative medical sources
- Acceptable sources: FDA labels, peer-reviewed studies, medical databases
- Unacceptable: General internet sources, anecdotal information
- If evidence unavailable: Refuse to answer, direct to healthcare provider

General health information:
- Evidence requirement: MUST cite sources for specific claims
- Acceptable sources: CDC, WHO, peer-reviewed literature
- Unacceptable: Blog posts, unverified sources
- If evidence unavailable: Refuse specific claims, provide general guidance to consult healthcare provider

## The Citation Format

When you do cite evidence, how do you format it?

**Inline citations (minimal friction):**

"Your subscription renews on March 15th (Account Settings, last updated Jan 2026)."

The citation is unobtrusive but present.

**Explicit citations (high-stakes):**

"According to FDA labeling for this medication, the standard dosage is 20mg daily. Source: FDA Drug Label Database, updated December 2025."

The source is prominent and specific.

**Linked citations (verification path):**

"Our return policy is 14 days for electronics. [View full policy]"

The user can verify if they want.

**Structured citations (academic style):**

For high-stakes domains like medical or legal information:

"Based on recent meta-analysis (Smith et al., 2025, Journal of Medicine, DOI: 10.xxx), the treatment shows 85% efficacy."

This lets experts verify the claim.

Choose citation format based on:
- Stakes (higher stakes = more explicit)
- Frequency (common queries = less verbose)
- Audience (experts want more detail)
- Medium (chat can be more compact than reports)

## The "Grounded in Context" Rule

For RAG systems, the fundamental rule: Answer only if grounded in retrieved context.

**What "grounded" means:**

Strongly grounded:
The retrieved documents directly state the answer.
Example: Doc says "Return period is 14 days." You say "Return period is 14 days."

Weakly grounded:
The retrieved documents support the answer but require inference.
Example: Doc says "Electronics: 14 days. Clothing: 30 days." User asks about a specific product category not listed. You can infer from similar categories with caution.

Not grounded:
The retrieved documents don't address the question.
Example: Docs discuss return policies but don't mention the specific question being asked. You can't just make up an answer that seems consistent.

**The policy:**
- Strongly grounded: Answer directly
- Weakly grounded: Answer with caveats ("Based on similar products...")
- Not grounded: Refuse ("I don't have information about that specific situation")

## When Evidence Conflicts

Sometimes your sources disagree. What then?

**Example:**
Document A (updated 2025): "Return policy is 30 days"
Document B (updated 2026): "Return policy is 14 days"

**Approach 1: Prioritize by recency**

"According to our current policy (updated January 2026), returns are accepted within 14 days. Note that this changed from a previous 30-day policy."

You're citing the most recent source and acknowledging the discrepancy.

**Approach 2: Acknowledge conflict**

"I'm seeing conflicting information — one document says 30 days, another says 14. Let me connect you with someone who can confirm the current policy."

You're being honest about uncertainty rather than guessing.

**Approach 3: Escalate**

For consequential queries, don't guess when evidence conflicts. Escalate to a human who can resolve the conflict.

## When Evidence is Incomplete

Sometimes you have partial evidence, but not enough for a complete answer.

User: "What's included in the Premium plan?"
Retrieved doc: "Premium includes features A, B, and C."
User: "What about feature X?"
Retrieved doc: Doesn't mention feature X.

**Bad response:**
"Feature X is not included."
(You don't actually know — absence of mention doesn't mean absence of feature)

**Good response:**
"The documentation I have lists features A, B, and C as included in Premium. I don't see feature X mentioned, but to be certain whether it's included, let me get you the complete feature list."

You're acknowledging what you know and what you don't.

## The Hallucination Firewall

For RAG systems, implement a hallucination firewall: a check that prevents the system from citing sources that don't exist.

**Pre-generation check:**
Before generating a response, verify that retrieved context actually supports the answer.

**Post-generation check:**
After generating a response, if the response includes citations, verify those citations exist and match.

Example:
Generated response: "According to the 2026 Product Guide, feature X costs $50."

Post-generation check:
- Does "2026 Product Guide" exist in retrieved docs? Yes.
- Does it mention feature X? Yes.
- Does it say $50? Yes.
- ✓ Allow response.

If any check fails:
- ✗ Block response.
- Log for review.
- Generate alternative response without the unsupported claim.

This catches hallucinations before they reach users.

## Evidence Requirements by Risk Tier

Different product areas have different evidence requirements based on risk.

**Critical-Risk Areas:**
- Medical advice
- Legal guidance
- Financial recommendations
- Safety instructions
- Security procedures

Evidence requirement: MUST cite authoritative, current sources. If no source exists, refuse to answer.

**High-Risk Areas:**
- Pricing
- Policies
- Contractual terms
- Account-specific information
- Compliance requirements

Evidence requirement: MUST cite sources. If source is unclear or outdated, acknowledge uncertainty.

**Medium-Risk Areas:**
- Product features
- Troubleshooting
- General procedures
- How-to guidance

Evidence requirement: SHOULD cite sources when available. Can provide general knowledge with caveats if no specific source.

**Low-Risk Areas:**
- General information
- Background context
- Educational content
- Creative responses

Evidence requirement: Citation helpful but not required for general knowledge.

## The "I Don't Know" Threshold

Define explicitly when your system should say "I don't know" rather than attempting to answer.

**Automatic "I don't know" triggers:**
- Confidence below threshold for risk tier
- No retrieved evidence for Tier 3/4 claims
- Conflicting evidence without clear resolution
- Question outside documented scope
- Evidence is significantly outdated for fast-changing topics

**Example policy:**

"If confidence is below 90% for critical-risk queries, respond: 'I don't have reliable information on this. You should consult with [appropriate professional].'

If confidence is below 80% for high-risk queries, respond: 'I'm not finding clear information on this. Let me connect you with [team] who can help.'

If confidence is below 70% for medium-risk queries, respond: 'I'm not certain about this. Based on general information [caveat], but I'd recommend [verification path].'"

## Evidence Freshness

Some information goes stale quickly. Your evidence policy should account for this.

**Fast-changing information:**
- Pricing (can change daily)
- Inventory/availability (real-time)
- News/events (daily)
- Regulations (monthly)

Requirement: Check recency of source. If >X old, flag as potentially outdated.

Example:
Retrieved doc: "Product costs $50" (last updated 6 months ago)

Response: "Based on documentation from six months ago, this product was $50, but pricing may have changed. Let me check current pricing."

**Slow-changing information:**
- Historical facts
- Scientific consensus
- Core product features
- Fundamental policies

Requirement: Less sensitive to staleness, but still cite when source was published.

**Define staleness thresholds:**

Critical domains (medical, legal): Information >1 year old requires extra verification
Pricing/inventory: Information >1 week old should trigger real-time check
Policies: Information >3 months old should be flagged for review
General information: Information >2 years old should note publication date

## Testing Your Evidence Policy

Build test sets that verify your evidence policy is working:

**Test Set 1: Grounded Answers**
Queries where evidence clearly supports the answer.
Expected: System answers confidently with citation.

**Test Set 2: Ungrounded Queries**
Queries where no evidence exists in retrieved context.
Expected: System refuses or acknowledges uncertainty, doesn't fabricate.

**Test Set 3: Partially Grounded**
Queries where evidence partially supports answer but has gaps.
Expected: System answers what's supported, acknowledges gaps.

**Test Set 4: Conflicting Evidence**
Queries where multiple sources disagree.
Expected: System acknowledges conflict, prioritizes appropriately, or escalates.

**Test Set 5: Stale Evidence**
Queries where evidence is outdated.
Expected: System flags staleness, offers to verify current information.

**Test Set 6: Citation Accuracy**
Take random sample of responses with citations.
Verify: Do cited sources exist? Do they say what system claims?

This last test is critical for catching hallucination.

## Common Evidence Policy Mistakes

**Mistake 1: Citation Theater**

The system cites sources that sound authoritative but are actually vague or don't support the claim.

Bad: "According to company policy, the return period is 30 days."
(There's no specific policy document cited, just a vague appeal to "company policy")

Good: "According to our Return & Exchange Policy (updated Jan 2026), the return period is 30 days. [View policy]"

**Mistake 2: Over-Citation**

Citing obvious facts that don't need citation.

Bad: "Water is H2O (Chemistry Textbook, Chapter 2)."

Nobody needs that citation. It's common knowledge.

**Mistake 3: Under-Citation**

Not citing things that absolutely need evidence.

Bad: "Your appointment is Tuesday at 3pm."
(Without checking the actual calendar)

This needs verification, not assumption.

**Mistake 4: Fake Confidence**

Presenting uncertain information confidently.

Bad: "The product costs $50."
(Based on stale data, not current pricing)

Good: "The product was $50 as of last month's pricing update. Let me verify current pricing."

**Mistake 5: Citation Without Verification**

Citing sources without checking they say what you claim.

Bad: "According to the 2026 report, sales increased 50%."
(Report doesn't exist or doesn't say this)

This is hallucination with extra steps. Always verify citations are real and accurate.

## Evidence Policy for Creative vs. Factual Responses

Different types of queries need different evidence standards.

**Factual queries:**
Strict evidence requirements. Don't guess.

**Creative queries:**
Looser evidence requirements. Synthesis and generation are expected.

The key: Know which category you're in.

User: "What's the return policy?" → Factual (strict evidence required)
User: "Write a story about a return policy" → Creative (no evidence needed)

User: "What does the contract say about termination?" → Factual (strict evidence required)
User: "Explain the contract like I'm five" → Creative synthesis (can paraphrase with attribution)

Make sure your system can distinguish these contexts.

## Documenting Your Evidence Policy

Your evidence policy should be explicit and documented:

**For each information category:**
- Evidence requirement (MUST/SHOULD/MAY cite)
- Acceptable sources
- Unacceptable sources
- Citation format
- Freshness requirements
- Confidence thresholds
- Fallback behavior when evidence is unavailable

Example:

---
**Evidence Policy: Product Pricing**

Requirement: MUST cite current pricing data
Acceptable sources: Product catalog API (real-time), pricing database (if < 1 day old)
Unacceptable: General knowledge, competitor prices, outdated catalog
Citation format: "$50 (current pricing as of [date])" or "$50 (subject to verification)"
Freshness: Real-time preferred, max 24 hours old
Confidence threshold: 95% — must be certain of price
Fallback: If pricing unavailable or uncertain, "Let me check current pricing for you" + API call or escalation
---

## The Evidence Policy as Trust Foundation

Here's why evidence policy matters so much: trust is binary in a weird way.

Users will forgive one or two incorrect answers if you're honest about uncertainty. They won't forgive confidently wrong answers, even if you're right 99% of the time.

One fabricated source, one wrong price stated confidently, one outdated policy presented as current — and the user stops trusting anything you say.

Evidence policy isn't about being perfect. It's about being honest. When you know, say so and cite your source. When you don't know, admit it and help them find the answer.

That honesty is what makes the system trustworthy.

In the next subchapter, we'll explore negative truth sets: the examples your system must get wrong on purpose. These are the harmful requests, unsafe queries, and inappropriate asks where "I can't help with that" is the only correct answer. Building these sets is just as important as building your positive examples, and often more nuanced.
