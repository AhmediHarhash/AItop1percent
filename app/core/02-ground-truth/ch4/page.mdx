# Chapter 4 — Building Ground Truth From Scratch

You understand what ground truth is. You know your risk tier. You've defined your behavior boundaries. Now comes the hard part: actually building it.

Every team faces the same cold start problem — you need ground truth to evaluate your system, but you don't have any yet. The temptation is to skip ahead, ship something, and figure it out later. That's how you end up six months in with no way to measure whether your product is getting better or worse.

This chapter takes you from zero to a validated, documented ground truth foundation. You'll learn how to extract knowledge from experts, mine existing documentation, convert customer feedback into signal, generate synthetic examples responsibly, build your first 50 examples, turn those examples into rubrics, and protect everything from contamination.

---

## What This Chapter Covers

- **4.1** — Starting With Zero (The Cold Start Problem)
- **4.2** — Expert Elicitation: Getting Knowledge Out of Heads
- **4.3** — Existing Documentation as Ground Truth Source
- **4.4** — Customer Feedback as Signal
- **4.5** — Competitive Analysis as Reference
- **4.6** — Synthetic Ground Truth (When and How)
- **4.7** — The First 50 Examples: Your Foundation
- **4.8** — From Examples to Rubrics
- **4.9** — Validating Your Ground Truth Before You Build On It
- **4.10** — Ground Truth Granularity: Claim-Level vs Response-Level vs Outcome-Level
- **4.11** — The Ground Truth Record: Fields, Metadata, Version & Source Links
- **4.12** — Inter-Annotator Agreement: Cohen's Kappa, Krippendorff's Alpha & When Numbers Lie
- **4.13** — Protecting Ground Truth From Contamination

---

*Let's start with the moment every team dreads — staring at an empty spreadsheet.*
