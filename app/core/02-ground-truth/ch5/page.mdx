# Chapter 5 — Stakeholder Alignment

Ground truth isn't just a technical artifact — it's a contract between everyone who touches your AI product. Engineers, product managers, domain experts, legal, leadership — they all have a different definition of "good," and if you don't align them explicitly, you'll spend more time arguing than building.

Most quality disagreements aren't about the AI. They're about people with different incentives looking at the same output and seeing different things. The engineer sees a technically correct response. The product manager sees a missed business opportunity. The legal team sees a compliance risk. Without alignment, every review becomes a negotiation.

This chapter gives you the tools to get stakeholders aligned, keep them aligned when priorities shift, and document decisions in ways that survive team turnover.

---

## What This Chapter Covers

- **5.1** — Why Teams Fight About Quality
- **5.2** — User Success vs Business Success vs Safety
- **5.3** — The Alignment Workshop (Getting Everyone in a Room)
- **5.4** — Resolving Conflicts Between Stakeholders
- **5.5** — Executive Buy-In for Ground Truth Investment
- **5.6** — Cross-Functional Ground Truth Ownership
- **5.7** — When Stakeholders Change Their Minds
- **5.8** — Documentation That Survives Team Turnover
- **5.9** — Adjudication Workflow: Who Decides When Experts Disagree
- **5.10** — Tie-Break Rules: Safety Wins, Policy Wins, Legal Wins

---

*Let's start with the real reason your team can't agree on what "good" means.*
