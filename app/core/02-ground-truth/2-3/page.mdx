# 2.3 — Tier 1: Low Tolerance (Transactional)

Imagine you're running a hotel booking platform. A guest uses your AI assistant to change their reservation from a king bed to two queens. The AI processes the change. The guest arrives at the hotel. The room still has a king bed.

Nobody dies. Nobody loses their life savings. But the guest is furious, your hotel partner is embarrassed, your support team spends an hour fixing the problem, and the guest leaves a scathing review. The mistake was fixable, but it cost you trust, time, and money.

This is Tier 1 — transactional tasks where mistakes can be corrected but the correction is costly. These aren't life-and-death scenarios, but they're not trivial either. They're the everyday operations that make or break product trust.

## What Makes Something Transactional

Tier 1 tasks have three characteristics: they create commitments, they can be reversed, but reversal has real costs.

**They create commitments:** The AI action establishes an expectation or obligation. A booking, an account change, a subscription modification, an order update. Users expect the commitment to be honored.

**They can be reversed:** Unlike Tier 0, these mistakes can be fixed. You can cancel the wrong booking and make a new one. You can correct the account change. You can refund the order. The world doesn't end.

**Reversal has real costs:** But fixing the mistake isn't free. There's customer frustration, support time, potential refunds, relationship damage, and opportunity cost. The more mistakes you make, the more your product degrades.

**Common Tier 1 examples:**

**E-commerce:**
- Processing orders
- Modifying shipping addresses
- Updating payment methods
- Applying promo codes
- Changing order items before shipment

**Booking and reservations:**
- Making hotel reservations
- Changing flight bookings
- Reserving restaurant tables
- Scheduling appointments
- Canceling reservations

**Account management:**
- Updating profile information
- Changing subscription plans
- Modifying notification preferences
- Adding team members
- Setting access permissions

**CRM and business tools:**
- Creating customer records
- Updating contact information
- Logging support tickets
- Assigning tasks
- Updating project statuses

**Financial (non-critical):**
- Viewing transaction history
- Categorizing expenses
- Setting budget alerts
- Generating reports
- Processing small refunds (below critical thresholds)

Notice the pattern: these are operational tasks that users expect to work correctly, where mistakes create friction but not disaster.

## The Tier 1 Quality Standard: High Correctness with Clear Confirmation

Tier 0 requires absolute certainty. Tier 1 requires high correctness — not perfect, but reliable enough that mistakes are rare exceptions rather than regular occurrences.

The target: 95-98% accuracy on transactional tasks. This means if a user makes 100 bookings, 95-98 of them should be correct without requiring manual intervention.

Why not 100%? Because achieving the last 2-5% would require Tier 0 rigor — multiple expert reviewers, exhaustive edge case coverage, slow human verification — and the cost would be disproportionate to the consequences. The 95-98% range represents the sweet spot where most transactions work correctly, mistakes are manageable through correction processes, and resources are efficiently allocated.

But this accuracy can't be silent. Tier 1 tasks require clear confirmation: the system must show the user what action will be taken before taking it, giving them a chance to catch errors.

## The Confirmation-Before-Action Pattern

The core Tier 1 safety mechanism is the confirmation step: before executing a transactional action, show the user exactly what will happen and require explicit confirmation.

This is different from Tier 0 in key ways:

**Tier 0 confirmation requires expert verification.** A pharmacist verifying a dosage, a banker approving a wire transfer, an attorney reviewing a filing. The confirming party needs domain expertise.

**Tier 1 confirmation requires user verification.** The user themselves verifies the action. They don't need expertise — they just need to understand what's about to happen and confirm it matches their intent.

**Tier 0 confirmation is deep.** Review all details, check calculations, validate against policies, consider edge cases.

**Tier 1 confirmation is breadth.** Verify the key details: what action, what parameters, what outcome.

Let me show you what good Tier 1 confirmation looks like in practice.

**Bad confirmation (too vague):**
"Do you want to proceed with this booking?"

What booking? The user might not remember what they requested. This doesn't help catch errors.

**Good confirmation (specific details):**
"I'll book a room at Grand Hotel for 2 guests, checking in March 15 and checking out March 17, with a king bed. The total cost is $450. Should I proceed?"

Now the user can verify: right hotel, right dates, right room type, right price. If any detail is wrong, they'll catch it.

**Even better confirmation (structured display):**

```
Your Booking Summary:
Hotel: Grand Hotel, Downtown
Check-in: Thursday, March 15, 2026
Check-out: Saturday, March 17, 2026
Guests: 2 adults
Room Type: King Bed
Nightly Rate: $225
Total Cost: $450

[Confirm Booking] [Change Details]
```

This structured format makes verification easy. The user can scan quickly and confirm, or spot problems immediately.

## What Tier 1 Ground Truth Looks Like

Your Tier 1 ground truth dataset should focus on two questions:

1. Does the AI correctly interpret user intent?
2. Does the AI correctly execute the transactional action?

**Intent interpretation:** The user says "Change my flight to next Tuesday." Does the AI understand which flight (if they have multiple), which Tuesday (next week or the one after), and what kind of change (same time, flexible time, cheapest option)?

**Action execution:** Once intent is understood, does the AI correctly translate it into system actions? Right API calls, right parameters, right sequence?

Both layers need ground truth coverage.

**Ground truth structure for Tier 1:**

Each example includes:
- User request (what they said)
- Context (account state, prior conversation, system data)
- Correct interpretation of intent
- Correct transactional action(s)
- Expected confirmation display
- Expected outcome after execution

**Annotator requirements:**

Tier 1 doesn't require domain experts like Tier 0, but annotators do need to understand your product domain. For a booking platform, they should understand how reservations work. For a CRM tool, they should understand customer record management.

You can train annotators without requiring years of experience, but they need clear guidelines and product knowledge.

**Multi-annotator protocol:**

Two annotators per example is standard. If they disagree on the correct action, a third annotator or a product expert reviews and makes the call.

Unlike Tier 0, disagreement doesn't automatically mean "escalate to human." It means the annotators discuss, clarify the guidelines, and reach consensus. The goal is to establish what the correct action is, even if it's not immediately obvious.

**Edge case coverage:**

Tier 1 ground truth should include:
- Ambiguous user requests ("change my reservation" when they have multiple)
- Incomplete information ("book a room in March" without specifying dates)
- Conflicting constraints ("cheapest flight" but also "no layovers")
- System limitations (requested action isn't available)
- Error conditions (payment failure, sold out inventory)

You don't need exhaustive coverage of every possible edge case like Tier 0. You need representative coverage — enough examples that the system learns to handle common ambiguities and knows when to ask for clarification.

## The Reversibility Window

A key Tier 1 concept: the reversibility window — the period during which a mistake can be easily corrected.

For a hotel booking made a month in advance, the reversibility window is wide. If the AI books the wrong dates, the user will probably notice and fix it well before check-in. There's time to correct mistakes.

For an appointment scheduled for tomorrow, the window is narrow. If the AI books the wrong time, there might not be availability to rebook.

For an order modification where the item ships in an hour, the window is very narrow. Mistakes might not be catchable.

Your Tier 1 ground truth should account for reversibility windows. Tasks with narrow windows need higher accuracy standards and more prominent confirmation displays. Tasks with wide windows can tolerate slightly more errors because correction is easier.

This means your "Tier 1" might internally have sub-tiers:
- **Tier 1a:** Wide reversibility window (weeks or months)
- **Tier 1b:** Medium window (days)
- **Tier 1c:** Narrow window (hours or less)

Same general tier, but different quality targets: 95% for 1a, 97% for 1b, 98%+ for 1c.

## User Confirmation UX Best Practices

Confirmation is only effective if users actually review it. Here's what works:

**Make it scannable:** Users won't read paragraphs. Use structured formats with clear labels, visual hierarchy, and emphasis on key details.

**Highlight changes:** If the user is modifying an existing transaction, show what's changing. "You're changing your check-in date from March 10 to March 15" is clearer than just showing the new date.

**Show consequences:** If there are costs, penalties, or trade-offs, display them. "Changing your flight will cost a $50 change fee" lets users make informed decisions.

**Make confirmation active:** Require a deliberate action, not just passive acceptance. A "Confirm Booking" button is better than auto-proceeding after showing details.

**Avoid confirmation fatigue:** Don't ask for confirmation on every tiny action. Confirmation should be proportional to consequence. Changing a profile name doesn't need heavy confirmation. Changing a subscription plan with billing implications does.

**Provide escape hatches:** Make it easy to go back and modify. "Change Details" should be as prominent as "Confirm."

## Audit Logging for Tier 1

Tier 1 doesn't require the same exhaustive audit trails as Tier 0, but logging is still important for:

**Debugging:** When something goes wrong, you need to reconstruct what the AI did and why.

**User support:** When a user reports a problem, support needs to see the transaction history.

**Product improvement:** Analyzing patterns in mistakes reveals where the AI needs improvement.

**What to log:**

- Timestamp of action
- User ID
- Action type (booking, modification, cancellation)
- Action parameters (dates, amounts, selections)
- AI confidence level
- User confirmation (did they review or skip?)
- Outcome (success, failure, error)

You don't need to log everything like Tier 0 — no need for annotator-level detail or regulatory compliance depth. But you need enough information to support users and debug issues.

## Real Example: E-Commerce Order Modification

Let me walk through a real Tier 1 system I worked with — an AI that handles order modifications for an online retailer.

**The task:** Customers contact the AI to modify orders after purchase: change shipping address, swap items, apply forgotten promo codes, upgrade shipping speed, or cancel before shipment.

**Why this is Tier 1:** Mistakes frustrate customers and create support burden, but they can be fixed. If the AI changes the address to the wrong place, customer service can correct it. If it applies the wrong promo code, it can be adjusted. The window for fixes is usually hours to days before shipment.

**Ground truth structure:**

Each example includes:
- Customer request in natural language
- Order details (items, quantities, current shipping address, order status)
- Account history (previous orders, addresses, payment methods)
- Correct interpretation of request
- Correct system action
- Expected confirmation message

Examples:
"I need to change my shipping address" → Extract new address from conversation, validate it, update order, confirm with customer
"Can I use my promo code?" → Identify which promo code (ask if not specified), validate eligibility, apply discount, recalculate total, confirm savings
"I want to change the blue shirt to red" → Identify which order (if multiple), which item (if multiple blue shirts), check red availability, swap items, confirm change and any price difference

**Annotator protocol:**

Two annotators per example. They must:
1. Identify the customer's intent
2. Determine the correct system action
3. Draft the confirmation message
4. Note any ambiguities that require clarification

If annotators disagree on intent, they discuss. If it's genuinely ambiguous, they label it as "requires clarification" and draft the clarifying question the AI should ask.

**Confirmation UX:**

Before executing changes, the AI displays:

```
I'll update your order #12345:

Current address: 123 Main St, Apt 4B, Boston MA 02101
New address: 456 Oak Ave, Cambridge MA 02138

Your order will arrive at the new address by March 10.

[Confirm Change] [Edit Address] [Cancel]
```

This lets the customer verify the address is correct before the change is made.

**Error recovery paths:**

If the customer confirms an address change and then realizes it's wrong, they can contact support within the reversibility window (before shipment) to fix it. The system logs all changes so support can see the history and quickly correct errors.

**The result:**

The system handles about 80% of order modifications correctly end-to-end, with 95%+ accuracy on individual action steps. The 20% that escalate to humans are usually cases requiring judgment (policy exceptions, complex multi-step changes) rather than AI errors.

Customer satisfaction with modifications is high because confirmations catch most potential errors before execution, and the narrow reversibility window is respected — changes stop being allowed once orders enter final packing.

## CRM Record Management Example

Another Tier 1 scenario: an AI that helps sales teams manage customer records in a CRM system.

**The task:** Sales reps tell the AI to create contacts, update deal stages, log activities, assign tasks, or update custom fields. The AI interprets the request and modifies the CRM.

**Why this is Tier 1:** Mistakes don't lose money directly, but they corrupt data quality. Wrong contact info means lost communication. Wrong deal stages mean inaccurate forecasting. Wrong activity logs mean team confusion. These mistakes are fixable but costly in aggregate.

**Ground truth structure:**

Each example includes:
- Sales rep request
- Current CRM state
- Correct data modification
- Any data validation requirements

Examples:
"Create a contact for John Smith at Acme Corp" → Check for duplicates, create record with available info, ask for missing required fields
"Move the Acme deal to closing" → Identify which deal (if multiple Acme deals), update stage, trigger any stage-change workflows, log the change
"Log that I called Sarah yesterday" → Identify which contact (search by name), create activity record with date/time, associate with any open opportunities

**Annotator protocol:**

Two annotators with CRM experience. They verify:
1. Correct entity identification (right contact, right deal, right company)
2. Correct field updates
3. Required vs optional information handling
4. Duplicate prevention

**Confirmation UX:**

The AI confirms actions before executing:

"I'll create a new contact:
Name: John Smith
Company: Acme Corp
Role: (not specified)
Email: (not specified)

Do you want to add role and email now, or create the record with just the name and company?"

This confirmation serves two purposes: verify the AI understood correctly, and prompt for additional information that improves data quality.

**Data validation:**

The system enforces validation rules:
- Email addresses must be formatted correctly
- Phone numbers must match expected patterns
- Required fields must be populated
- Duplicates should be flagged (not automatically blocked — sometimes duplicates are legitimate)

When validation fails, the system explains why and requests correction: "That email format doesn't look right. Could you double-check it?"

**The result:**

The system creates/updates records with 96% accuracy. The 4% error rate is mostly edge cases where entity identification is ambiguous ("John Smith" matches three contacts). Confirmation catches most of these before execution, and the remaining errors are correctable through CRM's built-in edit functions.

Data quality improves because the AI prompts for complete information, reducing the number of sparse records that sales reps would otherwise create manually.

## Subscription Management Example

A third Tier 1 scenario: an AI that handles subscription plan changes for a SaaS product.

**The task:** Users request to upgrade, downgrade, add seats, remove features, or change billing frequency. The AI processes these changes, handling prorations, billing updates, and feature access adjustments.

**Why this is Tier 1:** Billing mistakes upset users and create refund/adjustment work, but they're correctable. If the AI miscalculates a proration, you can issue a credit. If it applies the wrong plan, you can switch them and adjust billing.

**Ground truth structure:**

Each example includes:
- User request
- Current subscription details (plan, billing cycle, add-ons, seats)
- Billing history
- Correct plan change
- Correct proration calculation
- Expected billing impact

Examples:
"I want to upgrade to the Pro plan" → Switch from current plan to Pro, calculate prorated charge for remaining billing period, update feature access, confirm billing impact
"Add 5 more seats" → Increase seat count, calculate prorated charge, update account limits, confirm per-seat pricing
"Switch to annual billing" → Calculate savings, handle mid-cycle transition, apply annual discount, confirm new billing date and amount

**Annotator protocol:**

Two annotators with subscription billing knowledge. They verify:
1. Correct plan identification
2. Accurate proration math
3. Proper feature access updates
4. Clear billing impact communication

Proration calculations are particularly important to get right — users scrutinize billing changes and will dispute errors.

**Confirmation UX:**

```
I'll upgrade you to the Pro plan:

Current plan: Basic ($20/month)
New plan: Pro ($50/month)

You have 15 days remaining in your current billing cycle.
Prorated charge today: $15
Your next bill on March 15: $50

You'll immediately gain access to:
- Advanced analytics
- API access
- Priority support

[Confirm Upgrade] [See Details] [Cancel]
```

This confirmation makes the financial impact crystal clear, reducing disputes and buyer's remorse.

**Error recovery:**

If a user upgrades and immediately regrets it, there's a grace period (24-48 hours) where they can downgrade without penalty. After that, standard downgrade rules apply (effective at next billing cycle). This reversibility window gives users safety without creating abuse risk.

**The result:**

The system processes plan changes with 97% accuracy on billing calculations and 99% accuracy on feature access updates. The small error rate in billing is mostly edge cases around mid-cycle plan stacking (upgrade, add seats, then downgrade). These are caught by confirmation or handled in the grace period.

User satisfaction is high because billing impacts are transparent before changes are made, reducing surprise charges.

## The "Better Get It Right" Principle

Tier 1 isn't life-and-death, but it's not casual either. These are tasks where getting it right matters to your users and your business.

The principle: mistakes don't kill products, but frequent mistakes do. One wrong booking is fixable. Wrong bookings 5% of the time destroys trust.

This means your Tier 1 quality bar should be high — 95%+ accuracy — even though perfection isn't required. You're aiming for "reliable" not "perfect."

## When Mistakes Escalate from Tier 1 to Tier 0

Sometimes a Tier 1 task crosses into Tier 0 territory based on timing or context.

Changing a shipping address a week before delivery? Tier 1 — plenty of time to fix mistakes.

Changing a shipping address an hour before delivery? Tier 0 — there might not be time to correct errors, so wrong address could mean lost package.

Booking a hotel reservation a month out? Tier 1 — errors can be caught and fixed.

Booking a hotel reservation for tonight? Approaching Tier 0 — if you book the wrong hotel and they show up, they might not have alternatives.

Your ground truth and quality standards should account for these timing-based escalations. Tasks with narrow reversibility windows need higher accuracy, more prominent confirmations, and potentially more conservative AI behavior (escalate to human more readily).

## If You Skip This, Here's What Happens

Teams that treat Tier 1 tasks too casually (like Tier 2 or 3) face:

**Death by a thousand cuts:** No single mistake is catastrophic, but frequent mistakes erode trust until users abandon the product.

**Support burden:** Every mistake creates a support ticket. If your AI makes mistakes on 10% of transactions and you process 10,000 transactions per month, that's 1,000 support tickets — more than your team can handle.

**Revenue leakage:** Billing mistakes create refunds and credits. Booking mistakes create cancellations. Order mistakes create returns. The costs add up.

**Reputation damage:** Users don't say "This AI is 90% accurate!" They say "This thing makes mistakes all the time." Perception is shaped by error frequency.

**Competitive disadvantage:** Users switch to competitors whose transactional AI is more reliable.

Teams that treat Tier 1 tasks too rigorously (like Tier 0) face:

**Massive annotation costs:** Tier 0 rigor for high-volume transactional tasks burns through budget fast.

**Shipping delays:** Achieving Tier 0 quality on Tier 1 tasks slows development to a crawl.

**Over-engineered UX:** Too much confirmation and verification friction annoys users for tasks that don't warrant it.

**Wasted resources:** Expert annotators spending time on booking modifications when they should be focusing on actual high-risk tasks.

The sweet spot is Tier 1 standards: high accuracy with clear confirmation, two-annotator review, representative edge case coverage, and structured audit logging. Rigorous enough to maintain trust, efficient enough to scale.

Next, we'll look at Tier 2, where the focus shifts from transactional correctness to advisory helpfulness, and the ground truth standards change accordingly.
