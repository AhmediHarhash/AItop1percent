# Chapter 3 — Kubernetes at Scale: Multi-Tenancy, Control Plane, and Governance

The distance between "one team's Kubernetes cluster running AI workloads" and "the company's AI platform serving every team" is not a scaling problem — it is a governance problem wearing infrastructure clothes. The moment a second team wants GPU access, you face questions that no amount of YAML can answer. Who gets priority when capacity is constrained? How do you prevent one team's runaway training job from starving another team's production inference? How do you enforce cost accountability when a single pod can burn through hundreds of dollars per hour? These are organizational decisions that manifest as scheduling policies, resource quotas, and namespace boundaries. Get them wrong and your platform becomes a political battleground. Get them right and teams stop fighting over GPUs and start building products.

The control plane itself becomes a bottleneck at scales that web workloads never reach. AI jobs create and destroy pods at rates that stress the API server. Custom resources for training jobs, serving endpoints, and queued workloads multiply the object count. Etcd — the backing store for all cluster state — hits write throughput limits that your web-services cluster never approached. And cluster upgrades, which are already nerve-wracking for stateless workloads, become high-wire acts when GPU drivers, CUDA toolkits, and device plugins all need to remain compatible across the transition. A version mismatch that would cause a graceful error in a web service causes a hard crash in a GPU workload, often with no useful error message.

This chapter covers what breaks when Kubernetes graduates from a team tool to an enterprise AI platform — and how the organizations that run AI at serious scale have solved the multi-tenancy, control plane, upgrade, and governance challenges that no tutorial prepares you for.

---

## What This Chapter Covers

- **3.1** — Cluster multi-tenancy for AI
- **3.2** — Quota enforcement as governance
- **3.3** — The Kubernetes control plane at scale
- **3.4** — Cluster upgrades without outages
- **3.5** — Cluster federation and multi-cluster management
- **3.6** — Capacity fragmentation
- **3.7** — Preemption policy as organizational politics
- **3.8** — Topology-aware scheduling

---

*The first subchapter tackles the foundational multi-tenancy question: how to give every team fair access to GPU resources without turning your platform team into a help desk that manually arbitrates every scheduling conflict.*
