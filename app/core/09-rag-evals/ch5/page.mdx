# Chapter 5 â€” Context Assembly and Generation

You have retrieved the right documents. Now you must assemble them into a prompt that the model can use to generate a grounded answer. This is context assembly, and it is where retrieval meets generation. Context assembly decides what to include, in what order, with what instructions, and under what constraints. The quality of your answer depends as much on how you pack context as on what you retrieve.

This chapter teaches you how to construct prompts from retrieved documents, how to filter and rank chunks within the context window, how to enforce grounding and citation requirements, and how to handle edge cases like conflicting sources or unanswerable queries. Context assembly is the bridge between retrieval and generation, and in 2026 it is a distinct engineering discipline with its own best practices and failure modes.

Packing is the process of fitting retrieved chunks into the model's context window. Context windows in 2026 range from 8k to 200k tokens, but longer contexts increase latency and cost. Packing requires ordering chunks by relevance, truncating or summarizing long chunks, and leaving room for the query and instructions. Naive packing by concatenation often wastes tokens on redundant or irrelevant content. You will learn how to pack efficiently without losing critical information.

Filtering removes low-quality or irrelevant chunks before packing. Even top-ranked chunks may contain boilerplate, disclaimers, or off-topic content. Filtering can use relevance thresholds, diversity pruning, or content classifiers to exclude poor chunks. Aggressive filtering reduces noise but risks excluding marginal but useful information. You will learn how to tune filtering to balance precision and recall within the context window.

Prompt construction defines how chunks are presented to the model. Common patterns include chunk numbering for citation, source attribution before each chunk, and explicit grounding instructions. The prompt must also specify output format, tone, and constraints like answer length or required citations. Poor prompt construction leads to hallucination, ignored context, or off-format responses. You will learn how to design prompts that maximize grounding and minimize hallucination.

Citation is the mechanism by which answers reference specific sources. Citations can be inline with chunk IDs, footnoted with source titles, or linked with URLs. Citation requirements vary by use case: customer support may need source links, legal research may need pinpoint citations, and creative writing may need no citations at all. Enforcing citation in generation requires explicit instructions and output parsing. You will learn how to prompt for citations and how to validate citation correctness.

Faithfulness is the property that every claim in the answer is supported by retrieved context. Faithfulness is distinct from correctness: a faithful answer can be wrong if the retrieved context is wrong. Enforcing faithfulness requires instructing the model to stay grounded, penalizing extrapolation, and validating output against context. You will learn how to measure faithfulness and how to tune generation to maximize it.

Synthesis is the process of combining information from multiple chunks into a coherent answer. Synthesis requires resolving redundancy, merging complementary facts, and ordering information logically. Naive concatenation produces disjointed answers. Effective synthesis requires the model to understand relationships between chunks. You will learn how to prompt for synthesis and when to use multi-step reasoning.

Contradictions arise when retrieved chunks contain conflicting information. Contradictions can reflect data quality issues, versioning problems, or genuine disagreement in sources. The model must either reconcile contradictions, acknowledge them explicitly, or defer to trusted sources. Ignoring contradictions produces misleading answers. You will learn how to detect contradictions and how to instruct the model to handle them.

Abstention is the act of refusing to answer when the retrieved context is insufficient. Abstention is critical for trustworthy RAG because hallucination often occurs when the model tries to answer unanswerable queries. Teaching the model to say "I don't know" or "The provided context does not contain this information" requires explicit instructions and examples. You will learn how to prompt for abstention and how to measure abstention rates.

Streaming allows the model to generate answers incrementally as tokens are produced, improving perceived latency. Streaming is standard in 2026 for user-facing applications but complicates citation and validation. Citations must be inserted as generation proceeds, and faithfulness checks must happen post-generation. You will learn how to implement streaming RAG without sacrificing grounding guarantees.

Multi-step generation decomposes complex queries into sub-questions, retrieves for each, then synthesizes a final answer. Multi-step RAG is used for research tasks, comparative analysis, and questions that require aggregating information from disparate sources. Each step adds latency and cost but improves coverage and coherence. You will learn when multi-step generation is necessary and how to orchestrate it efficiently.

Structured output forces the model to respond in a specific format like JSON, Markdown tables, or enumerated lists. Structured output is required for programmatic consumption, data extraction, and integrations. Enforcing structure requires schema-aware prompting and output validation. You will learn how to prompt for structured output and how to parse and validate responses.

Answerability detection determines whether a query can be answered using the retrieved context. Unanswerable queries occur when retrieval fails, when the query is out of scope, or when the context is ambiguous. Detecting unanswerability requires comparing the query to retrieved content and assessing coverage. You will learn how to build answerability classifiers and how to integrate them into generation.

Conflict policy defines how the system resolves disagreements between sources. Policies can prioritize trusted sources, defer to recency, aggregate majority opinion, or escalate to human review. The right policy depends on the domain and risk tolerance. You will learn how to encode conflict policies in prompts and how to audit their behavior.

Regulated output enforces constraints like tone, length, language, or prohibited content. Regulated output is required in customer-facing applications, compliance-sensitive domains, and multi-tenant systems. Enforcement happens through prompt instructions, output filters, or fine-tuned models. You will learn how to design output regulations and how to validate compliance.

This chapter is where retrieval meets language. You have the right documents. Now you must use them correctly. Context assembly is not prompt engineering. It is architectural decision-making about grounding, citation, synthesis, and trust. In 2026, the best RAG systems do not just generate. They assemble, validate, and enforce.
