# 10.6 — Dashboard Design for Different Audiences

Most teams build one dashboard for eval metrics and expect it to serve everyone. The engineer wants latency percentiles, per-model breakdowns, and links to individual eval run logs. The product manager wants pass rate trends, user-impact summaries, and cost-per-feature visibility. The executive wants a single number that says whether the AI system is meeting its goals. One dashboard cannot serve all three. The engineer finds the exec view too shallow. The exec finds the engineering view incomprehensible. The product manager opens the dashboard, sees a wall of charts, and closes it without finding the answer they needed. The dashboard exists, but it is not used, because it was designed for no one in particular and therefore serves no one well.

**Dashboard design** is not about displaying all available data. It is about matching information density, granularity, and decision context to the audience. An effective eval dashboard strategy has at least three layers — an executive summary view, a product and operations view, and a deep engineering and debugging view. Each layer shows the same underlying metrics but filtered, aggregated, and visualized differently based on what that audience needs to decide or act on. When each role has a dashboard that answers their questions without overwhelming them with irrelevant detail, the dashboard becomes a decision-making tool instead of a data graveyard.

## The Executive Dashboard: One Page, Three Numbers, Clear Trajectory

Executives do not have time to interpret trend lines or drill into per-task breakdowns. They need to know whether the system is healthy, whether it is improving, and whether there are risks that require their intervention. The **executive dashboard** is a single page with three to five key metrics, each shown as a current value, a seven-day trend, and a status indicator.

**Overall system pass rate** is almost always metric one. Not per-task, not per-model, not per-tier — the aggregate pass rate across all production traffic evaluated in the last seven days. Show it as a percentage with one decimal place, a green-yellow-red status based on SLA thresholds, and a small sparkline showing the thirty-day trend. If the number is green and the trend is flat or rising, the executive knows the system is performing. If the number is yellow or the trend is declining, they know to ask questions.

**Cost efficiency** is metric two. Show cost per query or cost per successful output, compared to the target unit economics. If your product model assumes six cents per query and you are currently spending 6.2 cents, show that as a 3.3% deviation with a yellow indicator. If you are at 5.8 cents, show it as 3.3% under target with a green indicator. The executive does not need to know why cost is up or down — they need to know whether cost is within acceptable bounds and whether the trend is sustainable.

**User-impacting incidents** or **quality events** is metric three. Show the count of critical or high-severity alerts in the last seven days, the count of user-reported issues attributed to AI quality, and the mean-time-to-resolution for incidents. This gives the executive a sense of operational stability. A system with zero incidents and declining pass rate is a time bomb. A system with two incidents that were resolved in under an hour and stable pass rate is healthy even if not perfect.

Some dashboards add **deployment velocity** — how many model updates or prompt changes were deployed in the last thirty days — and **coverage confidence** — the percentage of production traffic that is actively evaluated. These are optional but useful for executives who want to understand whether the team is iterating effectively and whether the metrics they are seeing represent the full picture or just a sample.

The executive dashboard has no drill-down. No per-task breakdowns, no latency percentiles, no raw logs. If the executive wants more detail, they ask the product or engineering lead, who has access to the next layer. The executive dashboard is a health check, not a diagnostic tool. It answers the question "should I be worried?" in under ten seconds.

## The Product and Operations Dashboard: Segmentation, Trends, and Impact

Product managers and operational leads need more granularity than executives but less than engineers. They need to understand **which parts** of the system are performing well and which are struggling, so they can prioritize roadmap decisions and resource allocation. The **product dashboard** is organized around user-facing features, task types, or customer segments, not around models or infrastructure.

**Per-feature quality metrics** are the core. If your AI system supports five distinct features — document summarization, Q&A, classification, generation, and retrieval — the product dashboard shows pass rate, latency, and cost for each feature separately. This lets the product manager see that summarization is performing at 97% while Q&A is at 89%, which immediately suggests where to focus improvement efforts.

**Per-tier performance** is another key view. Show Tier 1, Tier 2, and Tier 3 task performance side by side. If Tier 1 is meeting SLA but Tier 3 is failing fifty percent of the time, that is a product decision point — do you invest in improving Tier 3, or do you accept that those tasks are best-effort? The tiering breakdown makes the trade-offs explicit.

**Cost per feature** or **cost per customer segment** helps product managers understand unit economics at a granular level. If one feature costs twelve cents per query while another costs three cents, that affects pricing, packaging, and prioritization. The product manager does not need to know why the first feature is more expensive — they just need to know the magnitude of the difference so they can decide whether to optimize it, price it higher, or limit its usage.

**Trend lines over thirty to ninety days** show whether the system is improving or degrading in areas the product team cares about. A feature that improved from 88% to 94% over two months is a success story to share with stakeholders. A feature that declined from 96% to 91% is a red flag that needs investigation. The product dashboard makes these trends visible without requiring the viewer to interpret raw metric deltas.

**User-impact correlation** is the most valuable and least common metric on product dashboards. If you can correlate eval pass rate with user satisfaction scores, retention metrics, or support ticket volume, show that correlation. A chart that shows eval pass rate on one axis and user NPS on the other axis, with a visible positive correlation, is the evidence that eval quality matters to real outcomes. If the correlation is weak or absent, that is also useful information — it suggests your eval might be measuring the wrong things, or that other factors dominate user experience.

The product dashboard supports drill-down into specific task types or time windows, but not into individual eval runs or model configurations. The product manager can click on a feature to see its quality breakdown by task type, or click on a cost spike to see which week it started, but they cannot and should not see the raw logs or per-example failures. That level of detail is for engineers.

## The Engineering Dashboard: Granularity, Debugging, and Root Cause

Engineers need to **debug**. When an alert fires or a metric degrades, they need to drill from the aggregate down to the individual eval run, the specific failing examples, the model configuration, the prompt version, the retrieval results, and the logs. The **engineering dashboard** is dense, technical, and optimized for investigation speed.

**Per-model, per-prompt, per-configuration breakdowns** are the foundation. Show pass rate, latency, and cost segmented by model version, prompt template, retrieval strategy, and any other variable you are testing or iterating on. This lets the engineer see that GPT-5.2 performs better than Claude Opus 4.5 on classification tasks but worse on open-ended generation, or that Prompt Version 3 improved pass rate but increased latency.

**Per-eval-suite results** are critical. If you run multiple eval suites — one for core tasks, one for edge cases, one for safety, one for regression — show each suite's results separately. The engineer needs to know whether a pass rate drop is global or isolated to a specific suite. A drop in the edge-case suite is less urgent than a drop in the core suite. A drop in the safety suite is more urgent than either.

**Latency percentiles and distributions** are shown in full detail. Median, p75, p95, p99, and max latency, segmented by task type, model, and infrastructure path. The engineer investigating a latency regression needs to see whether the p99 spiked while the median stayed flat, which suggests a tail-latency problem, or whether the entire distribution shifted, which suggests a systemic slowdown.

**Failure mode breakdowns** are the key to debugging quality regressions. If pass rate drops from 95% to 90%, the aggregate number does not tell you why. The engineering dashboard shows the distribution of failure modes — fifteen percent factual errors, ten percent formatting errors, five percent refusals, twenty percent hallucinations. The engineer can click on "factual errors" and see a sample of failing examples, the eval criteria that triggered the failure, and the model outputs that were flagged. This turns a vague "quality is down" alert into a concrete hypothesis about what changed.

**Annotations and event timelines** are essential for correlation. Every deployment, configuration change, data refresh, or infrastructure update should appear as a marker on the trend chart. The engineer sees a latency spike and immediately notices it coincides with a prompt update two hours earlier. That correlation is not proof, but it is a strong starting hypothesis. Without annotations, the engineer is left guessing what might have caused the change.

**Links to raw data** are the final layer. From the dashboard, the engineer can click through to the full eval run logs, the input-output pairs, the model API traces, and the retrieval results. This is the debugging layer. The dashboard surfaces the anomaly. The raw data shows the evidence. The engineer does not live in the raw data — they use the dashboard to identify the anomaly, then drill into the data to understand it.

The engineering dashboard is not designed for readability by non-engineers. It is dense, technical, and assumes the viewer knows what p95 latency means, what a retrieval precision score represents, and how to interpret a per-model breakdown. That is fine. This dashboard is a tool for investigation, not communication. The engineer uses it to find the root cause, then communicates the finding to product or exec using their respective dashboards or a written summary.

## Information Density and Cognitive Load

A common mistake is packing every possible chart onto a single dashboard page because the designer wants to avoid pagination or drill-down. The result is **cognitive overload** — the viewer sees twenty charts and does not know where to look. Effective dashboards manage **information density** by showing only the metrics relevant to the immediate question.

For the executive dashboard, density is minimal. Three to five top-level metrics, large fonts, high contrast, minimal visual clutter. The entire dashboard fits on one screen without scrolling. The viewer can absorb the status in under ten seconds.

For the product dashboard, density is moderate. Six to twelve charts per page, organized by feature or segment. Each chart has a title, a current value, and a trend line. The viewer can scan the page in thirty seconds and identify which areas need attention.

For the engineering dashboard, density is high. Twenty to forty charts, tabs for different subsystems, drill-down links, filters for time range and configuration. The viewer expects complexity and is equipped to navigate it. But even here, the layout should have hierarchy — the most critical metrics at the top, secondary metrics below, debugging details accessible via click-through.

**Progressive disclosure** is the design pattern that makes high-density dashboards usable. Start with the summary. If the viewer wants detail, they click to expand or navigate to a sub-page. The engineer does not see all forty charts at once. They see the top six, then expand into per-model breakdowns, then drill into failure mode distributions, then click through to raw logs. Each step reveals more detail, but the detail is hidden until requested.

## The Dashboard That Gets Used Is the Dashboard That Answers Questions

A dashboard is only valuable if it shortens the time from question to answer. The executive asks "is the system healthy?" and gets an answer in ten seconds. The product manager asks "which feature is underperforming?" and gets an answer in thirty seconds. The engineer asks "why did pass rate drop?" and gets a hypothesis in two minutes. If the dashboard does not answer the question that viewer came to answer, it will not be used.

This means **user testing dashboards** the same way you would user-test a product feature. Watch an executive use the exec dashboard. Do they understand the metrics without explanation? Do they know what to do if a metric is yellow? If not, revise. Watch a product manager investigate a feature performance question. Do they find the breakdown they need, or do they give up and ask an engineer? If they give up, the dashboard failed.

Watch an engineer debug a quality regression. Do they find the failure mode breakdown and example drill-down within two minutes, or do they bypass the dashboard and go straight to raw logs? If they bypass, the dashboard is not providing value. The goal is not to have a beautiful dashboard. The goal is to have a dashboard that the team relies on because it makes their job faster and their decisions more informed.

When dashboards are designed for specific audiences with specific questions, the same eval data serves multiple purposes. The executive sees confidence in system health. The product manager sees where to prioritize. The engineer sees how to debug. The metrics are the same, but the views are different, and that difference is what makes the dashboard system effective across the organization. The next step is making those metrics more trustworthy by visualizing confidence intervals and statistical significance, so every viewer knows not just what the number is, but how much to trust it.

---

*Next: 10.7 — Confidence Intervals and Statistical Significance in Reporting*
