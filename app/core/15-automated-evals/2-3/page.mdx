# 2.3 â€” Format Compliance: Structure, Length, and Patterns

Format compliance is the layer of validation that sits between schema correctness and semantic quality. Schema validation confirms the data is structured correctly. Semantic evals confirm the content is meaningful and accurate. Format compliance confirms the output looks right: correct length, correct visual structure, correct surface-level patterns. These checks are deterministic, fast, and catch an entire class of user-facing failures that schema validation misses.

A response can pass schema validation and still violate format requirements. A product description might be correctly typed as a string but exceed the 500-character limit your UI can display. A markdown document might be valid markdown but missing the required heading structure your documentation system expects. A code snippet might be syntactically correct but formatted without proper indentation. Format compliance catches these issues before they reach users or downstream systems.

## Length Constraints as Hard Boundaries

Length limits are the simplest and most common format compliance rule. A response must be between a minimum and maximum length. The length might be measured in characters, words, tokens, lines, or paragraphs depending on the use case. The validation rule is deterministic: count the units, compare to the threshold, pass or fail.

A customer support system generates responses that are delivered via SMS. SMS messages have a hard limit of 1,600 characters including spaces. The system specifies a 1,500-character max to leave room for metadata. The format compliance layer counts characters. If the response exceeds 1,500, it fails validation. The system retries with an explicit instruction to shorten the response or escalates to a human agent. Without this check, responses over the limit would be truncated mid-sentence when delivered, creating a broken user experience.

A content generation system produces blog post summaries for a homepage feed. Each summary must be between 80 and 120 words. Summaries shorter than 80 words feel incomplete. Summaries longer than 120 words overflow the UI component. The format compliance layer counts words. If a summary is 65 words or 145 words, it fails validation. The system regenerates. Over time, the team refines the prompt to hit the target range more consistently. But the validation layer remains as a safety net. It prevents broken UI from reaching production.

Length constraints are especially critical for voice systems. A voice assistant generates responses that are spoken aloud. Responses over 30 seconds feel too long. Responses under 5 seconds feel abrupt. The format compliance layer estimates speech duration based on word count and speaking rate. A 200-word response at 150 words per minute takes 80 seconds. The validation fails. The system retries with a length constraint. The user hears a concise, appropriately-sized response instead of a rambling monologue.

## Structural Requirements for Documents

Document-based outputs often require specific structural elements. A report must include an executive summary, a findings section, and a recommendations section. A legal brief must include a statement of facts, a legal argument, and a conclusion. A technical spec must include a problem statement, a proposed solution, and success criteria. Format compliance verifies that all required sections are present and correctly ordered.

A financial analysis system generates quarterly reports. The required structure is: executive summary, revenue analysis, expense analysis, key metrics, forward-looking statements, and risk factors. Each section is marked with a level-two heading in markdown. The format compliance layer parses the markdown, extracts all level-two headings, and checks for the presence of each required section. If any section is missing, the validation fails. If sections appear in the wrong order, the validation fails. The system regenerates with a clarified prompt specifying the exact structure.

This is not semantic validation. The compliance layer does not check whether the revenue analysis is accurate or whether the risk factors are comprehensive. It only checks that the sections exist and appear in the expected order. A human or LLM judge evaluates the content. The format compliance layer ensures the structure is correct.

Structural validation also applies to conversational outputs. A customer service interaction might require a specific flow: greeting, acknowledgment of the issue, proposed solution, confirmation question. The format compliance layer checks that each element is present. If the model skips the acknowledgment or the confirmation, the validation fails. The system retries. The final response follows the expected conversational structure.

## Pattern Matching for Surface-Level Correctness

Pattern matching uses regular expressions or string operations to verify that specific elements follow expected formats. Citations must match a specific pattern. Email addresses must contain an at-sign and domain. Phone numbers must follow a regional format. URLs must start with a protocol. Dates must be ISO 8601 compliant. These are surface-level checks. They do not verify that a citation is real or that a phone number is active. They verify that the output looks correct.

A research assistant generates summaries with inline citations. Each citation must follow the format: Author Last Name, Year. The format compliance layer uses a regex pattern to find all citations and verify they match the pattern. If a citation appears as "Smith" without a year or "John Smith, 2025" with a first name, the validation fails. The system retries with an example showing the correct format. The final output has consistently formatted citations.

A contact information extractor pulls names, emails, and phone numbers from unstructured text. The format compliance layer validates that extracted emails match the pattern: local part, at-sign, domain with at least one dot. If the model extracts "john.doe at example dot com" as an email, the pattern match fails. If it extracts "johndoe@example" without a top-level domain, the pattern match fails. The system flags the extraction as uncertain and routes it for human review.

Pattern matching is deterministic and fast. A regex check runs in microseconds. It catches malformed outputs before they propagate downstream. It does not replace semantic validation. A citation that matches the pattern "Smith, 2025" can still be a hallucinated reference. But at least it looks like a citation. Downstream systems can parse it. Users can read it. The pattern match ensures surface-level consistency.

## Markdown and HTML Structure Validation

Systems that generate markdown or HTML need format compliance layers that verify structural validity. A markdown document should have properly nested headings, correctly formatted lists, and valid links. An HTML snippet should have balanced tags, properly escaped special characters, and valid attributes. These checks prevent broken rendering.

A documentation generation system produces markdown files for a static site generator. The site generator requires that every document starts with a level-one heading and uses only level-two and level-three headings for subsections. The format compliance layer parses the markdown and checks the heading hierarchy. If a document starts with a level-two heading or jumps from level-one to level-four, the validation fails. The system regenerates with a clarified prompt.

An email generation system produces HTML emails. The format compliance layer validates that all HTML tags are balanced, that no script tags are present for security reasons, and that all image tags include alt text for accessibility. If the model generates an unclosed div tag or includes inline JavaScript, the validation fails. The system retries. The final email renders correctly across all clients and meets security and accessibility standards.

These checks do not evaluate content quality. They ensure the output is structurally sound. A markdown document with perfect heading hierarchy can still have poorly written content. An HTML email with balanced tags can still have broken links. But at least the structure is valid. The content can be rendered. Downstream systems can process it.

## Format Compliance as Pre-Filter for Expensive Evals

Format compliance runs after schema validation and before semantic evals. It filters out outputs that are structurally correct but formatted incorrectly. This reduces the load on expensive LLM-based judges and human reviewers. A response that fails format compliance is rejected before you pay for a model-based quality check.

A legal document generation system produces contracts. Schema validation confirms the contract has all required fields. Format compliance confirms the contract follows the expected structure: heading hierarchy, section numbering, clause formatting. If the contract passes both, it moves to semantic validation where an LLM judge checks for legal accuracy and completeness. If the contract fails format compliance, it never reaches the LLM judge. The system retries. This saves money and reduces latency. The pipeline only invokes expensive evals on outputs that meet basic structural and format standards.

The cost savings are significant at scale. A system generating 10,000 documents per day with a 5% format compliance failure rate rejects 500 documents before semantic eval. If semantic eval costs 2 cents per document, format compliance saves ten dollars per day or 3,650 dollars per year. Small per-unit costs compound quickly at high volume. Format compliance is free. It runs in milliseconds. It pays for itself immediately.

## Length-Based Fallback Strategies

When a response fails a length constraint, the system has several fallback options. It can retry with an explicit length instruction. It can truncate the response intelligently at a sentence or paragraph boundary. It can escalate to a human. The right choice depends on the cost of failure and the tolerance for imperfection.

A news summarization system generates summaries that must be under 100 words. If a summary is 120 words, the system retries with an instruction: "Rewrite this summary to be under 100 words while preserving the key points." If the retry succeeds, the summary enters production. If the retry also exceeds 100 words, the system attempts intelligent truncation: find the last complete sentence before the 100-word mark and cut there. If truncation would remove critical information, the system escalates to a human editor.

A voice assistant generating spoken responses has a hard limit of 150 words for user patience. If a response is 200 words, the system does not truncate. Truncation could cut off critical information or create an incomplete answer. Instead, the system retries with a prompt adjustment: "Answer in under 150 words." If the retry still exceeds the limit, the system uses a multi-turn response: "Here's the first part of your answer. Would you like me to continue?" The user stays in control. The length constraint is respected.

Fallback strategies are pre-defined. The system does not improvise. Each failure mode has a defined response. This makes the pipeline predictable and debuggable. When a length constraint fails, you know exactly what the system will do next.

## Combining Multiple Format Rules

Format compliance often involves multiple rules applied sequentially. A response must pass all rules to proceed. A single failure rejects the entire response. This ensures that outputs meet every format requirement before entering production.

A product recommendation system generates recommendations with four format requirements. First, the recommendation must be between 50 and 150 words. Second, it must include exactly three bullet points formatted as markdown list items. Third, it must include at least one numeric comparison like "20% faster" or "30% cheaper." Fourth, it must not include any markdown links or HTML tags. The format compliance layer checks all four. If word count is 45 or 160, validation fails. If there are two bullet points or four, validation fails. If no numeric comparison appears, validation fails. If a markdown link is present, validation fails. The response must satisfy all constraints simultaneously.

This multi-rule approach is common in production systems. Outputs have multiple format requirements. The compliance layer enforces all of them. The alternative is to check one rule, retry, check the next rule, retry again. That is inefficient. Better to check all rules once and reject outputs that fail any check.

## The Format-First Debugging Strategy

When a production system generates outputs that users report as "broken" or "wrong," format compliance failures are often the root cause. A UI component expects 200 characters and receives 500. A parser expects markdown headings and receives plain text. A voice system expects 20 words and receives 200. These are not semantic failures. They are format failures. The content might be correct, but the format is wrong.

Format compliance logs make debugging faster. A logged failure specifies which rule was violated and what value triggered the error. "Length constraint failed: expected max 200 characters, received 487 characters" is actionable. The team sees the issue immediately. They adjust the prompt to include an explicit length instruction. The failure rate drops. Without format logging, the team would see user complaints, investigate the semantic quality, find nothing wrong, and remain confused. The format compliance layer surfaces the root cause.

This is why format compliance belongs in every eval pipeline. It catches a class of failures that are invisible to schema validation and irrelevant to semantic evals but critical to user experience. It runs fast. It costs nothing. It makes debugging easier. It prevents broken UI, broken parsers, and broken user experiences.

The next layer of deterministic evals covers citation and reference checks, where rules verify that outputs include the evidence they claim to provide.

