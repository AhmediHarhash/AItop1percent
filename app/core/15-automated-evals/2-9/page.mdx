# 2.9 — Combining Rules into Composite Checks

In early 2025, a healthcare documentation system deployed 68 deterministic rules for clinical note generation. Each rule was simple: check for presence of patient identifier, verify timestamp format, confirm diagnosis code structure, validate medication dosage ranges, ensure allergy section exists. Each rule passed or failed independently. The system blocked any note that failed any rule. Within two weeks, the block rate reached 34%. Clinicians were furious. A note that was medically sound and contained all required information would be blocked because a timestamp used 24-hour format instead of 12-hour format with AM/PM. Another note was blocked because it listed allergies as "None known" instead of "NKDA" — both were correct, one matched the rule, one did not. The rules were individually correct. The combination was unusable. The team had built 68 independent gates and chained them with AND logic. A single borderline failure killed the entire output.

This is the Rule Explosion Problem: every additional rule multiplies decision branches, and every branch is a place where valid outputs die or invalid outputs slip through.

## AND Logic and the Compounding Failure Rate

When you combine rules with AND logic, the output must pass every rule to succeed. If you have three rules and each has a 5% failure rate, the combined pass rate is not 95% — it is 0.95 times 0.95 times 0.95, which equals 85.7%. Add a fourth rule with a 5% failure rate and the pass rate drops to 81.5%. Add ten rules and the pass rate is 59.9%. The failure rates compound. A legal contract generator used AND logic across twelve formatting and content rules. Each rule was well-calibrated with a false positive rate under 3%. The combined false positive rate was 31%. Nearly one in three valid contracts was blocked because at least one rule misfired. The team had optimized each rule in isolation and ignored the combinatorial effect.

**AND logic is correct when all rules are mandatory.** A financial transaction system required every payment instruction to include an account number, a routing number, an amount, and a recipient name. Missing any one of these made the instruction unprocessable. The four rules were combined with AND logic. The failure rate was 6%, and every failure was legitimate — the model had genuinely omitted required information. AND logic worked because the requirements were non-negotiable. You cannot process a payment without an account number. The rule is not advisory. The threshold is not tunable. The output either meets the spec or it does not.

The mistake is using AND logic when some rules are hygiene checks and others are critical failures. A content moderation system combined toxicity detection, PII detection, and formatting rules with AND logic. An output failed if it scored above 0.3 on toxicity, contained any PII pattern, or violated formatting rules like ending without punctuation. Toxicity and PII detection were critical — those failures should block the output. Formatting failures were cosmetic — they should trigger a warning, not a block. The system treated all three as equal. A customer support response that was empathetic, accurate, and helpful was blocked because it ended with a dash instead of a period. The rule was correct. The enforcement was not. The team split the rules into two tiers: critical rules used AND logic and blocked outputs, hygiene rules used soft thresholds and flagged warnings.

## OR Logic and the Coverage Trade-Off

OR logic passes the output if any rule passes. This is rare in evaluation but common in fallback systems. A content generation pipeline had three acceptance criteria: semantic similarity to the reference answer above 0.8, keyword match score above 0.7, or exact phrase match for required disclosures. If any of the three passed, the output was accepted. The system was designed to handle edge cases where one metric failed but the output was still valid. A legal disclaimer might not score high on semantic similarity to the reference because the wording was different, but if it contained the exact required phrase, it passed. OR logic created multiple paths to success.

**OR logic lowers precision.** A spam detection system used three classifiers: a keyword-based rule, a regex pattern for known spam phrases, and an LLM-based intent classifier. If any classifier flagged the message as spam, it was blocked. The keyword rule had 8% false positives. The regex rule had 6% false positives. The LLM classifier had 3% false positives. Combined with OR logic, the false positive rate was 15% because a message could trip any one of the three. The system over-blocked. The team switched to AND logic for the keyword and regex rules — both had to agree — and used the LLM classifier as a tiebreaker. The false positive rate dropped to 4%, and the false negative rate stayed below 2%. OR logic had prioritized recall over precision. AND logic balanced both.

**OR logic works for redundancy.** A document processing system required every invoice to include either a PO number or a contract reference number. Most invoices had one or the other. Some had both. The eval checked for presence of either identifier. If neither was found, the invoice was flagged for manual review. OR logic was appropriate because the requirement was "at least one," not "all." The system flagged 9% of invoices, and manual review found that 7% were missing both identifiers — legitimate failures — and 2% had identifiers in non-standard formats the regex missed. The OR logic was correct. The regex patterns needed tuning.

## Weighted Rule Scoring

Binary pass/fail logic is fragile. Weighted scoring is more forgiving. Instead of blocking an output that fails one rule, you assign each rule a weight and compute a total score. If the total exceeds a threshold, the output passes. A resume screening system used weighted scoring across eight criteria: presence of required skills, years of experience in range, education level match, location compatibility, salary expectation within budget, resume formatting quality, writing clarity, and keyword density. Each criterion was scored 0 to 10. The weights were: required skills 30%, experience 25%, education 15%, location 10%, salary 10%, formatting 5%, writing 3%, keywords 2%. A candidate who scored poorly on formatting but strongly on skills and experience could still pass. The threshold was set at 65 out of 100. Candidates above 65 were interviewed. Candidates below 50 were auto-rejected. Candidates between 50 and 65 were reviewed by a recruiter. The weighted system allowed trade-offs. A candidate with perfect skills but mediocre formatting scored higher than a candidate with mediocre skills but perfect formatting.

**Weight tuning is preference encoding.** The resume system initially weighted education at 25%, the same as experience. After six months, hiring managers reported that experienced candidates without degrees were outperforming recent graduates with degrees. The team dropped education weight to 15% and raised experience weight to 25%. The threshold stayed at 65, but the composition of who passed changed. More experienced candidates without degrees crossed the threshold. Fewer recent graduates with minimal experience passed. The weights encoded what the business valued. Changing the weights changed hiring outcomes without changing the threshold.

**Weighted scoring hides failures.** A contract compliance system used weighted scoring across twelve legal requirements. Each requirement was scored 0 to 10. The weights were evenly distributed. The threshold was 70 out of 120. A contract could fail three requirements entirely — scoring 0 on each — and still pass if it scored 8 or higher on the other nine. Legal reviewed a sample of passing contracts and found 14% were missing critical clauses. The clauses were in the three failed requirements. The contract passed the eval but failed legal review. Weighted scoring had allowed critical failures to be offset by non-critical successes. The team switched to a hybrid model: four requirements were mandatory and enforced with AND logic, and the remaining eight used weighted scoring. A contract had to pass all four mandatory checks and score above 60 on the weighted checks. The failure rate jumped to 19%, but every blocked contract was a legitimate failure. Weighted scoring works when all rules are trade-offs. It fails when some rules are non-negotiable.

## Rule Priority and Short-Circuiting

When you have dozens of rules, evaluation time adds up. If each rule takes 5 milliseconds and you have 40 rules, evaluation takes 200 milliseconds. If the first rule fails and you are using AND logic, the other 39 rules do not matter — the output already failed. **Short-circuiting** stops evaluation as soon as the outcome is determined. A content moderation pipeline had 23 rules ordered by speed and severity. The first rule checked for PII using regex — 2 milliseconds, critical failure. The second rule checked for profanity using keyword matching — 3 milliseconds, critical failure. If either failed, evaluation stopped and the output was blocked. If both passed, the system ran fifteen more rules for formatting, tone, and policy compliance. The average evaluation time was 47 milliseconds because 22% of outputs failed one of the first two rules and never reached the slower checks. Short-circuiting saved 150 milliseconds per blocked output.

**Rule ordering matters.** A document classification system had twelve rules. The team initially ordered them alphabetically by rule name. Then they profiled evaluation time and found that three rules accounted for 80% of total runtime — all three used LLM-based classification. The other nine rules were regex and keyword checks that ran in under 10 milliseconds combined. The team reordered the rules: fast rules first, slow rules last. Short-circuiting was enabled. If any of the nine fast rules failed, the three slow rules never ran. Average evaluation time dropped from 420 milliseconds to 180 milliseconds. The pass/fail outcomes did not change. The speed did.

**Priority encoding** determines which rule wins when multiple rules conflict. A pricing validation system had a rule that discounts must not exceed 30% and another rule that certain promotional SKUs could have discounts up to 50%. Both rules applied to the same product during a promotion. The eval framework needed to know which rule took precedence. The team assigned priorities: promotional rules priority 1, standard rules priority 2. When rules conflicted, the higher-priority rule won. The promotional SKU was allowed a 45% discount. Without priority encoding, the system would have either blocked the valid discount or ignored the 30% cap on non-promotional products. Priority turns rule conflicts into rule hierarchies.

## Rule Dependency Management

Some rules depend on others. A clinical note generator had a rule that every note must include a diagnosis section and a separate rule that the diagnosis section must contain at least one ICD-10 code. The second rule only makes sense if the first rule passed. If the diagnosis section is missing, checking for ICD-10 codes is meaningless. The eval framework needed to encode the dependency: rule 2 depends on rule 1. If rule 1 fails, rule 2 is skipped. A naive implementation would run rule 2 anyway, fail to find the diagnosis section, and report "missing ICD-10 code" as a second failure. This is confusing. The root cause is one failure — missing diagnosis section — but the system reports two. The dependencies were explicit in the eval config: rule 2 has a precondition that rule 1 passed.

**Dependency graphs** prevent redundant failures. A contract analysis system had 34 rules with 18 dependencies. The framework built a directed acyclic graph of rule execution order. A rule only ran if its preconditions were satisfied. If a root rule failed, all dependent rules were skipped. The system reported failure causes without noise. A contract missing a signatures section would fail the signatures-presence rule, and twelve downstream rules that validated signature formatting, date accuracy, and witness requirements were never evaluated. The failure report showed one root cause, not thirteen cascading failures.

**Circular dependencies break evaluation.** A team building a legal document validator wrote two rules: rule A required that every liability clause reference the indemnity section, and rule B required that every indemnity section reference the liability clause. Both rules depended on each other. The eval framework detected the cycle and rejected the configuration. The team rewrote the rules as a single composite rule: verify that liability and indemnity sections cross-reference each other. Circular dependencies indicate poorly decomposed requirements. The fix is not cleverer dependency resolution — it is better rule design.

## The Explosion of Rule Combinations

The Rule Explosion Problem is not just about compounding failure rates. It is about cognitive load. A team maintaining 70 deterministic rules across formatting, content, policy, and compliance had no mental model of how the rules interacted. A product manager asked, "If I add a rule that blocks outputs longer than 300 words, what percentage of current outputs will fail?" Nobody knew. The rules were independent. The interactions were emergent. The team ran the new rule on 10,000 historical outputs and found it would have blocked 19%. They ran the same experiment for three other proposed rules. Each would have blocked 8% to 15% of outputs in isolation. Combined, the four rules would have blocked 48% of outputs because failure rates stacked. The team added two of the four rules and rejected the others. Rule addition had become a design decision, not a configuration change.

**Rule audits** prevent entropy. Every six months, the team reviewed the full rule set. They identified rules that had not fired in 60 days — rules that caught failures so rare they added complexity without value. They identified rules with false positive rates above 5% — rules that were miscalibrated or poorly specified. They identified overlapping rules — two rules that caught the same failure in different ways. The audit reduced the rule set from 70 to 52 without reducing failure coverage. The remaining rules were better calibrated, better documented, and easier to reason about. Rule sets grow by accretion. Audits prune dead weight.

**Composite checks** become their own abstraction. Instead of managing 52 independent rules, the team grouped them into five composite checks: PII and security, policy compliance, formatting and structure, content quality, and required disclosures. Each composite check was a weighted combination of underlying rules. The product team no longer reasoned about individual rules — they reasoned about the five checks. A new feature required adjusting the content quality check. The team tuned weights within that check without touching the other four. The abstraction reduced cognitive load. The underlying rules still existed. The interface to them was simplified.

The fundamental limitation of rule-based evaluation is that rules are brittle. They catch what you anticipated. They miss what you did not. When the failure modes evolve faster than the rules, you need a different approach, and that is when deterministic checks give way to model-based evaluation.

