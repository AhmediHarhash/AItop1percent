# Chapter 6 — Behavioral and System-Level Evals

Text-based evaluation misses half of what matters for agents and multi-step systems. An agent that produces well-written responses but calls the wrong tools has failed. A workflow that generates correct intermediate outputs but never completes the task has failed. A system that loops endlessly or takes destructive actions has failed catastrophically. Behavioral evaluation measures what your system does, not just what it says. This chapter covers how to detect task completion, measure tool selection accuracy, evaluate multi-step workflows, detect loops and runaway behavior, verify graceful error recovery, and build end-to-end scenario tests that measure the outcomes users actually care about.

---

- 6.1 — Evaluating Behavior, Not Just Text
- 6.2 — Task Completion Detection for Agents
- 6.3 — Tool Selection Accuracy Metrics
- 6.4 — Multi-Step Workflow Evaluation
- 6.5 — Error Recovery and Graceful Degradation Checks
- 6.6 — Loop and Infinite Recursion Detection
- 6.7 — Stopping Conditions and Appropriate Termination
- 6.8 — Latency and Performance Behavioral Metrics
- 6.9 — Side Effect Detection: What the System Changed
- 6.10 — End-to-End Scenario Evaluation
- 6.11 — Behavioral Eval Coverage for Agentic Systems

---

*The agent that writes a beautiful explanation while quietly deleting the wrong file has not passed your eval — unless your eval measures what it deleted.*
