# Chapter 3 — Heuristic Evaluations

Heuristics sit between deterministic rules and semantic understanding. They are fast approximations that catch patterns rules cannot see but without the cost or complexity of model-based evaluation. A response that repeats the same sentence five times is probably broken — you do not need an LLM judge to tell you that. A response that is three times longer than typical for the task type might be rambling. A response that contains known refusal phrases might be deflecting instead of helping. Heuristics are blunt instruments, but blunt instruments that run in milliseconds and cost nothing are powerful tools in your eval pipeline. This chapter covers how to design heuristics that catch real failures, how to calibrate them against human judgment, and how to recognize their brittleness before they mislead you.

---

- 3.1 — Heuristics as Early Warning Systems
- 3.2 — Length and Verbosity Detection
- 3.3 — Repetition and Loop Detection
- 3.4 — Refusal and Deflection Pattern Matching
- 3.5 — Keyword and Phrase Presence Signals
- 3.6 — Readability and Complexity Scores
- 3.7 — Sentiment and Tone Heuristics
- 3.8 — Combining Heuristics into Anomaly Scores
- 3.9 — Heuristic Calibration Against Human Judgments
- 3.10 — Heuristic Failure Modes and Brittleness

---

*The heuristic that fires on 2% of outputs and is right 90% of the time is worth more than the perfect eval that costs too much to run on everything.*
