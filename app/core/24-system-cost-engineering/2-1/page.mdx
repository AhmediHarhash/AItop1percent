# 2.1 â€” How Token Pricing Works: Input, Output, and the Price Asymmetry

Every dollar you spend on a large language model is priced in tokens. Not in requests, not in compute hours, not in characters. Tokens. A token is the atomic unit of cost in every commercial LLM API, and until you understand how tokens translate into money, you cannot control what you spend. The pricing model is deceptively simple on the surface: you pay per million tokens consumed, with separate rates for input and output. But buried inside that simplicity is an asymmetry that most teams discover only after their first month's invoice arrives. Output tokens cost three to five times more than input tokens across every major provider. That single fact reshapes how you should design every prompt, every system instruction, and every response format in your entire system.

## What a Token Actually Is

A token is not a word. It is not a character. It is a chunk of text that the model's tokenizer has decided represents a meaningful unit. For English text, one token averages roughly four characters or about three-quarters of a word. The word "understanding" is typically two tokens. The word "cat" is one token. A common punctuation mark like a period or comma is usually its own token. A space before a word often gets grouped with the word itself into a single token. The number "2026" might be one token or two depending on the tokenizer. The key mental model is that one hundred tokens of English text is roughly seventy-five words, or about half a short paragraph.

This approximation breaks in important ways. Code is more token-dense than prose because variable names, operators, and syntax characters each consume tokens that convey less semantic meaning per token than natural language. JSON structures are token-expensive because every brace, bracket, colon, and quotation mark eats a token. A JSON object with five fields might consume thirty to forty tokens just for the structural characters, before any of the actual data gets counted. This matters for cost engineering because every structural token you send or receive costs real money.

The approximation breaks even harder for non-English languages. Tokenizers are trained primarily on English text, which means English words get efficiently compressed into fewer tokens. Other languages do not get the same treatment. The same sentence in Arabic might consume two to three times as many tokens as the English equivalent. Chinese text, despite being semantically dense per character, tokenizes into more tokens per concept because each character often becomes its own token rather than being grouped into multi-character units the way English words are. Korean, Thai, and many South Asian languages face similar inflation. A company operating a customer service system in Thai will pay significantly more per query than an identical system operating in English, not because the model works harder but because the tokenizer is less efficient. This is the **tokenizer tax**, and it falls disproportionately on non-English markets. Newer tokenizers from providers like Google and Alibaba have expanded their vocabularies to reduce this gap. Gemini 3 uses a vocabulary of over 260,000 tokens, compared to roughly 100,000 in older OpenAI tokenizers, which helps compress non-English text more efficiently. But the gap has not disappeared. If your product serves multilingual users, factor the tokenizer tax into every cost projection.

## The 2026 Pricing Landscape

Every major provider prices tokens per million, with separate rates for input and output. Here is where the market sits as of early 2026, described in prose because the numbers themselves tell a story.

OpenAI's GPT-5 charges one dollar and twenty-five cents per million input tokens and ten dollars per million output tokens. GPT-5-mini charges twenty-five cents per million input tokens and two dollars per million output tokens. GPT-5-nano is the budget option at five cents per million input tokens and forty cents per million output tokens. At the frontier, GPT-5 Pro charges significantly more, with output tokens reaching over a hundred dollars per million. The standard GPT-5.1 and GPT-5.2 models maintain the same base pricing as GPT-5 at one dollar twenty-five cents input and ten dollars output per million tokens.

Anthropic's Claude Opus 4.5 and Opus 4.6 charge five dollars per million input tokens and twenty-five dollars per million output tokens. Claude Sonnet 4.5 charges three dollars input and fifteen dollars output per million tokens. Claude Haiku 4.5 charges one dollar input and five dollars output per million. The previous-generation Claude Opus 4 charged fifteen dollars input and seventy-five dollars output per million tokens, making the newer Opus 4.5 a 67% price reduction while delivering better performance.

Google's Gemini 3 Pro charges two dollars per million input tokens and twelve dollars per million output tokens for context windows up to 200,000 tokens. Beyond that threshold, the price doubles to four dollars input and eighteen dollars output. Gemini 3 Flash is substantially cheaper, positioned as a competitor to GPT-5-mini.

On the open-source side, Llama 4 Scout costs roughly fifteen cents per million input tokens and fifty cents per million output tokens through inference providers like Together AI or Deep Infra. Llama 4 Maverick runs about twenty-two cents input and eighty-five cents output. DeepSeek V3.2 is aggressively priced at twenty-eight cents per million input tokens and forty-two cents per million output tokens, with cached input tokens dropping to less than three cents per million.

The spread across the market is enormous. The cheapest option, GPT-5-nano at five cents input, costs one hundred times less per input token than Claude Opus 4.5 at five dollars. The most expensive output pricing, Claude Opus 4 at seventy-five dollars per million, costs nearly two hundred times more than GPT-5-nano output at forty cents. This range is not a quirk. It reflects fundamentally different models serving fundamentally different tasks. The cost engineering challenge is matching the right price tier to the right task.

## The Output Premium: Why Output Tokens Cost More

Here is the fact that restructures how you think about cost: output tokens are three to eight times more expensive than input tokens at every price tier, across every provider. GPT-5 charges eight times more for output than input. Claude Opus 4.5 charges five times more for output. Claude Sonnet 4.5 charges five times more. Gemini 3 Pro charges six times more. Even budget models like GPT-5-nano charge eight times more for output than input. This is not arbitrary margin extraction. It reflects a fundamental computational difference.

When the model processes your input, it can read all input tokens in parallel. The entire prompt, system instruction, and context get processed simultaneously through the transformer layers. This is a matrix multiplication that benefits enormously from GPU parallelism. The hardware is doing what it was built to do: crunching massive parallel computations in a single forward pass.

Output generation is different. The model generates tokens one at a time, sequentially. Each output token depends on every token that came before it, both the input tokens and every output token already generated. The model cannot generate the tenth output token until it has generated the ninth. This sequential dependency means the GPU sits partially idle during generation because it cannot fully parallelize the work. Each token requires its own forward pass through the model. A response of five hundred output tokens requires five hundred sequential computation steps. The hardware utilization during generation is inherently lower than during input processing, which means each output token consumes more wall-clock time and more effective compute per token.

This is why the pricing ratio exists. Providers are not charging a convenience premium on output. They are reflecting the actual cost difference in how input processing and output generation use hardware. Understanding this mechanism changes how you design systems. Every design decision that increases output length, asking for verbose explanations, requesting structured output with repeated field names, generating chain-of-thought reasoning, producing multiple response candidates, multiplies your most expensive cost line. Every design decision that reduces output length while maintaining quality, asking for concise responses, using terse output formats, generating single-candidate responses, directly reduces your highest per-token expense.

This asymmetry is **The Output Premium**, and it is the single most important concept in token economics. A system that sends two thousand input tokens and receives five hundred output tokens is not paying for 2,500 tokens at some average rate. It is paying a low rate on the two thousand and a high rate on the five hundred. Because output is three to eight times more expensive, those five hundred output tokens might account for 60% to 80% of the total cost despite being only 20% of the total token count. Your most expensive tokens are the ones your model writes, not the ones you send it.

## Cached Input Pricing: The Third Price Tier

The input-output split is not the complete picture. In 2025 and 2026, every major provider introduced a third pricing tier: cached input tokens. When your system sends the same prompt prefix repeatedly, providers can cache the key-value computations from the first request and reuse them for subsequent requests. The provider charges less for these cached tokens because they require less computation.

Anthropic charges roughly ten percent of the standard input price for cached reads. If Claude Opus 4.5 input costs five dollars per million tokens, cached input costs about fifty cents per million tokens, a 90% discount. There is a small premium for the initial cache write, typically 25% above the standard input price, but that cost amortizes quickly if the cached prefix is reused even twice.

OpenAI offers automatic caching with a 50% discount on cached input tokens. If GPT-5 input costs one dollar twenty-five cents per million, cached input costs about sixty-three cents. Google offers similar discounts on Gemini models for context caching. DeepSeek's cached input pricing drops to under three cents per million tokens, making repeated queries extraordinarily cheap.

The practical impact is significant. Consider a customer service system where every request includes an 800-token system prompt. That system prompt is identical across every request. Without caching, you pay the full input price on those 800 tokens every single time. With caching, you pay the full price once and then 50% to 90% less on every subsequent request. For a system handling ten thousand queries per day, the savings on just the system prompt can be hundreds of dollars per month. When you add retrieved context that overlaps between queries, shared few-shot examples, and repeated instructions, the savings compound.

Cached pricing creates a new design principle: maximize the shared prefix. The more tokens at the beginning of your prompt that are identical across requests, the more you benefit from caching. This means putting your system prompt first, followed by stable few-shot examples, followed by stable retrieved context, and putting the variable user input last. The order of your prompt components now has a direct cost consequence.

## Pricing Is Not Static: The Deflation Curve

Token prices are not fixed. They fall over time, and they fall fast. When OpenAI launched GPT-4 in March 2023, input tokens cost thirty dollars per million and output cost sixty dollars per million. By the time GPT-4 Turbo arrived in late 2023, those prices had dropped to ten dollars and thirty dollars. GPT-5 launched in August 2025 at one dollar twenty-five cents input and ten dollars output. That is a 96% reduction in input cost and an 83% reduction in output cost from GPT-4 to GPT-5 in roughly two and a half years. Claude followed a similar curve. The original Claude Opus 4 cost fifteen dollars per million input tokens. Claude Opus 4.5 and 4.6, released within the next year, cost five dollars, a 67% reduction with better performance.

This deflation has two implications for cost engineering. First, any cost projection you make today will overestimate costs twelve months from now if you hold token consumption constant. A system that costs ten thousand dollars per month in January 2026 might cost six thousand dollars per month by January 2027 for the same workload on a newer model. Second, the deflation is not uniform across tiers. Budget models see smaller absolute drops because they are already near the cost floor. Frontier models see the largest drops as competition intensifies and hardware efficiency improves. This means the price gap between frontier and budget models is narrowing, which changes the cost-quality tradeoff calculation every few months.

Do not lock in a cost architecture based on today's prices. Build your system so that swapping models is a configuration change, not a rewrite. The team that can switch from Claude Opus 4.5 to a cheaper model in an afternoon captures the deflation curve. The team that hardcoded their prompts and parsing logic around a specific model's output format pays today's prices until they do the migration work.

## The Mental Model: Think in Dollars Per Million

The way to internalize token pricing is to convert everything into dollars per million tokens and then convert your actual query volumes into fractions of a million. A system that processes ten thousand queries per day, each consuming an average of three thousand tokens total, processes thirty million tokens per day. At GPT-5 pricing, with roughly 2,500 input tokens and 500 output tokens per query, that is twenty-five million input tokens at one dollar twenty-five cents per million, costing thirty-one dollars twenty-five cents per day for input, plus five million output tokens at ten dollars per million, costing fifty dollars per day for output. Total daily cost: eighty-one dollars twenty-five cents. Monthly cost: roughly twenty-four hundred dollars.

Now change one variable. Double the average output length from 500 to 1,000 tokens because your product team wants more detailed responses. Input cost stays the same at thirty-one dollars twenty-five cents. Output cost doubles to one hundred dollars per day. Monthly cost jumps from twenty-four hundred to roughly four thousand dollars. A single product decision about response verbosity increased the bill by 65%. That is The Output Premium in action.

Now change the model. Move the same workload to GPT-5-mini. Input cost drops from thirty-one dollars twenty-five cents to six dollars twenty-five cents per day. Output cost for the 1,000-token response drops from one hundred dollars to twenty dollars per day. Monthly cost drops from four thousand dollars to under eight hundred. Same workload, same response length, one-fifth the cost. The only question is whether GPT-5-mini's quality meets your bar.

This is the mental arithmetic you need to run instinctively. Every product decision, every prompt change, every format choice is a cost decision. The teams that succeed at cost engineering are the ones who can calculate the impact of a design change on their token bill before they ship it, not after the invoice arrives.

The next subchapter walks through the complete method for calculating cost per query, including the hidden token flows that most teams miss entirely.