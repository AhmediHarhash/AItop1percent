# 10.4 — Cost Forecasting and Capacity Planning: Modeling Growth Before It Arrives

In late 2024, a healthcare analytics company signed a $2 million annual contract with a large hospital network. The deal was the biggest in the company's history. Sales celebrated. The CEO mentioned it in the board deck. Finance projected the revenue into their annual plan. Nobody modeled the AI serving cost. The hospital network's primary use case was clinical note summarization — long, complex documents averaging 8,000 tokens of input, processed through a premium model tier with strict accuracy requirements. The customer onboarded aggressively, rolling out the product to 1,400 physicians across 23 facilities within the first two months. By month three, the customer was generating 47,000 requests per day. The cost to serve them was $51,000 per month — on a contract that paid $167,000 per month. That looked fine until you subtracted the cost of embeddings, vector storage, reranking, the dedicated compliance infrastructure the contract required, and the support engineering hours the customer consumed. All in, the customer cost $185,000 per month to serve. The company was losing $18,000 per month on its largest deal. Over the remaining nine months of the annual commitment, that gap would cost $162,000 — and the customer's usage was still growing.

The root cause was not bad pricing. The pricing was reasonable for average usage. The root cause was the absence of a cost forecast. Nobody had asked the question that matters before signing any AI contract: given what we know about this customer's use case, how much will it cost to serve them at full adoption, and does the contract price cover that cost with margin? The team had revenue projections, sales projections, headcount projections — and zero AI cost projections. They were planning for growth with one eye closed.

## Why AI Cost Forecasting Is Harder Than Traditional Forecasting

Traditional infrastructure forecasting is relatively straightforward. You estimate how many users you will have, multiply by their expected resource consumption, and provision compute, storage, and bandwidth accordingly. The cost per user is small and predictable. A SaaS application serving 100,000 users on standard cloud infrastructure has a per-user infrastructure cost that varies maybe 2x between light and heavy users. The cost curve is roughly linear, and the per-unit cost tends to decrease with scale because of volume discounts and infrastructure efficiency gains.

AI cost forecasting breaks every one of those assumptions. First, cost scales with usage complexity, not just usage volume. Two customers making the same number of requests can cost 50x different amounts depending on the models they invoke, the context lengths they require, and the features they trigger. Forecasting total request volume is necessary but nowhere near sufficient. You need to forecast the distribution of request types, model tiers, context lengths, and multi-step reasoning chains across your user base.

Second, model pricing changes unpredictably. Between 2024 and 2026, the major model providers reduced pricing on their flagship models by 60% to 90% in some cases, while simultaneously introducing new premium tiers that cost more than anything previously available. A forecast built on today's pricing may be wildly wrong in six months — in either direction. The same providers that dropped GPT-4 class pricing from $30 per million output tokens to under $5 also introduced reasoning models and agent-capable tiers at $60 per million output tokens. Your forecast needs to account for both the possibility that costs drop and the possibility that your usage shifts toward more expensive tiers.

Third, new features add entirely new cost surfaces. When your product adds an agent workflow that chains six model calls per user interaction, or a document analysis pipeline that generates embeddings for every page, you have introduced cost dimensions that did not exist when the original forecast was built. Traditional infrastructure rarely adds fundamentally new cost categories mid-year. AI products do it regularly — every significant feature launch is a potential cost structure change.

Fourth, user behavior evolves in ways that are difficult to predict. Industry experience consistently shows that AI feature usage grows superlinearly after adoption. Users who make 10 requests per day in their first month make 35 requests per day by month six. Enterprise customers who start with a single department roll out to three more departments within a quarter. The usage intensity curve is steeper and less predictable than traditional SaaS usage patterns because AI features tend to replace workflows rather than supplement them. Once a physician uses AI note summarization for 30% of their patients, the path to 90% is fast because the value is immediately obvious.

## The Foundation: Current Unit Economics

Every cost forecast starts with what you know today. Before you can project forward, you need clean, current measurements of your unit economics. The three unit costs that anchor any AI cost forecast are **cost per request**, **cost per user**, and **cost per tenant**.

Cost per request is the fully loaded cost of serving a single user-facing interaction. This includes the model inference cost for all calls in the chain — the primary generation call, any reranking or verification calls, any tool-use calls — plus the embedding cost if the request triggers RAG retrieval, plus the vector database query cost, plus any post-processing costs. Do not use averages blindly. Calculate the cost per request by request type, because a simple classification request and a complex multi-step agent workflow have completely different cost profiles. If your system handles five distinct request types, you need five distinct cost-per-request figures.

Cost per user is the monthly cost of serving an individual user, calculated by multiplying their average request volume by the average cost per request for their usage pattern. This metric matters because users within the same tenant can have dramatically different usage intensities. A power user making 200 requests per day costs the system very differently than a casual user making 5 requests per week.

Cost per tenant is the aggregated cost of serving an entire customer account — the sum of all user costs within that tenant plus any tenant-level overhead like dedicated infrastructure, custom model deployments, or compliance-specific processing. This is the number you compare to contract revenue to determine whether the account is profitable. As discussed in the previous subchapter on per-tenant cost tracking, this metric is the foundation of customer-level economics.

## Building the Forecast: From Unit Economics to Projected Spend

With current unit economics in hand, the forecast builds in layers. Each layer adds a dimension of growth or change, and the combined result is your projected cost over the forecast horizon.

The first layer is user growth. How many users will you have in each of the next four quarters? Use your sales pipeline, your historical growth rate, and your planned go-to-market investments to project the user base. For enterprise customers already under contract, estimate their adoption ramp — most enterprise accounts take two to four quarters to reach full user penetration within their organization. For new customers in the pipeline, assign probability-weighted user counts based on deal stage. A deal at 80% probability with an estimated 500 users contributes 400 users to the forecast.

The second layer is usage intensity growth. Users don't maintain a static usage level. As they become more comfortable with the product, their usage increases. Apply an intensity multiplier to your user projections. If your current users average 25 requests per day and historical data shows a 15% quarterly increase in per-user usage, your forecast should reflect 25 requests in Q1 growing to approximately 38 requests per day by Q4. This is the multiplier that most teams underestimate because they anchor on current behavior rather than the adoption curve they have already observed.

The third layer is feature launches. Look at your product roadmap for the next 12 months. Each feature that touches the AI stack adds or changes a cost dimension. A new agent workflow adds multi-call chain costs. A new model tier upgrade increases per-token costs but might reduce token volume through better efficiency. A new embedding model might be cheaper per vector but require re-indexing existing data. Translate each planned feature into its estimated cost impact: additional cost per affected request, change in the percentage of requests that are affected, and the expected adoption timeline for the feature.

The fourth layer is model pricing changes. This is the hardest layer to forecast because it depends on vendor decisions outside your control. Build three scenarios: a base case that assumes current pricing holds, an optimistic case that assumes a 20% to 30% price reduction (consistent with historical pricing trends from 2024 to 2026), and a pessimistic case that assumes your workload shifts toward more expensive model tiers. If you have committed pricing agreements with your providers, the base case is your contract rate. If you are on pay-as-you-go pricing, you have full exposure to pricing changes.

The fifth layer is optimization initiatives. If you have planned cost optimization work — implementing caching, deploying model routing, migrating workloads to cheaper models — estimate the cost reduction each initiative will deliver and the quarter it will take effect. Be conservative. Most optimization projects take longer to implement than planned, and the savings are typically 60% to 70% of the initial estimate. A caching initiative projected to save $40,000 per month should enter your forecast at $25,000 per month, starting one quarter later than the engineering team estimates.

The final layer is the risk buffer. After combining all five layers, add a buffer of 20% to 30% above the base forecast. This accounts for the unknown unknowns: a customer who ramps faster than expected, a feature that drives more usage than projected, a model pricing change you did not anticipate, or an optimization initiative that gets delayed. The buffer is not padding — it is recognition that AI cost forecasts carry higher uncertainty than traditional infrastructure forecasts, and planning without a margin of error is planning to be surprised.

## Seasonal Patterns and Usage Cycles

AI usage is not constant throughout the year, and your forecast should reflect the patterns specific to your business. Healthcare AI products see lower usage during holiday weeks when physician volumes drop. Financial services AI products spike during earnings season and quarter-end reporting. E-commerce AI products surge during November and December for holiday shopping analysis. Education technology products follow academic calendars with deep troughs in summer.

Beyond industry-specific patterns, there are universal patterns to model. Monday usage is typically 15% to 25% higher than Friday usage for enterprise products. Morning hours in each time zone concentrate 40% to 50% of daily volume into a four-hour window. Month-end and quarter-end drive spikes in any product used for reporting or analysis.

These patterns matter for capacity planning more than for cost forecasting, because your capacity must handle the peaks even if your cost forecast works with averages. A system that averages 100,000 requests per day might peak at 180,000 requests on a Monday morning in October. If your infrastructure is sized for 100,000, you have a capacity problem two days per week that your monthly cost average will never reveal.

## From Cost Forecast to Capacity Plan

A cost forecast tells you how much you will spend. A **capacity plan** tells you what infrastructure you need to support that spend without performance degradation. Translating one into the other requires mapping cost projections to specific infrastructure requirements.

Start with inference throughput. If your forecast projects 500,000 requests per day in Q3 with an average latency target of 800 milliseconds, calculate the concurrent request capacity you need. Assuming each request occupies a GPU for 400 milliseconds of actual compute, you need enough GPU capacity to handle the peak concurrent load — not the daily average. For a product with a 4-hour peak window where 45% of daily volume concentrates, 500,000 daily requests means 225,000 requests in four hours, or roughly 16 requests per second sustained during peak. With 400 milliseconds per request, you need at least 7 GPU inference slots running continuously during peak, plus headroom. In practice, you would provision for 2x to 3x this minimum to handle burst traffic within the peak window.

Embedding throughput is a separate capacity dimension. If your RAG pipeline processes embeddings on every request, your embedding model needs to keep pace with your request volume. If re-indexing schedules add batch embedding load on top of real-time query embeddings, your embedding infrastructure must handle both simultaneously. A common capacity mistake is sizing embedding infrastructure for query volume alone and then discovering that a weekly re-indexing job competes with real-time queries for the same GPU resources.

Vector database capacity scales with both the number of vectors stored and the query throughput required. If your forecast projects adding 50 million new document chunks to your vector store over the next year, ensure your vector database can handle the increased index size without query latency degradation. Many vector databases experience significant latency increases as index sizes grow beyond certain thresholds — a 10-million-vector index might return results in 15 milliseconds while a 100-million-vector index takes 80 milliseconds on the same hardware. Your capacity plan must account for index growth, not just query volume growth.

## The Forecasting Cadence

Cost forecasting is not a one-time exercise. It is a rolling discipline with three time horizons that serve different purposes.

The monthly rolling forecast is a 90-day forward projection updated every month. It uses the most recent unit economics, the latest user growth data, and any changes to the product roadmap or pricing. The monthly forecast drives operational decisions: do we need to provision additional GPU capacity next month? Is a customer ramping faster than expected? Should we accelerate an optimization initiative because costs are running above forecast?

The quarterly deep review is a 12-month forward projection updated every quarter. It involves engineering, finance, product, and sales leadership. The quarterly review examines whether the fundamental assumptions underlying the forecast still hold: is user growth tracking to plan? Are unit economics improving or deteriorating? Has the competitive landscape changed pricing dynamics? The quarterly review is where strategic decisions get made — committing to a vendor contract, approving a major optimization investment, adjusting pricing for new customers.

The annual planning cycle is the 24-month to 36-month view that feeds into the company's financial plan. This is where AI cost projections intersect with revenue projections, hiring plans, and capital allocation. The annual forecast carries the most uncertainty and should always include multiple scenarios — base, optimistic, and pessimistic — so that the financial plan can accommodate a range of outcomes. A company that builds its annual plan on a single AI cost estimate is one bad quarter away from a margin surprise that cascades into every other financial commitment.

## The Worked Example: Forecasting Q3 Costs

Here is a complete forecast for a mid-size B2B AI product planning its Q3 costs. Today the product serves 12,000 active users across 45 enterprise tenants. The average user makes 30 requests per day. The average cost per request is $0.018, broken down as $0.012 for model inference, $0.003 for embeddings, $0.002 for vector search, and $0.001 for post-processing. The current monthly AI cost is approximately $194,000.

For Q3, the sales pipeline indicates 8 new enterprise tenants will onboard, adding approximately 3,200 users. However, new tenants typically reach only 40% adoption in their first quarter, so the effective user addition is 1,280 active users. Existing user growth from organic expansion within current tenants adds another 1,500 users based on historical patterns. Total projected Q3 active users: 14,780.

Usage intensity is trending up at 12% per quarter. The current 30 requests per day grows to approximately 34 requests per day by Q3. Total projected daily requests: 502,520. Monthly request volume: approximately 15.1 million.

A planned feature launch in Q3 adds an agent workflow for contract analysis. Based on beta testing, 15% of requests will use this workflow, which costs $0.045 per request — 2.5x the current average. This shifts the blended average cost per request from $0.018 to approximately $0.022.

Model pricing: the team is on a committed contract with their primary provider through Q4, so inference pricing is locked. Embedding costs are on pay-as-you-go and are projected to decrease 10% based on planned migration to a newer, cheaper embedding model. Adjusted average cost per request: $0.021.

A caching initiative launching in Q2 is expected to reduce total request volume by 12% by eliminating redundant queries. Applying the conservative 70% realization factor, the effective reduction is 8.4%. Adjusted monthly request volume: 13.8 million.

Monthly cost projection: 13.8 million requests times $0.021 equals approximately $289,800 per month. Add the 25% risk buffer: $362,250 per month. Compare to the current $194,000 per month — an 87% increase. This is the number that goes into the financial plan. The infrastructure team uses the 502,520 daily requests figure — before caching — to plan GPU capacity, because caching reduces API calls but not the capacity needed to handle cache misses during peak traffic.

## Common Forecasting Mistakes

The most dangerous forecasting mistake is assuming linear growth when AI usage grows superlinearly. If your users averaged 20 requests per day in Q1 and 25 in Q2, projecting 30 for Q3 feels reasonable. But the actual pattern may be exponential — 20, 25, 33, 45 — because AI feature adoption accelerates as users integrate it into their core workflow. Always compare your projection against both linear and exponential growth curves and plan capacity for the more aggressive one.

The second mistake is ignoring feature launches that change the cost structure. A product roadmap that adds three new AI-powered features in the next year does not simply increase volume — it adds entirely new cost profiles. An agent feature that chains four model calls per interaction changes the per-request cost equation fundamentally. Your forecast must include the roadmap, not just the growth rate.

The third mistake is underestimating enterprise customer ramp speed. Enterprise customers onboard slowly — procurement takes months, security reviews take weeks, pilot programs start small. But once the pilot succeeds and the rollout begins, enterprise adoption happens fast. A customer who had 50 pilot users in Q1 might have 2,000 active users by Q3. If your forecast models enterprise ramp as gradual and linear, you will be caught off guard by the step-function jumps that enterprise rollouts actually produce.

The fourth mistake is forecasting cost without forecasting revenue alongside it. A cost forecast in isolation tells you what you will spend. A cost forecast paired with a revenue forecast tells you whether you can afford to grow. The teams that get into trouble are the ones who forecast costs accurately but never compare those costs to the revenue the usage generates. When cost grows faster than revenue — a common pattern in AI products scaling enterprise accounts — margin erodes with every new customer, and the faster you grow the worse it gets.

## Bridging Forecast to Action

A forecast that sits in a spreadsheet changes nothing. A forecast that drives action changes everything. Every monthly forecast update should generate three outputs: a revised infrastructure provisioning plan that ensures capacity meets projected demand, a revised optimization priority list that targets the highest-impact cost reduction opportunities, and a revised pricing review that flags any customer segments or use cases where projected costs exceed projected revenue.

The forecast is your financial early warning system. It tells you, months in advance, whether you are heading toward a cost surprise, a capacity shortfall, or a margin problem. The companies that treat forecasting as a core operating discipline — not a finance exercise done once per quarter — are the ones that scale without the margin crises that force emergency optimization under pressure.

But knowing what your costs will be is only half of the cost governance equation. The other half is managing the vendors who determine your per-unit costs. The next subchapter examines vendor strategy and negotiation — how to build multi-provider leverage, secure commitment discounts, and avoid the dependency trap that turns vendor relationships into vendor lock-in.
