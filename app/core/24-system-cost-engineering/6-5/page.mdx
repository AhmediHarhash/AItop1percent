# 6.5 — Vector Database Costs: Storage, Query, and Index Maintenance Economics

In early 2025, a healthcare analytics company migrated their clinical knowledge base to a managed vector database. The decision was quick — a product manager saw a demo, the engineering lead ran through the getting-started tutorial, and within two weeks the team had their 2.3 million document chunks indexed in a fully managed service. The retrieval quality was excellent. The developer experience was smooth. The monthly bill was $8,200.

Nobody questioned the cost for the first three months because the project was in its "prove value" phase, and executives do not scrutinize infrastructure costs during proof of concept. By the time the team moved to production and finance started reviewing recurring cloud charges, the vector database had become entrenched — the application was built around the provider's API, the team had optimized their chunking and retrieval logic for the provider's specific query semantics, and switching would mean weeks of migration work. A junior engineer ran the numbers and found that the same corpus, at the same query volume, could run on a self-managed PostgreSQL instance with the pgvector extension for roughly $190 per month. The 2.3 million vectors at 1536 dimensions fit comfortably in memory on a single database instance they were already paying for. The forty-times cost difference was not because the managed service was doing something magical. It was because managed vector databases price for convenience, and that convenience premium is enormous at certain scales.

This story is not unusual. It repeats across the industry because vector database selection happens early in a project's life, during prototyping, when cost is the last thing anyone considers. By the time cost matters, switching costs are high and the team is locked in.

## The Four Cost Components

Every vector database deployment, whether managed or self-hosted, has four cost components. You need to understand all four to model your total spend, because the visible costs often mask the dominant ones.

The first component is **storage cost** — the price of keeping your vectors on disk or in memory. Vectors are dense numerical arrays, and they take up meaningful space. A single 1536-dimension vector stored as 32-bit floats occupies 6,144 bytes, roughly 6 kilobytes. That sounds tiny until you multiply by millions. Five million vectors at 1536 dimensions require approximately 29 gigabytes of raw vector data. Add metadata, index structures, and overhead, and the actual storage footprint is 1.5 to 3 times the raw vector size — roughly 45 to 90 gigabytes for five million vectors. Storage costs vary by provider, but managed services typically charge $0.25 to $1.00 per gigabyte per month. At 90 gigabytes, that is $22 to $90 per month just for storage.

The second component is **query compute cost** — the price of executing similarity searches against your vectors. This is where managed services often extract the most margin. Every query requires computing distances between the query vector and some subset of stored vectors, which consumes CPU or GPU cycles. Managed services charge per query, per compute unit, or per "read unit," and these charges accumulate fast at high volume. A service charging $0.01 per 1,000 queries seems trivial until you process 500,000 queries per day — at which point you are paying $150 per day, or $4,500 per month, just for query compute.

The third component is **index maintenance cost** — the price of building and rebuilding the data structures that make similarity search fast. Vector databases use approximate nearest neighbor indexes — HNSW, IVF, or similar structures — that need to be built when data is loaded and periodically rebuilt as data changes. For managed services, index maintenance is typically bundled into the storage or query pricing. For self-hosted databases, index builds consume significant CPU time and memory, and during a full index rebuild, query performance can degrade.

The fourth component is **infrastructure cost** — the compute, networking, and operational overhead required to run the database. For managed services, this is abstracted into the pricing. For self-hosted deployments, it is the price of the virtual machines, the storage volumes, the load balancers, and the engineering time to maintain them.

## Managed Service Pricing in 2026

The managed vector database market in 2026 has consolidated around a few major players, each with distinct pricing models that make direct comparison deliberately difficult.

Pinecone, the most widely adopted managed vector database, moved to a serverless consumption model in 2024 and has refined it since. As of early 2026, Pinecone charges based on stored vector dimensions and query volume. Storage runs roughly $0.33 per gigabyte per month for vector data. Query costs depend on your tier and volume but typically land between $0.04 and $0.10 per 1,000 queries for serverless workloads. A deployment with five million vectors at 1536 dimensions and 200,000 queries per day costs approximately $800 to $1,500 per month on Pinecone, depending on the specific plan and usage patterns. The pricing is transparent for small deployments but becomes opaque at scale because volume discounts require sales conversations.

Weaviate Cloud offers a usage-based serverless model with pricing that starts around $25 per month for small workloads. For a typical production workload — one million vectors at 1536 dimensions with moderate query volume — Weaviate's pricing benchmarks around $150 to $400 per month. Weaviate's pricing advantages show up for hybrid search workloads that combine vector and keyword search, since that capability is included in the base pricing rather than charged as an add-on.

Qdrant Cloud offers both serverless and dedicated cluster options. The serverless tier is competitive for low-volume workloads, while dedicated clusters give predictable pricing for high-volume production deployments. Pricing is comparable to Weaviate for similar workloads but with more granular control over cluster sizing.

The common thread across all managed services is that they price for the convenience of not managing infrastructure. The vector storage itself is cheap — the raw data costs pennies per gigabyte on commodity storage. What you are paying for is the managed indexing, the query optimization, the automatic scaling, the high availability, and the operational team that gets paged when something breaks at three in the morning. For teams without dedicated database engineers, this premium is often worth it. For teams with infrastructure expertise, the premium is often not.

## The Self-Hosted Alternative

Self-hosting a vector database means running the database software on infrastructure you control — your own cloud instances, your own Kubernetes cluster, or your own bare metal. The database software itself is typically free: pgvector is an extension for PostgreSQL, Milvus is open source under Apache 2.0, Qdrant has an open-source version, and Weaviate has an open-source self-hosted option. Your cost is the infrastructure to run it and the engineering time to maintain it.

For the healthcare analytics company from the opening, the economics looked like this. Their 2.3 million vectors at 1536 dimensions required approximately 14 gigabytes of raw vector data. With index overhead, the total memory footprint was about 35 gigabytes. They were already running a PostgreSQL instance on a cloud VM with 64 gigabytes of RAM and 500 gigabytes of SSD storage for their application database. Installing pgvector and loading the vectors into that existing instance cost zero additional infrastructure because the vectors fit within the existing memory headroom. The only incremental cost was the engineering time to set up pgvector, build the HNSW index, and tune query performance — roughly two weeks of one engineer's time. After that, the ongoing cost was zero incremental infrastructure because the database was already provisioned and paid for.

This is the scenario that makes managed vector database vendors uncomfortable: when your corpus fits within existing infrastructure that you are already paying for. If you have a PostgreSQL instance with spare memory and CPU, pgvector turns it into a capable vector database at no additional cost. For corpora under one million vectors, pgvector handles query latency and throughput requirements well. Several production benchmarks from 2025 showed PostgreSQL with pgvector and the pgvectorscale extension achieving 1.4 times lower p95 latency and 1.5 times higher query throughput than Pinecone for approximate nearest neighbor queries at 90% recall, at roughly 75% to 80% lower monthly cost when self-hosted on comparable cloud instances.

For larger corpora — ten million to one hundred million vectors — pgvector starts to strain, and a dedicated vector database becomes worthwhile. Milvus, designed for billion-scale vector workloads, runs efficiently on a Kubernetes cluster and handles corpus sizes that would overwhelm pgvector. A Milvus cluster on three to five cloud instances capable of serving fifty million vectors with sub-100-millisecond p95 latency costs $400 to $800 per month in infrastructure, compared to $3,000 to $8,000 per month for a managed service at the same scale. The savings are real, but so is the operational burden: you need engineers who can configure HNSW parameters, debug distributed query routing, handle node failures, and manage rolling upgrades.

## The Dimensionality Cost Multiplier

Embedding dimensionality is the single most powerful lever for controlling vector database cost. It affects storage, memory, query compute, and index build time — every cost component simultaneously.

A 1536-dimension embedding stored as 32-bit floats takes 6,144 bytes. A 768-dimension embedding takes 3,072 bytes. A 384-dimension embedding takes 1,536 bytes. For five million vectors, these dimensions translate to storage requirements of approximately 29 gigabytes, 15 gigabytes, and 7 gigabytes respectively. The memory required to serve queries follows the same ratios because most vector databases keep active indexes in memory for performance.

Query compute scales with dimensionality because each distance calculation involves multiplying and summing across every dimension. Comparing two 1536-dimension vectors requires 1,536 multiplications and 1,536 additions. Comparing two 384-dimension vectors requires one quarter of that work. In practice, hardware vectorization and SIMD instructions reduce the linear scaling, but the relationship holds: higher dimensions mean slower queries and higher compute costs. A vector database that serves 1,000 queries per second against 384-dimension vectors might only serve 400 queries per second against 1536-dimension vectors on the same hardware.

The cost implication is direct. If you can reduce your embedding dimensionality from 1536 to 384 without meaningful retrieval quality loss, you reduce your vector database storage cost by 75%, your memory requirements by 75%, and your query compute cost by roughly 60% to 75%. For a deployment spending $4,000 per month on a managed vector database, dimension reduction alone can drop the bill to $1,000 to $1,500 per month. Combined with the dimension reduction techniques described in the previous subchapter — particularly Matryoshka-style truncation in OpenAI's text-embedding-3 models — this is often the single most impactful cost optimization available for your vector infrastructure.

Quantization extends the savings further. Instead of storing each dimension as a 32-bit float (4 bytes), you can store it as a 16-bit float (2 bytes), an 8-bit integer (1 byte), or even a binary value (1 bit). Binary quantization reduces a 1536-dimension vector from 6,144 bytes to 192 bytes — a 32-times reduction. The quality trade-off depends on your data and queries, but many production systems report less than 5% recall degradation with int8 quantization and less than 10% with binary quantization when combined with reranking. Combined with dimension reduction — say, 384 dimensions with int8 quantization — you can shrink a 6,144-byte vector to 384 bytes, a 16-times reduction that cascades through every cost component.

## Right-Sizing: Most Teams Over-Provision

The most common vector database cost mistake is over-provisioning. Teams choose a managed service designed for billion-vector scale when their corpus has 200,000 vectors. They select 1536-dimension embeddings when 384 dimensions would work. They provision dedicated clusters when serverless tiers would handle their query volume. They add replicas for high availability when their SLA does not require five-nines uptime.

Here is a decision tree based on corpus size and query volume that prevents over-provisioning.

If your corpus is under 100,000 vectors and your query volume is under 1,000 queries per day, you do not need a vector database at all. An in-memory search using a library like FAISS or Annoy, running within your application process, handles this scale in single-digit milliseconds. Total incremental cost: zero.

If your corpus is 100,000 to one million vectors and your query volume is under 50,000 queries per day, pgvector in your existing PostgreSQL instance is almost certainly sufficient. If you do not have PostgreSQL, a small managed Postgres instance with pgvector costs $50 to $100 per month. You do not need a dedicated vector database.

If your corpus is one million to ten million vectors and your query volume is under 500,000 queries per day, you are in the zone where both pgvector and managed vector databases work. pgvector with proper indexing and tuning handles this scale well on a sufficiently provisioned Postgres instance. A managed vector database provides better query performance and operational simplicity. The cost difference is typically $150 to $400 per month for pgvector versus $800 to $3,000 per month for a managed service. Choose based on whether you have the engineering capacity to tune and maintain pgvector.

If your corpus exceeds ten million vectors or your query volume exceeds 500,000 queries per day, a dedicated vector database is warranted. At this scale, evaluate managed versus self-hosted based on your team's infrastructure expertise, your cost sensitivity, and whether the three-to-five-times managed premium is worth the operational simplicity.

## The Index Rebuild Cost

When you change your embedding model — and you will, because the embedding landscape evolves rapidly — you rebuild your entire vector index. This is not a vector database cost in isolation. It compounds the embedding generation cost from the previous subchapter with the index build cost in your vector database.

A full index rebuild on a ten-million-vector corpus involves three phases. First, generate new embeddings for all ten million chunks, which costs embedding tokens plus compute. Second, load the new vectors into the database, which takes ingestion time and storage capacity for the new data alongside the old. Third, build the HNSW or IVF index on the new vectors, which consumes significant CPU time and memory.

The index build phase is often the most expensive part for self-hosted deployments. Building an HNSW index on ten million 1536-dimension vectors takes one to four hours on a modern multi-core server, during which the server's CPU and memory are heavily loaded. If this server also serves production queries, those queries slow down during the build. The blue-green pattern — building the new index on a separate instance, then swapping — avoids the performance impact but doubles your infrastructure cost during the transition.

For managed services, index rebuilds are handled by the provider, but you still pay for the ingestion throughput. Most managed services charge for write operations in addition to reads, and ingesting ten million vectors generates a significant write bill. Pinecone's serverless model, for example, charges for "write units" that can add several hundred dollars to the cost of a full re-index at scale.

The total cost of an embedding model migration — re-embedding plus re-ingestion plus index rebuild — typically ranges from $500 to $5,000 for a medium corpus and $5,000 to $50,000 for a large corpus, depending on your embedding model, vector database, and deployment type. This cost creates a strong financial incentive to choose your embedding model carefully and change it infrequently.

## Monitoring and Controlling Vector Database Spend

Vector database costs are easy to ignore and hard to control once they spiral. Implement three monitoring practices from day one.

First, track your cost per query. Divide your monthly vector database bill by the number of queries served. If your cost per query is increasing over time, you are either growing your corpus faster than your query volume (increasing storage cost per query) or your provider is applying usage-based pricing that scales unfavorably. A healthy cost per query for most deployments is $0.0001 to $0.001. If your cost per query exceeds $0.005, you are likely over-provisioned or using a pricing tier that does not match your usage pattern.

Second, track your storage utilization. If you are paying for 100 gigabytes of storage but using 30 gigabytes, you are over-provisioned by 70%. Managed services with serverless pricing adjust automatically, but dedicated cluster plans often charge for provisioned capacity regardless of usage. Right-size quarterly. If your corpus is not growing as fast as projected, downgrade your storage tier.

Third, track your query patterns. If 20% of your queries account for 80% of your vector database cost because they trigger expensive full-index scans, optimize those specific query patterns. Add metadata filters to narrow the search space. Implement query caching at the application layer so that repeated queries hit the cache instead of the vector database. Add a similarity threshold that rejects queries with no good matches early, before they trigger a full scan.

The combination of right-sizing, dimensionality optimization, and query-level cost tracking typically reduces vector database spend by 40% to 60% compared to an unoptimized deployment. For a team spending $5,000 per month on a managed vector database, that is $2,000 to $3,000 per month in savings — $24,000 to $36,000 annually — from optimization work that takes one to two engineering weeks.

## The Provider Lock-In Trap

Vector database lock-in is more severe than it appears. Each provider has slightly different APIs, query semantics, metadata filtering syntax, and indexing behavior. An application optimized for Pinecone's API does not trivially migrate to Weaviate or Qdrant. The migration requires changing ingestion code, query code, metadata handling, and often retuning retrieval parameters. Add the re-embedding cost if you are changing dimensions or models simultaneously, and a database migration becomes a multi-week engineering project.

Protect yourself from lock-in by abstracting your vector database behind an internal interface from the start. Your application should call a search function that takes a query and returns results, not Pinecone-specific API calls scattered throughout your codebase. This abstraction takes a few hours to implement and saves weeks if you ever need to migrate. Given that the vector database market is still maturing rapidly — consolidating providers, changing pricing models, adding features — the probability that you will want to migrate within two years is high.

Retrieval precision matters as much as retrieval speed, and the next subchapter examines the cost of the component that improves precision the most: reranking. Adding a reranker to your retrieval pipeline improves quality, but it adds a per-query cost that you need to measure against the inference savings it delivers.
