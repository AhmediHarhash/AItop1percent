# Chapter 5.8 — Compliance & Legal Requirements by Industry

Compliance requirements exist whether you know about them or not. And "we didn't know" is never an acceptable defense. If you're building AI products in 2026, legal and compliance requirements are part of your product requirements — not an afterthought you deal with before launch.

---

### The Universal Requirements

These apply to almost every AI product regardless of industry:

**Data privacy.** If your product processes personal data (names, emails, IP addresses, behavioral data), privacy laws apply. GDPR in the EU. CCPA/CPRA in California. LGPD in Brazil. PIPL in China. POPIA in South Africa. At minimum: get consent, minimize data collection, allow deletion requests, and document your data processing.

**Transparency.** Multiple jurisdictions now require disclosure when users interact with AI. The EU AI Act mandates it. The FTC has taken action against companies that fail to disclose AI involvement. Be transparent: tell users they're talking to an AI.

**Non-discrimination.** AI products that make decisions about people (hiring, lending, insurance, housing) are subject to anti-discrimination laws. In the US: Civil Rights Act, Equal Credit Opportunity Act, Fair Housing Act. In the EU: AI Act high-risk provisions. Your AI can't discriminate even if the underlying data reflects historical biases.

**Consumer protection.** AI products that make claims about their capabilities must be truthful. The FTC has pursued companies for deceptive AI claims. Don't say "our AI guarantees accurate results" unless you can prove it.

---

### Industry-Specific Requirements

**Healthcare.**
- HIPAA (US): encryption, access controls, audit trails, business associate agreements for any entity handling protected health information
- FDA (US): AI software that diagnoses, treats, or prevents disease may be classified as a medical device requiring clearance
- MDR (EU): Medical Device Regulation applies to AI-based medical software
- Clinical validation required before deployment in patient care

**Financial Services.**
- SOX (US): internal controls and audit trails for systems affecting financial reporting
- Basel III/IV: model risk management requirements for models used in risk assessment
- Fair lending laws: explainability requirements for credit decisions
- PCI-DSS: if processing payment card data
- MiFID II (EU): requirements for algorithmic trading and automated investment advice

**Legal.**
- Unauthorized practice of law: AI providing legal advice may constitute UPL in some jurisdictions
- Attorney-client privilege: AI systems processing privileged communications need appropriate protections
- Court rules on AI-generated content: several jurisdictions require disclosure of AI involvement in legal filings

**Education.**
- FERPA (US): protections for student educational records
- COPPA (US): additional protections for children under 13
- Accessibility requirements: AI products used in education must be accessible to students with disabilities

**Insurance.**
- State-level regulations (US): many states regulate AI in underwriting and claims
- Solvency II (EU): model governance requirements
- Non-discrimination in pricing: AI can't use prohibited factors even indirectly

**Employment/HR.**
- NYC Local Law 144: automated employment decision tools must undergo bias audits
- Illinois AIPA: consent required before AI analysis of video interviews
- EU AI Act: employment AI classified as high-risk with mandatory conformity assessment

---

### The Compliance Action Plan

**Step 1: Identify your regulatory surface.** List every regulation that might apply based on your industry, geography, data types, and user base. When in doubt, assume it applies.

**Step 2: Get legal counsel.** Not general counsel — counsel who understands AI regulation specifically. This is a specialization, and generic legal advice often misses AI-specific requirements.

**Step 3: Build compliance into the product.** Consent mechanisms, audit logging, bias testing, transparency notices, data handling procedures. Build these from day one, not as a retrofit.

**Step 4: Document everything.** Regulators want to see evidence of compliance, not just assertions. Document your risk assessments, evaluation results, bias audits, data handling procedures, and decision-making processes.

**Step 5: Monitor regulatory changes.** AI regulation is evolving rapidly. What's optional today may be mandatory tomorrow. Assign someone to track regulatory developments in your markets.

---

*Next: the pre-mortem — predicting failure before you ship, so you can prevent it.*
