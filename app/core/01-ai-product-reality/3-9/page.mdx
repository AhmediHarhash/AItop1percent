# Chapter 3.9 — How Risk Tier Dictates Your Monitoring Depth

Building an AI product without monitoring is like driving at night without headlights. You might be fine for a while. But when something goes wrong — and it will — you won't see it until you've already crashed.

Monitoring depth should match your risk tier. Here's what that looks like in practice.

---

### Tier 1 Monitoring: Know If Anyone Uses It

At Tier 1, monitoring is about basic health and adoption.

**What to track:**
- Usage volume (is anyone using this?)
- Error rates (is the system returning errors?)
- User feedback (thumbs up/down, reports)
- Basic latency (is it fast enough to not be annoying?)

**How often to check:** Weekly dashboard review. Set up a simple alert for error rate spikes.

**What to do when something's wrong:** Fix it when you notice. No on-call, no incident process. If it's broken, fix it during work hours.

This is enough because Tier 1 products have a human in the loop, internal users who can report issues, and low consequences for temporary quality drops.

---

### Tier 2 Monitoring: Know If Quality Drops

At Tier 2, monitoring is about detecting quality degradation before customers notice.

**What to track (everything from Tier 1, plus):**
- Quality scores on a sample of production traffic (automated eval or LLM-as-judge on 1-5% of queries)
- Latency percentiles (P50, P95, P99)
- Cost per query and total daily cost
- Model provider status (API availability, latency)
- User satisfaction signals (CSAT, NPS, support ticket volume)
- Traffic pattern anomalies (sudden spikes or drops)

**How often to check:** Daily automated reports. Real-time alerts for critical metrics (error rate above threshold, latency above SLA, quality score below minimum).

**Detection target:** Know about quality degradation within 24 hours.

**What to do when something's wrong:** Defined incident response: who gets paged, what the severity levels are, what the escalation path is. For critical issues, rollback capability within 30 minutes.

---

### Tier 3 Monitoring: Know Everything, Immediately

At Tier 3, monitoring is about catching every significant failure and proving you caught it.

**What to track (everything from Tier 2, plus):**
- Per-segment quality (performance across different user groups, input types, and demographic categories)
- Drift detection (is the input distribution or model behavior changing over time?)
- Safety-specific metrics (rate of harmful, inappropriate, or policy-violating outputs)
- Human override rate (how often do domain experts change the AI's recommendation?)
- Confidence calibration (do the system's confidence scores match its actual accuracy?)
- Outlier detection (unusual inputs or outputs that might indicate problems)
- Adversarial input detection (attempts to manipulate or exploit the system)

**How often to check:** Real-time monitoring with automated alerting. Hourly quality sampling. Daily quality review by a human. Weekly deep dive with domain experts.

**Detection target:** Know about quality degradation within 1 hour. Know about safety issues within 15 minutes.

**What to do when something's wrong:** Tiered incident response. Safety incidents: immediate automated mitigation (block outputs, enable fallback). Quality incidents: rapid human review and decision to rollback or fix. All incidents: documented, root-cause analyzed, and fed back into the eval process.

---

### Tier 4 Monitoring: Prove Compliance Continuously

At Tier 4, monitoring also serves as compliance evidence.

**What to track (everything from Tier 3, plus):**
- Regulatory-specific metrics (whatever the applicable regulation requires you to monitor)
- Serious incident detection (EU AI Act requires reporting of serious incidents to authorities)
- Audit trail completeness (are all decisions logged with full context?)
- Data processing compliance (are you staying within your authorized data processing scope?)
- System version tracking (which model, prompt, and config version is running at any moment?)

**How often to check:** Continuous automated monitoring with real-time alerting. Regulatory reporting cadence (varies by regulation — EU AI Act requires "without undue delay" for serious incidents).

**Documentation:** Every monitoring finding, every alert, every response action — documented and stored for regulatory review. Your monitoring system isn't just protecting users; it's building your compliance record.

---

### The Investment Curve

Monitoring cost scales roughly with risk tier:

- **Tier 1:** Near-zero. Basic logging and a dashboard. A few hours to set up.
- **Tier 2:** Moderate. Automated eval sampling, alerting, dashboards. Dedicated infrastructure. Several weeks to build.
- **Tier 3:** Significant. Real-time monitoring, domain-expert review processes, drift detection, bias auditing. Months to build, ongoing operational cost.
- **Tier 4:** Major. Everything from Tier 3 plus compliance documentation, regulatory reporting, and audit support. Dedicated team.

Invest proportionally. Under-monitoring is risky. Over-monitoring is wasteful. Match the depth to the tier.

*Next: the most expensive mistake in risk classification — getting the tier wrong.*
