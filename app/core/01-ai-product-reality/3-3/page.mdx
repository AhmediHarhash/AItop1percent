# Chapter 3.3 — Tier 2: Medium-Risk — Customer-Facing, Non-Critical

Tier 2 is where most commercial AI products live. The system is in front of customers, but the consequences of errors are manageable — embarrassing, costly, or annoying, but not dangerous. This is also where most teams underestimate the jump from internal to external.

---

### What Tier 2 Looks Like

Tier 2 products interact directly with customers or external users, but they don't make high-stakes decisions. The user can recover from a bad output without serious harm.

Common Tier 2 products:

- **Customer support chatbots.** Answering questions about products, policies, and account status. A wrong answer frustrates the customer and might require human escalation, but doesn't cause serious harm.
- **Product recommendations.** "Based on your purchase history, you might like these items." A bad recommendation wastes the user's time but doesn't cause damage.
- **Content personalization.** Tailoring news feeds, learning paths, or marketing content. Getting it wrong means showing irrelevant content, not harmful content.
- **Search and discovery.** Helping users find products, articles, or information. Irrelevant results are frustrating but not dangerous.
- **Automated email responses.** First-response emails that acknowledge, categorize, and provide initial information. Wrong categorization delays resolution but doesn't cause harm.

---

### The Quality Jump from Tier 1 to Tier 2

Moving from internal to customer-facing changes everything:

**Trust is harder to earn and easier to lose.** Internal users give your AI the benefit of the doubt because they know it's an internal project. Customers don't. One bad experience and they might never use the feature again. Research shows it takes five positive AI interactions to recover from one negative one.

**Volume exposes edge cases.** Your internal tool served 50 users with predictable queries. Your customer-facing product serves 50,000 users who type things you never imagined. The diversity and volume of inputs will expose every weakness in your system within the first week.

**Brand reputation is on the line.** When an internal tool gives a funny wrong answer, people laugh about it in Slack. When a customer-facing tool gives a wrong answer, it ends up on social media, in a support ticket, and in the quarterly business review. Your AI's mistakes become the company's mistakes.

**You need actual monitoring.** At Tier 1, checking a dashboard weekly was fine. At Tier 2, you need daily quality signals: automated eval scores on production traffic samples, error rate tracking, latency monitoring, and user satisfaction metrics. If quality degrades, you need to know within hours, not weeks.

---

### The Tier 2 Quality Bar

The quality bar for Tier 2 is: **reliably helpful with graceful failure.**

This means:
- **Accuracy above 85-90%** for the core use case (the exact number depends on your domain and error cost)
- **Graceful degradation** when the system is uncertain — it should say "I'm not sure, let me connect you with a human" rather than confidently giving a wrong answer
- **Consistent tone and brand voice** across all interactions
- **Response time under user expectations** — typically under 3 seconds for text, under 1 second for search
- **No harmful, offensive, or legally problematic outputs** (even if accuracy is imperfect, safety must be high)

What you need at Tier 2:
- A comprehensive eval set (200+ examples covering main use cases and known edge cases)
- Daily or real-time quality monitoring
- A human escalation path for uncertain or high-stakes queries
- User feedback collection and analysis
- Incident response process (what happens when quality drops)
- Basic safety testing (adversarial inputs, policy-violating queries)

---

### The Tier 2 Decision: Human in the Loop or Not?

The biggest architectural decision at Tier 2 is whether a human reviews outputs before they reach the customer. The options form a spectrum:

- **Full human review:** Every output is reviewed. High quality but doesn't scale and defeats the cost savings of AI.
- **Confidence-based review:** Outputs above a confidence threshold go directly to the customer; below it, they go to a human reviewer. The sweet spot for most Tier 2 products.
- **Post-hoc review:** All outputs go to the customer immediately, but a sample is reviewed afterward. Faster but risks quality issues reaching customers before you catch them.
- **No review:** Full automation. Only appropriate when your quality metrics consistently exceed your threshold and you have robust monitoring.

Choose based on your error cost and volume. If wrong answers cost you $50 each in customer churn and support escalation, even a 5% error rate at 10,000 queries per day is $25,000/day in damage.

*Next: Tier 3 — high-risk products where errors cause real harm.*
