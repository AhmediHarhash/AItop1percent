# 5.11 — SLOs for AI Products

In February 2025, a SaaS company launched an AI-powered customer support chatbot with great fanfare. The product was "up" — the servers were running, the API was responding, the uptime dashboard showed 99.97% availability. But customers were furious. The AI was giving wrong answers 40% of the time. Response latency had degraded from two seconds to twelve seconds. The cost per conversation had ballooned to three dollars, far exceeding the value of an automated support interaction. The company had uptime SLOs, but they had no quality SLOs, no latency SLOs, and no cost SLOs. The system was "available" but unusable.

The executive team demanded answers. The engineering team pulled data. They discovered that quality had been declining for three weeks, but no one had noticed because no one was measuring it. Latency had spiked after a model provider change, but no one had set thresholds or alerts. Costs had tripled after a prompt engineering change that increased token usage, but no one was tracking cost per query. The team had built an AI product using traditional software reliability practices, and those practices were insufficient. The product was online, but it was failing in every dimension that mattered.

This is the gap: traditional SLOs measure availability and performance. AI products need SLOs that measure quality, cost, and safety. You cannot manage what you don't measure, and if your SLOs were designed for traditional software, you are not measuring the things that determine whether your AI product succeeds or fails.

## Why AI Products Need Different SLOs

Traditional software either works or it doesn't. A database query returns the right data or it errors. An API endpoint responds within the latency threshold or it times out. The failure modes are binary. You can measure success with availability and latency.

AI products are probabilistic. They don't fail cleanly. They degrade. An AI that gives the right answer 95% of the time and the wrong answer 5% of the time is not "down" — it's operating within its expected error rate, but that error rate might be unacceptable for your use case. An AI that responds in two seconds on average but takes thirty seconds for 5% of queries creates a terrible experience for those users, even though your average latency looks fine. An AI that costs five cents per query when your revenue per query is three cents is operationally successful but economically unviable.

This is why you need SLOs that go beyond uptime. You need commitments that reflect the actual quality, speed, cost, and safety of your AI's behavior. Without those commitments, you are flying blind. You have no way to know whether your product is getting better or worse. You have no framework for making tradeoff decisions. You have no credible way to communicate your product's reliability to customers.

## The Four SLO Dimensions for AI Products

**Quality SLO** measures the accuracy, helpfulness, or correctness of AI outputs. This is the SLO that traditional software doesn't need because traditional software is deterministic. For AI, quality is the primary success metric.

What it measures: the percentage of AI outputs that meet your quality bar. The quality bar varies by use case. For a customer support chatbot, it might be "the response fully addresses the user's question and contains no factual errors." For a document summarization tool, it might be "the summary captures all key points and contains no hallucinations." For a code generation tool, it might be "the generated code compiles and passes basic correctness checks."

How to measure it: automated evaluation on a sample of production traffic. You cannot manually review every output — production volume is too high. Instead, you sample. Take one to five percent of production queries each day, run them through your evaluation pipeline, and score them. The scoring mechanism depends on your use case. LLM-as-judge is common: you use a separate model to evaluate whether the output meets your criteria. Rule-based checks work for structured outputs: does the response contain all required fields, are the values within expected ranges. Periodic human review provides ground truth: a human evaluator scores a subset of the sampled queries to validate that your automated scoring is accurate.

Example quality SLO: "85% of customer support responses are rated acceptable or better by our automated quality scorer, measured daily on a random sample of 2% of production traffic."

Setting the target: start with your current baseline. If your current quality is 87%, your SLO should not be 87% — it should be lower, with a buffer. Set it at 83%. SLOs are not aspirations. They are commitments. They represent the minimum level you guarantee, not the level you hope to achieve. If you set your SLO at your current performance, any degradation violates it. If you set it slightly below your current performance, you have room to absorb normal variance without breaking your commitment.

**Latency SLO** measures how long users wait for a response. For real-time products — chatbots, voice assistants, live tools — latency determines usability. Users tolerate a two-second wait. They abandon after a ten-second wait.

What it measures: response time from user input to AI output. Measured in percentiles, not averages. Average latency is misleading because it hides the tail. An average of 1.5 seconds might mean 90% of users wait one second and 10% wait six seconds. The 10% who wait six seconds have a terrible experience, and the average doesn't capture that.

How to measure it: track P50, P95, and P99 latency. P50 is the median — half of users experience this latency or better. P95 means 95% of users experience this latency or better, and 5% experience worse. P99 means 99% of users experience this latency or better, and 1% experience worse. The tail percentiles — P95 and P99 — are what matter for user experience. If your P99 is twelve seconds, one in every hundred users waits twelve seconds or more. That's a problem, even if your P50 is two seconds.

Example latency SLO: "P95 response latency is under three seconds."

Why this matters: latency directly affects user retention. Research shows that users abandon interactions when latency exceeds their tolerance threshold. For customer support, that threshold is around five seconds. For search, it's around two seconds. For creative tools, users tolerate more — maybe ten seconds — because they understand that quality takes time. Know your threshold and set your SLO accordingly.

**Cost SLO** measures the cost per query, per user, or per resolved task. AI costs are variable — they depend on input length, output length, model choice, and usage patterns. Without a cost SLO, costs can spiral unpredictably.

What it measures: total AI spend divided by usage volume. Total AI spend includes model inference costs, infrastructure costs, human review costs, and any third-party API costs your AI calls. Usage volume is the number of queries, conversations, documents processed, or tasks completed, depending on your product. The result is your cost per unit.

How to measure it: instrument your system to log costs at the query level. Every time your AI processes a request, log the model cost, the infrastructure cost amortized per query, and any additional costs incurred. Aggregate daily or weekly. Divide total spend by total volume. Track the trend. If your cost per query is increasing, you need to investigate why.

Example cost SLO: "Cost per resolved customer query stays below 50 cents."

Why this matters: cost determines whether your product is economically viable. If your cost per query exceeds your revenue per query, you lose money on every interaction. If your cost per query is close to your revenue per query, your margins are too thin to sustain the business. A cost SLO forces you to monitor costs proactively and gives you a framework for evaluating cost-saving changes. If a new model reduces cost by 40% but also reduces quality, you can ask: does the quality reduction violate our quality SLO? If yes, the cost savings aren't worth it. If no, the cost savings are viable.

**Safety SLO** measures the rate of harmful, policy-violating, or inappropriate outputs. Safety failures have outsized impact — a single safety failure can generate more damage than a thousand quality failures.

What it measures: the percentage of outputs that violate your safety policies. Safety policies vary by product. For a customer-facing chatbot, safety might mean no toxic language, no personally identifiable information leakage, no medical or legal advice. For a content moderation tool, safety might mean no false positives that suppress legitimate speech. For a code generation tool, safety might mean no code that introduces security vulnerabilities.

How to measure it: automated safety classifiers on 100% of production traffic. Unlike quality, which you can sample, safety must be checked on every output because even a single violation can cause significant harm. Use classifiers to detect toxic content, PII, policy violations, and prohibited content types. Log every flagged output. Route flagged outputs to human review for confirmation and further action.

Example safety SLO: "Harmful or policy-violating outputs occur in fewer than 0.1% of interactions."

Why this matters: safety violations are the highest-cost failures. A quality failure frustrates a user. A safety failure might expose private data, generate harmful content, violate regulations, or damage your brand. The safety SLO is often the tightest because the tolerance for failure is the lowest. A 0.1% violation rate means one in a thousand outputs violates policy. That might sound rare, but at 100,000 queries per day, it's 100 violations per day. For high-risk products, even that might be unacceptable.

## SLO Error Budgets

An SLO of 90% quality means you have a 10% error budget. That 10% is not a failure — it is the budget you spend on experimentation, rapid iteration, and learning from production.

Here is how error budgets work. Every time your product produces an output that doesn't meet your quality SLO, you consume part of your error budget. Every time a query exceeds your latency SLO, you consume part of your latency error budget. Every time a query costs more than your cost SLO, you consume part of your cost error budget. Every time an output violates your safety SLO, you consume part of your safety error budget.

When you are well within your error budget — you've consumed only 20% of your allowed errors — you are in a good state. Ship faster. Experiment more. Try new models. Push boundaries. The error budget is there to enable velocity.

When you are close to exhausting your error budget — you've consumed 80% of your allowed errors — you need to slow down. Focus on reliability. Stop shipping changes that increase variance. Investigate the top failure modes. Fix the issues causing the most errors.

When you have exhausted your error budget — you've violated your SLO — you stop shipping new changes. You shift into incident response mode. You investigate what caused the SLO violation. You fix the root cause. You restore quality, latency, cost, or safety to within SLO limits. Only then do you resume normal operations.

Error budgets transform the conversation from "we need to be perfect" to "we need to stay within our budget." This is psychologically healthier and operationally more effective. Perfection is not achievable for probabilistic systems. Staying within budget is achievable, and it gives you a clear framework for decision-making.

## When to Page, When to Alert, When to Log

Not all SLO violations are equal. Some require immediate human intervention. Some require awareness but not immediate action. Some are worth logging but not alerting on.

**Page: immediate intervention required.** You page when an SLO violation indicates a critical failure that is actively harming users or the business. Safety SLO violations often warrant pages — if your safety classifier detects a spike in harmful outputs, someone needs to investigate immediately. Extreme latency violations might warrant pages — if P99 latency spikes to sixty seconds, your product is effectively unusable for a meaningful percentage of users. Catastrophic cost spikes might warrant pages — if your cost per query suddenly triples, you might be burning through budget at an unsustainable rate.

**Alert: awareness required, but not urgent.** You alert when an SLO violation indicates a problem that needs attention within hours, not minutes. Quality SLO violations often warrant alerts — if your daily quality score drops below your SLO, your team should investigate, but it's not an all-hands emergency. Moderate cost increases warrant alerts — if cost per query is trending upward but hasn't yet exceeded the SLO, you want visibility so you can investigate before it becomes critical.

**Log: record for analysis, no immediate action.** You log when something is worth tracking but doesn't require human intervention. Individual query failures are logged but not alerted on — a single wrong answer is expected variance. Latency outliers are logged but not alerted on unless they exceed your P99 threshold. Cost per query is logged on every request so you can analyze trends, but you only alert when the aggregate crosses a threshold.

The distinction matters because alert fatigue kills reliability. If you page for everything, your team ignores pages. If you alert for everything, your team ignores alerts. The on-call engineer needs to trust that when they get paged, it is genuinely urgent.

## Getting Started with SLOs

Do not try to set all four SLOs on day one. Start with the one that matters most for your product. Customer-facing chatbot? Start with quality SLO. Real-time voice assistant? Start with latency SLO. High-volume internal tool? Start with cost SLO. Any Tier 3 or higher product? Start with safety SLO.

Add the others as your monitoring infrastructure matures. One SLO you actually measure, monitor, and act on is worth far more than four SLOs that no one tracks. The SLO is not the number you write in a document — it is the commitment you enforce through instrumentation, dashboards, alerts, and operational discipline.

Here is the process for setting your first SLO:

First, measure your current baseline. Run your evaluation pipeline on production traffic for one week. What is your current quality, latency, cost, and safety performance? Do not guess. Measure.

Second, set your SLO below your baseline. If your current quality is 87%, set your SLO at 83%. If your current P95 latency is 2.8 seconds, set your SLO at 3.5 seconds. The buffer accounts for normal variance and gives you room to experiment without immediately violating your commitment.

Third, instrument your system to measure SLO compliance continuously. Log every query. Score a sample for quality. Track latency percentiles. Calculate cost per query. Run safety classifiers. Aggregate the data daily. Publish it to a dashboard. Make it visible.

Fourth, set up alerts for SLO violations. When your daily quality score drops below your SLO, alert the team. When your P95 latency exceeds your SLO, alert the team. When your cost per query exceeds your SLO, alert the team. When your safety violation rate exceeds your SLO, page the on-call.

Fifth, review your SLOs regularly. Every quarter, look at your SLO compliance. Are you consistently exceeding your SLO by a wide margin? Consider tightening it. Are you frequently violating your SLO? Either you need to fix your product, or your SLO is set unrealistically high. Adjust.

SLOs are not static. They evolve as your product matures, as your understanding of acceptable performance deepens, and as your user expectations change.

## SLOs Create Accountability

Without SLOs, quality is a feeling. "The AI seems to be working well." This is how most teams operate. It is useless. Feelings are not measurable. They are not actionable. They do not create accountability.

SLOs replace feelings with numbers. When you commit to "90% answer accuracy measured on a daily sample of production traffic," you are committing to measure, monitor, and maintain that level. The commitment forces the infrastructure. You cannot commit to an SLO without instrumenting your system to measure it. You cannot maintain an SLO without monitoring it continuously. You cannot improve an SLO without identifying and fixing the failure modes that cause violations.

SLOs also align your team. When everyone knows the targets, they make consistent decisions. The engineer asks, "Will this change affect our quality SLO?" The product manager asks, "Are we hitting our cost SLO?" The conversation is grounded in shared metrics, not opinions.

SLOs communicate credibility to customers. Enterprise customers want commitments, not promises. An SLA backed by SLOs — "We guarantee 88% answer accuracy as measured by our evaluation framework" — is more credible than "Our AI is really good." Customers can evaluate your SLO against their requirements. They can hold you accountable if you fail to meet it. This is how trust is built in enterprise sales.

Your AI product is chaos until you define what success looks like in measurable terms. SLOs are how you translate that chaos into commitments. Next, you need to understand whether those commitments are economically sustainable — which means looking at unit economics.
