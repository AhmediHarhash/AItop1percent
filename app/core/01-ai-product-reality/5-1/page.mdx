# Chapter 5.1 — Why Traditional PRDs Fail for AI

If you've ever written a traditional product requirements document and handed it to an AI engineering team, you've probably noticed what happens next: polite confusion, a lot of follow-up questions, and a product that doesn't match what you described.

That's not because your PRD was bad. It's because the PRD format was designed for deterministic software, and AI is fundamentally not deterministic.

---

### What Traditional PRDs Assume

A traditional PRD says: "When the user clicks this button, the system does X." It assumes predictable, repeatable behavior. The same input always produces the same output. The spec can describe exactly what the system will do in every situation.

This works beautifully for traditional software. It fails for AI because:

**AI outputs are probabilistic.** The same input can produce different outputs. A PRD that says "the chatbot should answer questions about our return policy" doesn't specify what happens when the question is ambiguous, the policy is unclear, or the user asks something adjacent to but not exactly about returns.

**Quality is a distribution, not a binary.** Traditional software either works or it doesn't. AI works "about 87% of the time, but worse on long queries, and much worse on topics we didn't anticipate." A PRD needs to define acceptable performance distributions, not just desired behaviors.

**Edge cases are infinite.** In traditional software, you can enumerate edge cases: empty input, very long input, special characters. In AI, edge cases include every possible thing a human might say or ask. You can't spec them all — you need to define policies for handling the unexpected.

**The system changes behavior over time.** Model updates, prompt adjustments, and data drift cause AI behavior to change even without code changes. A PRD that describes "the system does X" is a snapshot that might not be accurate next month.

---

### What AI Requirements Need Instead

**Behavior ranges, not exact specs.** Instead of "the system responds with the return policy," write: "the system should provide accurate return policy information in 90%+ of queries. For queries it can't answer, it should acknowledge the limitation and offer to connect the user with a human."

**Quality criteria, not feature lists.** Instead of listing every feature, define: what does "good" look like? What's the minimum acceptable accuracy? What failure modes are unacceptable? What's the tolerance for latency? What's the cost budget?

**Example-driven specs.** The most effective way to communicate AI requirements is through examples. Provide 20-30 representative inputs with expected outputs and annotated failure cases. These become the seed of your eval set and communicate more clearly than any written spec.

**Explicit unknowns.** AI products have known unknowns: we don't know exactly how the model will handle X. The PRD should list these unknowns, identify which are blockers vs which are acceptable risks, and define how the team will learn the answers (usually through evaluation).

**Iteration assumptions.** AI products are built iteratively. The first version won't be perfect. The PRD should define the initial quality bar and the improvement trajectory: "V1 targets 80% accuracy. V2 targets 90%. V3 targets 95%." This sets realistic expectations and prevents the "why isn't it perfect?" conversation.

---

### The AI Requirements Template

Replace your traditional PRD with this structure:

1. **Problem statement.** What specific problem are we solving? For whom?
2. **Success criteria.** How will we know this is working? (Measurable metrics)
3. **Quality bar.** Minimum acceptable accuracy, safety, latency, and cost targets
4. **Example inputs and expected outputs.** 20-30 representative cases
5. **Unacceptable failure modes.** What the system must never do
6. **Known unknowns.** What we don't yet know and how we'll learn
7. **Fallback behavior.** What happens when the AI can't help
8. **Constraints.** Cost budget, latency requirements, data restrictions, compliance requirements
9. **Iteration plan.** V1 target, V2 target, and criteria for moving between versions

This format gives the engineering team what they actually need: a clear problem, measurable success criteria, and explicit quality standards — not a feature list that assumes deterministic behavior.

*Next: how to write AI product requirements that actually survive contact with reality.*
