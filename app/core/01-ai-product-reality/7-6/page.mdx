# Chapter 7.6 — Go/No-Go Criteria: When to Proceed, Pivot, or Stop

You've built a prototype. You've run your first evaluation. You have a baseline quality number. Now comes the hardest decision in AI product development: should you keep going?

Most teams skip this decision entirely. They built it, so they ship it. But a disciplined team defines explicit criteria for proceeding before they're emotionally invested in the outcome.

---

### The Go/No-Go Framework

Define three thresholds before you evaluate:

**Go threshold.** "If our eval score is above X%, we proceed to MVP development." This is the quality level where the product is useful enough to put in front of real users (even in a limited way).

**Conditional go.** "If our eval score is between X% and Y%, we proceed but with specific constraints." Maybe you launch with human review on every output. Maybe you limit the product to a narrow use case where quality is high enough. Maybe you add a prominent "AI-generated, please verify" disclaimer.

**No-go threshold.** "If our eval score is below Y%, we do not proceed with the current approach." This doesn't mean you abandon the idea — it means the current technical approach isn't working and you need to change something fundamental (different model, different architecture, different task definition, or different product concept entirely).

---

### Setting the Thresholds

The right thresholds depend on your risk tier and product type:

**Tier 1 (internal tools, drafts):** Go above 70%. Conditional 50-70%. No-go below 50%. Users can easily verify and correct outputs, so imperfect AI is still useful.

**Tier 2 (customer-facing, non-critical):** Go above 85%. Conditional 70-85%. No-go below 70%. Users trust the output more, so quality needs to be higher.

**Tier 3 (high-risk decisions):** Go above 92%. Conditional 85-92%. No-go below 85%. Wrong answers have real consequences, so the bar is high.

**Tier 4 (regulated):** Go above 95%. Conditional 90-95%. No-go below 90%. Regulatory and liability considerations demand near-perfection on the evaluated dimensions.

These numbers are starting points. Adjust them based on your specific domain, your users' tolerance for errors, and the consequences of failure.

---

### The Pivot Signals

Sometimes the answer isn't "stop" but "change direction." Here are the signals that suggest a pivot:

**The model is great at a different task than you planned.** You built a contract summarizer, but the AI is better at extracting specific clauses than summarizing entire contracts. Pivot to extraction.

**Quality is high for a subset of inputs.** The AI handles simple queries at 95% quality but complex queries at 40%. Pivot to launching with the simple use case first and expanding later.

**Users want something different.** Your prototype testing reveals that users don't actually want the thing you built — they want a related but different capability. This is product learning, not AI failure.

**The economics don't work at this quality level.** The AI is good enough, but it costs too much per query to be viable. Pivot to a more efficient approach (model routing, caching, open-source models) or a different pricing model.

---

### Making the Decision

The go/no-go decision should be made by the team — PM, engineering, and ML together — using the pre-defined criteria. Not by the executive who promised the feature. Not by the engineer who's emotionally invested in the prototype. Not by the salesperson who already told a customer it's coming.

Write down your criteria before you evaluate. Then follow them. The discipline of making data-driven go/no-go decisions is what separates professional AI product teams from teams that ship products they shouldn't.

---

*Next: the minimum viable AI product — what to include, what to cut, and how to ship something useful fast.*
