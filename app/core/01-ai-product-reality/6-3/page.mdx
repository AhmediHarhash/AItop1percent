# Chapter 6.3 — Foundation Model Dependency & Vendor Lock-In

Imagine building your entire business on a platform where the owner can change the pricing, deprecate your key feature, or go down for six hours — and you have zero say in any of it. That's what it means to build on foundation model APIs in 2026.

Every AI product that calls an external model API has a dependency problem. The question isn't whether to depend on foundation models — most products must. The question is how to manage that dependency so it doesn't become a single point of failure.

---

### The Dependency Risks

**Pricing changes.** Model providers have changed pricing multiple times. Usually prices drop — but not always, and not for every model. If your unit economics depend on a specific price per token, a pricing increase can break your business overnight. And you won't get advance notice.

**Model deprecation.** Models get deprecated. GPT-3.5 is already legacy. Every model you build on today will eventually be replaced. When your model is deprecated, you have a migration deadline — and the replacement model won't behave identically. Prompts that worked perfectly on the old model may need rewriting.

**Behavior changes.** Even without deprecation, model behavior changes with updates. A model that was great at following your specific prompt format might become worse (or better, but differently) after a provider update. You'll discover this in production, from user complaints, unless you have continuous evaluation running.

**Rate limits and throttling.** During peak demand, providers throttle API calls. If your product depends on real-time responses and the provider throttles you during your busiest hour, your users experience degradation that you can't fix.

**Outages.** Every major model provider has had outages in the past 12 months. When they go down, your product goes down — unless you've built for it.

**Policy changes.** Providers update their acceptable use policies. A use case that was allowed yesterday might be restricted tomorrow. If your product operates in a gray area, a policy change can shut you down.

---

### Managing the Dependency

**Multi-provider architecture.** Don't build for one provider. Abstract your model calls behind an interface that can route to multiple providers. This isn't theoretical — teams that did this survived the OpenAI outage of November 2024 by routing to Anthropic. Teams that didn't went down with the ship.

**Model evaluation on every change.** Run your eval suite whenever you switch models, update prompts, or when a provider announces changes. This catches behavioral regressions before users do.

**Contractual protections.** For enterprise-scale usage, negotiate terms that include: deprecation notice periods, pricing guarantees (even short-term), SLA commitments with financial penalties, and data handling guarantees.

**Fallback models.** Always have a fallback. If your primary model is Claude, your fallback might be GPT-4. If both are down, your fallback might be an open-source model running on your own infrastructure. The fallback doesn't need to be as good — it needs to keep your product functional.

**Cost monitoring with alerts.** Track your API spend daily. Set alerts for unusual spikes. A bug that causes retry loops can burn through your monthly budget in hours.

---

### The Independence Spectrum

On one end: fully dependent on a single provider's API. On the other: running your own fine-tuned open-source model on your own infrastructure. Most products should be somewhere in the middle — using provider APIs for primary inference with the ability to switch providers or fall back to self-hosted models.

Where you sit on this spectrum depends on your risk tolerance, your volume, and your budget. But "fully dependent on one provider with no fallback" is never the right answer.

---

*Next: the open-source vs proprietary decision — and why it's not as simple as "free vs paid."*
