# Chapter 4.5 — Cross-Functional Decision Making for AI

AI product decisions are inherently cross-functional. No single discipline has enough information to make good decisions alone. The PM doesn't know the technical constraints. The engineer doesn't know the business context. The domain expert doesn't know the cost implications. And legal doesn't know any of it.

The teams that build great AI products aren't the ones with the best engineers or the smartest PMs. They're the ones that make cross-functional decisions well.

---

### The Decisions That Require Cross-Functional Input

**Quality thresholds.** "What accuracy level is acceptable?" This requires: PM (business impact of errors), ML (what's technically achievable), domain expert (professional standard of care), legal (liability implications), and business (cost of the required quality level).

**Ship vs wait.** "Is this ready?" Requires: ML (quality metrics), PM (market timing and user need), engineering (reliability and monitoring readiness), and legal (compliance status).

**Cost vs quality tradeoffs.** "Should we use the expensive model or the cheap one?" Requires: ML (quality difference), PM (what quality the user expects), finance (budget and unit economics), and engineering (performance implications).

**Safety policy.** "What should the AI refuse to do?" Requires: PM (user expectations), legal (liability and compliance), trust and safety (abuse patterns), and engineering (implementation feasibility).

**Data handling.** "What data can we use for training and evaluation?" Requires: legal (privacy and consent), engineering (data infrastructure), PM (data availability), and compliance (regulatory requirements).

---

### Three Decision-Making Patterns

**Pattern 1: The Decision Matrix.**
For each major decision type, pre-define: who has input, who has veto, and who makes the final call.

Example:
- Quality thresholds → PM decides, ML and domain expert input, legal has veto for Tier 3+
- Ship decisions → PM decides for Tier 1-2; multi-stakeholder approval for Tier 3+
- Cost tradeoffs → PM decides with finance input
- Safety policy → Legal and trust/safety decide, PM and engineering input

Write this down. When a decision comes up, everyone knows who's in the room and who makes the call. No ad hoc arguments.

**Pattern 2: The Quality Review Board.**
For Tier 3+ products, establish a regular review meeting (weekly or bi-weekly) where representatives from each function review quality metrics, discuss issues, and make collective decisions. This prevents quality decisions from being made in silos and ensures all perspectives are heard.

**Pattern 3: The Decision Log.**
Record every significant AI product decision: what was decided, by whom, with what data, and what alternatives were considered. This serves three purposes: accountability (we know who decided), learning (we can review past decisions), and compliance (we can show regulators our decision process).

---

### The Communication Problem

The biggest obstacle to good cross-functional decisions isn't disagreement — it's miscommunication. Each function speaks a different language:

- ML says "the model's perplexity improved by 12%." The PM hears nothing useful.
- PM says "users are unhappy." ML hears nothing actionable.
- Legal says "we need a DPIA." Engineering doesn't know what that is.
- Domain experts say "this answer is clinically inaccurate." Everyone else doesn't know how to fix it.

The fix is a shared vocabulary (we covered this in Chapter 1.7) and a translation layer — usually the PM or a technical product lead who can bridge between functions. Invest in this translation capability. It's more valuable than any technical improvement.

---

### The Speed Tax

Cross-functional decision making is slower than unilateral decision making. That's the tradeoff. A single engineer can make a decision in five minutes. Getting PM, ML, legal, and domain expert input takes a day.

Minimize the tax by pre-defining which decisions need cross-functional input and which can be made unilaterally. Not every prompt change needs legal review. Not every model swap needs domain expert approval. Define the threshold: what level of change triggers cross-functional review? What can individuals decide on their own?

The answer depends on your risk tier. Higher risk = more cross-functional involvement. Lower risk = more individual autonomy. Match the process to the stakes.

*Next: why domain experts matter more than most AI teams realize.*
