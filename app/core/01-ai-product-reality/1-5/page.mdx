# Chapter 1.5 — What "Production-Ready" Actually Means

"Is it production-ready?" is the most loaded question in AI engineering. I've watched teams answer "yes" because the model gives good answers on their test set. That's like saying a car is road-ready because the engine starts.

Production-ready means your system can handle real users, real scale, real failures, and real consequences — and you have the infrastructure to know when something goes wrong before your users do.

---

### The Production-Ready Checklist

Most teams think of production readiness as a binary: it works or it doesn't. In reality, it's a spectrum across multiple dimensions. Here's what actually matters:

**Reliability.**
Can your system stay up? Not just "does the model return a response" but the full chain: input validation, model call, output processing, response delivery. What happens when the model API has a 500ms latency spike? What happens when it returns malformed JSON? What happens when it times out entirely?

Production-ready means you have answers — and implementations — for all of these. Fallback responses, retry logic, circuit breakers, graceful degradation. If your system's only failure mode is "show the user an error page," you're not ready.

**Consistency.**
Run the same input through your system ten times. Do you get acceptable results every time? Foundation models are probabilistic — the same prompt can produce different outputs. Production-ready means you've measured this variance and either controlled it (through temperature settings, structured outputs, validation layers) or accepted it with eyes open.

**Evaluation coverage.**
You need an eval set that covers your real-world input distribution, not just the happy paths you designed for. This means edge cases, adversarial inputs, long-tail queries, multilingual inputs if applicable, and the weird stuff users actually type. If your eval set is 50 hand-picked examples, you're not production-ready.

**Monitoring.**
Can you tell if your system degrades tomorrow? Not next month when the quarterly review happens — tomorrow. Production-ready means you have real-time quality signals: automated eval scores on a sample of production traffic, latency percentiles, error rates, cost tracking, and drift detection. If the model starts giving worse answers on Wednesday, you need to know by Thursday, not by the next user complaint.

**Cost predictability.**
Do you know what this will cost at 10x your current traffic? At 100x? Have you modeled the cost per query, the cost per user, and the cost per resolved task? Production-ready means your CFO won't get a surprise five-figure bill because you didn't account for retry storms or unexpectedly long inputs.

**Safety and abuse handling.**
What happens when someone tries to jailbreak your system? What happens when a user asks for something dangerous, illegal, or against your terms of service? Production-ready means you have input filters, output validators, and a clear policy for edge cases — not "we'll figure it out when it happens."

**Rollback capability.**
If you ship a prompt change that makes quality worse, can you revert in minutes? Production-ready means you have versioned prompts, versioned configurations, and a deployment process that supports instant rollback. Shipping without rollback capability is like driving without brakes.

---

### The Minimum Bar

Not every product needs every item on this list at the same depth. A low-risk internal tool has a different bar than a customer-facing medical product. But here's the minimum for anything touching real users:

- You have an eval set with at least 100 representative examples
- You've measured quality, latency, and cost at projected scale
- You have monitoring that catches degradation within 24 hours
- You have a fallback for when the model is unavailable
- You have a rollback plan for bad deployments
- You've tested adversarial and edge-case inputs

If you can't check all six, keep building. Shipping without these isn't bold — it's reckless.

---

### The "Good Enough" Trap

Teams sometimes define production-ready as "good enough for now." That's fine if "for now" has a specific meaning: "we're launching to 100 beta users with a feedback form and a human review queue." It's not fine if "for now" means "we're hoping nothing goes wrong."

Be explicit about what you're shipping, what risks you're accepting, and what you're deferring. Write it down. A deliberate tradeoff is engineering. An unexamined assumption is a future incident.

*Next: the AI product lifecycle — from prototype to scale, and what changes at each stage.*
