# Chapter 2.5 — Agent Products (Autonomous Workflows, Tool-Using Systems)

Agent products are the frontier of AI in 2026 — and the frontier is dangerous territory. Unlike every other archetype we've covered, agents don't just produce outputs. They take actions. They call APIs, modify databases, send emails, execute code, and interact with real-world systems. When an agent makes a mistake, it doesn't just say something wrong — it does something wrong.

---

### What Makes Agents Different

A chatbot gives you a wrong answer and you ignore it. An agent gives you a wrong answer and then acts on it before you can stop it.

That's the fundamental difference. Agent products operate in a loop: perceive the current state, decide what to do, take an action, observe the result, and repeat. Each cycle introduces a new opportunity for error, and those errors compound. A wrong decision in step 2 leads to a wrong action in step 3, which creates a wrong state for step 4.

The simplest agent is a model that can call tools — search the web, query a database, run a calculation. The most complex agents orchestrate multi-step workflows involving dozens of tools, branching logic, human approvals, and long-running processes.

---

### Agent Product Patterns in 2026

**Task completion agents.** "Book me a flight to London next Thursday under $500." The agent searches flights, compares options, and either presents recommendations or completes the booking. The value is clear: the agent does in 30 seconds what takes the user 15 minutes.

**Workflow automation agents.** "Process this refund: verify the order, check the return policy, calculate the refund amount, update the database, and email the customer." The agent orchestrates a multi-step business process that previously required a human operator.

**Research agents.** "Find the top 10 competitors in the enterprise AI space, summarize their pricing models, and identify gaps we can exploit." The agent searches multiple sources, synthesizes information, and produces a structured deliverable.

**Code agents.** "Fix the bug in this file, write tests, and submit a pull request." The agent reads code, reasons about it, makes changes, verifies its work, and interacts with development tools.

---

### The Unique Risks

**Irreversible actions.** A chatbot's worst case is a bad response you can delete. An agent's worst case is sending an email you can't unsend, executing a trade you can't reverse, or deleting data you can't recover. Agent products need explicit, carefully designed guardrails around irreversible actions — human approval gates, confirmation steps, undo capabilities.

**Cascading failures.** In a multi-step workflow, an error in step 3 propagates through steps 4, 5, and 6. By the time anyone notices, the system has executed a series of actions based on a flawed premise. Agent products need checkpoints — places where the system pauses, validates its current state, and confirms it's still on track.

**Tool abuse and privilege escalation.** An agent with access to tools can potentially use those tools in unintended ways. An agent authorized to send emails could spam your entire customer list. An agent authorized to query a database could exfiltrate sensitive data. Tool permissions need to follow the principle of least privilege, with hard limits on scope, rate, and blast radius.

**Cost explosion.** Agents run in loops. A poorly designed agent can loop hundreds of times, calling expensive APIs at each step, before anyone notices. A single runaway agent session can cost more than your entire monthly AI budget. Agent products need hard limits on loop iterations, API calls per session, and total spend per task.

---

### Eval Strategy for Agents

Agent evaluation is fundamentally harder than output evaluation:

- **Trajectory evaluation.** Did the agent take a reasonable sequence of steps? Not just "did it reach the right answer" but "did it get there efficiently and safely?"
- **Tool use correctness.** Did the agent call the right tools with the right parameters? Did it use the tools in the right order?
- **Error recovery.** When something went wrong mid-workflow, did the agent recover gracefully or spiral?
- **Safety boundary compliance.** Did the agent stay within its authorized scope? Did it attempt actions it shouldn't have?

Section 3, Chapter 8 goes deep on agent evaluation. For now, understand that evaluating agents is the hardest problem in AI evaluation — and if you're building an agent product, evaluation isn't optional, it's existential.

---

*Next: voice and conversational products — where latency isn't a metric, it's the entire user experience.*
