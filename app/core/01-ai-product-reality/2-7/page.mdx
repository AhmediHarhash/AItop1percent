# 2.7 â€” Vision and Multimodal Products

In mid-2025, a healthcare technology company launched an automated patient intake system that processed scanned insurance cards and handwritten medical history forms. The promise was compelling: eliminate thirty minutes of manual data entry per patient, reduce front-desk staffing costs by 40%, and improve accuracy by removing human transcription errors. The pilot ran for six weeks across three clinics. By week four, staff had stopped using the system entirely. The problem was not that the system failed catastrophically. The problem was that it failed inconsistently. It read printed text on insurance cards with 98% accuracy but hallucinated policy numbers when cards were photographed at an angle or had glare from overhead lighting. It correctly extracted dates from typed forms but misread handwritten dates in European format as American format, creating impossible birthdates like February 31st. The system worked brilliantly on clean inputs and silently produced garbage on messy ones, and no one could predict which category a given input would fall into. The root cause was not a technical defect. The root cause was treating vision AI as if it were as robust and consistent as text AI, when in fact vision systems have failure modes that are fundamentally harder to anticipate, test, and handle gracefully.

This is the central challenge of multimodal AI products. Vision and multimodal systems unlock use cases that text-only systems cannot touch. The real world is visual. Receipts, medical scans, manufacturing defects, satellite imagery, video surveillance, handwritten forms, architectural plans, product photos, identity documents, damage assessments. But visual AI is not just text AI applied to images. It has different failure modes, different evaluation requirements, different cost structures, and different regulatory constraints. Building a production-grade vision product in 2026 requires understanding these differences deeply, not treating vision as a feature you bolt onto a text product.

## What Multimodal Products Actually Do

Multimodal AI products process images, video, and documents alongside text. The term multimodal is often used loosely, but in practice there are four distinct categories of vision products, each with its own quality bar and technical requirements.

Document understanding products process scanned documents, PDFs, forms, invoices, contracts, and reports. This is not the same as OCR, though OCR is a component. OCR extracts text as if the document were a long string of characters. Document understanding sees the document the way a human does: layout, tables, headers, signatures, stamps, checkboxes, handwriting, formatting. A document understanding system knows that the number in the top-right corner of an invoice is the invoice number, not a phone number, because it understands document structure. These products are deployed in finance, legal, healthcare, insurance, and government. They replace manual data entry workflows that cost organizations billions of dollars annually. The quality bar is high because errors create financial liability. An incorrectly parsed invoice amount is not a typo; it is a payment error that must be reconciled.

Image analysis products interpret photographs and still images. Quality inspection on manufacturing lines. Medical imaging systems that detect anomalies in X-rays, CT scans, MRI images, or pathology slides. Satellite and aerial imagery analysis for agriculture, urban planning, and environmental monitoring. Product recognition in retail environments. Damage assessment for insurance claims. Each of these domains has its own accuracy requirements, regulatory constraints, and ground truth challenges. A manufacturing inspection system might need 99.5% defect detection accuracy because missing a defect costs more than flagging false positives. A medical imaging system might need 95% sensitivity and regulatory approval from the FDA or equivalent authority. An agricultural monitoring system might tolerate 80% accuracy because the output is advisory, not diagnostic. Image analysis products are not generic. They are domain-specific, and their evaluation must reflect domain-specific quality standards.

Video understanding products add the time dimension. Security and surveillance systems that detect anomalies, count people, recognize events, and flag unusual behavior. Content moderation systems that review uploaded videos for prohibited content. Sports analytics platforms that track player movements, ball trajectories, and game events. Manufacturing process monitoring that detects deviations in real time. The challenge with video is not just understanding what is in the frame; it is understanding what happened over time. A person standing still for ten seconds is different from a person pacing for ten seconds, even if individual frames look similar. Video products must reason about sequences, not just snapshots. They also face harder latency constraints. A real-time surveillance system must process video as it streams. A content moderation system might process uploads in batch. These are fundamentally different architectures.

Multimodal reasoning products combine vision and text. A system that takes a photo of a product and writes a listing description. A system that takes a screenshot of an error message and diagnoses the problem. A system that takes a floor plan and estimates square footage, construction costs, or furniture layouts. A customer support system that accepts a photo of a damaged product and generates a return authorization. These products require the model to see and reason simultaneously. They are harder to build than single-modality products because errors can occur in the vision stage, the reasoning stage, or the handoff between them. Evaluation must cover both modalities and their interaction.

## Why Vision Products Fail Differently Than Text Products

Vision products fail for reasons that text products do not, and teams that treat vision as just another input modality learn this the hard way.

Ground truth is expensive. Labeling images requires specialized tools, domain expertise, and significantly more time than labeling text. Drawing bounding boxes around objects, segmenting regions, classifying visual features, annotating anatomical structures in medical images. A radiologist labeling chest X-rays costs $200 per hour. A pathologist labeling tissue samples costs more. Even non-expert labeling is slower for images than for text. A human can read and label a sentence in seconds. Labeling an image with ten objects, each requiring a bounding box and a class label, takes minutes. The data pipeline for vision products is fundamentally more expensive than for text products, which means eval sets are smaller, iteration cycles are slower, and improvement is costlier.

Confidence calibration is critical in ways it is not for text. A text generation system that is 85% confident can say "I think this might be X, but verify." A medical imaging system that is 85% confident is making a clinical decision. Vision products that operate in high-stakes domains need carefully calibrated confidence scores, not just high accuracy. Calibration means that when the model says it is 90% confident, it is correct 90% of the time. Many vision models are overconfident or underconfident. An overconfident model makes errors that users trust. An underconfident model escalates cases that it could have handled. Building a well-calibrated confidence score often requires domain-specific calibration datasets and post-processing. You cannot assume that the raw model output is calibrated.

Edge cases are visual, not linguistic. The long tail of vision failures includes poor lighting, unusual angles, occlusion where something blocks the view, rare objects that appear infrequently in training data, domain-specific visual patterns that the model has never seen, and adversarial images designed to fool the system. These are much harder to enumerate in advance than text edge cases. You can write down common misspellings, punctuation errors, or ambiguous phrasings. You cannot easily write down all the ways an image can be degraded, distorted, or unusual. Vision eval sets must be built empirically by collecting real-world failures, not by imagining hypothetical ones.

Privacy is more complex with images than with text. Images often contain faces, license plates, street addresses, personal identifying information visible on documents, and incidental bystanders who never consented to be in the image. Processing visual data raises privacy concerns that text data does not. A text transcript of a customer service call contains what the customer said. A video of the same call contains what the customer looks like, what is visible in the background, and potentially what the customer is wearing or holding. EU GDPR, CCPA, and the EU AI Act impose stricter requirements on biometric data processing than on text processing. The EU AI Act Article 5 explicitly prohibits certain real-time biometric identification systems in public spaces. If your vision product processes faces, you are subject to biometric regulations. If it processes medical images, you are subject to HIPAA or equivalent. If it processes video in public spaces, you may be prohibited outright in some jurisdictions. Vision products have regulatory exposure that text products do not.

## The Multimodal Gimmick Versus the Multimodal Product

In 2026, many products add vision capabilities because they can, not because they should. The availability of high-quality vision APIs from OpenAI, Anthropic, Google, and others makes it trivial to add image understanding to any application. But trivial to add is not the same as valuable to users.

A multimodal product adds value when the visual input provides information that text cannot. A damage assessment tool for insurance claims needs photos because text descriptions of damage are subjective and unreliable. A medical imaging diagnostic assistant needs scans because symptoms described in text do not replace radiological evidence. A manufacturing quality inspection system needs images because defects are visual. These are legitimate multimodal products. The visual input is not optional; it is the primary signal.

A multimodal gimmick adds vision where text would suffice, creating complexity without proportional value. A customer support chatbot that accepts photos of error messages when the user could copy and paste the text. A document Q&A system that processes PDFs as images when the PDFs are already searchable text. A voice assistant that asks users to show their face for authentication when a password would be simpler and more secure. These products add vision because it seems impressive, not because it solves a real problem better than alternatives. The result is higher cost, more failure modes, and worse user experience than a text-only version.

The test is simple. If you removed the vision capability, would the product still solve the user's problem? If yes, you have a gimmick. If no, you have a product. Build the latter.

## Cost Structure of Vision APIs

Vision products are more expensive to run than text products. In early 2026, GPT-5 charges approximately $2.50 per thousand input tokens for text and $10 per thousand input tokens for images, depending on resolution. Claude Opus 4.5 has similar pricing. A high-resolution image consumes roughly 1,500 tokens, making each image analysis call cost around $0.015. For a product that processes thousands or millions of images, this adds up quickly. A document processing system that handles 100,000 invoices per month at $0.015 per invoice spends $1,500 per month on API calls alone, not including storage, compute, or labor. A surveillance system that analyzes video in real time must process 30 frames per second; even if it only analyzes one frame per second, that is 86,400 frames per day per camera, costing over $1,200 per camera per day. These costs are not sustainable at API pricing. High-volume vision products must either negotiate volume discounts, use cheaper models, use open-source models hosted internally, or redesign the product to process fewer images.

Cost optimization for vision products requires treating the vision model as an expensive resource to be used sparingly. Pre-filter inputs before sending them to the model. Use a lightweight classifier to determine whether an image is worth analyzing. Use OCR for text-heavy images and only invoke the vision model for complex visual reasoning. Cache results aggressively if the same image is analyzed multiple times. Downsample images to the minimum resolution required for the task. A 4K image might look impressive, but if the task is reading a printed invoice, a 1024x768 image is sufficient and costs less to process. Vision product economics improve dramatically when you stop treating the vision API as an infinite resource.

## Evaluation Strategy for Vision Products

Evaluating vision products is harder than evaluating text products because visual correctness is context-dependent and domain-specific.

Use domain-specific accuracy metrics. Medical imaging uses sensitivity, specificity, positive predictive value, and negative predictive value. Object detection uses mean average precision, intersection over union, and recall at various confidence thresholds. OCR uses character error rate, word error rate, and field-level accuracy for structured documents. Facial recognition uses false acceptance rate and false rejection rate. Do not invent your own metrics. Use the metrics your domain expects. If your product will be compared to existing systems or evaluated by domain experts, use the metrics they already understand.

Build edge case coverage into your eval sets. Vision systems fail on poor quality images, unusual angles, rare object classes, adversarial examples, and inputs that are out-of-distribution relative to training data. Your eval set must include these deliberately. Collect real-world failures from early deployments and add them to the eval set. Synthetically generate challenging inputs: add noise, blur, compression artifacts, rotation, occlusion. Test across different lighting conditions, backgrounds, and image sources. A vision system trained and evaluated on high-quality studio photos will fail in production when users submit blurry smartphone photos taken in poor lighting.

Conduct bias audits. Vision systems can perform differently across demographic groups. Facial recognition systems have historically had higher error rates for darker skin tones. Medical imaging systems trained primarily on data from one population may perform worse on patients from other populations. Product recognition systems may work better for Western brands than for products from other regions. If your vision product makes decisions about people, you must test explicitly for demographic fairness. Build eval sets that are stratified by protected characteristics and measure performance separately for each group. If performance differs significantly, you have a fairness problem that must be addressed before deployment.

Measure latency under realistic conditions. Real-time vision applications have strict latency budgets. A manufacturing inspection system that processes items on a conveyor belt has milliseconds to make a decision. A video surveillance system that detects intrusions must respond in seconds, not minutes. Offline batch processing applications can tolerate higher latency, but users still expect results within a reasonable timeframe. Measure latency in production-like environments, not on a developer laptop. Account for image upload time, preprocessing, model inference, and postprocessing. If latency is too high, you must optimize the model, reduce image resolution, or rearchitect the pipeline.

## When Multimodal Adds Real Value

The biggest opportunity in 2026 is not pure vision or pure text. It is the combination. Products that can see a document, understand its structure, extract information, and answer questions about it in natural language are replacing entire manual workflows that previously required humans. A contract review system that reads a 50-page agreement, extracts key terms, flags unusual clauses, and answers questions like "What is the termination notice period" is worth more than a system that only extracts terms or only answers questions. A medical intake system that processes insurance cards, driver's licenses, and handwritten forms, then integrates the extracted data into the EHR and prompts the front desk staff to resolve ambiguities, is worth more than a system that only does OCR. A real estate platform that analyzes property photos, floor plans, and listing descriptions to generate market valuations, renovation recommendations, and buyer-targeted marketing copy is worth more than a system that only processes text listings.

Multimodal products are harder to build, harder to evaluate, and more expensive to run. But they are also harder to commoditize. Text-only AI products face intense competition because text models are widely available and well understood. Multimodal products that work well in a specific domain create defensible value because they require domain-specific data, domain-specific evaluation, and deep integration into domain workflows. The teams that build these well have a genuine competitive advantage.

But only if they treat vision as a first-class product challenge, not a bolt-on feature. Vision products fail differently, cost more, and require different evaluation strategies. Understand that, or build a text product instead.

Next, we turn to the AI product archetype with the most objective feedback loop: code generation and developer tools, where the output either compiles and runs or it does not.
