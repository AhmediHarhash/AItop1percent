# Chapter 2.7 — Vision & Multimodal Products (Image, Video, Document Understanding)

In 2026, AI products that only understand text are leaving value on the table. The real world is visual — receipts, medical scans, manufacturing defects, satellite imagery, video surveillance, handwritten forms, architectural plans. Multimodal AI products process images, video, and documents alongside text, unlocking use cases that text-only systems simply can't touch.

---

### What Multimodal Products Do

**Document understanding.** Processing scanned documents, PDFs, forms, invoices, and contracts — not as text extraction (which treats the document as a string) but as visual understanding (which sees layout, tables, headers, signatures, stamps, and formatting). A text extractor sees words. A document understanding system sees the document the way a human does.

**Image analysis.** Quality inspection on manufacturing lines. Medical imaging — detecting anomalies in X-rays, CT scans, or pathology slides. Satellite and aerial imagery analysis. Product recognition in retail. Damage assessment in insurance claims. Each domain has its own quality bar and regulatory requirements.

**Video understanding.** Security and surveillance (anomaly detection, people counting, event recognition). Content moderation (detecting prohibited content in uploaded videos). Sports analytics. Manufacturing process monitoring. Video adds the time dimension — it's not just "what's in the frame" but "what happened over the last 30 seconds."

**Multimodal reasoning.** Systems that combine image and text understanding: "Here's a photo of a product — write a listing description," "Here's a screenshot of an error — diagnose the problem," "Here's a floor plan — estimate the square footage." These require the model to see and reason simultaneously.

---

### Why Vision Products Are Different

**Ground truth is expensive.** Labeling images is harder and slower than labeling text. Drawing bounding boxes, segmenting regions, classifying visual features — all require specialized tools and often domain expertise. A radiologist labeling medical images costs $200/hour. The data pipeline for vision products is fundamentally more expensive than for text products.

**Confidence calibration is critical.** A text system that's 85% sure can say "I think this might be X." A medical imaging system that's 85% sure is making a clinical decision. Vision products that operate in high-stakes domains need carefully calibrated confidence scores — and clear protocols for what happens at different confidence levels.

**Edge cases are visual, not linguistic.** The long tail of failure cases includes poor lighting, unusual angles, occlusion (something blocking the view), rare objects, domain-specific visual patterns, and adversarial images designed to fool the model. These are much harder to enumerate in advance than text edge cases.

**Privacy is more complex.** Images often contain faces, license plates, addresses, personal identifying information, and incidental bystanders. Processing visual data raises privacy concerns that text data doesn't — especially in surveillance, retail, and healthcare applications. EU AI Act Article 5 specifically prohibits certain biometric AI applications.

---

### Eval Strategy for Vision Products

- **Domain-specific accuracy metrics.** Medical imaging uses sensitivity and specificity. Object detection uses mAP (mean Average Precision). OCR uses character error rate. Use the metrics your domain expects — don't invent your own.
- **Edge case coverage.** Build eval sets that include difficult conditions: poor quality images, unusual angles, rare classes, adversarial examples.
- **Bias audits.** Vision systems can perform differently across skin tones, genders, age groups, and geographies. Test explicitly for demographic fairness.
- **Latency requirements.** Real-time applications (manufacturing inspection, live video) have strict latency budgets. Offline applications (document processing) can tolerate more.

---

### The Multimodal Opportunity

The biggest opportunity in 2026 isn't pure vision or pure text — it's the combination. Products that can see a document, understand its structure, extract information, and answer questions about it in natural language are replacing entire manual workflows. The teams that build these well have a genuine competitive advantage, because multimodal AI is harder to commoditize than text-only AI.

*Next: code generation and developer tools — the archetype that's reshaping how software gets built.*
