# Chapter 2.6 — Voice & Conversational Products (Real-Time, Telephony, Assistants)

Voice changes everything. When you move from text to voice, you don't just change the interface — you change the physics of the interaction. In text, a user waits three seconds for a response and it feels instant. In voice, a user waits three seconds and it feels broken.

Voice AI products are some of the hardest to build well, and in 2026, they're also some of the most commercially valuable.

---

### Why Voice Is a Different Animal

**Latency is the product.** In text-based AI, users tolerate 2-5 second response times. In voice, anything above 500 milliseconds feels like an awkward pause. Above one second, users assume the system is broken. This means your entire architecture — speech recognition, language model processing, speech synthesis — needs to complete in under a second. That's not a nice-to-have. That's the minimum bar.

**Errors are immediately obvious.** When a chatbot hallucinates, the user might not notice for a few sentences. When a voice assistant mispronounces a word, stutters, speaks over the user, or gives a response that doesn't match the question, the user notices instantly. Voice amplifies errors.

**Turn-taking is an art.** In human conversation, we manage turn-taking through subtle cues — pauses, intonation changes, filler words. Voice AI needs to handle: when to start speaking, when to stop and listen, how to handle interruptions, what to do when the user pauses mid-sentence (are they thinking or done?), and how to handle cross-talk. Getting this wrong creates interactions that feel robotic, frustrating, or rude.

**Speech-to-text adds a failure layer.** Before your language model even sees the input, a speech recognition system has to convert audio to text. Recognition errors — misheard words, dropped words, wrong homophones — propagate through the entire pipeline. A user says "I need to cancel my order" and the system hears "I need to cancel my daughter" — and everything downstream goes wrong.

---

### Voice Product Patterns

**Customer service IVR replacement.** Replacing "press 1 for billing" with natural conversation. The user calls, describes their problem in natural language, and the system routes them, answers their question, or completes their task. This is the largest commercial market for voice AI in 2026.

**Real-time assistants.** Siri, Alexa, Google Assistant, and their enterprise equivalents. Always-on voice interfaces that answer questions, control devices, and execute commands. The challenge is breadth — users expect these to handle anything, but quality is only acceptable for a narrow set of tasks.

**Voice agents in telephony.** AI systems that make or receive phone calls: appointment scheduling, debt collection, sales qualification, survey administration. These operate in real-time over phone networks, which adds constraints around audio quality, latency, and connection reliability.

**Transcription and analysis.** Converting spoken content (meetings, calls, interviews) into structured data — transcripts, summaries, action items, sentiment analysis. Not real-time, but the accuracy requirements are high because the outputs feed into business decisions.

---

### The Latency Budget

For real-time voice products, you have roughly 800 milliseconds total from the moment the user stops speaking to the moment your system starts responding. That budget breaks down approximately like this:

- Voice activity detection (knowing the user stopped talking): 100-200ms
- Speech-to-text processing: 100-300ms
- Language model generation (first token): 100-300ms
- Text-to-speech (first audio): 50-150ms

There's no room for waste. Every component in your pipeline needs to be optimized for latency, and you often need to start generating the response before the full output is ready — streaming audio to the user as it's generated.

---

### Eval Strategy for Voice

Voice evaluation adds dimensions that text products don't have:

- **Word Error Rate (WER):** How accurately does speech recognition convert audio to text?
- **Latency percentiles:** Not just average latency, but P95 and P99. Users remember the worst interactions.
- **Turn-taking quality:** Does the system interrupt? Does it create awkward silences? Does it handle interruptions gracefully?
- **Voice quality:** Is the synthesized speech natural, or does it sound robotic? Does it pronounce domain-specific terms correctly?
- **End-to-end task completion:** Did the user accomplish what they called to do?

We go deep on voice evaluation in Section 21. For now, understand that voice products face every challenge of text products plus an entirely separate set of real-time, perceptual, and audio-specific challenges.

---

*Next: vision and multimodal products — where AI processes images, video, and documents alongside text.*
