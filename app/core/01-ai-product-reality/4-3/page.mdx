# Chapter 4.3 — ML Engineers vs AI Engineers vs Software Engineers

These three titles get used interchangeably, and that's causing real problems. A company hires an "AI engineer" expecting someone who can build evaluation pipelines and production AI systems, and gets someone who's great at training models but has never deployed one. Or they hire an "ML engineer" to integrate an API and wonder why they're spending weeks on model architecture when the job is prompt engineering and orchestration.

The roles are different. Understanding how they're different helps you staff correctly.

---

### ML Engineer (Machine Learning Engineer)

**Core skill:** Building and training models.

The ML engineer understands model architectures, training procedures, loss functions, data pipelines for training, hyperparameter tuning, and model evaluation in the research sense. They work with PyTorch or TensorFlow, manage training infrastructure, and think in terms of model performance metrics.

**When you need them:**
- You're training or fine-tuning custom models
- You're building specialized classifiers, embedding models, or domain-specific models
- You need someone who understands why a model is behaving a certain way at the architecture level
- You're doing research-adjacent work that requires deep model expertise

**When you don't need them:**
- You're building products on top of foundation model APIs
- Your product is primarily prompt engineering, orchestration, and application logic
- You don't have training data or the infrastructure to train models

---

### AI Engineer

**Core skill:** Building products that use AI models.

The AI engineer is the role that has exploded in 2025-2026. They understand prompt engineering, RAG architectures, agent frameworks, evaluation methodologies, model routing, and the operational aspects of running AI in production. They work with APIs, orchestration tools (LangChain, LlamaIndex, custom frameworks), and evaluation infrastructure.

**When you need them:**
- You're building products on top of foundation model APIs (most companies in 2026)
- You need prompt engineering, RAG implementation, and agent design
- You need evaluation infrastructure: eval sets, automated scoring, quality monitoring
- You're integrating AI into existing software products

**When you don't need them:**
- You're doing fundamental model research
- Your work is primarily traditional software with a thin AI layer that a software engineer can handle

---

### Software Engineer

**Core skill:** Building reliable, scalable software systems.

The software engineer builds the application: APIs, databases, frontend, deployment, monitoring, security. In an AI product, they own the infrastructure that the AI sits inside — the shell that makes the model's capabilities accessible, reliable, and safe.

**When you need them:**
- Always. Every AI product needs software engineering.
- They build the API layer, handle authentication, manage deployments, implement caching, set up monitoring, handle error recovery
- They ensure the product works even when the AI doesn't — fallback paths, graceful degradation, retry logic

**The overlap:**
In practice, the best AI product teams have engineers who span these categories. An AI engineer who can also build solid application infrastructure. A software engineer who understands enough about prompting and evaluation to make good design decisions. Rigid role boundaries create handoff problems.

---

### The Staffing Decision

**Stage 1 (Prototype/MVP): AI engineer + software engineer.** You're building on APIs. You need prompt engineering, basic evaluation, and solid application development. An ML engineer is usually overkill unless your use case genuinely requires custom training.

**Stage 2 (Production): AI engineer + software engineer + evaluation specialist.** As you scale, evaluation becomes a full-time job. The person building the eval framework, maintaining the eval set, and running quality reviews shouldn't also be designing prompts and building features.

**Stage 3 (Scale/Differentiation): Add ML engineer.** When you have enough data and clear evidence that a custom or fine-tuned model would outperform prompted APIs, bring in an ML engineer. Not before — because ML engineering without clear data and use cases is expensive exploration.

---

### The Hiring Trap

The most common hiring mistake in 2026 is hiring ML engineers when you need AI engineers. Companies think "AI product = we need ML" and hire PhDs who are brilliant at training models but have never built a production application on an API. The result: over-engineered model infrastructure when the real need was good prompt engineering, solid evaluation, and reliable application code.

Hire for what you need now. Plan for what you'll need later. And be honest about which stage you're at.

*Next: where evaluation ownership actually lives — and why getting it wrong breaks everything.*
