# Chapter 3.2 — Tier 1: Low-Risk — Internal Tools, Drafts, Suggestions

Tier 1 products are where most AI journeys should start. Not because they're less important, but because they're the safest place to learn what works before you raise the stakes.

---

### What Tier 1 Looks Like

Tier 1 products share three characteristics:

1. **A human reviews the output before it has any real-world effect.** The AI suggests, drafts, or recommends — a human decides whether to accept.
2. **The cost of a wrong output is low.** A bad draft gets edited. A bad suggestion gets ignored. Nobody is harmed, no money is lost, no data is compromised.
3. **The blast radius is small.** The output affects one person (the user) or a small internal team, not customers, patients, or the public.

Common Tier 1 products:

- **Internal knowledge assistants.** "Search our company docs and draft an answer." If the answer is wrong, the employee notices and looks it up themselves.
- **Email and message drafters.** The AI writes a draft; the human edits and sends. Every output goes through a human filter.
- **Meeting summary generators.** The AI summarizes a meeting transcript. If it misses something, someone on the call catches it.
- **Code suggestions.** Inline completions that the developer accepts or rejects. The developer is the quality gate.
- **Data exploration assistants.** "Show me a chart of last quarter's sales by region." If the chart is wrong, the analyst recognizes it.

---

### The Tier 1 Quality Bar

Tier 1 doesn't mean "quality doesn't matter." It means the consequences of low quality are bounded.

The quality bar for Tier 1 is: **useful more often than annoying.** If the AI's suggestions are helpful 70% of the time, users will adopt it. If helpful only 40% of the time, users will turn it off. The exact threshold depends on the interruption cost — a code completion that's wrong costs the developer two seconds to dismiss, so it can afford a lower hit rate than an email drafter that's wrong and costs five minutes to rewrite.

What you need at Tier 1:
- A basic eval set (50-100 examples covering your main use cases)
- Lightweight monitoring (error rates, usage metrics, user feedback)
- A feedback mechanism (thumbs up/down, "this was wrong" button)
- No formal compliance requirements (unless the data itself is regulated)

What you don't need yet:
- Real-time quality monitoring
- Human review pipelines
- Formal safety testing
- Compliance certifications
- Incident response playbooks

---

### The Tier 1 Trap

The trap is staying at Tier 1 too long. Teams build an internal tool, it works well, and someone says, "Let's give this to customers." That single decision moves you from Tier 1 to Tier 2 or Tier 3, and the entire quality, safety, and monitoring bar changes overnight.

Before you move a Tier 1 product to a higher tier, go through the risk assessment from Chapter 3.1 again. What was low-risk internally might be high-risk externally. An internal chatbot that occasionally hallucinates is a minor annoyance. A customer-facing chatbot that occasionally hallucinates is a trust crisis.

The other trap is under-investing because "it's just internal." Even Tier 1 products need basic evaluation. If your internal knowledge assistant consistently gives wrong answers, employees stop trusting it, stop using it, and your AI initiative gets a reputation for not working. First impressions matter, even internally.

---

### Tier 1 as a Learning Ground

The best reason to start at Tier 1 is learning. You build your evaluation muscles, your monitoring habits, your feedback loops, and your team's AI intuition — all in an environment where mistakes are cheap. By the time you're ready for Tier 2, you've already made the beginner mistakes and built the infrastructure to avoid them.

*Next: Tier 2 — where your AI meets customers, and the stakes go up.*
