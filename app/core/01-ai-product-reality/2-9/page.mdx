# Chapter 2.9 — Hybrid Products: When Your System Is Multiple Archetypes

Here's the reality that the clean archetype categories don't capture: most production AI products in 2026 are hybrids. They combine multiple archetypes in a single user experience, and the interaction between those archetypes creates challenges that no single archetype prepares you for.

---

### What Hybrid Products Look Like

**A customer support platform** that classifies the incoming ticket (classification), searches the knowledge base for relevant articles (retrieval), generates a draft response (text generation), and if the customer agrees, processes a refund (agent action). That's four archetypes in a single workflow.

**A legal research tool** that takes a natural language question (text generation), finds relevant case law (retrieval), extracts key holdings and dates (extraction), and summarizes the findings in a memo (text generation again). Three archetypes, feeding into each other.

**A healthcare triage system** that listens to a patient describe symptoms (voice), classifies urgency level (classification), extracts medical terms from the transcript (extraction), and generates a preliminary assessment for the doctor (text generation). Four archetypes with real-time constraints.

Most AI products are hybrid products. If yours is, you need to know what that means for your architecture, evaluation, and failure modes.

---

### Why Hybrids Are Harder

**Error propagation across stages.** In a single-archetype product, an error affects one output. In a hybrid product, an error in stage one cascades through every subsequent stage. If the classifier gets the ticket category wrong, the retrieval searches the wrong knowledge base, and the generated response answers the wrong question. By the time the user sees the output, three things have gone wrong, and debugging requires tracing back through the entire pipeline.

**Evaluation complexity multiplies.** You can't just evaluate the final output. You need to evaluate each stage independently and the full pipeline end-to-end. A hybrid product with three stages needs at least four eval dimensions: stage 1 quality, stage 2 quality, stage 3 quality, and end-to-end quality. Skipping intermediate evaluations means you can't diagnose where failures occur.

**Latency budgets get divided.** If your total latency budget is two seconds and you have four stages, each stage gets roughly 500 milliseconds. That might be fine for classification and extraction, but tight for generation and impossible for complex retrieval. Hybrid products require careful latency budgeting across the pipeline, and often force architectural tradeoffs like streaming responses before the full pipeline completes.

**Different quality bars per stage.** Your classification stage might need 95% accuracy because errors propagate. Your generation stage might tolerate 85% quality because users can edit the output. But these different quality bars interact: a 95%-accurate classifier feeding an 85%-quality generator produces end-to-end quality that's worse than either number suggests. The math of compound accuracy is unforgiving.

---

### How to Design Hybrid Products

**Map your pipeline explicitly.** Draw every stage, every input and output, every handoff between archetypes. Make the pipeline visible to the entire team — not just in architecture docs, but in your evaluation framework. Every stage boundary is a potential failure point and an evaluation point.

**Build checkpoints between stages.** At each stage boundary, validate the output before passing it to the next stage. If the classifier returns a confidence below 70%, don't pass it to retrieval — escalate to a human. Checkpoints prevent cascading failures and give you instrumentation to diagnose issues.

**Evaluate stages independently first, then end-to-end.** Build separate eval sets for each stage. Run them independently. Only after each stage passes its quality bar do you run end-to-end evaluation. This layered approach makes debugging dramatically faster.

**Design fallbacks per stage.** Each stage needs its own fallback strategy. If retrieval fails, fall back to a broader search. If generation fails, show the raw retrieved documents. If classification is uncertain, ask the user to clarify. A hybrid product with stage-level fallbacks is much more resilient than one with only an end-to-end fallback.

---

### The Architecture Trap

The biggest mistake in hybrid products is building the entire pipeline as one monolithic system. When something breaks, you can't isolate the problem. When you want to improve one stage, you risk breaking another. Build hybrid products as composable stages with clear interfaces, independent evaluation, and the ability to swap or upgrade each component without rebuilding the whole thing.

---

*That wraps up Chapter 2. You now know the nine product archetypes and the unique challenges each one brings. In Chapter 3, we'll build the risk framework that determines how seriously you need to take evaluation, safety, and compliance for your specific product.*
