# Chapter 5.12 — Unit Economics: Cost-to-Serve, Margins & Pricing Constraints

You can build the best AI product in the world. If it costs more per query than the value it creates, it's a hobby, not a business. Unit economics is where AI product dreams meet financial reality — and it's the conversation most teams have too late.

---

### The Unit Economics Framework

Every AI product has a unit — the atomic interaction that creates value. For a chatbot, it's a conversation. For a document processor, it's a document. For a search tool, it's a query. For an agent, it's a completed task.

Your unit economics answer one question: **does each unit generate more value than it costs?**

**Cost per unit:**
- Model inference cost (input tokens + output tokens + any reasoning overhead)
- Infrastructure cost (hosting, compute, storage, networking — amortized per unit)
- Human cost (moderation, review, escalation — amortized per unit)
- Tool and API costs (third-party APIs called during processing)
- Monitoring and evaluation overhead

**Value per unit:**
- Revenue generated (subscription fee amortized per query, or per-transaction pricing)
- Cost avoided (human labor replaced or reduced)
- Business value created (faster decisions, better outcomes, customer satisfaction)

If cost per unit is less than value per unit, your economics work. If not, you need to either reduce costs or increase value.

---

### Where AI Costs Surprise You

**Token costs at scale.** A single GPT-4 query might cost $0.03. That sounds cheap. At 100,000 queries per day, it's $3,000/day or $90,000/month — just for the model. Add infrastructure, monitoring, and human operations, and your monthly AI spend might exceed $150,000.

**Retry and fallback costs.** When a query fails and retries, you pay twice. When a query falls back to a more expensive model, you pay the premium. When a query escalates to a human agent, you pay the full human cost. Your effective cost per unit is higher than your model cost per query.

**Long input costs.** Users don't type 100-token queries. They paste entire documents, write multi-paragraph questions, or have 30-turn conversations. Your cost model based on average query length is wrong if 10% of users send 10x-average inputs.

**Agent loop costs.** Agent products run in loops — each loop iteration costs model tokens plus tool API calls. A task that takes 5 iterations costs 5x what you might estimate from a single prompt-response. Complex tasks might take 20-30 iterations.

**Evaluation costs.** Running quality evaluations on production traffic costs money — both the model costs for automated scoring and the human costs for manual review. This is a real, ongoing cost that most teams forget to budget.

---

### The Pricing Constraint

Your pricing has a ceiling: what users will pay. And a floor: what it costs you to serve them.

**Per-seat pricing** (monthly subscription per user): Your cost depends on how much each user uses the product. Heavy users cost you more. Light users subsidize heavy users. If your heaviest users cost more than their subscription, your pricing model breaks at scale.

**Per-transaction pricing** (pay per query/document/task): Your margin is visible on every transaction. But users may be reluctant to pay per-use, and usage-based pricing creates unpredictable revenue.

**Tiered pricing** (free tier, pro tier, enterprise tier): The free tier costs you money. The pro tier needs to cover the free tier's costs plus its own. The enterprise tier needs to cover custom requirements and support.

For each pricing model, calculate: at what usage level does the marginal user cost you more than they pay? That's your breakeven point, and every user beyond it is profitable (or unprofitable, depending on which side of the line they're on).

---

### Cost Optimization Levers

When the math doesn't work, these are your options (in order of impact):

1. **Model routing.** Send 80% of queries to a cheaper model, 20% to the expensive one. Savings: 50-70%.
2. **Caching.** Cache common responses. Cache hit rates of 20-40% are typical. Savings: proportional to cache hit rate.
3. **Prompt compression.** Shorter prompts, fewer examples, more efficient instructions. Savings: 10-30%.
4. **Batch processing.** For non-real-time tasks, batch queries and process during off-peak hours at lower compute costs. Savings: 20-40%.
5. **Fine-tuning a smaller model.** Trade the API cost for training cost. Only worth it if query volume is high enough to amortize the training investment. Savings: 60-80% on per-query cost, but requires upfront investment.

Don't optimize costs before you have product-market fit. Premature cost optimization is a waste. But do model costs before you build, so you know whether the unit economics can ever work.

---

*Next: explainability — when and how to open the black box.*
