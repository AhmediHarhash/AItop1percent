# Chapter 2.2 — Classification & Decision Products (Moderation, Routing, Triage)

If text generation is AI writing an essay, classification is AI checking a box. It looks simpler. In many ways, it is simpler. But the consequences of getting it wrong can be much higher, because classification products make decisions — and decisions have downstream effects.

---

### What Classification Products Do

A classification product takes an input and assigns it to a category. That's it. But "that's it" powers some of the most critical AI applications in production today:

- **Content moderation:** Is this user-generated post safe, toxic, spam, or harmful? Platforms like social media, marketplaces, and forums process millions of pieces of content per day. Every misclassification is either a harmful post that stays up or a legitimate post that gets removed.

- **Ticket routing:** Does this customer support ticket go to billing, technical support, account management, or escalation? Wrong routing means longer resolution times, frustrated customers, and wasted agent effort.

- **Risk triage:** Is this insurance claim routine, complex, or suspicious? Is this transaction legitimate or fraudulent? Is this patient case urgent or standard? These decisions trigger workflows, allocate resources, and sometimes determine whether someone gets help in time.

- **Intent detection:** What does the user want? Are they asking a question, making a complaint, requesting a refund, or trying to place an order? Getting intent wrong means the entire response or workflow that follows is wrong.

---

### Why Classification Is Deceptively Hard

**The categories look clean on paper.** Your taxonomy has five neat categories. In reality, 20% of inputs belong to two categories, 10% don't fit any category, and 5% are genuinely ambiguous. Classification products need a strategy for ambiguity — confidence thresholds, "uncertain" categories, or human escalation — not just the happy-path labels.

**Class imbalance is the silent killer.** In content moderation, 98% of posts might be safe and 2% might be toxic. If your model learns to always say "safe," it's 98% accurate — and completely useless. Evaluating classification products on overall accuracy is meaningless. You need per-class precision and recall, especially for the rare but important categories.

**Threshold tuning is an ongoing job.** Every classification product has a confidence threshold: above X, we auto-decide; below X, we escalate to a human. That threshold isn't a set-and-forget number. It changes as input distributions shift, as model behavior drifts, and as business priorities evolve. A threshold that was perfect last month might be creating ten false positives per hour today.

**Feedback loops can be dangerous.** If your classifier routes tickets to teams, and those teams only see tickets the classifier sent them, nobody catches the tickets that were routed wrong. You need a separate quality assurance process that samples across all categories, not just the ones you're monitoring.

---

### Eval Strategy for Classification

You need:
- **Per-class precision and recall**, not just overall accuracy
- **Confusion matrix analysis** to see which categories get confused
- **Threshold sensitivity testing** — what happens if you raise or lower the confidence bar by 5%?
- **Ambiguity handling metrics** — how often does the system punt to "uncertain," and what happens to those cases?
- **Bias audits** — does classification accuracy differ across demographic groups, languages, or input types?

The output of your eval shouldn't be "93% accuracy." It should be "93% overall, but only 71% recall on the 'escalation' category, which is the one that matters most."

---

### The Cost of Getting It Wrong

Classification errors compound. A wrongly routed ticket wastes agent time. A missed content violation erodes user trust. A misclassified fraud alert either lets fraud through or blocks a legitimate customer. Every classification product needs to quantify the cost of each error type — false positives and false negatives are not equally expensive, and your threshold should reflect that asymmetry.

*Next: search and retrieval products — where the model doesn't create the answer, it finds it.*
