# 28.11 — Evaluation Locality: Running Evals in the Tenant's Legal Boundary

The alert comes in at 9:14 AM Berlin time. A platform engineer reviewing the weekly data processing audit for a German banking customer notices something that makes her stomach drop. The eval pipeline ran 4,200 scoring events for this tenant over the past seven days. Every one of them was processed in us-east-1. The tenant's contract specifies eu-central-1 as the exclusive processing region. Their production data is served from Frankfurt. Their model inference runs in Frankfurt. But the evaluation pipeline — which ingests the tenant's production outputs, scores them against their golden set, and stores the results — routed everything through Virginia because that is where the platform's centralized eval cluster runs.

The data that crossed the Atlantic includes customer service transcripts from a German bank's clients. Real names. Account references. Financial questions. All of it processed in a US data center for the purpose of quality evaluation. This is not a hypothetical compliance concern. Under GDPR, this is an unauthorized transfer of personal data to a third country. Under the EU AI Act's requirements for high-risk AI systems, this is a failure to maintain the data governance practices that the platform documented in its conformity assessment. The banking customer's data protection officer will need to be notified. The regulators may need to be notified. And the platform's credibility with every EU customer is now at risk, because if it happened to one tenant, it could be happening to all of them.

## Why Evaluation Creates a Data Residency Blindspot

Most multi-tenant platforms get data residency right for production workloads. The engineering team understands that customer data must be stored and processed in the customer's required region. Databases are region-scoped. Model inference runs in the tenant's designated region. API gateways route traffic regionally. The production data pipeline respects the boundaries.

Evaluation is where the boundaries break, because most platforms build evaluation as an internal tool rather than a production system. The eval pipeline was designed when the platform had twenty customers, all in the US, and nobody thought about data residency for quality scoring. It runs in a single centralized cluster because that is simpler to operate. It ingests outputs from all tenants into a shared queue because that is easier to scale. It stores results in a centralized database because that is how the reporting dashboard was built. None of these design decisions considered data residency because, at the time they were made, data residency was not a constraint.

Then the platform expanded to European customers. Then to customers in regulated industries. Then to customers who operate under contractual data residency clauses that go beyond regulatory minimums — financial institutions whose internal compliance policies require all data processing, including analytics and quality assurance, to occur within their designated jurisdiction. The production pipeline was updated to support regional deployment. The eval pipeline was not, because it was classified as an internal analytics tool, not a data processing system. This classification is wrong. **Evaluation Locality** is the principle that eval data must be processed in the same legal jurisdiction as the tenant's production data, because the eval pipeline processes the same data — the tenant's real outputs, their real inputs, their real scoring criteria — and is therefore subject to the same residency requirements.

## The Legal Framework for Eval Data Residency

Three overlapping regulatory frameworks create data residency obligations for evaluation pipelines in 2026.

GDPR, which has been enforceable since 2018, requires that personal data transferred outside the European Economic Area be subject to adequate safeguards. The standard contractual clauses and the EU-US Data Privacy Framework provide mechanisms for lawful transfers, but many enterprise customers — particularly in financial services and healthcare — contractually prohibit transfers entirely, regardless of legal mechanisms. Their position is that data does not leave the EU, period. No exception for eval. No exception for analytics. No exception for quality scoring. The platform that processes their eval data in Virginia violates the contract even if it satisfies the regulatory framework.

The EU AI Act adds a layer specific to AI systems. Providers of high-risk AI systems must implement data governance practices that ensure training, validation, and testing datasets are managed in a manner that is "relevant, sufficiently representative, and to the extent possible, free of errors and complete." The Act requires documentation of these practices as part of the conformity assessment. If your documented data governance states that customer data is processed within the EU, and your eval pipeline routes that data through a US cluster, you have a discrepancy between your documentation and your actual practice. Under the August 2026 compliance deadline for high-risk systems, this discrepancy is a conformity violation that can result in penalties of up to 15 million euros or 3 percent of worldwide turnover.

Industry-specific regulations compound the requirements. HIPAA requires that protected health information be processed by covered entities and business associates in accordance with their business associate agreements, which frequently specify processing locations. PCI DSS requires that cardholder data environments be explicitly defined and controlled, including the physical locations where data is processed. SOX compliance for financial reporting systems requires that data processing controls be documented, verified, and auditable — including the geographic location of processing.

The net effect is that evaluation locality is not optional for any platform serving enterprise customers in regulated industries. It is a compliance requirement with real enforcement mechanisms, real penalties, and real customer contract implications.

## The Architecture of Regional Eval Infrastructure

Supporting evaluation locality requires deploying eval infrastructure in every region where your tenants require data processing. For a platform with EU, US, and APAC customers, this means at minimum three regional eval clusters, each capable of independently executing the full evaluation pipeline — ingesting outputs, scoring against golden sets, running judge pipelines, storing results, and generating reports.

**Regional eval compute** means that the judge models, scoring prompts, and calibration parameters must be available in each region. If your judge pipeline uses Claude Opus 4.6 as the scoring model, you need access to that model in every region where you run evaluations. In 2026, the major model providers offer regional API endpoints across the US, EU, and Asia, but not every model is available in every region. The constraint may force you to use different judge models in different regions, which creates a calibration challenge — two different judge models scoring the same output may produce different scores. Cross-regional judge calibration, where you verify that judge models in different regions produce comparable scores for the same inputs, becomes a periodic operational requirement.

**Regional data storage** means that eval results, golden sets, and scoring artifacts are stored within the tenant's required region. A tenant whose data residency requirement is eu-central-1 has their golden set stored in eu-central-1, their eval results stored in eu-central-1, and their scoring artifacts stored in eu-central-1. The reporting dashboard pulls from regional data stores rather than from a centralized database. This adds query complexity — a platform-wide report that aggregates scores across all tenants must query multiple regional stores and aggregate the results — but the alternative is centralizing data in violation of residency requirements.

**Regional eval orchestration** means that the system that schedules, executes, and monitors eval runs operates regionally. The orchestrator in eu-central-1 manages eval runs for EU tenants. The orchestrator in us-east-1 manages eval runs for US tenants. Each orchestrator is independently operable — if the EU orchestrator goes down, US evaluations continue unaffected. This independence also provides blast radius containment for operational incidents. A misconfigured eval job that consumes excessive resources in one region does not starve eval jobs in other regions.

## The Centralized Control Plane vs. Regional Data Plane

The architecture that works for most platforms separates the control plane from the data plane. The control plane is centralized — a single system that manages tenant configurations, schedules eval runs, tracks pipeline versions, and serves the management dashboard. The control plane does not process tenant data. It processes metadata — tenant identifiers, config hashes, scheduling parameters, pipeline definitions. Metadata is not subject to the same residency constraints as customer data, because metadata does not contain the tenant's production inputs or outputs.

The data plane is regional. Each region has its own eval workers, its own judge model access, its own golden set storage, its own result storage, and its own scoring pipeline. When the centralized control plane schedules an eval run for a tenant, it sends a job definition to the regional data plane in the tenant's required region. The job definition contains the config hash, the scoring parameters, and references to the golden set and eval targets — but it does not contain the actual data. The regional data plane fetches the data from regional storage, executes the evaluation, stores the results in regional storage, and sends a completion notification with aggregate metrics back to the control plane. The tenant's data never leaves the region. The control plane never touches the data.

This separation is not just architecturally clean — it is auditable. The control plane logs show that a job was dispatched to eu-central-1. The data plane logs in eu-central-1 show that the job executed locally. The network logs show no cross-region data transfers for tenant data. The audit trail is complete and demonstrates residency compliance without ambiguity.

## The Cost and Complexity Multiplier

Regional eval infrastructure is more expensive and more complex than centralized eval infrastructure. This is not an argument against it — it is a reality that must be planned for.

The cost multiplier comes from three sources. First, compute resources are duplicated across regions. A centralized cluster that handles all evaluation needs one pool of GPU-backed eval workers. A regional architecture needs a pool in each region, each sized to handle the peak load for that region's tenants. The aggregate compute across all regions is typically 30 to 50 percent higher than a single centralized pool, because each regional pool must have enough headroom to handle its own peak, and the peaks across regions do not perfectly offset each other.

Second, judge model API costs may differ across regions. Some model providers charge the same price regardless of region. Others charge a premium for regional deployments, particularly in regions with limited infrastructure. A platform that uses Claude Opus 4.6 as its judge model may pay 10 to 20 percent more for API access in the APAC region compared to the US region, depending on the provider's pricing model.

Third, operational complexity increases. The platform team must monitor, maintain, and troubleshoot eval infrastructure in multiple regions. A pipeline bug that manifests only in the EU region — perhaps due to regional differences in the judge model's behavior, or due to timestamp handling across time zones — requires debugging by a team member with access to the EU data plane. On-call rotations must cover all regions. Deployment processes must roll out updates to all regional data planes, preferably with canary deployments per region to catch region-specific issues before they affect all tenants.

For a platform with 300 tenants generating $40 million in annual revenue, the incremental cost of regional eval infrastructure is typically $200,000 to $500,000 per year. The cost of a single GDPR enforcement action — up to 20 million euros or 4 percent of worldwide turnover — dwarfs this investment by orders of magnitude. The cost calculation is not close.

## Enforcing Locality in the Pipeline

Enforcement is the difference between a policy that is followed and a policy that is violated. Evaluation locality must be enforced at the pipeline level, not at the organizational level. Three enforcement mechanisms, used together, prevent cross-region data processing.

The first mechanism is **tenant-to-region mapping** enforced at the orchestrator layer. Every tenant has a designated eval region stored in their configuration. The orchestrator consults this mapping before dispatching any eval job. If the mapping says eu-central-1, the job is dispatched to eu-central-1. There is no manual override. There is no "process this one in us-east-1 because the EU cluster is busy." The mapping is the law.

The second mechanism is **network-level isolation** between regional data planes. The eval workers in eu-central-1 can access data stores in eu-central-1 but cannot reach data stores in us-east-1 or ap-southeast-1. This is enforced through network policies, security groups, and service mesh configurations that block cross-region data access at the infrastructure level. Even if a software bug attempts to read data from the wrong region, the network layer prevents it.

The third mechanism is **audit logging with locality verification**. Every eval event carries a region field in its metadata, as described in the Tenant Metadata Contract subchapter. A nightly audit job compares the region field on each eval event against the tenant's designated eval region. Any mismatch triggers a priority alert. The platform team investigates, determines how a cross-region processing occurred, and remediates both the specific event and the pipeline path that allowed it. The audit is the safety net that catches any locality violation that slips through the first two mechanisms.

## Edge Cases That Break Locality

Even well-designed regional architectures face edge cases that create locality challenges.

**Model migration** is the most common edge case. When the platform migrates to a new judge model, the new model may not be available in all regions simultaneously. If Claude Opus 4.6 launches a new version that is available in the US and EU but not yet in APAC, the APAC eval cluster must continue using the previous version until the new one becomes available regionally. This creates a period of judge version divergence across regions — APAC tenants are scored by one judge version while US and EU tenants are scored by another. The config hash captures this divergence, so it is visible in the data, but it complicates cross-regional comparisons and can delay platform-wide judge model upgrades.

**Disaster recovery** creates a tension between availability and locality. If the EU eval cluster experiences a major outage, the platform faces a choice: pause all EU tenant evaluations until the cluster recovers, or fail over to another region and process the backlog in violation of data residency requirements. The correct answer is almost always to pause. The cost of paused evaluations — a gap in quality monitoring that is visible and bounded in time — is far lower than the cost of a residency violation that creates regulatory exposure. The disaster recovery plan for regional eval infrastructure should explicitly state that cross-region failover is not permitted for tenants with data residency requirements.

**Tenant migration** occurs when a customer changes their data residency requirement — a company that was processing in the US opens a European subsidiary and needs EU processing. The migration involves moving the tenant's golden set, eval history, and pipeline configuration to the new region. The historical eval data that was processed in the original region stays there — you cannot retroactively change where data was processed. But all future eval runs execute in the new region. The migration creates a seam in the tenant's eval history that must be documented: "eval results before March 2026 were processed in us-east-1 per the original contract; eval results from March 2026 forward are processed in eu-central-1 per the amended contract."

## Proving Locality Under Audit

The ultimate test of evaluation locality is the audit. A customer's data protection officer asks: "Can you prove that our evaluation data was processed exclusively within the EU for the past twelve months?" The answer must be yes, backed by evidence.

The evidence package includes the tenant-to-region mapping showing that the tenant's designated eval region has been eu-central-1 for the entire period. It includes the metadata on every eval event showing the region field as eu-central-1. It includes the audit log showing zero locality violations for this tenant. And it includes the network policy configuration showing that the eu-central-1 data plane cannot access or be accessed by non-EU infrastructure.

This evidence is not assembled manually in response to the audit request. It is generated continuously by the evaluation system and stored in a compliance evidence repository that is ready for retrieval at any time. Section 7 of this section covers evidence package generation in detail. The locality dimension of that evidence package depends entirely on the mechanisms described in this subchapter — the regional architecture, the enforcement mechanisms, and the audit logging that together prove where the data was processed.

The platform that cannot prove evaluation locality will lose its EU customers. Not because they want to leave, but because their regulators and compliance teams will require them to. With the EU AI Act's August 2026 compliance deadline for high-risk systems approaching, every platform serving EU enterprise customers must have regional eval infrastructure operational, auditable, and provably compliant before that deadline. The next subchapter addresses a different category of isolation risk — not where the data is processed, but how shared infrastructure within a region can allow one tenant's evaluation to contaminate another's through cache poisoning and shared state attacks.
