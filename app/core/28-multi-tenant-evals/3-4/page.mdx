# 28.4 — Eval Data Privacy Under GDPR, HIPAA, and the EU AI Act

Evaluation data is production data. This is not a philosophical position. It is a regulatory fact that most multi-tenant platforms learn too late. The patient interaction summary you sample from production to include in an evaluation run carries the same GDPR protections, the same HIPAA obligations, and the same EU AI Act documentation requirements as the moment it was generated. The act of copying it into an evaluation pipeline does not change its regulatory classification. The act of scoring it against a rubric does not diminish its privacy protections. The act of including the scored result in an evaluation report does not create a new legal basis for processing. Every regulatory obligation that applies to the data in production applies to the data in evaluation — and in multi-tenant systems, additional obligations arise from the fact that multiple data controllers' data flows through shared infrastructure.

Platforms that treat evaluation as an internal engineering activity — exempt from the privacy controls that govern production — create regulatory exposure that scales with their tenant count. A platform with 50 tenants processing evaluation data without proper legal basis has 50 potential regulatory violations. A platform with 500 tenants has 500. The fines, the enforcement actions, and the contract terminations that follow are not hypothetical. They are the predictable consequence of treating evaluation data as somehow different from the data it was derived from.

## GDPR: Evaluation as Data Processing

Under GDPR, every processing activity involving personal data requires a lawful basis. The six lawful bases — consent, contractual necessity, legal obligation, vital interests, public interest, and legitimate interest — each come with specific conditions and limitations. Most B2B platforms rely on contractual necessity as their basis for processing tenant data in production: the customer has a contract with the platform, the platform processes data to fulfill that contract, and the processing is necessary for the service the customer is paying for.

Evaluation stretches this basis. The customer contracted for a service — document processing, customer support automation, content generation. They did not explicitly contract for their data to be sampled, annotated, scored, compared against reference examples, and stored in evaluation result databases. Whether evaluation falls within the scope of contractual necessity depends on how the contract is drafted and how the evaluation relates to the contracted service. If your evaluation pipeline exists to maintain and improve the quality of the service the customer pays for, and the contract includes provisions for quality measurement and service improvement, contractual necessity is defensible. If your evaluation pipeline uses customer data for purposes beyond the contracted service — benchmarking against competitors, training internal models, publishing aggregate performance reports — contractual necessity does not cover those uses.

**Article 25** of GDPR requires data protection by design and by default. For multi-tenant evaluation, this means that tenant isolation is not a best practice. It is a legal requirement. The regulation demands that technical measures be implemented to ensure that personal data is processed only for the specified purpose and is not made accessible to an indefinite number of persons. In a multi-tenant evaluation system, "an indefinite number of persons" includes the engineers, annotators, and customer success managers who might access evaluation data for tenants other than the one they are authorized to work with. Data protection by design means that your evaluation architecture enforces tenant isolation at the technical level — through access controls, through data scoping, through compute separation — rather than relying on policies and training that hope people will not access data they should not.

**Data minimization**, another GDPR principle, directly constrains how much data you can include in evaluation pipelines. You must process the minimum amount of personal data necessary to achieve the evaluation purpose. Sampling 10,000 production interactions for evaluation when 500 would provide statistically valid quality scores violates the minimization principle unless you can demonstrate that 10,000 is necessary. The minimization analysis must be documented, because a Data Protection Authority conducting an investigation will ask why you processed the volume of data you processed and will expect a quantitative justification — sample size calculations, confidence interval requirements, stratification needs — not a vague assertion that more data is better.

**Data subject rights** complicate multi-tenant evaluation in ways that many platforms have not considered. Under GDPR, individuals have the right to access their personal data, the right to rectification, the right to erasure, and the right to restriction of processing. If a data subject exercises their right to erasure against one of your tenants, and that tenant's customer interaction data has been copied into your evaluation pipeline, you must be able to identify and delete that specific individual's data from your evaluation storage. This requires that evaluation data maintain traceability to the original data subject — a requirement that conflicts with the common practice of anonymizing evaluation samples by stripping identifiers. If you strip identifiers, you cannot fulfill erasure requests. If you retain identifiers, you carry additional privacy obligations. The resolution is pseudonymization — replacing direct identifiers with tenant-scoped pseudonyms that allow you to trace evaluation samples back to their source when a rights request arrives, while preventing evaluation pipeline participants from identifying data subjects during normal evaluation operations.

## HIPAA: The Minimum Necessary Standard

For platforms serving healthcare tenants in the United States, HIPAA's minimum necessary standard creates constraints that go beyond GDPR's data minimization principle. The minimum necessary standard requires covered entities and their business associates to limit access to protected health information to the minimum necessary to accomplish the intended purpose. In evaluation systems, this means that every person and every process that accesses evaluation data containing PHI must be limited to the minimum data necessary for their specific role.

An annotator scoring a healthcare tenant's golden set examples needs access to those examples. They do not need access to the tenant's full production interaction log. They do not need access to other healthcare tenants' examples. They do not need access to the evaluation scores for previous months. Each of these access boundaries must be enforced technically, not just procedurally. A policy that says "annotators should only access the examples assigned to them" is not sufficient under HIPAA. A technical control that limits annotators' data access to their assigned examples and logs every access attempt is the minimum standard.

The distinction between de-identified data and PHI determines the scope of HIPAA's reach into your evaluation pipeline. If evaluation data is de-identified according to the Safe Harbor method — all 18 categories of identifiers removed — HIPAA's protections no longer apply to that data. This makes de-identification an attractive strategy for evaluation: de-identify all production data before it enters the evaluation pipeline, and HIPAA no longer constrains how you process, store, or share that data within the evaluation system.

The problem is that effective de-identification is harder than most platforms realize. Removing names, dates, and medical record numbers is straightforward. Removing all 18 identifier categories — which include geographic subdivisions smaller than a state, all elements of dates except year for individuals over 89, telephone numbers, fax numbers, email addresses, Social Security numbers, account numbers, certificate and license numbers, vehicle identifiers, device identifiers, URLs, IP addresses, biometric identifiers, full-face photographs, and any other unique identifying number — requires systematic processing that most platforms implement imperfectly. A patient interaction summary that mentions "the clinic on Main Street" contains a geographic identifier. A clinical note that references "the patient's January 15 lab results" contains a date element. A support transcript that includes "I'm calling from 555-0147" contains a telephone number. Each of these must be identified and removed before the data qualifies as de-identified under Safe Harbor.

For multi-tenant platforms, the de-identification challenge multiplies because each healthcare tenant may have different data formats, different documentation styles, and different patterns of identifier inclusion. A de-identification pipeline calibrated for one hospital's clinical notes may miss identifiers in another hospital's format. Per-tenant validation of de-identification effectiveness is not optional — it is the mechanism that prevents a de-identification failure for one tenant from creating HIPAA exposure for the platform.

The Business Associate Agreement that your platform signs with each healthcare tenant must explicitly cover evaluation data processing. Many BAAs are drafted to cover the production service without mentioning evaluation. When a healthcare tenant's data is used in evaluation — sampled, annotated, scored, stored — that use is covered entity data processing by a business associate, and it must be documented in the BAA. A BAA that does not mention evaluation creates a gap where the platform is processing PHI without contractual authorization, which is itself a HIPAA violation independent of whether any data is actually exposed.

## The EU AI Act: Provider Obligations for Evaluation

The EU AI Act, with its GPAI provider obligations becoming enforceable on August 2, 2026, introduces a new category of requirements that directly affect multi-tenant evaluation systems. Article 53 requires providers of general-purpose AI models to maintain technical documentation that describes the model's training and testing processes, including evaluation results. For multi-tenant platforms, this creates a tension between the documentation obligation — which requires transparency about how the model was evaluated — and tenant isolation requirements, which prohibit sharing tenant-specific evaluation data.

The resolution lies in understanding what the EU AI Act's documentation requirement actually demands. The regulation requires documentation of the evaluation methodology, the evaluation results in aggregate, and sufficient information for downstream providers to understand the model's capabilities and limitations. It does not require disclosure of individual tenant data or per-tenant evaluation scores. A multi-tenant platform can fulfill its Article 53 obligations by documenting the evaluation framework — the dimensions evaluated, the scoring methodology, the sample selection approach — and providing aggregate results that demonstrate the model's performance characteristics without revealing any individual tenant's data or scores.

However, the GPAI Code of Practice published in July 2025 added granularity to these obligations. The Code specifies that providers must document evaluation procedures with enough detail for the AI Office to assess whether the evaluation is adequate. For multi-tenant platforms, this means documenting not just that per-tenant evaluation exists but how it works — how tenants are isolated, how per-tenant rubrics are constructed, how golden sets are maintained, and how tenant-specific results are aggregated into the platform-level documentation that the AI Office may request. The documentation must demonstrate that per-tenant evaluation produces reliable, uncontaminated results, which requires describing the isolation mechanisms covered in the previous subchapters.

The August 2026 enforcement deadline creates a specific planning requirement. Platforms that have not yet built compliant evaluation documentation will need to do so before that date. For platforms placed on the market before August 2, 2025, the compliance deadline extends to August 2, 2027, but new models and significant updates after August 2025 must comply immediately. In practice, this means that any model update deployed to your multi-tenant platform after August 2025 must be accompanied by evaluation documentation that meets the EU AI Act's requirements. If your evaluation system cannot produce that documentation — because isolation is insufficient, because per-tenant evaluation does not exist, or because the evaluation methodology is not documented to the required standard — you have a compliance gap that must be closed before the enforcement window opens.

Non-compliance penalties under the EU AI Act are substantial. GPAI providers face fines of up to 15 million euros or 3 percent of global annual revenue, whichever is higher. For a platform with 200 million euros in annual revenue, that is a potential fine of 15 million euros. The fine structure is designed to make non-compliance more expensive than compliance, and the calculation applies globally — a platform headquartered outside the EU that serves EU customers is subject to the regulation if its models are placed on the EU market.

## Where the Three Regulations Intersect

GDPR, HIPAA, and the EU AI Act are not independent compliance silos. They intersect in ways that create compounding obligations for multi-tenant evaluation systems. A healthcare platform serving European hospitals operates under all three simultaneously. GDPR governs the personal data in evaluation samples. HIPAA governs the protected health information in those same samples (if the platform also serves US healthcare entities). The EU AI Act governs the evaluation methodology and documentation.

The intersections create requirements that exceed what any single regulation demands. GDPR requires data minimization — use the least data necessary. HIPAA requires minimum necessary access — limit who sees what. The EU AI Act requires comprehensive evaluation documentation — prove that your evaluation is thorough. Together, these create a mandate to evaluate thoroughly using the minimum data necessary, with access limited to the minimum people required, while documenting the entire process comprehensively enough for regulatory review. Each regulation's requirements constrain how you fulfill the others.

For multi-tenant platforms, the intersecting obligations converge on one architectural requirement: per-tenant isolation with comprehensive auditability. You must isolate tenant data to satisfy GDPR and HIPAA. You must document the isolation to satisfy the EU AI Act. You must maintain audit trails to prove compliance under all three. And you must do all of this for each tenant independently, because each tenant may be subject to different regulatory combinations depending on their jurisdiction, their industry, and their data types.

## Building Regulatory-Compliant Evaluation Architecture

The architecture that satisfies all three regulatory frameworks simultaneously has five components.

The first is a **processing register** for evaluation activities. GDPR Article 30 requires a record of processing activities. Your evaluation pipeline is a processing activity, and it must be documented in your Article 30 register with the same specificity as your production processing: what data is processed, for what purpose, under what lawful basis, with what retention period, and with what technical and organizational measures. For multi-tenant platforms, the register must specify that evaluation processing is performed per tenant, with tenant isolation measures documented as technical safeguards.

The second is **per-tenant data processing agreements** that explicitly cover evaluation. Whether structured as amendments to existing DPAs or as standalone agreements, these documents must specify that the platform evaluates the tenant's data for quality maintenance purposes, describe the evaluation methodology, identify the categories of data processed, and define retention periods for evaluation artifacts. Without these agreements, evaluation processing lacks legal basis under GDPR and contractual authorization under HIPAA.

The third is **automated data lifecycle management** for evaluation artifacts. Every evaluation sample, annotation, score, and report must have a defined retention period that is enforced automatically. When the retention period expires, the artifact is deleted. When a tenant offboards, all their evaluation artifacts are deleted within the contractually specified timeframe. When a data subject exercises their right to erasure, the evaluation pipeline can identify and delete that subject's data. Manual data lifecycle management does not scale to 500 tenants with different retention requirements, different regulatory obligations, and different contractual terms.

The fourth is **access logging and audit trails** that satisfy all three regulatory frameworks simultaneously. GDPR requires demonstrating compliance through documented technical measures. HIPAA requires access logs for all PHI access. The EU AI Act requires documentation sufficient for regulatory review. A unified audit trail that records every data access, every evaluation execution, every report generation, and every human access to evaluation data — with timestamps, tenant context, user identity, and action performed — satisfies all three requirements with a single system. As Section 29 discusses in the context of enterprise governance, the audit trail is not a compliance checkbox. It is the evidence that your isolation architecture actually works.

The fifth is **regulatory mapping per tenant**. Each tenant on your platform is subject to a specific combination of regulations depending on their jurisdiction, industry, and data types. A European healthcare tenant is subject to GDPR and the EU AI Act and may be subject to HIPAA if they also serve US patients. A US financial services tenant is subject to SOX and Gramm-Leach-Bliley but not GDPR unless they serve European customers. A Canadian retail tenant is subject to PIPEDA. Your evaluation infrastructure must know which regulations apply to each tenant and enforce the corresponding requirements — data minimization thresholds, retention periods, access controls, documentation standards — per tenant rather than applying a single regulatory profile across the platform.

## The Compliance Advantage

Regulatory compliance in multi-tenant evaluation is expensive. The processing register, per-tenant DPAs, automated lifecycle management, audit trails, and regulatory mapping represent a significant investment in infrastructure that does not directly improve model quality. But compliance creates a competitive advantage that is difficult for competitors to replicate.

Enterprise customers in regulated industries — healthcare, financial services, insurance, pharmaceuticals — evaluate vendors partly on regulatory compliance posture. A platform that can demonstrate GDPR-compliant evaluation with documented data minimization, HIPAA-compliant evaluation with minimum necessary access controls, and EU AI Act-compliant evaluation documentation is a safer choice than a platform that cannot. In competitive evaluations, compliance evidence often breaks ties. The platform that can show an audit trail of per-tenant evaluation isolation, a processing register that covers evaluation activities, and per-tenant DPAs that explicitly authorize evaluation processing wins the trust assessment that regulated-industry procurement teams conduct.

Two of the largest healthcare platform contracts signed in the second half of 2025 included evaluation compliance as a scored criterion in the vendor selection process. In both cases, the winning vendor's ability to demonstrate per-tenant evaluation isolation with regulatory documentation was cited as a differentiating factor. The losing vendors had equivalent model quality and lower pricing but could not provide evidence of evaluation-specific compliance measures. The regulated-industry sales cycle does not reward the cheapest product. It rewards the product that reduces the buyer's regulatory risk. Per-tenant evaluation compliance is one of the most tangible ways to demonstrate that risk reduction.

Regulatory requirements will continue to evolve. The EU AI Act's GPAI obligations are just beginning to be enforced. Additional guidance from the AI Office, additional enforcement precedents from Data Protection Authorities, and additional harmonization between GDPR and the AI Act will create new requirements that multi-tenant evaluation systems must satisfy. Building the architectural foundations now — per-tenant isolation, comprehensive auditability, regulatory mapping — positions your platform to absorb those new requirements as configuration changes rather than architectural rewrites. But compliance is only one dimension of tenant isolation. The next subchapter examines the noisy neighbor effect — the performance isolation challenge that occurs when shared evaluation infrastructure causes one tenant's workload to degrade another tenant's evaluation quality.
