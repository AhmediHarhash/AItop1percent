# 28.1 — What Happens When Tenant Boundaries Fail in Evaluation

In September 2025, a cloud-based clinical documentation platform serving 72 hospital systems across the United States and Canada ran its monthly evaluation cycle. The evaluation pipeline pulled production samples from each hospital's interaction logs, scored them against clinical accuracy rubrics, and generated per-hospital quality reports. Those reports were delivered to each hospital's compliance office as evidence that the platform met contractual quality commitments. They were the foundation of a trust relationship worth, in aggregate, $28 million in annual recurring revenue.

A quality assurance analyst at a pediatric hospital in Ontario opened their October report and found something that should not have been there. Buried in the sample set used to compute their quality score were three patient interaction summaries that referenced adult cardiac catheterization procedures. The pediatric hospital did not perform cardiac catheterizations. Their patient population was children. The samples clearly belonged to another hospital on the platform. The analyst flagged the issue to the hospital's Chief Privacy Officer, who escalated within hours. By the end of the day, the platform's CEO was on a call with the hospital's legal counsel, attempting to explain how one hospital's patient interaction data appeared in another hospital's evaluation report.

The technical root cause was a query filter bug. The evaluation pipeline used a tenant identifier to scope data pulls, but a recent database migration had introduced a partitioning change that caused a small percentage of records to be associated with the wrong tenant partition. The bug affected fewer than 0.2 percent of evaluation samples across the platform. In absolute terms, roughly 40 records out of approximately 18,000 sampled that month were scoped to the wrong tenant. The engineering fix took eleven hours. The organizational consequences took eleven months.

## The Difference Between a Bug and an Existential Event

A query filter bug in a single-tenant system is a severity-two incident. You find it, fix it, run a regression, move on. The same bug in a multi-tenant evaluation system is an existential event. The difference is not technical. It is contractual, regulatory, and reputational.

The pediatric hospital's contract contained a data isolation clause that guaranteed their data would never be processed, stored, or evaluated alongside another institution's data. The three misrouted cardiac catheterization records violated that clause. The hospital's legal counsel sent a formal breach notification within 72 hours, triggering the platform's obligations under both the contract and the Business Associate Agreement required by HIPAA. That BAA required the platform to notify the Department of Health and Human Services Office for Civil Rights if the breach met the threshold for a reportable event under the Breach Notification Rule. The platform spent four weeks and $180,000 in outside legal fees determining whether the exposure of three de-identified interaction summaries from one hospital to the evaluation report of another hospital constituted a reportable breach. The final determination was that it did not meet the threshold because the records were de-identified and the exposure was limited to an internal evaluation report, not a public disclosure. But the four weeks of uncertainty consumed the executive team's attention and dominated every board meeting during that period.

The regulatory exposure was only one dimension of the damage. The reputational damage was worse. The pediatric hospital shared the incident with three other hospital systems in their network. Within six weeks, two of those systems requested formal security audits of the platform's data isolation practices. One of them paused a planned expansion from 12 departments to 40, representing $1.4 million in deferred revenue. The platform's sales team reported that two prospects in active pipeline cited "concerns about data isolation" as a reason for choosing a competitor, though neither prospect named the specific incident. Word travels in healthcare IT. It does not need to be public to be damaging.

## Why Evaluation Data Is Especially Dangerous

Production data flowing through an AI system is protected by whatever access controls, encryption, and isolation mechanisms the platform has built for its serving infrastructure. Those controls are typically mature because production data handling is where security reviews focus, where compliance audits probe, and where engineering teams invest the most isolation work.

Evaluation data lives in a parallel universe. It flows through a different pipeline, stored in different locations, accessed by different teams, with different retention policies. And because evaluation is often treated as an internal engineering function rather than a data processing activity, it receives less scrutiny from security and privacy reviews. The clinical documentation platform had invested $2.3 million in production data isolation over three years. It had invested roughly $40,000 in evaluation pipeline isolation, which consisted of the tenant ID filter that the migration broke.

This asymmetry is common. When teams build multi-tenant evaluation systems, they inherit whatever isolation model the production system uses and assume it extends to evaluation. It does not. The production system routes requests through an API gateway that enforces tenant scoping at the network level. The evaluation system pulls data from a warehouse or lake, often through batch queries that operate outside the production request path. The production system encrypts data in transit and at rest with tenant-specific keys. The evaluation system copies data into evaluation-specific storage that may use platform-wide keys. The production system logs access by tenant. The evaluation system logs access by evaluation job, which may span multiple tenants in a single execution.

Every one of these gaps is a cross-tenant contamination vector. The platform that suffered the pediatric hospital incident had five other isolation gaps in its evaluation pipeline that the subsequent security audit uncovered: shared evaluation result caches with no tenant scoping, evaluation logs that mixed tenant identifiers with sample content, a debugging interface that allowed engineers to view evaluation samples without tenant filtering, an evaluation result archive that stored all tenants' results in a single object store bucket with path-based separation rather than access-control separation, and a sample deduplication step that compared records across tenant boundaries to remove duplicates before scoring. Five gaps, any one of which could have produced a similar incident. The query filter bug was just the one that happened to manifest first.

## The Contamination Taxonomy

Cross-tenant contamination in evaluation systems takes four distinct forms, each with different detection difficulty and different consequences.

**Data contamination** is the most obvious form. Tenant A's data appears in Tenant B's evaluation pipeline. This is what happened at the pediatric hospital. Data contamination is the easiest form to detect after the fact because the evidence is visible in the evaluation samples, but it is also the most damaging because it involves actual data exposure across tenant boundaries. Detection requires per-tenant data provenance tracking — every record in every evaluation run must be traceable to its source tenant, and any record whose source tenant does not match the evaluation tenant triggers an immediate alert.

**Score contamination** is subtler. Tenant A's data does not appear in Tenant B's evaluation, but Tenant A's data influences Tenant B's scores. This happens when evaluation systems use shared components that carry state across tenants. A shared LLM judge that processes Tenant A's evaluations before Tenant B's can carry context from Tenant A's samples into its scoring of Tenant B's samples if the judge's context window is not properly cleared between tenants. A shared embedding model used for semantic similarity scoring can have its internal state influenced by the distribution of recent inputs, meaning the order in which tenants are evaluated can affect their scores. Score contamination does not expose data across boundaries, but it makes evaluation results unreliable because they depend on the evaluation order rather than the actual quality of each tenant's outputs.

**Configuration contamination** occurs when one tenant's evaluation settings influence another tenant's evaluation. This happens when configuration systems use inheritance or defaults incorrectly. A platform might maintain a "default rubric" that all tenants inherit from, with per-tenant overrides for specific dimensions. If an engineer modifies the default rubric to accommodate one tenant's request without understanding that the change propagates to all tenants, every tenant's evaluation is affected. This is not a data breach, but it produces incorrect evaluation results across the platform. Configuration contamination is especially difficult to detect because the symptoms — score changes across multiple tenants — look like a model quality shift rather than a configuration error.

**Reporting contamination** is the form that most directly affects customer trust. Tenant A sees information about Tenant B in their evaluation reports. This can be as blatant as Tenant B's data appearing in Tenant A's report, or as subtle as aggregate statistics in Tenant A's report that are computed across all tenants rather than scoped to Tenant A. A report that tells a customer "your quality ranks in the 85th percentile across the platform" reveals information about other tenants' quality. A report that shows "platform-wide average accuracy is 91 percent" gives the customer information about the aggregate performance of all tenants, which sophisticated customers can use to infer things about their competitors. Even seemingly harmless aggregate data can constitute information leakage that your customer contracts may prohibit.

## The Samsung Lesson, Applied to Evaluation

When Samsung employees pasted proprietary semiconductor source code into ChatGPT in early 2023, the incident became a defining case study in AI data leakage. The data entered a shared system where the boundaries between one user's data and another's were, at that point, not guaranteed. Samsung subsequently banned internal use of generative AI tools, and the incident accelerated enterprise demands for data isolation in every AI product.

The lesson that most companies extracted from the Samsung incident was about production data handling: do not send sensitive data to shared AI systems. That lesson is correct but incomplete. The evaluation layer of AI systems handles data that is often more sensitive than production data, because evaluation requires examining model outputs in detail, comparing them against reference data, and storing scored samples for analysis. If your production system is a locked vault, your evaluation system is the room where you bring the vault's contents out to inspect them. The inspection room needs the same security as the vault itself — and in multi-tenant systems, it needs per-tenant isolation that prevents one tenant's inspection from contaminating another's.

The Air Canada chatbot lawsuit of 2024, where a customer was given incorrect bereavement fare information by an AI chatbot and Air Canada was held liable for the chatbot's statements, reinforced a different dimension of this argument. When AI outputs have legal consequences, every step of the process that produces those outputs — including evaluation — falls under scrutiny. If a customer's outputs are evaluated using contaminated data or influenced by another tenant's configuration, the evaluation results are not just unreliable. They are legally questionable. A customer whose contract guarantees per-tenant evaluation cannot trust scores produced by a contaminated pipeline, and their lawyers will make that argument if quality disputes escalate to litigation.

## The Response Playbook When Boundaries Fail

When a tenant boundary failure is discovered in evaluation, the response must be faster and more structured than a standard incident response. Every hour of delay increases the probability that the exposure cascades into a contractual, regulatory, or legal crisis.

The first action is containment. Stop all evaluation runs that involve the affected tenants. This feels extreme, but the alternative is continuing to produce potentially contaminated results while you investigate, which deepens the exposure and creates additional evidence of a problem. A paused evaluation pipeline is inconvenient. A pipeline that continues producing contaminated results is ammunition in a breach notification.

The second action is scoping. Determine exactly which tenants were affected, which evaluation runs contained cross-tenant contamination, and what data was exposed. Scoping requires per-tenant audit logs that record every data access, every evaluation execution, and every result generation. If your evaluation system does not produce audit logs at tenant granularity, you cannot scope the incident with confidence, which means your breach notification — if one is required — must assume worst-case exposure. The difference between "three records from one hospital appeared in another hospital's report" and "we cannot determine the full scope of potential data exposure" is the difference between a manageable incident and an existential one.

The third action is notification. The affected tenants must be told, even if the exposure was minor. Especially if the exposure was minor. A platform that proactively informs a customer about a three-record evaluation contamination incident builds more trust than a platform whose customer discovers the contamination themselves. The pediatric hospital's trust was destroyed not just by the contamination but by the fact that they found it, not the platform. Proactive disclosure converts an adversarial dynamic into a collaborative one. It changes the customer's perception from "they are hiding problems" to "they caught a problem and told us immediately."

The fourth action is remediation, which goes beyond fixing the immediate bug. Remediation requires a systematic review of every isolation boundary in the evaluation pipeline, identification of all gaps, and a prioritized plan to close them. The clinical documentation platform's eleven-hour fix addressed the query filter bug. The subsequent eleven-month remediation addressed the five other isolation gaps that the security audit uncovered. Both were necessary. Only the second prevented recurrence.

## The Cost Equation That Changes Executive Minds

Platform architects who advocate for evaluation isolation often struggle to justify the investment to executives who see evaluation as an internal tool, not a customer-facing system. The cost equation that changes minds is straightforward. Take the annual contract value of your ten largest customers. Add the regulatory penalties that apply in your jurisdiction — GDPR fines can reach four percent of global annual revenue, HIPAA penalties reach $2.1 million per violation category per year. Add the cost of a security audit triggered by an incident, which typically runs $150,000 to $400,000 for a comprehensive third-party assessment. Add the revenue impact of delayed deals caused by reputational damage, which is difficult to quantify but typically exceeds the direct costs.

The clinical documentation platform's total cost from the pediatric hospital incident, across legal fees, deferred revenue, security audits, and engineering remediation, exceeded $3.8 million. The per-tenant evaluation isolation infrastructure that would have prevented the incident was estimated at $290,000 in engineering investment and $4,200 per month in incremental infrastructure costs. The ratio is stark: a $340,000 first-year investment versus a $3.8 million incident cost, and the incident cost does not include the unquantifiable damage to the platform's market reputation in healthcare IT.

Every multi-tenant platform will eventually experience an isolation failure somewhere in its stack. The question is whether that failure occurs in a system with comprehensive isolation enforcement, where the blast radius is contained and the response is structured, or in a system where evaluation data flows through shared pipelines with tenant scoping implemented as an afterthought. The next subchapter examines the three distinct layers where isolation must be enforced — data, compute, and reporting — and the specific mechanisms that make each layer hold under pressure.
