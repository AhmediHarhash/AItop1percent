# 28.72 — Tiered Eval Coverage: Different SLAs, Different Eval Spend

The cheapest eval system that meets every customer's quality requirements is the right eval system. Every dollar spent beyond that is waste. Every dollar short of that is risk. This principle sounds obvious until you realize its implication: if your customers have different quality requirements, different regulatory exposures, and different contract values, then spending the same amount on evaluation for every customer is guaranteed to be wrong — overspending on customers who do not need it, underspending on customers who do, and creating a cost structure that subsidizes low-value accounts at the expense of high-value ones.

**Tiered eval coverage** is the practice of matching your evaluation investment — frequency, depth, method, and human involvement — to each customer's value and risk profile. A customer paying two million dollars per year for a healthcare platform with HIPAA obligations and contractual quality floors gets continuous monitoring, dedicated golden sets, human-in-the-loop review, and monthly evidence packages. A customer on a five-thousand-dollar-per-month self-serve plan gets weekly automated sampling with platform-default rubrics. Both customers receive evaluation that is appropriate for their tier. Neither customer is underserved. Neither customer is subsidized.

## Defining the Tiers

Most multi-tenant platforms settle on three to four eval tiers. More than four creates operational complexity without proportional benefit. Fewer than three fails to capture the range between your largest enterprise customers and your smallest self-serve accounts.

**Tier 1 — Enterprise Critical** is for customers whose contract value, regulatory exposure, or strategic importance justifies the highest level of eval investment. Tier-1 customers get continuous or near-continuous evaluation: every production output is scored, or a statistically significant sample is scored multiple times per day. They get dedicated golden sets curated specifically for their domain and use cases. They get human-in-the-loop review where flagged outputs are reviewed by trained analysts before quality scores are finalized. They get LLM judges configured with customer-specific rubrics, weighted to the dimensions that matter most to their business. They get monthly evidence packages, quarterly business reviews with detailed report diffs, and a named eval owner on your platform team who is accountable for their quality trajectory. A platform serving a $2 million per year pharmaceutical customer whose clinical summarization AI is subject to FDA and HIPAA scrutiny operates at tier 1.

**Tier 2 — Enterprise Standard** is for mid-range enterprise customers with meaningful contract values and some regulatory or quality sensitivity, but without the extreme requirements that justify tier-1 investment. Tier-2 customers get daily automated evaluation on a representative sample — typically 10 to 20 percent of production volume. They use shared judge models with customer-specific rubric configurations. Their golden sets are maintained but reviewed less frequently — quarterly rather than monthly. They receive automated quality reports with basic diffs, and their evidence packages are generated on demand rather than proactively. A platform serving a $300,000 per year financial services customer with standard quality SLAs operates at tier 2.

**Tier 3 — Growth and Self-Serve** is for smaller accounts where the contract value does not justify individualized eval investment. Tier-3 customers get weekly or biweekly automated evaluation on a smaller sample — 5 to 10 percent of production volume. They use platform-default rubrics with minimal customization. Their golden sets are generated from platform-wide templates rather than custom-curated. Quality reports are automated and delivered without manual review. Evidence packages are available only as an add-on. A customer on a $5,000 per month self-serve plan with no contractual quality floor operates at tier 3.

Some platforms add a **Tier 0 — Regulated Mission-Critical** for the rare customer whose requirements are so extreme that they need dedicated eval infrastructure: dedicated judge model deployments, dedicated compute for eval jobs, and continuous human oversight. Government defense contracts, safety-critical healthcare applications, and financial trading systems sometimes fall into tier 0. The eval cost per customer at tier 0 can exceed $10,000 per month, but the contract values justify it.

## The Cost Structure of Each Tier

The cost gap between tiers is not linear. It is exponential, driven primarily by two factors: eval frequency and human involvement.

Tier-3 eval for a single customer typically costs $40 to $80 per month. The eval jobs run weekly on a small sample, use shared judge infrastructure, and require no human review. The cost is almost entirely compute: a few hundred LLM judge calls per week at standard API pricing, plus minimal storage for scores and traces.

Tier-2 eval costs $400 to $1,200 per month per customer. Daily evaluation on a larger sample increases judge call volume by roughly 5 to 10 times compared to tier 3. Customer-specific rubric configuration adds setup and maintenance cost. Quarterly golden set reviews add a few hours of analyst time per quarter. The cost is split between compute and the amortized cost of human review.

Tier-1 eval costs $2,500 to $6,000 per month per customer. Continuous or near-continuous evaluation multiplies judge call volume again. Dedicated golden sets require ongoing curation by domain specialists. Human-in-the-loop review on flagged outputs adds direct labor cost — typically 10 to 20 hours per month of analyst time per customer. Monthly evidence packages add storage and generation overhead. The named eval owner's time, amortized across their portfolio of tier-1 customers, adds further cost.

Tier-0 eval can cost $8,000 to $15,000 per month per customer, driven by dedicated infrastructure, continuous human oversight, and the specialized expertise required for safety-critical or regulated domains.

These cost ranges are not arbitrary. They follow directly from the mechanics of what each tier includes. Understanding the cost structure lets you price each tier profitably and explain to customers exactly what they are paying for, as explored in detail in Section 30.

## Determining Which Tier a Customer Belongs To

Tier assignment is not a subjective judgment call. It follows from four measurable factors, and your platform should have a scoring model that weighs them.

The first factor is **contract value**. Higher contract value justifies higher eval spend because the cost of losing the customer is greater. A rough guideline: eval spend should represent 3 to 8 percent of a customer's annual contract value. A $2 million contract can absorb $80,000 to $160,000 in annual eval cost. A $60,000 contract cannot absorb more than $2,000 to $5,000. Contract value sets the ceiling on what you can spend without making the customer unprofitable — a topic covered in depth in subchapter 7-2.

The second factor is **regulatory exposure**. Customers in healthcare, financial services, government, and other regulated industries have compliance requirements that mandate specific eval practices — evidence packages, audit trails, data residency proof, human oversight. Regulatory exposure can push a customer to a higher tier even if their contract value alone would not justify it, because the cost of a compliance failure (regulatory penalties, contract termination, reputational damage) exceeds the incremental eval spend.

The third factor is **data sensitivity**. Customers whose AI systems process personally identifiable information, protected health information, financial records, or classified data require more careful evaluation because eval failures in sensitive domains carry disproportionate consequences. A quality failure in a marketing copy generator is embarrassing. A quality failure in a clinical decision support system is potentially life-threatening. Data sensitivity amplifies the stakes of eval and pushes the customer toward higher tiers.

The fourth factor is **churn risk and strategic importance**. A customer who is a reference account, a case study partner, or a gateway to a lucrative vertical deserves higher eval investment even if their current contract value is modest. Losing a $150,000 customer who is your only foothold in the insurance vertical costs more than the contract value — it costs the market position. Strategic importance is harder to quantify than the other factors, but ignoring it means your tier model optimizes for today's revenue at the expense of tomorrow's growth.

## The Upgrade Path

Tier assignment is not permanent. Customers move between tiers as their usage, contract value, and requirements evolve.

The most common upgrade path is tier 3 to tier 2: a self-serve customer grows their usage, signs an annual contract, and needs quality assurance beyond what the default weekly sampling provides. The upgrade should be seamless. The customer's eval configuration already exists at tier 3. Upgrading means increasing the eval frequency, adding customer-specific rubric weights, and assigning a golden set review cadence. The transition should take less than a week and should not require re-onboarding.

The tier-2 to tier-1 upgrade is more involved. It requires golden set curation, human-in-the-loop review setup, evidence package generation configuration, and a named eval owner assignment. This transition typically takes two to four weeks and often coincides with a contract expansion or a move into a regulated use case. The customer's existing tier-2 evaluation provides a baseline that the tier-1 setup builds on rather than replaces.

Downgrades happen too, though they are rarer. A customer who reduces their contract scope or moves to a less sensitive use case may no longer need tier-1 evaluation. Downgrading gracefully — reducing eval frequency without creating the perception of reduced quality commitment — requires careful communication. The account team should frame the change as right-sizing evaluation to match the customer's current needs, not as a cost-cutting measure.

## The Communication Challenge

Tiered eval coverage creates a perception risk: the customer on tier 3 who discovers that another customer gets daily evaluation may feel that they are receiving an inferior product. How you communicate tiered coverage matters as much as how you implement it.

The most effective approach is transparency without comparison. Describe what the customer's plan includes — "your plan includes weekly quality evaluation with automated reporting" — without volunteering what higher tiers include. When a customer asks for more frequent evaluation or human review, position the upgrade as an available option tied to their plan level: "daily evaluation with dedicated golden sets is available as part of our Enterprise tier. Would you like to discuss what that upgrade looks like for your account?"

Never frame tiered coverage as "you get less." Frame it as "every tier includes the evaluation appropriate for that tier's use cases and risk profile." A self-serve customer running a content generation tool does not need the same eval depth as a pharmaceutical company running a clinical summarizer. Tiered coverage is not about providing less — it is about matching the evaluation investment to what the customer's use case actually requires.

Your sales and customer success teams must understand the tier model well enough to explain it confidently. A sales representative who cannot explain why tier-2 evaluation is appropriate for a $300,000 contract — and what additional capabilities the customer would gain by upgrading to tier 1 — will either oversell (promising tier-1 evaluation at tier-2 pricing, which destroys margins) or undersell (failing to explain the value of higher-tier evaluation when the customer's use case warrants it).

## Connecting Eval Tiers to Pricing Tiers

Eval tier and pricing tier are not the same thing, but they must be aligned. A pricing tier that includes unlimited evaluation at the lowest plan level makes eval cost unpredictable and subsidizes high-eval-cost customers at the expense of low-eval-cost ones. A pricing tier that charges separately for every eval feature creates a confusing menu that customers resist.

The cleanest approach is to bundle eval coverage into the platform's pricing tiers as a defined component. "Enterprise includes daily evaluation, custom rubrics, and quarterly evidence packages. Growth includes weekly evaluation with platform-default rubrics." The eval capabilities are a named part of the value proposition, not an afterthought or a hidden cost. Section 30 covers the detailed economics of how to price eval coverage without creating margin leakage or customer confusion.

## Why Tiered Coverage Is More Honest Than Uniform Promises

The alternative to tiered eval coverage is the promise of uniform evaluation for everyone. "Every customer gets continuous, human-reviewed, audit-grade evaluation." This promise sounds generous. In practice, it is a lie — or if true, it is financially unsustainable.

A platform with 400 customers cannot afford $4,000 per month in eval cost for every one of them. That is $1.6 million per month in eval infrastructure alone, before accounting for the engineering team that operates it. The math does not work unless every customer is paying enough to absorb that cost, and in a multi-tier platform, the majority of customers are not. What happens in practice is that the platform promises uniform evaluation, discovers it cannot afford it, and quietly reduces eval quality for everyone to a level it can sustain. The top-tier customers who need deep evaluation get less than they were promised. The bottom-tier customers who do not need it still consume resources that could be better allocated elsewhere.

Tiered coverage is more honest because it acknowledges that different customers have different needs and that meeting those needs costs different amounts. It lets you invest deeply where the investment matters most and operate efficiently where it matters least. It aligns your eval costs with your revenue, your risk exposure, and your customer commitments. And it gives every customer exactly the level of evaluation that their contract and use case justify — no more, no less.

The organizational patterns that support multi-tenant evaluation — team structures, escalation paths, and governance models — are the subject of Chapter 8, where the focus shifts from systems to the people who operate them.
