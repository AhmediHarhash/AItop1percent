# Chapter 3 — Task Taxonomy & Coverage Map

**What we're doing in Chapter 3:**
We're building a clear map of *everything your AI system does* (tasks), then a clear map of *what you actually test* (coverage).
This is how enterprise teams avoid the #1 eval failure: **testing only the easy, obvious cases**.

**Why this matters:**
If you don't define tasks and coverage, you'll get "great metrics" and still ship bugs, because your eval set didn't include the real-world mess.

---

## Chapter 3.1 — Build a Task Taxonomy (intents, skills, channels)

### Mechanics (how it works)

A **task taxonomy** is a structured list of what your system must handle, grouped by:
- **Intent** (what the user wants)
- **Skill** (what the system must do)
- **Channel** (chat, RAG, agent, voice)
- **Risk level** (low vs high stakes)
- **User segment** (new user vs power user, free vs enterprise)

You're not doing this for beauty. You're doing it so you can:
- build eval datasets per task,
- track regressions by task,
- assign owners,
- and communicate clearly with leadership.

---

### The taxonomy layers (use all 5)

#### Layer 1 — Product surface (channel)
- Chat assistant
- RAG knowledge assistant
- Agent workflows (tool-use)
- Voice agent
- Multi-modal (screenshots, forms, UI actions) if applicable

#### Layer 2 — User intent (what they want)
Examples (you will replace with your product intents):
- Ask a question
- Summarize something
- Draft something
- Retrieve policy / knowledge
- Troubleshoot a problem
- Complete a workflow (book, refund, update account)
- Escalate to human
- Report an issue / complaint

#### Layer 3 — Required skills (what the system must do)
Common skills:
- Instruction following
- Reasoning (light vs complex)
- Grounding in sources (RAG)
- Tool use (agents)
- Data extraction (structured output)
- Personalization (within allowed privacy rules)
- Safety handling (refusal/redirect)
- Tone control (brand voice)
- Multi-turn memory/state

#### Layer 4 — Risk tier (how dangerous if wrong)
Use a simple 4-tier model:
- **Tier 0:** Low risk (creative ideas, basic writing)
- **Tier 1:** Medium (how-to guidance, general troubleshooting)
- **Tier 2:** High (account actions, payments, business-critical decisions)
- **Tier 3:** Regulated/critical (medical, legal, financial, child safety, identity/PII)

#### Layer 5 — Complexity tier (how hard it is)
- **C0:** Single-turn, obvious
- **C1:** Multi-turn clarification needed
- **C2:** Needs retrieval or structured reasoning
- **C3:** Needs tools + state + error recovery

---

### Knobs & defaults (what you actually set)

**Defaults that work well in enterprise:**
- Keep the taxonomy to **30–80 leaf tasks** (not 500)
- Each leaf task must be:
  - testable
  - owned
  - tied to a dataset slice
- Use **risk tier** as a first-class label
- Use **channel** as a first-class label
- Keep naming consistent:
  - Verb + object + constraint
  - Example: `Retrieve refund policy (RAG, Tier 2, C2)`

---

### Failure modes (symptoms + root causes)

**Symptom: "Our evals look good but production is bad."**
Root causes:
- Taxonomy is too shallow (only "QA" and "summarization")
- No risk tiers (high-risk tasks hidden inside averages)
- No channel split (RAG issues hidden inside chat averages)
- Too many vague buckets ("general help")

**Symptom: Teams argue about what broke.**
Root causes:
- Tasks not clearly named
- No ownership per task group
- No standard labels for tier/complexity/channel

---

### Debug playbook (how to diagnose + fix)

1. Pull the top **1000 real user interactions** (or the best sample you can)
2. Cluster them into **10–20 intent groups**
3. Expand each group into **leaf tasks** until they are testable
4. Tag each leaf task with:
   - channel
   - risk tier
   - complexity tier
5. Assign an owner for each major branch
6. Build your first evaluation dataset using the taxonomy slices

**Quick check:**
If you can't easily answer "Which tasks are we best at?" your taxonomy is not ready.

---

### Enterprise expectations (what serious teams do)

- Maintain a shared taxonomy doc + version it (v1, v1.1…)
- Add a change control rule:
  - New product feature = new tasks added to taxonomy
  - New incident = new leaf task or new edge case added
- Scorecards are always sliced by:
  - task
  - tier
  - channel
  - top customers/segments

---
