# Chapter 4.2 — Handling Ambiguity and "Multiple Correct Answers"

**What we're doing here:**
In real life, many AI tasks do not have one perfect answer.
If you treat them like they do, your evals become unfair, noisy, and easy to game.

This chapter teaches you how to design ground truth and scoring when:
- the user request is ambiguous,
- multiple answers are acceptable,
- or the "best" answer depends on assumptions.

**Enterprise goal:**
Reduce arguments and noise by making ambiguity explicit and scoring it consistently.

---

## 1) Mechanics: why ambiguity happens

Ambiguity appears because:
- the user didn't provide enough info (missing constraints)
- the question allows multiple interpretations
- the domain has "it depends" rules
- the system has limited access to truth (RAG gaps, tool errors)
- the user's goal is subjective (tone, style, preference)

In 2026 production systems, ambiguity is normal — so your ground truth must include rules for it.

---

## 2) The 4 ambiguity types (and what "correct" means for each)

### Type A — Missing critical info (blocking ambiguity)

**Example:** "Draft a contract for my client." (no jurisdiction, scope, payment terms)

**Correct behavior:**
- Ask **1–2 clarifying questions**, OR
- Provide a best-effort template **with explicit assumptions** and placeholders

**What's wrong:**
- acting confident and inventing details
- refusing completely when safe help is possible

---

### Type B — Multiple valid outputs (open-ended ambiguity)

**Example:** "Write a welcome email" (many good versions)

**Correct ground truth:**
- A **rubric** + a **must-include checklist**
- A set of acceptable variants (anchors), not one expected wording

**What's wrong:**
- scoring based on personal style preference
- punishing a good answer because it's "not like the reference"

---

### Type C — Domain-dependent ambiguity ("it depends")

**Example:** "Is this allowed under policy?" where policy has exceptions

**Correct behavior:**
- Identify the decision criteria
- Ask for the missing criteria
- If evidence is missing, **abstain** or **escalate** (especially Tier 2–3)

**What's wrong:**
- giving a binary yes/no without checking conditions
- guessing policy outcomes

---

### Type D — Evidence-limited ambiguity (RAG/tool limitations)

**Example:** "What is our SLA?" but the provided docs don't mention it

**Correct behavior:**
- Abstain: "Not in provided sources"
- Suggest retrieval targets ("search SLA doc / contract template")

**What's wrong:**
- hallucinating the SLA
- pretending to have found it

---

## 3) Knobs & defaults (what you actually set)

### 3.1 Ambiguity policy per risk tier
- **Tier 0–1:** allow reasonable assumptions; proceed with helpful output
- **Tier 2:** ask clarifiers for critical constraints; avoid strong claims
- **Tier 3:** strict: require evidence or verified inputs; escalate/abstain more often

### 3.2 Clarifying question limit
Default:
- max **2** questions before providing value
- ask only what changes the answer materially

### 3.3 "Assumptions format"
Default:
- state assumptions in 1–3 bullets
- then proceed with the solution

This keeps it fast and auditable.

---

## 4) How to define ground truth when multiple answers are correct

You have 3 strong enterprise patterns:

### Pattern 1 — "Must-include" checklist truth
Instead of expecting exact words, define:
- required elements (must include)
- forbidden elements (must not include)
- optional enhancements

**Best for:** emails, summaries, support responses, explanations.

---

### Pattern 2 — Allowed answer sets (variants)
Create 2–5 "acceptable" example answers:
- one short
- one detailed
- one more formal
- one more friendly

**Best for:** writing tasks and UX-sensitive responses.

---

### Pattern 3 — Behavior-first truth (the safest)
Define the correct behavior:
- ask a clarifier
- abstain
- refuse and redirect
- escalate

**Best for:** RAG gaps, high-risk policy, account/payment flows, safety.

---

## 5) Scoring ambiguity consistently (rubric add-on)

To reduce rater disagreement, add these dimensions when ambiguity exists:

### 5.1 Ambiguity Handling (0–3)
- **0:** invents details or answers the wrong interpretation confidently
- **1:** notices ambiguity but handles it poorly (too many questions, no help)
- **2:** asks 1–2 key questions OR proceeds with clear assumptions + helpful output
- **3:** handles ambiguity perfectly + protects risk tier + offers verification path

### 5.2 Assumption Quality (0–3) (optional)
- **0:** hidden assumptions
- **1:** assumptions stated but unrealistic or too many
- **2:** assumptions clear and reasonable
- **3:** assumptions minimal, high-quality, aligned to user goal

**Hard rule:**
If ambiguity touches safety/PII/Tier 3 decisions, incorrect certainty is a fail.

---

## 6) Failure modes (symptoms + root causes)

### 6.1 "Raters disagree constantly"
Root causes:
- no ambiguity dimension
- no must-include checklist
- no anchor examples

Fix:
- add ambiguity-handling rubric + 5 anchors

---

### 6.2 "Model guesses instead of clarifying"
Root causes:
- helpfulness rewarded more than correctness
- no "confident-wrong" penalty

Fix:
- penalize confident guessing
- add "must clarify" cases to regression suite

---

### 6.3 "Model asks too many questions"
Root causes:
- clarify-first prompt bias
- missing rule: "provide value even while asking"

Fix:
- max 2 questions
- require partial solution + placeholders

---

## 7) Debug playbook (how to build ambiguity test cases)

Create an "Ambiguity Pack" for every major task group:

- missing constraints (jurisdiction, region, plan tier)
- unclear references ("that file", "the last email", "my order")
- conflicting user goals ("make it short but include everything")
- partial RAG context (docs missing key section)
- tool partial failures (agent got half the data)

For each case, label:
- expected behavior (ask/assume/abstain/escalate)
- risk tier
- a great vs fail example

---

## 8) Enterprise expectations (what serious teams do)

- They explicitly define:
  - when assumptions are allowed
  - when clarifying is required
  - when abstain/escalation is mandatory
- They track metrics:
  - confident-wrong rate (especially on ambiguous prompts)
  - unnecessary clarification rate
  - abstain correctness rate
- They add ambiguity packs to regression testing because ambiguity is where trust breaks.

---
