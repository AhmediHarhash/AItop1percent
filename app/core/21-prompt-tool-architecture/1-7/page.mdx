# 1.7 â€” The Prompt as Contract: Inputs, Outputs, and Failure Modes

A healthcare technology company deployed a patient intake form processor in March 2025 using Claude 3.5 Sonnet. The system extracted patient information, insurance details, and medical history from scanned forms. The prompt was 650 tokens of carefully crafted instructions with examples. Quality assurance testing showed 96 percent accuracy across 2,000 test forms.

Three months into production, the system suddenly started failing on 12 to 18 percent of forms. Extracted data included hallucinated phone numbers, transposed patient names, and fabricated insurance policy numbers. These errors caused appointment delays, billing problems, and compliance violations. The engineering team blamed model degradation until they examined actual failures.

The root cause was input drift. The original prompt assumed intake forms would always be legible PDFs with standard formatting. But real-world usage included photos of forms taken with phones in poor lighting, faxed copies with degraded quality, and handwritten forms with unclear text. The prompt had no specification for handling these input variations and no defined failure behavior. The model guessed when it should have refused. The contract between prompt and application was implicit and incomplete.

## Why Prompts Need Formal Contracts

Software engineers understand that functions need contracts specifying inputs, outputs, preconditions, and postconditions. A function signature like `extractPatientData(form: PDF): PatientRecord` defines what goes in and what comes out. But most AI prompts lack this rigor. They are informal instructions hoping for reasonable behavior rather than specifications ensuring correct behavior.

This informality works fine in prototypes and demos where humans review every output. It fails catastrophically in production where thousands or millions of automated decisions happen without human oversight. When you treat prompts as casual suggestions rather than enforceable contracts, you create systems that fail unpredictably and silently.

The solution is prompt contract design: explicitly defining expected inputs, guaranteed outputs, error handling behavior, and performance boundaries. This discipline catches mismatches during development rather than after production deployment. It also enables automated testing and monitoring that detects contract violations.

## Defining Expected Inputs with Validation Criteria

Your prompt must specify exactly what inputs it handles and how it behaves when inputs fall outside specifications. This goes beyond "The input is a document" to precise constraints: document types, length limits, format requirements, language constraints, and content expectations.

A contract for document summarization might specify: "Input must be English-language text between 500 and 50,000 tokens, containing at least 3 paragraphs, with no more than 30 percent technical jargon. Input may include markdown formatting. Input must not contain PII or confidential information." These constraints let you validate inputs before sending them to the model and reject invalid inputs gracefully.

Include handling instructions for boundary cases. What happens if the document is 49,000 tokens (just under limit) versus 51,000 tokens (just over)? What if it is 95 percent English with 5 percent Spanish? What if it contains markdown tables that break your parser? Every boundary case without explicit handling becomes a potential production failure.

## Specifying Output Format as Enforceable Schema

Vague output requirements like "return a summary" or "extract key information" create parsing nightmares. The model might return markdown, plain text, JSON, or a prose paragraph. Your downstream code must handle all variations or fail on unexpected formats. This creates brittle integration points that break whenever model behavior shifts slightly.

Define output format with schema precision. For structured data, specify JSON schema with required fields, field types, and validation rules. For text outputs, specify format templates with placeholders. For classifications, enumerate all valid categories and specify the exact return format.

A contract for entity extraction might specify: "Output must be valid JSON with top-level keys: entities, confidence, metadata. entities must be an array of objects with keys: text, type, span. type must be one of: PERSON, ORG, LOCATION, DATE, AMOUNT. confidence must be a number between 0 and 1. metadata must be an object with key: processing_time." This schema enables automated validation and prevents undefined behavior.

## Prompt SLAs: Performance and Quality Guarantees

Service level agreements define performance expectations and quality thresholds. Your prompt contract should include SLA-like guarantees that you monitor in production. These guarantees create accountability and trigger alerts when performance degrades.

Define quality guarantees as measurable metrics with thresholds. "Accuracy must exceed 90 percent on standard test set" gives you a concrete target. "Hallucination rate must stay below 2 percent" defines acceptable error bounds. "Output must match schema 99.5 percent of the time" specifies format compliance.

Include latency and cost guarantees when relevant. "95th percentile latency must not exceed 3 seconds" creates a performance target. "Average cost per request must stay below $0.02" bounds economic impact. These guarantees let you detect when prompt changes or model updates violate contracts, triggering rollback or remediation.

## What Happens When the Contract Breaks

A prompt contract must specify failure behavior explicitly. When inputs violate preconditions, when the model cannot produce valid output, or when quality falls below thresholds, what should happen? Default AI behavior is to try anyway and return something, even if that something is wrong or nonsensical.

Define three failure modes: hard failures, soft failures, and degraded operation. Hard failures refuse to process invalid inputs and return error codes or null responses. Soft failures return partial results with confidence scores indicating uncertainty. Degraded operation returns results but flags them for human review.

The healthcare intake system from the opening story needed hard failure behavior: when form quality is too poor for confident extraction, return an error and route the form to manual processing. Instead, the implicit contract was "always extract something," leading to hallucinated data. Explicit failure specification prevents this category of error.

## Defensive Prompt Design Against Contract Violations

Even with perfect contracts, production inputs will violate assumptions. Users will upload wrong file types, send queries in unexpected languages, or trigger edge cases you did not anticipate. Defensive prompt design adds guard rails that detect and handle violations gracefully.

Start prompts with input validation instructions: "First, verify that the input is a valid product description in English between 50 and 500 words. If not, return an error object with key: error, value: [description of violation]." This instruction creates a model-based validation layer that catches issues before processing.

Add output validation instructions at the end: "Before returning your response, verify it matches the required JSON schema. If not, revise your response until it complies." This creates a self-correction mechanism that reduces format violations. While not perfect, it catches many errors that would otherwise escape.

Include explicit refusal instructions for impossible tasks: "If you cannot complete this task with high confidence, return: {status: 'unable_to_process', reason: [explanation]}." This gives the model permission to fail gracefully rather than guessing or hallucinating.

## Contract Testing and Validation Frameworks

You cannot enforce contracts without systematic testing. Build a contract validation framework that runs before production deployment and continuously in production. This framework checks that prompts comply with their contracts across diverse inputs and scenarios.

Create test suites covering normal cases, boundary cases, and adversarial cases. Normal cases verify standard behavior meets quality thresholds. Boundary cases test input limits: maximum length, minimum length, edge values, missing fields. Adversarial cases test robustness: malformed inputs, injection attempts, nonsensical queries.

Run contract tests against every prompt change before deployment. A test suite with 200 to 500 examples per prompt provides reasonable coverage of common patterns and failure modes. Track which contract requirements each test validates so you know your coverage. Tests that pass on 95 percent of examples but fail on 5 percent indicate contract violations needing remediation.

## Input Sanitization and Preprocessing

Many contract violations happen because inputs reach the model in unexpected states. User-generated text includes malicious prompts, random characters, or formatting that confuses the model. Documents include corrupted sections, mixed languages, or embedded content that breaks parsing.

Implement preprocessing pipelines that sanitize inputs before they reach the model. Remove or escape control characters, strip excessive whitespace, normalize unicode, and validate character encodings. Detect and reject inputs that appear malicious or malformed based on heuristic rules.

For document processing, use OCR quality detection, language identification, and format validation. If a scanned document has OCR confidence below 70 percent, route it to human processing rather than sending garbled text to the model. If a document is 40 percent English and 60 percent German but your contract specifies English-only, reject it or route to a multilingual system.

## Output Validation and Postprocessing

Even with defensive prompt design, models occasionally produce outputs that violate contracts. Output validation catches these violations before they reach downstream systems or users. Implement validation layers that check schema compliance, business logic rules, and safety constraints.

For structured outputs, parse JSON and validate against schemas using libraries like JSON Schema validators. Reject responses that fail validation and optionally retry with modified prompts. For text outputs, check length constraints, forbidden phrases, and format requirements using regex or NLP tools.

Implement business logic validation that checks whether outputs make sense in your domain. If you extract a birth date of "January 45, 2025" from a form, validation should flag this as impossible even if it matches your date field schema. If you classify a product as both "electronics" and "food" when your contract specifies single-label classification, reject the response.

## Version Control and Contract Evolution

Prompts evolve over time as you refine behavior, handle new cases, or adapt to model updates. Every prompt change potentially modifies the implicit contract. Without explicit contract tracking, these changes introduce regressions where new versions break expectations that downstream systems depend on.

Version your prompts and their contracts together. When you change a prompt, update its contract specification and version number. Run contract tests against the new version to verify it maintains compatibility with existing integration points. Track breaking changes separately from non-breaking improvements.

Define semantic versioning for prompts: major version changes for breaking contract modifications, minor version changes for backward-compatible improvements, patch version changes for bug fixes. This versioning signals to downstream consumers whether they need to adapt to prompt updates or can upgrade seamlessly.

## Contract Monitoring in Production

Contract specifications enable sophisticated production monitoring that detects violations in real time. Instrument your application to log input characteristics, output characteristics, and contract compliance metrics. Alert when violation rates exceed thresholds.

Monitor input drift by tracking feature distributions over time. If 90 percent of inputs were 500 to 2,000 tokens last month but this month 40 percent exceed 5,000 tokens, your input distribution has shifted. This shift might violate your contract assumptions and explain quality degradation.

Monitor output compliance by validating every response against schemas and business rules. Track the percentage of responses requiring retries, the percentage flagged for review, and the percentage rejected as invalid. Trends in these metrics reveal contract violations before they cause visible failures.

## Contracts Enable Safe Prompt Optimization

When you optimize prompts for cost or latency, contracts provide safety rails that prevent optimizations from degrading quality below acceptable thresholds. You can aggressively compress prompts, remove examples, or simplify instructions while monitoring contract compliance to ensure changes do not break guarantees.

Run A/B tests comparing original and optimized prompts with contract validation on both variants. If the optimized prompt violates quality contracts on 8 percent of requests compared to 1 percent for the original, the optimization failed regardless of cost savings. Contracts make these trade-offs explicit and measurable.

Use contracts to define quality floors below which optimizations are rejected. A contract specifying "accuracy must not fall below 88 percent" prevents you from shipping a highly optimized prompt achieving 85 percent accuracy. This discipline ensures optimization improves efficiency without sacrificing reliability.

## Documentation as Contract Specification

Your prompt contract should exist as machine-readable documentation that lives alongside the prompt itself. Use structured formats like YAML or JSON to specify inputs, outputs, guarantees, and failure modes. This documentation becomes the source of truth for validation, testing, and monitoring.

A contract specification might include: expected input schema, input validation rules, output schema, output validation rules, quality thresholds, latency thresholds, cost budgets, supported languages, supported models, failure modes and handling, version number, and change log. This information guides both human developers and automated systems.

Store contracts in version control alongside prompt code. Require contract updates for any prompt modification. Review contracts during code review to ensure changes maintain compatibility and do not introduce unhandled edge cases. Treat contract violations in production with the same severity as code bugs because they represent similar failures of specification and implementation.

The next subchapter examines the taxonomy of prompt failures in production and how to detect and monitor each failure type.
