# 1.7 â€” The Prompt as Contract: Inputs, Outputs, and Failure Modes

A healthcare technology company deployed a patient intake form processor in March 2025 using Claude 3.5 Sonnet. The system extracted patient information, insurance details, and medical history from scanned forms. The prompt was 650 tokens of carefully crafted instructions with examples. Quality assurance testing showed 96 percent accuracy across 2,000 test forms.

Three months into production, the system suddenly started failing on 12 to 18 percent of forms. Extracted data included hallucinated phone numbers, transposed patient names, and fabricated insurance policy numbers. These errors caused appointment delays, billing problems, and compliance violations. The engineering team blamed model degradation until they examined actual failures.

The root cause was input drift. The original prompt assumed intake forms would always be legible PDFs with standard formatting. But real-world usage included photos of forms taken with phones in poor lighting, faxed copies with degraded quality, and handwritten forms with unclear text. The prompt had no specification for handling these input variations and no defined failure behavior. The model guessed when it should have refused. The contract between prompt and application was implicit and incomplete.

After three months of escalating error rates, the company spent $340,000 rebuilding the system with explicit contracts. They added input validation specifications, output schema enforcement, and defined failure modes. The rebuilt system achieved 98 percent accuracy with a 0.3 percent hallucination rate, down from 4 percent. The cost of the initial failure included not just the rebuild but also 1,200 hours of manual correction work and potential HIPAA violation exposure.

## Why Prompts Need Formal Contracts

Software engineers understand that functions need contracts specifying inputs, outputs, preconditions, and postconditions. A function signature like extractPatientData taking a PDF and returning a PatientRecord defines what goes in and what comes out. But most AI prompts lack this rigor. They are informal instructions hoping for reasonable behavior rather than specifications ensuring correct behavior.

This informality works fine in prototypes and demos where humans review every output. It fails catastrophically in production where thousands or millions of automated decisions happen without human oversight. When you treat prompts as casual suggestions rather than enforceable contracts, you create systems that fail unpredictably and silently.

The solution is prompt contract design: explicitly defining expected inputs, guaranteed outputs, error handling behavior, and performance boundaries. This discipline catches mismatches during development rather than after production deployment. It also enables automated testing and monitoring that detects contract violations.

Contracts answer questions that informal prompts ignore. What input formats are valid? What input lengths can you handle? What happens when inputs fall outside specifications? What output format will you guarantee? What quality thresholds must you meet? What latency can users expect? These questions have concrete answers that determine system behavior.

The healthcare company's initial prompt said "extract patient information from the form." This is not a contract. It does not specify what counts as a form, what patient information means, how to handle missing data, or what to do with illegible inputs. The model made reasonable guesses most of the time and terrible guesses the rest of the time.

## Defining Expected Inputs with Validation Criteria

Your prompt must specify exactly what inputs it handles and how it behaves when inputs fall outside specifications. This goes beyond "The input is a document" to precise constraints: document types, length limits, format requirements, language constraints, and content expectations.

A contract for document summarization might specify: "Input must be English-language text between 500 and 50,000 tokens, containing at least 3 paragraphs, with no more than 30 percent technical jargon. Input may include markdown formatting. Input must not contain PII or confidential information." These constraints let you validate inputs before sending them to the model and reject invalid inputs gracefully.

Include handling instructions for boundary cases. What happens if the document is 49,000 tokens versus 51,000 tokens? What if it is 95 percent English with 5 percent Spanish? What if it contains markdown tables that break your parser? Every boundary case without explicit handling becomes a potential production failure.

For the healthcare intake system, proper input specification would include: "Input must be a scanned form or digital document in PDF or image format. Text must be machine-readable with minimum 70 percent OCR confidence. Forms must follow standard medical intake structure with identifiable fields for patient name, date of birth, insurance information, and medical history. Forms with OCR confidence below 70 percent or missing critical fields must be flagged for manual review."

Input validation also means checking semantic validity, not just format validity. A form might be technically parseable but contain impossible data: birth dates in the future, insurance policy numbers with invalid check digits, phone numbers with wrong digit counts. Your contract should specify which semantic validations to perform and how to handle violations.

Consider edge cases at the boundary of validity. A barely legible fax might have 69 percent OCR confidence. Do you process it or reject it? A form might have all required fields but with values that seem suspicious. Do you extract them with confidence flags or refuse to process? Your contract must make these decisions explicit.

## Specifying Output Format as Enforceable Schema

Vague output requirements like "return a summary" or "extract key information" create parsing nightmares. The model might return markdown, plain text, JSON, or a prose paragraph. Your downstream code must handle all variations or fail on unexpected formats. This creates brittle integration points that break whenever model behavior shifts slightly.

Define output format with schema precision. For structured data, specify JSON schema with required fields, field types, and validation rules. For text outputs, specify format templates with placeholders. For classifications, enumerate all valid categories and specify the exact return format.

A contract for entity extraction might specify: "Output must be valid JSON with top-level keys: entities, confidence, metadata. entities must be an array of objects with keys: text, type, span. type must be one of: PERSON, ORG, LOCATION, DATE, AMOUNT. confidence must be a number between 0 and 1. metadata must be an object with key: processing_time." This schema enables automated validation and prevents undefined behavior.

For the healthcare system, the output contract should specify exact field names, data types, required versus optional fields, and valid value ranges. Patient age must be an integer between 0 and 120. Phone numbers must match a specific pattern. Insurance policy numbers must conform to known formats. Dates must use ISO 8601 format. Every field in the output has explicit requirements.

Output contracts also specify what the model should not include. No hallucinated fields beyond the schema. No explanatory text mixed with structured data. No metadata that was not explicitly requested. These negative specifications are as important as positive ones. They prevent the model from being helpful in ways that break your parsing logic.

Schema validation catches contract violations immediately. If the model returns a string where you expected a number, validation fails. If required fields are missing, validation fails. If the JSON structure is malformed, validation fails. This fast feedback enables retry logic, fallback strategies, or human escalation before bad data propagates downstream.

## Prompt SLAs: Performance and Quality Guarantees

Service level agreements define performance expectations and quality thresholds. Your prompt contract should include SLA-like guarantees that you monitor in production. These guarantees create accountability and trigger alerts when performance degrades.

Define quality guarantees as measurable metrics with thresholds. "Accuracy must exceed 90 percent on standard test set" gives you a concrete target. "Hallucination rate must stay below 2 percent" defines acceptable error bounds. "Output must match schema 99.5 percent of the time" specifies format compliance.

Include latency and cost guarantees when relevant. "95th percentile latency must not exceed 3 seconds" creates a performance target. "Average cost per request must stay below two cents" bounds economic impact. These guarantees let you detect when prompt changes or model updates violate contracts, triggering rollback or remediation.

The healthcare system needed quality guarantees like: "Accuracy on legible forms must exceed 98 percent. False positive rate for extracted values must stay below 0.5 percent. Hallucination rate must not exceed 0.2 percent. Forms with OCR confidence below 70 percent must be flagged, not processed. Processing latency must not exceed 5 seconds for 95 percent of forms."

SLA violations trigger different responses based on severity. Minor violations might log warnings for later investigation. Moderate violations might switch to a backup prompt or model. Severe violations might halt automated processing and escalate to humans. Your contract specifies these thresholds and responses.

Performance guarantees also inform capacity planning. If your contract promises 3-second latency but your model takes 5 seconds during peak load, you need more capacity or a faster model. If your contract promises specific accuracy but you cannot achieve it reliably, you need better prompts or different models. Contracts make these gaps visible and actionable.

## What Happens When the Contract Breaks

A prompt contract must specify failure behavior explicitly. When inputs violate preconditions, when the model cannot produce valid output, or when quality falls below thresholds, what should happen? Default AI behavior is to try anyway and return something, even if that something is wrong or nonsensical.

Define three failure modes: hard failures, soft failures, and degraded operation. Hard failures refuse to process invalid inputs and return error codes or null responses. Soft failures return partial results with confidence scores indicating uncertainty. Degraded operation returns results but flags them for human review.

The healthcare intake system from the opening story needed hard failure behavior: when form quality is too poor for confident extraction, return an error and route the form to manual processing. Instead, the implicit contract was "always extract something," leading to hallucinated data. Explicit failure specification prevents this category of error.

Hard failures apply when continuing would be dangerous or useless. A form with 30 percent OCR confidence cannot be processed reliably, so hard failure is appropriate. A form missing critical fields like patient name cannot populate the required database records, so hard failure prevents partial records.

Soft failures apply when partial information has value. A form with 95 percent OCR confidence might be processable even if a few fields are unclear. Return the high-confidence extractions and flag low-confidence fields for human verification. The partial result is useful, and the confidence scores enable appropriate handling.

Degraded operation applies when you can proceed but want human oversight. A form with unusual formatting might process correctly but merits review. Extract the data, flag it for verification, and route it to a manual QA queue. The system continues operating but with appropriate caution.

## Defensive Prompt Design Against Contract Violations

Even with perfect contracts, production inputs will violate assumptions. Users will upload wrong file types, send queries in unexpected languages, or trigger edge cases you did not anticipate. Defensive prompt design adds guard rails that detect and handle violations gracefully.

Start prompts with input validation instructions: "First, verify that the input is a valid product description in English between 50 and 500 words. If not, return an error object with key: error, value describing the violation." This instruction creates a model-based validation layer that catches issues before processing.

Add output validation instructions at the end: "Before returning your response, verify it matches the required JSON schema. If not, revise your response until it complies." This creates a self-correction mechanism that reduces format violations. While not perfect, it catches many errors that would otherwise escape.

Include explicit refusal instructions for impossible tasks: "If you cannot complete this task with high confidence, return: status unable_to_process, reason explaining why." This gives the model permission to fail gracefully rather than guessing or hallucinating.

The healthcare system could have included defensive instructions like: "If OCR quality is poor and you cannot read critical fields with confidence, do not guess. Return an error indicating which fields are illegible. If multiple interpretations of a field are plausible, return the most likely interpretation with a confidence flag indicating uncertainty."

Defensive design also means anticipating adversarial inputs. Users might submit test data, deliberately malformed inputs, or injection attempts. Your contract should specify how to detect and handle these cases. Patterns that look like test data, obvious attempts to confuse the system, or inputs that violate basic sanity checks should trigger special handling.

## Contract Testing and Validation Frameworks

You cannot enforce contracts without systematic testing. Build a contract validation framework that runs before production deployment and continuously in production. This framework checks that prompts comply with their contracts across diverse inputs and scenarios.

Create test suites covering normal cases, boundary cases, and adversarial cases. Normal cases verify standard behavior meets quality thresholds. Boundary cases test input limits: maximum length, minimum length, edge values, missing fields. Adversarial cases test robustness: malformed inputs, injection attempts, nonsensical queries.

Run contract tests against every prompt change before deployment. A test suite with 200 to 500 examples per prompt provides reasonable coverage of common patterns and failure modes. Track which contract requirements each test validates so you know your coverage. Tests that pass on 95 percent of examples but fail on 5 percent indicate contract violations needing remediation.

For the healthcare system, contract testing would include: legible forms with all fields present, forms with one field missing, forms with multiple fields missing, forms with illegible handwriting, forms with mixed handwriting and typed text, forms in non-standard layouts, forms with unusual names or addresses, forms with impossible dates, and forms that are not intake forms at all.

Contract tests also validate failure modes. Test that hard failures trigger for inputs below quality thresholds. Test that soft failures return appropriate confidence scores. Test that degraded operation flags suspicious patterns. Your failure handling is as important as your success handling, and it needs equal testing rigor.

## Input Sanitization and Preprocessing

Many contract violations happen because inputs reach the model in unexpected states. User-generated text includes malicious prompts, random characters, or formatting that confuses the model. Documents include corrupted sections, mixed languages, or embedded content that breaks parsing.

Implement preprocessing pipelines that sanitize inputs before they reach the model. Remove or escape control characters, strip excessive whitespace, normalize unicode, and validate character encodings. Detect and reject inputs that appear malicious or malformed based on heuristic rules.

For document processing, use OCR quality detection, language identification, and format validation. If a scanned document has OCR confidence below 70 percent, route it to human processing rather than sending garbled text to the model. If a document is 40 percent English and 60 percent German but your contract specifies English-only, reject it or route to a multilingual system.

Preprocessing also handles format normalization. Convert various date formats to a standard format. Normalize phone numbers to a consistent structure. Standardize address formatting. This reduces the variety the model must handle and improves accuracy on the normalized inputs.

The healthcare system should preprocess forms by validating they are readable documents, running OCR with confidence scoring, detecting form structure, and normalizing field locations. Forms that fail any preprocessing step should not reach the extraction model. This separates format handling from information extraction, making both more reliable.

## Output Validation and Postprocessing

Even with defensive prompt design, models occasionally produce outputs that violate contracts. Output validation catches these violations before they reach downstream systems or users. Implement validation layers that check schema compliance, business logic rules, and safety constraints.

For structured outputs, parse JSON and validate against schemas using libraries like JSON Schema validators. Reject responses that fail validation and optionally retry with modified prompts. For text outputs, check length constraints, forbidden phrases, and format requirements using regex or NLP tools.

Implement business logic validation that checks whether outputs make sense in your domain. If you extract a birth date of January 45, 2025 from a form, validation should flag this as impossible even if it matches your date field schema. If you classify a product as both electronics and food when your contract specifies single-label classification, reject the response.

For the healthcare system, output validation would check: all required fields are present, dates are valid and in the past, ages match birth dates, phone numbers have correct digit counts, insurance policy numbers match known formats, and no fields contain obvious OCR errors like strings of random characters.

When output validation fails, you have several options. Retry with the same prompt and different temperature. Retry with a modified prompt that emphasizes the constraint that was violated. Fall back to a more conservative prompt. Escalate to human review. Your choice depends on the failure type and the cost of each option.

## Version Control and Contract Evolution

Prompts evolve over time as you refine behavior, handle new cases, or adapt to model updates. Every prompt change potentially modifies the implicit contract. Without explicit contract tracking, these changes introduce regressions where new versions break expectations that downstream systems depend on.

Version your prompts and their contracts together. When you change a prompt, update its contract specification and version number. Run contract tests against the new version to verify it maintains compatibility with existing integration points. Track breaking changes separately from non-breaking improvements.

Define semantic versioning for prompts: major version changes for breaking contract modifications, minor version changes for backward-compatible improvements, patch version changes for bug fixes. This versioning signals to downstream consumers whether they need to adapt to prompt updates or can upgrade seamlessly.

A breaking change might be modifying output schema in incompatible ways, changing input requirements, or altering failure behavior. These require major version increments and careful migration planning. Non-breaking changes might be improving accuracy within existing schema, adding optional output fields, or handling additional input variations. These can deploy without coordination.

The healthcare system would benefit from contract versioning that tracks: schema changes to extracted fields, changes to quality thresholds, changes to failure handling, and changes to input requirements. Downstream systems consuming the extracted data need to know when changes might break their parsing logic.

## Contract Monitoring in Production

Contract specifications enable sophisticated production monitoring that detects violations in real time. Instrument your application to log input characteristics, output characteristics, and contract compliance metrics. Alert when violation rates exceed thresholds.

Monitor input drift by tracking feature distributions over time. If 90 percent of inputs were 500 to 2,000 tokens last month but this month 40 percent exceed 5,000 tokens, your input distribution has shifted. This shift might violate your contract assumptions and explain quality degradation.

Monitor output compliance by validating every response against schemas and business rules. Track the percentage of responses requiring retries, the percentage flagged for review, and the percentage rejected as invalid. Trends in these metrics reveal contract violations before they cause visible failures.

For the healthcare system, contract monitoring would track: percentage of forms processed versus flagged, OCR confidence score distributions, extraction accuracy on validated samples, schema compliance rates, retry rates, and manual review escalation rates. Sudden changes in any metric indicate contract violations or input distribution shifts.

Monitoring also validates that your contract specifications remain realistic. If you specified 98 percent accuracy but production achieves only 94 percent, either your testing was unrepresentative or your contract was too aggressive. Adjust contracts to reflect achievable performance, then work to improve performance to meet more ambitious contracts.

## Contracts Enable Safe Prompt Optimization

When you optimize prompts for cost or latency, contracts provide safety rails that prevent optimizations from degrading quality below acceptable thresholds. You can aggressively compress prompts, remove examples, or simplify instructions while monitoring contract compliance to ensure changes do not break guarantees.

Run A/B tests comparing original and optimized prompts with contract validation on both variants. If the optimized prompt violates quality contracts on 8 percent of requests compared to 1 percent for the original, the optimization failed regardless of cost savings. Contracts make these trade-offs explicit and measurable.

Use contracts to define quality floors below which optimizations are rejected. A contract specifying "accuracy must not fall below 88 percent" prevents you from shipping a highly optimized prompt achieving 85 percent accuracy. This discipline ensures optimization improves efficiency without sacrificing reliability.

The healthcare system might optimize by reducing prompt length, using fewer examples, or switching to a faster model. Each optimization is validated against contracts: Does it maintain 98 percent accuracy? Does it keep hallucination below 0.2 percent? Does it preserve schema compliance? Only optimizations that meet all contract requirements deploy to production.

Optimization also includes cost targets. If your contract specifies maximum cost per extraction, you can experiment with cheaper models or shorter prompts while ensuring cost reductions do not cause quality degradation. Contracts quantify the trade-off between cost and quality, enabling informed optimization decisions.

## Documentation as Contract Specification

Your prompt contract should exist as machine-readable documentation that lives alongside the prompt itself. Use structured formats like YAML or JSON to specify inputs, outputs, guarantees, and failure modes. This documentation becomes the source of truth for validation, testing, and monitoring.

A contract specification might include: expected input schema, input validation rules, output schema, output validation rules, quality thresholds, latency thresholds, cost budgets, supported languages, supported models, failure modes and handling, version number, and change log. This information guides both human developers and automated systems.

Store contracts in version control alongside prompt code. Require contract updates for any prompt modification. Review contracts during code review to ensure changes maintain compatibility and do not introduce unhandled edge cases. Treat contract violations in production with the same severity as code bugs because they represent similar failures of specification and implementation.

For the healthcare system, the contract document would serve as the authoritative reference for all teams touching the intake feature. Developers know what inputs to expect and what outputs to handle. QA knows what to test. Operations knows what to monitor. Product knows what performance to expect. The contract aligns all stakeholders on system behavior.

Contracts also facilitate handoffs and transitions. When a new engineer takes over prompt maintenance, the contract explains what the prompt guarantees and why. When you migrate to a new model, the contract specifies what behavior must be preserved. When product requests changes, the contract makes clear what would be breaking changes requiring careful rollout.

The next subchapter examines the taxonomy of prompt failures in production and how to detect and monitor each failure type.
