# Chapter 4 — Defining Success Criteria Before You Build

"The AI should give good answers." That's the success criterion most teams start with. It's also completely useless.

Good by whose standard? Good at what cost? Good how often? Good in what contexts? Good compared to what baseline? Until you answer these questions — precisely, measurably, before you write a single prompt — you're building blind. You'll ship something, argue about whether it's working, and discover months later that engineering, product, and leadership all had different definitions of "good" the entire time.

Success criteria are the contract between what you're building and what counts as done. They're specific enough to test, realistic enough to achieve, and clear enough that everyone on the team can point to the same definition when asked "is this working?"

This chapter covers functional criteria, behavioral criteria, performance criteria, negative criteria, and the failure impact analysis that tells you what's at stake when any of them break.

---

## What This Chapter Covers

- **4.1** — The Success Criteria Gap
- **4.2** — Functional Success Criteria
- **4.3** — Behavioral Success Criteria
- **4.4** — Performance Success Criteria
- **4.5** — Negative Success Criteria: What the System Must Never Do
- **4.6** — Success Criteria by Risk Tier
- **4.7** — Quantifying Criteria: Thresholds, Targets, and Baselines
- **4.8** — Criteria That Survive Model Changes
- **4.9** — The Success Criteria Review: Getting Sign-Off Before Building
- **4.10** — Failure Impact Analysis: What Breaks If Wrong, by Tier

---

*Let's start with the gap between what teams think success looks like and what they actually wrote down.*
