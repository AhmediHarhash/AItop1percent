# 4.6 — Success Criteria by Risk Tier

In the spring of 2025, two teams at a large retail bank launched AI projects on the same day. The first team built an internal tool to help operations staff categorize incoming email requests. The second team built a credit risk assessment system that contributed to loan approval decisions. Both teams spent three weeks defining success criteria. The internal email tool team wrote a two-page criteria document with five bullet points: "generally helpful, reduces manual sorting time, accuracy around 80%, no catastrophic misrouting, team subjectively prefers it to manual sorting." The credit risk team produced a forty-seven-page criteria specification with stakeholder sign-offs from Legal, Compliance, Risk Management, and the Chief Credit Officer, detailing precision and recall thresholds for seventeen different risk categories, mandatory human review triggers, audit trail requirements, fairness metrics across protected demographic groups, and quarterly model recalibration procedures.

Six months later, both systems were still running successfully. The email categorization tool had drifted to 76% accuracy, but nobody cared because it still saved time. The credit risk system maintained 97.2% accuracy because anything below 95% triggered mandatory retraining and compliance review. The difference was not that one team worked harder or cared more. The difference was that they correctly calibrated the rigor of their success criteria to the consequences of failure.

This is the art of success criteria design in 2026: knowing when to be lightweight and when to be exhaustive. Applying the same criteria rigor to every AI system wastes time on low-stakes projects while creating risk on high-stakes ones. The solution is tiered criteria that scale with impact.

## Why Criteria Rigor Must Scale with Risk

The fundamental principle is simple: the more severe the consequences of failure, the more rigorous your success criteria need to be. Rigor in this context means specificity, measurability, stakeholder involvement, documentation, and enforcement mechanisms.

For a low-risk internal automation tool, informal criteria are sufficient because the blast radius of failure is small. If the system makes mistakes, a human notices and corrects them without significant cost. Users have context to recognize errors. Failure does not cascade into legal, financial, or safety problems. The cost of over-engineering criteria exceeds the benefit.

For a high-risk system deployed in regulated domains, informal criteria are professionally negligent. Failure can trigger compliance violations, regulatory fines, customer harm, litigation, or safety incidents. Stakeholders need documented assurance that the system was built to appropriate standards. Auditors need evidence that criteria were defined, measured, and enforced. The cost of under-engineering criteria is existential.

The challenge is that most organizations treat success criteria as a uniform practice. Every project gets the same template, the same review process, the same level of documentation. This creates two problems. Low-risk projects get slowed down by bureaucracy that adds no value. High-risk projects get approved with criteria that would not survive regulatory scrutiny because the organization has no muscle memory for rigorous criteria.

Tiered criteria solve this. You define standard criteria patterns for each risk tier, so teams know what level of rigor is expected, stakeholders know what level of review to provide, and leadership can allocate approval resources appropriately.

## Tier 1 Criteria: Low-Risk Internal Tools

Tier 1 systems are internal-facing tools with limited impact if they fail. Examples include document summarization for internal research, meeting transcription assistants, email auto-categorization for routing, or internal search improvements. These systems help employees work faster, but failure does not affect customers, revenue, compliance, or safety.

For Tier 1 systems, success criteria can be lightweight and flexible. The criteria typically consist of qualitative outcomes and approximate quantitative thresholds. A typical Tier 1 criteria set might look like: "The tool should be generally helpful to the target users. Accuracy should be in the 75-85% range. Users should prefer using the tool over the manual process. The tool should not produce catastrophically wrong outputs that create more work than it saves."

Notice what is missing: formal precision and recall metrics, signed stakeholder approvals, regulatory documentation, quarterly review processes. These are not necessary because the cost of occasional errors is low and the mitigation is simple — users can ignore bad suggestions or override the system.

Evaluation for Tier 1 can be informal. A small user study with five to ten internal employees. Spot-checking a hundred outputs manually. Collecting subjective feedback through surveys or Slack messages. The goal is to validate that the system provides value without investing months in formal evaluation infrastructure.

Sign-off for Tier 1 systems usually comes from the team lead or director level, not executive leadership. The approval question is "Does this help our team?" not "Does this meet compliance requirements?"

What happens when Tier 1 criteria are not met? Typically, the team iterates or deprioritizes the project. There is no regulatory fire drill, no incident post-mortem, no executive escalation. The low stakes make it safe to experiment and learn.

The principle for Tier 1: criteria should be just rigorous enough to prevent wasting time on systems that provide no value, but no more rigorous than that.

## Tier 2 Criteria: User-Facing, Non-Critical

Tier 2 systems face external users but do not make high-stakes decisions. Examples include customer support chatbots with human escalation, content recommendation engines, search ranking improvements, marketing copy generation, or product description assistants. These systems affect user experience and potentially revenue, but failure does not create legal liability, safety risk, or irreversible harm.

For Tier 2 systems, success criteria need structure and measurability. You cannot rely on "generally helpful" anymore because the user base is large and diverse. You need specific thresholds that define acceptable performance.

A typical Tier 2 criteria set includes quantitative thresholds, behavioral expectations, and escalation paths. For example: "The chatbot must resolve at least 60% of customer inquiries without human escalation. Response accuracy must be above 90%. The system must correctly identify when it cannot help and escalate to a human agent. Response tone must align with brand guidelines. The system must not make commitments or promises on behalf of the company."

These criteria are measurable, specific, and testable. You can build automated evaluations to verify that the 60% resolution rate and 90% accuracy thresholds are met. You can manually review a sample of interactions to verify tone and escalation behavior.

Evaluation for Tier 2 requires formal evaluation infrastructure. You need labeled test sets, automated eval pipelines, and regular quality reviews. Evaluation is not a one-time pre-launch activity — it is an ongoing monitoring practice because user behavior and edge cases evolve.

Sign-off for Tier 2 involves product leadership and domain experts. The approval question is "Does this meet our quality bar for customer-facing features?" Legal and compliance typically review to ensure no obvious risk exposure, but they are consulted, not accountable for final approval.

What happens when Tier 2 criteria are not met? The system does not ship, or it gets pulled from production if degradation is detected. There is a formal review process to understand why criteria were missed and what remediation is required. This is not a crisis, but it is not optional either.

Tier 2 criteria are reviewed quarterly or when significant changes are made to the system. Product, engineering, and domain experts revisit thresholds to ensure they still reflect business goals and user expectations.

The principle for Tier 2: criteria must be rigorous enough to ensure quality at scale and protect brand reputation, while remaining flexible enough to allow iteration and improvement.

## Tier 3 Criteria: Financial or Legal Impact

Tier 3 systems make decisions that affect financial outcomes or legal obligations. Examples include fraud detection, credit risk assessment, insurance claims processing, contract review automation, compliance monitoring, or pricing optimization. Failures in these systems can trigger direct financial loss, regulatory violations, or legal liability.

For Tier 3 systems, success criteria must be formal, comprehensive, and stakeholder-approved. The criteria document is not a team-internal artifact — it is a compliance record that may be reviewed by auditors, regulators, or legal counsel.

A typical Tier 3 criteria set includes precision and recall thresholds for critical decision paths, mandatory human review rules, audit trail requirements, fairness and bias metrics, edge case handling specifications, and model recalibration triggers. For example: "The fraud detection system must achieve a minimum precision of 95% on confirmed fraud cases to limit false positives. Recall must be at least 85% to limit missed fraud. Any transaction flagged with confidence below 80% must be reviewed by a human analyst. The system must log all decisions with full input context for audit purposes. The system must be evaluated quarterly for disparate impact across customer demographics. If precision or recall drops below threshold for two consecutive weeks, the model must be retrained and re-evaluated before continued deployment."

These criteria are exhaustive because the stakes are high. A false positive in fraud detection can freeze a legitimate customer's account, creating customer harm and potential legal exposure. A false negative lets fraud through, creating direct financial loss. Both matter.

Evaluation for Tier 3 requires robust infrastructure and documentation. You need large, representative test sets that cover edge cases and demographic segments. You need automated evaluation pipelines that run continuously. You need manual review processes for high-stakes edge cases. And you need documentation showing that all evaluations were performed, thresholds were met, and deviations were addressed.

Sign-off for Tier 3 is multi-stakeholder and formal. Legal, Compliance, Risk Management, Finance, and Product must all review and approve. Each stakeholder signs off on the aspects they own: Legal confirms no regulatory violations, Compliance confirms audit trail adequacy, Risk Management confirms acceptable failure modes, Finance confirms ROI justifies risk. Sign-off is documented with names, dates, and roles.

What happens when Tier 3 criteria are not met? The system does not ship, period. If degradation is detected post-launch, the system is disabled or put into human-review-only mode until criteria are restored. There is a formal incident review, root cause analysis, and remediation plan. Leadership is notified. If the failure creates customer impact, there may be regulatory disclosure requirements.

Tier 3 criteria are reviewed at least quarterly, and more frequently if regulations change, business context shifts, or performance degrades. The review is not casual — it is a scheduled meeting with the same stakeholders who provided original sign-off.

The principle for Tier 3: criteria must be rigorous enough to satisfy regulatory and legal scrutiny, with documentation and enforcement mechanisms that ensure compliance is not optional.

## Tier 4 Criteria: Safety-Critical and Heavily Regulated

Tier 4 systems operate in domains where failure can cause physical harm, psychological trauma, or violation of fundamental rights. Examples include medical diagnosis assistants, autonomous vehicle decision systems, content moderation for child safety, mental health support bots, or systems subject to the EU AI Act's high-risk categories. These systems have near-zero tolerance for certain failure modes and face regulatory requirements that mandate formal verification.

For Tier 4 systems, success criteria are not just comprehensive — they are subject to formal verification, third-party audit, and regulatory approval. The criteria document is a regulatory filing, not an internal product spec.

A typical Tier 4 criteria set includes zero-tolerance requirements for critical failure modes, mandatory validation against external benchmarks, independent audit requirements, continuous monitoring with automatic shutdown triggers, and regulatory compliance documentation aligned with frameworks like the EU AI Act, FDA guidelines for medical devices, or ISO 26262 for automotive safety.

For example, a medical triage assistant might specify: "The system must achieve a sensitivity of 99.5% for life-threatening conditions to ensure no critical cases are missed. Any case classified as non-urgent must be reviewed by a licensed healthcare provider before patient dismissal. The system must be validated against an independent test set of 10,000 real-world cases reviewed by board-certified physicians. The system must undergo quarterly third-party audit by an accredited medical AI auditor. If sensitivity drops below 99.5% or more than two critical misclassifications occur in a rolling 30-day window, the system automatically escalates all cases to human triage until recertified. All criteria validation and monitoring data must be available for regulatory inspection."

These criteria are not negotiable. They reflect legal requirements, ethical obligations, and professional standards in safety-critical domains.

Evaluation for Tier 4 requires the most rigorous infrastructure in AI product development. Independent test sets validated by domain experts. Continuous monitoring with real-time alerting. Third-party audits conducted by credentialed external evaluators. Documentation packages that can withstand regulatory review.

Sign-off for Tier 4 includes all Tier 3 stakeholders plus external validators. A medical AI system requires sign-off from physicians, medical ethicists, and potentially regulatory bodies depending on jurisdiction. An autonomous driving system requires sign-off from safety engineers, legal, and potentially transportation authorities. Sign-off is not just internal consensus — it is demonstrable compliance with external standards.

What happens when Tier 4 criteria are not met? The system is immediately disabled. Not "put in review mode" or "escalated for decision" — shut down. There is a formal incident investigation, regulatory notification if required, public disclosure if the failure created harm, and a recertification process before the system can be re-enabled.

Tier 4 criteria are reviewed continuously, not quarterly. Any change to the system — model upgrade, data pipeline change, interface modification — triggers a review to ensure criteria are still met. Regulations evolve, and criteria must evolve with them. The EU AI Act, which took effect in 2026, introduced new requirements for high-risk AI systems including transparency, human oversight, and robustness standards. Any Tier 4 system operating in EU jurisdiction must update criteria to reflect these requirements.

The principle for Tier 4: criteria must satisfy the highest standards of safety, ethics, and regulatory compliance, with enforcement mechanisms that prevent any deviation from approved operation.

## The Tier Transition: When Systems Move Between Tiers

One of the most common mistakes in criteria planning is failing to account for tier changes over time. A system that starts as Tier 1 can migrate to Tier 2 or Tier 3 as it scales, expands scope, or shifts use cases. When that happens, your success criteria must be upgraded to match the new risk profile.

Consider a chatbot that starts as an internal customer service training tool. It helps new agents practice responses in a simulated environment. This is clearly Tier 1 — low risk, internal users, no real customer impact. Criteria are lightweight: "generally helpful for training, provides reasonable example responses, agents find it useful."

The tool is so successful that the team proposes deploying it as a customer-facing assistant with human escalation. Now it is Tier 2. The criteria must be upgraded to include accuracy thresholds, escalation behavior, brand tone alignment, and regular quality monitoring. The informal evaluation from Tier 1 is insufficient for Tier 2 deployment.

Two years later, the business wants to expand the chatbot to handle account changes and transaction requests. Now the chatbot is making decisions with financial impact. This is Tier 3. Criteria must be upgraded again to include formal approval processes, audit trails, compliance documentation, and stricter accuracy requirements.

The tier transition is a re-framing moment. You must revisit every aspect of your success criteria, evaluation approach, stakeholder involvement, and enforcement mechanisms. Teams often resist this because it feels like bureaucracy, but the alternative is deploying a Tier 3 system with Tier 1 criteria — a recipe for compliance failure or customer harm.

The sign that you need to upgrade criteria rigor: your system's failure modes now have consequences that were not present when you originally defined criteria. If failure can now affect customers, money, compliance, or safety in ways it could not before, your criteria must evolve.

## Practical Implementation: The Criteria Rigor Checklist

To operationalize tiered criteria, use this checklist to determine what level of rigor applies to your system:

**Tier 1 Indicators**: Internal users only, no customer impact, failures create minor inconvenience, users have full context to recognize errors, no financial or legal implications, no regulated data processing.

**Tier 2 Indicators**: External users, affects user experience or satisfaction, failures create frustration or minor inconvenience, potential brand impact, no direct financial or legal consequences, human escalation available.

**Tier 3 Indicators**: Decisions affect financial outcomes, regulatory compliance requirements apply, failures can create legal liability or financial loss, processed data subject to privacy regulations, stakeholder sign-off required for deployment.

**Tier 4 Indicators**: Potential for physical or psychological harm, subject to safety regulations, operates in medical/automotive/other heavily regulated domains, failures can violate fundamental rights, regulatory approval required for deployment.

For each tier, the checklist guides you to the appropriate criteria elements:

**Tier 1**: Qualitative outcomes, approximate thresholds, informal evaluation, team-level approval.

**Tier 2**: Quantitative thresholds, behavioral specifications, automated evaluation infrastructure, product and domain expert sign-off, quarterly review cadence.

**Tier 3**: Formal thresholds with rationale, mandatory human review rules, compliance documentation, multi-stakeholder approval, audit trail requirements, quarterly or event-driven review.

**Tier 4**: Zero-tolerance requirements, external validation, independent audit, regulatory documentation, continuous monitoring, automatic shutdown triggers, ongoing review and regulatory alignment.

## Why Mismatched Criteria Create Risk

Under-rigorous criteria for high-risk systems is the obvious danger — deploying a Tier 3 system with Tier 1 criteria is negligent. But over-rigorous criteria for low-risk systems is also a problem. It slows down innovation, wastes resources on low-impact projects, and trains teams to treat all criteria as bureaucratic box-checking rather than genuine quality gates.

When you apply Tier 3 rigor to a Tier 1 internal tool, you create several problems. The project takes three months instead of three weeks, engineering spends more time on criteria documentation than building features, stakeholders get approval fatigue and stop paying attention, and teams start gaming the criteria process to reduce overhead. The result is a culture where criteria are seen as obstacles, not value.

When you apply Tier 1 rigor to a Tier 3 system, you create existential risk. The system ships without adequate evaluation, failures are not monitored, degradation is not detected, and eventually something breaks with real consequences — customer harm, regulatory violation, financial loss, public incident. The cost of the shortcut is paid with interest later.

The discipline of tiered criteria is matching precision to consequences. High-stakes systems get high-rigor criteria because the cost of failure justifies the investment in thoroughness. Low-stakes systems get low-rigor criteria because speed and learning matter more than perfection.

## The 2026 Context: Regulatory Pressure on High-Risk Systems

The regulatory landscape in 2026 makes tiered criteria more important than ever. The EU AI Act categorizes AI systems into risk levels and imposes requirements accordingly. High-risk systems — those affecting safety, fundamental rights, or critical infrastructure — must meet transparency, documentation, and human oversight requirements. Deploying a high-risk system without appropriate criteria and governance can trigger regulatory penalties.

This means Tier 3 and Tier 4 criteria are not just internal best practices — they are compliance requirements. Organizations operating in regulated industries or jurisdictions must demonstrate that their success criteria, evaluation processes, and monitoring systems meet regulatory standards.

The practical implication: if your system falls into a regulated high-risk category, your criteria must be designed with regulatory scrutiny in mind. They must be documented, measurable, enforced, and auditable. Informal criteria will not survive a compliance review.

Conversely, low-risk systems benefit from regulatory clarity. If your system is clearly Tier 1 or Tier 2, you can confidently apply lightweight criteria without worrying that you are missing a compliance obligation. The tier framework helps you allocate rigor where it is required and avoid it where it is not.

## Connecting Criteria Rigor to Evaluation Strategy

Tiered criteria naturally lead to tiered evaluation strategies, which we will explore in detail in Section 3. The rigor of your criteria determines the sophistication of your evaluation infrastructure.

Tier 1 systems can be evaluated with small user studies, spot checks, and qualitative feedback. Tier 2 systems need automated evaluation pipelines, labeled test sets, and regular monitoring dashboards. Tier 3 systems require comprehensive test coverage, continuous monitoring, audit trails, and formal review cycles. Tier 4 systems demand independent validation, third-party audits, and real-time safety monitoring.

The criteria tier is the input, and the evaluation tier is the output. When you define Tier 3 criteria, you commit to building Tier 3 evaluation infrastructure. When you accept Tier 1 criteria, you accept Tier 1 evaluation constraints.

This connection prevents the common mistake of defining ambitious criteria that you have no plan to measure. If your criteria specify 95% precision but you have no evaluation infrastructure to measure precision reliably, your criteria are aspirational fiction, not operational guidance.

The success criteria tier must match the evaluation investment you are willing to make. If you are not willing to invest in formal evaluation infrastructure, you cannot credibly commit to formal criteria.

Having established how criteria rigor scales with risk, the next question is how to turn qualitative expectations into quantitative targets — the practice of defining baselines, thresholds, and targets that convert vague goals into measurable gates.
