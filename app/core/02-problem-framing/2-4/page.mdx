# 2.4 — Decomposing Agentic Workflows

The fintech startup had built something genuinely impressive: an AI agent that could analyze financial documents, extract key data, cross-reference it with market information, generate investment summaries, and produce formatted reports—all without human intervention.

The founder demoed it to investors. He uploaded a 10-Q filing from a public company. The agent read it, identified revenue figures and risk factors, pulled current stock prices and analyst ratings from financial APIs, generated a three-page summary with charts, and exported it as a PDF. Start to finish: 45 seconds.

Investors loved it. They funded a $5 million Series A.

Three months later, the company had a crisis. A client uploaded an earnings report. The agent misread a table, calculated revenue growth as negative 40% instead of positive 15%, called an API with the wrong ticker symbol, retrieved data for a completely different company, generated a report saying the company was in financial distress, and emailed it to the client's entire investment committee before anyone could stop it.

The client lost trust. They canceled their contract. Two other clients heard about it and left too.

What happened? The agent had worked perfectly in controlled demos. But in production, with messy real-world inputs and cascading decisions, it failed catastrophically. And the team couldn't debug it because they'd built it as one monolithic "agent" without decomposing it into testable sub-problems.

Agents are the hardest systems to build because they make decisions. Each decision creates a branch point. Each branch point multiplies the possible paths through the system. If you don't decompose agents into sub-problems with clear boundaries, you end up with an untraceable black box that works in demos and fails in production.

## What Makes Agents Different

Let me start by defining what makes agentic workflows fundamentally different from other AI systems.

Non-agentic systems are reactive. You give them input, they produce output. The path from input to output is fixed. A RAG system always does: query understanding, retrieval, ranking, synthesis. The order is predetermined.

Agentic systems are autonomous. They decide what to do based on the situation. Given a goal, they plan a sequence of actions, execute them, observe the results, and adjust the plan accordingly.

That autonomy creates complexity. The agent might:
- Choose tool A in one scenario, tool B in another
- Call the same tool multiple times with different parameters
- Decide mid-execution that the plan isn't working and change strategy
- Encounter an error and choose whether to retry, skip, or abort
- Reach a state where it doesn't know what to do next

Each of these decision points is a sub-problem. And if you haven't decomposed them, you can't evaluate them, debug them, or improve them.

## The Seven Core Sub-Problems In Agents

Every agentic workflow has at least seven sub-problems. Let me walk through each one.

Sub-problem one: Planning. Given a goal, what sequence of steps should the agent take? This is strategic reasoning. The user says: "Analyze this company's financial health." The agent must plan: read the filing, extract financial metrics, retrieve market data, compare to industry benchmarks, synthesize findings, generate report.

Planning can fail in multiple ways: the plan might be incomplete (missing a necessary step), inefficient (taking unnecessary steps), or impossible (trying to use a tool that doesn't exist).

Sub-problem two: Tool selection. At each step of the plan, which tool should the agent use? If the step is "retrieve market data," should it call the stock price API, the analyst ratings API, the SEC filings API, or all three?

Tool selection depends on: what information is needed, what tools are available, what the tool capabilities are, and what the current context is.

Sub-problem three: Tool execution. Calling the selected tool with the correct parameters. This isn't just invoking a function. It's: constructing the API request, formatting parameters correctly, handling authentication, managing rate limits, and dealing with timeouts.

Tool execution can fail due to: incorrect parameters, API errors, network issues, permission problems, or malformed requests.

Sub-problem four: Result interpretation. The tool returned something. What does it mean? If the stock price API returned "AAPL: 182.45," the agent needs to interpret: this is Apple Inc., current price is $182.45, currency is USD, timestamp is now.

Result interpretation requires: parsing the response format, extracting relevant fields, understanding the semantics, and converting to internal representation.

Sub-problem five: Error recovery. Something went wrong. The API returned an error, the data was malformed, or the result contradicted expectations. What should the agent do?

Options include: retry with the same parameters, retry with modified parameters, try a different tool, skip this step and continue, abort the entire workflow, or escalate to a human.

Error recovery is the sub-problem that separates robust agents from brittle ones.

Sub-problem six: State management. The agent is partway through a multi-step workflow. What has been done? What information has been gathered? What's left to do? State management tracks: completed steps, pending steps, gathered data, intermediate results, and decision history.

Without proper state management, the agent might: repeat steps unnecessarily, forget information it already retrieved, or lose track of where it is in the plan.

Sub-problem seven: Termination. When is the task complete? This sounds simple but it's not. The agent must recognize: the goal has been achieved, or the goal is unachievable with available tools, or the workflow has exceeded time/cost budgets.

Agents that don't handle termination properly either: stop too early (incomplete results) or run forever (infinite loops, repeated retries, escalating costs).

Each of these is a distinct sub-problem with its own inputs, outputs, failure modes, and evaluation criteria. If you build an agent without decomposing these, you can't tell which one failed when something goes wrong.

## Why Each Sub-Problem Needs Independent Evaluation

Let me show you why independent evaluation matters, using the fintech agent failure as an example.

The agent failed. But where? Let's trace through the sub-problems:

Planning: Did the agent plan the right steps? Check the plan. It says: extract revenue from document, retrieve stock price, compare to historical data, generate summary. The plan looks reasonable.

Tool selection: Did it pick the right tools? Check the tool selection log. It chose the table extraction tool for revenue. Correct. It chose the stock price API. Correct.

Tool execution: Did it call the tools correctly? Check execution logs. For table extraction, it sent the correct page of the PDF. For stock price API, it sent ticker "XYZ" instead of "ABC." Error found.

But why did tool execution get the wrong ticker? Go back one level.

Result interpretation: After extracting the revenue table, did it correctly interpret the company ticker? Check the interpretation log. The table extraction returned "XYZ Corp (ABC)" but the agent parsed only "XYZ" as the ticker. Interpretation failure.

Now you know: the root cause is result interpretation for the table extraction step. The parser extracted the company name instead of the ticker symbol.

That's a specific, fixable bug. Improve the parsing logic to prioritize ticker symbols in parentheses.

Without decomposition, you'd just see: "The agent produced a wrong report." You wouldn't know if it was planning, tool selection, execution, interpretation, or something else. You'd guess, patch the prompt, and hope.

## Planning: The First Sub-Problem

Let's decompose each sub-problem in detail, starting with planning.

Planning is: given a goal and available tools, determine the sequence of actions to achieve the goal.

There are multiple planning strategies:

Strategy one: Upfront planning. The agent creates a complete plan before executing any steps. "First I'll do A, then B, then C." Pro: You can validate the plan before starting. Con: Plans often need adjustment based on intermediate results.

Strategy two: Step-by-step planning. The agent plans one step, executes it, observes the result, then plans the next step. Pro: Adaptive to intermediate outcomes. Con: Can't optimize across steps or detect circular paths upfront.

Strategy three: Hierarchical planning. The agent creates a high-level plan with sub-goals, then plans each sub-goal in detail. Pro: Handles complex tasks. Con: More complex to implement and debug.

The fintech agent used upfront planning. It worked in demos with clean inputs but failed with messy real-world documents because the plan didn't adapt when table extraction returned ambiguous data.

They should have used step-by-step planning: extract table, interpret results, validate ticker symbol, then plan next steps based on whether validation succeeded.

Planning evaluation asks: Is the plan valid? Is it complete? Is it efficient? Can you simulate execution without actually executing to find flaws?

## Tool Selection: The Second Sub-Problem

Tool selection is: given the current step in the plan and available tools, choose which tool to use.

This requires the agent to understand: what each tool does, what inputs it requires, what outputs it produces, and what its reliability is.

Tool selection can be rule-based: "If the step is 'get stock price,' always use the stock price API." Or it can be learned: the agent observes which tools work best for which tasks and selects accordingly.

The fintech agent had a rule-based tool selector. The rule was: "For market data, use API X." But API X had different endpoints for different data types: one for stock prices, one for analyst ratings, one for company financials. The rule didn't specify which endpoint, so the agent sometimes called the wrong one.

Tool selection needs to be more granular: not just which API, but which endpoint, which parameters, which authentication method.

Tool selection evaluation asks: Did the agent choose a tool capable of accomplishing the step? Were there better alternatives? How often does tool selection lead to execution failures?

## Tool Execution: The Third Sub-Problem

Tool execution is: call the selected tool with the correct parameters and handle the response.

This is where theory meets reality. The tool has an API. That API has: required parameters, optional parameters, authentication requirements, rate limits, error codes, and response formats.

Tool execution must:
- Construct a valid request (right format, right parameters, right headers)
- Handle authentication (API keys, tokens, OAuth flows)
- Manage rate limits (backoff if rate limited, queue requests if necessary)
- Handle timeouts (retry with exponential backoff or fail gracefully)
- Parse responses (successful or error)

The fintech agent failed at parameter construction. It extracted "XYZ" as the ticker, passed it to the API, and the API returned data for XYZ instead of ABC. The API call succeeded—wrong ticker, but syntactically valid.

Tool execution validation should have caught this: before sending the ticker to the API, validate it against a known list of tickers or fuzzy-match against the company name.

Tool execution evaluation asks: Are requests well-formed? Do error rates correlate with specific tools or parameters? Are retries effective?

## Result Interpretation: The Fourth Sub-Problem

Result interpretation is: parse the tool's response and extract the relevant information in a usable format.

APIs return data in structured formats—JSON, XML, CSV. The agent must:
- Parse the format correctly
- Extract the relevant fields
- Validate that the data makes sense
- Convert to internal representation

The fintech agent parsed the stock price response but didn't validate it. It received a price for XYZ and used it without checking: does this match the company we're analyzing?

Result interpretation needs validation: after retrieving stock price for ticker XYZ, cross-check—did we expect XYZ or did we expect ABC? If mismatch, flag an error.

Advanced result interpretation also includes: handling missing fields (what if the API doesn't return analyst ratings?), handling unexpected formats (what if the API changed its response schema?), and detecting anomalies (what if the stock price is 0?).

Result interpretation evaluation asks: Are responses parsed correctly? Are all necessary fields extracted? Are anomalies detected?

## Error Recovery: The Fifth Sub-Problem

Error recovery is: something went wrong, now what?

Errors happen constantly in agentic workflows:
- APIs return errors (rate limit, timeout, server error)
- Responses are malformed (invalid JSON, missing fields)
- Results are semantically invalid (negative stock price, future date)
- Tools are unavailable (network failure, service down)

The agent needs a recovery strategy for each error type.

For rate limits: wait and retry.
For timeouts: retry with exponential backoff, up to N attempts.
For malformed responses: try parsing with a fallback parser, or skip and continue.
For semantic invalidity: flag for human review or abort.
For unavailable tools: try an alternative tool or mark step as failed.

The fintech agent had no error recovery. When the table extraction tool returned ambiguous data, it proceeded anyway. When it should have detected "ticker mismatch" as an error, it didn't.

Proper error recovery would: detect that the ticker symbol was ambiguous (multiple companies mentioned), escalate to request clarification or use a validation step.

Error recovery evaluation asks: What percentage of errors are recovered successfully? How often does recovery lead to correct outcomes vs. cascading failures?

## State Management: The Sixth Sub-Problem

State management is: tracking what the agent has done and what it knows.

Agents execute multi-step workflows. At any point, the agent needs to know:
- What steps have been completed
- What information has been gathered
- What decisions have been made
- What the current goal is
- What sub-goals are pending

State can be stored as: a simple list of completed steps, a key-value store of gathered data, a graph of dependencies and completions, or a full execution trace.

The fintech agent stored state as a sequence of tool calls. When it needed to reference earlier data—like the company name from the initial document—it re-parsed the document instead of retrieving from state.

Efficient state management stores intermediate results: after extracting the company name once, store it. After retrieving stock price, store it. Don't re-fetch.

State management also enables: checkpointing (save state periodically so you can resume after failure), rollback (undo the last N steps if they led to an error), and debugging (inspect state to understand what the agent was thinking).

State management evaluation asks: Is state maintained correctly across steps? Can workflows resume after interruption? Is state storage efficient?

## Termination: The Seventh Sub-Problem

Termination is: deciding when the workflow is complete.

There are three termination conditions:

Condition one: Goal achieved. The agent completed all steps and produced the desired output. Success.

Condition two: Goal unachievable. The agent tried available tools, encountered insurmountable errors, and cannot complete the task. Graceful failure.

Condition three: Resource limits exceeded. The workflow exceeded time budget, cost budget, or step budget. Forced termination.

The fintech agent had only one termination condition: "plan is complete." If the plan was "extract, retrieve, generate," and all three steps executed (even if they executed incorrectly), the agent terminated with "success."

It should have had validation-based termination: after generating the report, validate that key metrics are present and plausible. If revenue is negative, if ticker mismatches company name, flag for review instead of terminating.

Termination evaluation asks: Does the agent correctly identify success vs. failure? Does it avoid infinite loops? Does it respect resource budgets?

## The Sub-Problem That Makes Agents Debuggable

Here's the insight: decomposition makes agents debuggable.

Agents are complex. They have dozens of decision points. If you treat the agent as one black box, debugging means: stare at the final output, guess what went wrong, change the prompt, hope it improves.

If you decompose into sub-problems, debugging means: inspect logs for each sub-problem, identify which one failed, understand why, fix that specific component.

The fintech agent should have had logs like:

- Planning: Planned 5 steps: extract_table, interpret_data, get_stock_price, compare_trends, generate_report
- Tool selection (step 1): Selected tool 'pdf_table_extractor'
- Tool execution (step 1): Called pdf_table_extractor with params page=3, table_index=0
- Result interpretation (step 1): Extracted company='XYZ Corp (ABC)', revenue='$2.3B'
- Error: Ambiguous ticker symbol detected: 'XYZ' vs 'ABC'. Requires validation.
- Error recovery: No recovery strategy defined. Proceeding with 'XYZ'.
- Tool selection (step 3): Selected tool 'stock_price_api'
- Tool execution (step 3): Called stock_price_api with ticker='XYZ'
- Result interpretation (step 3): Received price=$45.20 for XYZ. Warning: ticker mismatch with expected company.

With logs like that, you see exactly where it went wrong: result interpretation extracted two potential tickers but didn't validate which was correct. Error recovery didn't catch it. Tool execution proceeded with the wrong ticker.

Fix: add ticker validation to result interpretation. Add ticker mismatch detection to error recovery.

## The 2026 Context: Multi-Agent Orchestration

In 2026, agents don't just use tools—they coordinate with other agents.

Multi-agent patterns include:

Pattern one: Sequential delegation. Agent A completes a task, hands off to Agent B for the next task. Like an assembly line.

Pattern two: Parallel collaboration. Multiple agents work on sub-tasks simultaneously, then combine results.

Pattern three: Hierarchical orchestration. A supervisor agent delegates tasks to specialist agents, monitors progress, and integrates outputs.

Each pattern adds new sub-problems:

Agent-to-agent communication: How do agents pass information? What protocol do they use?

Task decomposition and delegation: How does the supervisor agent decide which tasks to delegate to which specialist agents?

Conflict resolution: What happens when two agents produce contradictory results?

Synchronization: How do agents coordinate timing when one depends on another's output?

The fintech startup evolved their agent into a multi-agent system: one agent for document extraction, one for market data retrieval, one for analysis, one for report generation. A supervisor agent orchestrated them.

New sub-problems emerged: the extraction agent sometimes finished before the market data agent was ready, so state management needed synchronization. The analysis agent sometimes received incomplete data from the market data agent, so error recovery needed cross-agent validation.

Multi-agent systems are more powerful but exponentially more complex. Decomposition becomes even more critical.

## Tool Chains: Composed Agentic Actions

Another 2026 pattern: tool chains. Instead of the agent calling tools individually, tools are pre-composed into chains that execute atomically.

Example: "Get financial summary" is a tool chain that combines: fetch_document → extract_tables → interpret_data → validate_ticker. The agent calls the chain as a single tool.

This simplifies planning (one step instead of four) but moves complexity into the tool chain itself. Now the tool chain needs internal error recovery, state management, and termination logic.

Tool chains add a new sub-problem: chain composition. How do you design chains that are reusable, composable, and maintainable?

## OWASP Agentic AI Security Concerns

Here's the security dimension: agents make autonomous decisions, which creates risk.

OWASP's Agentic AI Security project identifies two critical concerns:

Concern one: Excessive agency. The agent has more permissions than necessary. It can call tools it shouldn't have access to, modify data it shouldn't change, or escalate privileges beyond its intended scope.

Concern two: Privilege escalation. The agent manipulates tool sequences to gain higher privileges. Example: it uses a "read user data" tool to find admin credentials, then uses an "update permissions" tool to grant itself admin access.

Decomposition helps mitigate these risks:

Tool selection becomes a security boundary. Before selecting a tool, check: does the agent have permission to use this tool in this context?

Tool execution becomes a security boundary. Before calling a tool, validate: are the parameters within acceptable ranges? Does this action require additional authorization?

State management becomes a security boundary. Audit: what permissions has the agent used? What sensitive data has it accessed? Is there a suspicious pattern?

The fintech agent had no security decomposition. It could call any financial API, retrieve any company's data, and generate reports without access control. If it had been deployed in a multi-tenant environment, it could have accessed competitors' data.

Proper decomposition adds permission checking at tool selection and execution. Each sub-problem enforces security constraints.

## What You Should Do Differently

If you're building an agentic system, decompose it into the seven core sub-problems: planning, tool selection, tool execution, result interpretation, error recovery, state management, and termination.

For each sub-problem, define:
- Inputs and outputs
- Success criteria
- Failure modes
- Evaluation metrics
- Security constraints

Build independent evaluation for each sub-problem. Don't just test end-to-end workflows. Test: planning quality, tool selection accuracy, execution error rates, interpretation correctness, recovery success rates, state consistency, termination appropriateness.

Log at sub-problem boundaries. When debugging, you should be able to trace: what was planned, what tool was selected, how it was executed, how results were interpreted, what errors occurred, how they were recovered, what state was maintained, and why termination happened.

Implement error recovery explicitly. Don't assume the LLM will handle errors gracefully. Define recovery strategies for each error type.

Add security boundaries. Validate permissions at tool selection and execution. Audit agent actions. Limit privilege escalation.

If you're already in production with an agent, retrofit decomposition. Add logging, metrics, and evaluation for each sub-problem. Identify which sub-problem has the highest failure rate. Focus improvements there.

## The Competitive Advantage

Agents are the frontier of AI systems. They're more powerful than single-turn or multi-turn systems because they can accomplish complex, multi-step goals autonomously.

They're also harder to build. Most teams that try agents end up with unreliable systems that work in demos and fail in production.

The teams that win are the ones who decompose agents into sub-problems, evaluate each sub-problem independently, and build systems they can actually debug.

Agents without decomposition are black boxes. Agents with decomposition are maintainable, improvable, and trustworthy.

That's not just an engineering advantage. It's a product advantage. Users trust agents that fail gracefully and transparently. They don't trust agents that fail mysteriously.

Decomposition turns mysterious failures into understandable ones. And understandable failures are fixable.

If you're building agents, decompose first. It's the difference between shipping a demo and shipping a product.

This completes our journey through problem decomposition. We've seen how business goals decompose into user tasks, AI capabilities, and technical sub-problems. We've seen how single-turn and multi-turn systems require different decomposition strategies. We've seen how retrieval-augmented systems hide five sub-problems inside one interface. And we've seen how agentic workflows multiply complexity through autonomous decision-making.

The pattern is consistent: decompose before you build. Understand the sub-problems. Define their boundaries. Evaluate them independently. That's how you ship AI products that work in production, not just in demos.

In the next chapter, we'll shift from decomposition to another critical framing skill: understanding the difference between classification, generation, and reasoning tasks, and why mixing them up leads to systems that fail in subtle, dangerous ways.
