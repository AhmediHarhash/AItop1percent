# 1.9 — Stakeholder Map and Decision Rights

In late 2025, a Fortune 500 insurance company kicked off an ambitious project to build an AI-powered claims processing system. The engineering team spent six weeks framing the problem, defining success metrics, and scoping the initial deployment. They produced a stellar framing document that covered task taxonomy, failure modes, evaluation criteria, and constraints. The team presented it to leadership with confidence. Two days later, the VP of Legal sent an email with a single line: "We cannot process any claims without human review under our current regulatory framework." The entire framing had to be redone. The issue was not that the team did bad work — they did excellent work. The issue was that Legal was never in the room when the problem was being framed.

This is the most common and most expensive mistake in AI problem framing: treating it as a purely technical exercise. Framing is a **stakeholder alignment exercise** disguised as a technical document. Every line in your framing doc represents a decision, and every decision has an owner. If you do not know who has the authority to approve what you are proposing, you are not framing a problem — you are writing fiction.

This subchapter covers the stakeholder map for AI problem framing, who owns which decisions, and how to run the alignment process that ensures your framing work actually ships.

## The Stakeholder Map: Who Owns What in AI Problem Framing

In traditional software, you can often get away with a small team making technical decisions and escalating to product only when scope changes. In AI systems, the stakeholder surface is much wider because AI touches parts of the organization that classical software does not. A recommendation system influences revenue. A support bot represents your brand voice. A risk model triggers compliance reviews. A RAG system processes customer data under privacy regulations.

Here is the stakeholder map for AI problem framing in 2026. Each stakeholder has a distinct role, and each role has specific decision rights that must be respected for framing to succeed.

**Product** defines **what** to build. They own the problem definition, the business goals, the user outcomes, and the prioritization. Product answers questions like: What problem are we solving? For whom? Why now? What does success look like from the user perspective? Which use cases are in scope for v1 versus v2? Product does **not** decide how the system will work technically, but they do decide whether the proposed approach aligns with the user experience and business model. If your framing says "we will build a chatbot that requires users to type structured queries," product needs to approve that UX constraint.

**Engineering** defines **how** to build. They own the architecture, the technical feasibility, the implementation plan, and the resource estimates. Engineering answers questions like: Is this problem solvable with current technology? What are the trade-offs between different approaches? How long will this take? What infrastructure do we need? Engineering does **not** decide what problem to solve, but they do have veto power on infeasible framings. If your framing requires real-time inference on a billion-parameter model with 100ms latency, engineering will tell you that is not happening without a reframe.

**Domain Experts** define what **correct** looks like. They own the ground truth, the quality bar, the edge cases, and the failure modes. Domain experts are the people who currently do the work you are trying to automate or augment. If you are building a legal document review system, your domain experts are lawyers. If you are building a radiology assistant, your domain experts are radiologists. They answer questions like: What does a good answer look like? What are the mistakes we cannot tolerate? What context is required to make this decision? Domain experts are **critical** in AI framing because they define the eval criteria that your system will be judged against. If you do not involve them early, you will build a system that passes your metrics but fails their quality bar.

**Legal and Compliance** define the **constraints**. They own the regulatory boundaries, the data handling rules, the risk appetite, and the audit requirements. Legal answers questions like: Can we use this data for training? Can we deploy this system without human review? Do we need opt-in consent? What happens if the system makes a mistake? In 2026, legal and compliance are not optional stakeholders — they are mandatory. The EU AI Act is in effect, covering high-risk systems. GDPR and CCPA govern data use. Industry-specific regulations like HIPAA, SOX, and PCI-DSS apply to many AI deployments. If legal is not in the framing conversation, you will waste months building something that cannot ship.

**Leadership** defines **priorities and resources**. They own the business case, the budget, the headcount, and the strategic alignment. Leadership answers questions like: Why are we doing this now instead of other projects? How much can we spend? What is the expected ROI? What is the risk if this fails? Leadership does **not** micromanage the framing details, but they do set the boundary conditions that make a framing viable or not. If your framing requires hiring ten engineers and leadership only approved two, you need to reframe.

**Users** define **value**. This is the most overlooked stakeholder in AI framing. Users are not in your framing meetings, but they are the ultimate decision-makers. If users do not adopt the system, it does not matter how good your framing was. Users answer questions like: Does this solve a problem I actually have? Is this easier than the current workflow? Do I trust this system? Can I understand why it made this decision? You involve users through research, interviews, usability testing, and beta programs. If your framing does not include a plan to validate with real users, you are guessing.

## Decision Rights: Who Has Final Say on What

Having a stakeholder map is not enough. You also need **decision rights**: explicit clarity on who has the final say when stakeholders disagree. Without decision rights, framing becomes a negotiation with no clear winner, which usually means the loudest voice or the highest title wins — not the best idea.

Here are the key decision points in AI problem framing and who typically owns them.

**Scope**: Product has final say. Engineering and domain experts provide input on feasibility and quality, but product decides what is in scope for v1, what is deferred, and what is a non-goal. If product says "we need to support ten languages in v1," engineering cannot override that — but engineering can flag the cost and timeline implications, which may cause product to reconsider.

**Success Criteria**: Domain experts have final say. Product defines the business metrics, but domain experts define what "correct" means. If you are building a fraud detection system, the fraud team decides what precision and recall thresholds are acceptable. If you are building a code assistant, engineers decide what "helpful" means. Product cannot say "we will ship with 60% accuracy" if domain experts say "anything below 80% is dangerous."

**Constraints**: Legal and compliance have final say. Product, engineering, and domain experts can debate latency, cost, and UX constraints all day, but if legal says "you cannot deploy this without human review," that constraint is non-negotiable. Legal does not have veto power over the entire project, but they do have veto power over approaches that violate regulations or create unacceptable risk.

**Trade-offs**: This is where it gets messy. Trade-offs require negotiation across stakeholders. If you cannot meet the latency constraint without blowing the cost budget, who decides whether to relax latency or increase budget? The answer depends on the trade-off. Latency versus cost is usually a product decision with input from leadership. Quality versus cost is usually a domain expert decision with product approval. Security versus UX is usually a shared decision between product and legal. The key is to **escalate trade-offs explicitly** rather than letting one stakeholder quietly make the call.

**RACI for Framing Decisions**

RACI is a simple framework for clarifying decision rights. For each decision, you assign four roles: Responsible (who does the work), Accountable (who has final say), Consulted (who provides input), Informed (who needs to know). Here is a sample RACI for AI problem framing.

| Decision | Responsible | Accountable | Consulted | Informed |
|----------|-------------|-------------|-----------|----------|
| Problem definition | Product | Product | Engineering, Domain Experts, Users | Leadership |
| Task taxonomy | Engineering | Engineering | Domain Experts, Product | Leadership |
| Success metrics | Domain Experts | Domain Experts | Product, Engineering | Leadership, Legal |
| Constraints | Legal/Compliance | Legal/Compliance | Product, Engineering | Leadership |
| Architecture approach | Engineering | Engineering | Product, Domain Experts | Leadership |
| Resource estimate | Engineering | Leadership | Product | Legal |
| Prioritization | Product | Leadership | Engineering, Domain Experts | Legal |

This is not a universal RACI — it depends on your organization. The point is to **make it explicit** before you start framing. If you do not know who is Accountable for success metrics, you will discover it the hard way when stakeholders disagree after you have already done the work.

## Common Failure Mode: Everyone Has Input, Nobody Has Authority

The worst framing meetings are the ones where ten people sit in a room, everyone shares their opinion, and no one makes a decision. You walk out with a long list of concerns and zero clarity on what to do. This happens when decision rights are unclear.

The symptom looks like this: Product says "we need this feature." Engineering says "that is too expensive." Domain experts say "that will not work." Legal says "we need to review it." Leadership says "we need to ship faster." Everyone is right. Everyone is also stuck.

The fix is to assign a **Directly Responsible Individual** for the framing exercise. This is the person who owns the framing document, runs the stakeholder meetings, and escalates trade-offs when consensus is not possible. In most organizations, this is a senior engineer or a technical product manager. The DRI does not have final say on every decision, but they do have the authority to **force decisions** by escalating to the right Accountable party.

For example, if product and engineering disagree on scope, the DRI escalates to leadership. If domain experts and product disagree on success metrics, the DRI escalates to the domain expert with product providing a business case for why the bar should be lower. If legal and product disagree on constraints, the DRI escalates to the chief legal officer and the chief product officer. The DRI is the person who prevents framing from becoming an endless debate.

## The Two-Pizza Rule for Framing Teams

Jeff Bezos famously said that any team should be small enough to be fed with two pizzas. The same principle applies to framing teams. If you have more than eight people in your framing meetings, you have too many. Large groups produce diffuse accountability, slow decisions, and watered-down framings that try to make everyone happy.

The ideal framing team is four to six people: one product lead, one engineering lead, one domain expert, one legal or compliance representative, and optionally one design or UX lead. That is it. Everyone else is Consulted or Informed, not in the room for every decision.

If you have a large stakeholder group, break it into phases. Run a **kickoff meeting** with the full group to align on goals and constraints. Run **working sessions** with the core team to draft the framing. Run a **review meeting** with the full group to collect feedback. Run a **sign-off meeting** with decision-makers to approve the framing. Do not try to do all four phases in one meeting with fifteen people.

## How to Run a Stakeholder Alignment Session

A stakeholder alignment session is not a presentation where you show slides and ask for approval. It is a **structured conversation** designed to surface disagreements, clarify decision rights, and build consensus on the framing.

Here is a template for a 90-minute alignment session:

**Phase 1: Frame the Problem (15 minutes).** The DRI presents the problem definition, the business goals, the user outcomes, and the scope. This is not up for debate yet — it is context-setting. The goal is to ensure everyone understands what problem you are trying to solve and why it matters.

**Phase 2: Present the Proposed Framing (20 minutes).** The DRI walks through the task taxonomy, the success metrics, the constraints, and the non-goals. This is the meat of the framing. The DRI should explain the reasoning behind each decision and flag any areas where there is uncertainty or disagreement.

**Phase 3: Collect Concerns (20 minutes).** Go around the room and ask each stakeholder: What are your top two concerns with this framing? What is missing? What is wrong? The DRI captures concerns without debating them yet. The goal is to get everything on the table.

**Phase 4: Triage Concerns (20 minutes).** The DRI groups concerns into three buckets: **blockers** (things that must be resolved before you can proceed), **trade-offs** (things that require a decision between competing options), and **refinements** (things that can be addressed with minor edits). Blockers get addressed immediately. Trade-offs get assigned to the right decision-maker. Refinements get added to a backlog.

**Phase 5: Agree on Next Steps (15 minutes).** The DRI summarizes the decisions made, the open questions, and the action items. Each action item has an owner and a deadline. The session ends with a clear statement: "If we resolve these blockers, is everyone aligned on this framing?" Get explicit yes or no from each stakeholder.

This structure works because it **separates listening from deciding**. You do not try to resolve every concern in the moment. You acknowledge it, triage it, and assign it to the right person. This prevents the meeting from devolving into a debate where the loudest voice wins.

## Why Framing Without Stakeholder Buy-In Is Worthless

You can write the best framing document in the world, but if stakeholders do not agree with it, you will not ship. Worse, you will spend months building something, only to discover at launch time that legal has concerns, or product changed the scope, or domain experts think the quality bar is too low. At that point, you have three options: reframe and rebuild, ship something that does not meet stakeholder expectations, or cancel the project. All three are expensive.

The value of framing is not in the document. The value is in the **shared understanding** that the document represents. When product, engineering, domain experts, legal, and leadership all agree on what you are building and why, you have alignment. When they do not, you have risk.

This is why stakeholder buy-in is not a nice-to-have — it is the entire point. If you finish framing and you are not confident that every key stakeholder would approve your plan, you are not done. Go back and run another alignment session. It is much cheaper to spend two extra weeks getting alignment than to spend two extra months rebuilding a system because you skipped that step.

## Practical Takeaways

**Map your stakeholders early.** Before you write a single line of your framing doc, identify who needs to be involved and what role they play. Do not assume you know — ask them.

**Clarify decision rights.** Use RACI or a similar framework to make explicit who has final say on scope, success criteria, constraints, and trade-offs. Do not leave this ambiguous.

**Assign a DRI.** Someone needs to own the framing process end-to-end. That person is responsible for running meetings, escalating decisions, and getting sign-off.

**Keep the team small.** Four to six people in working sessions. Larger groups for reviews and sign-offs.

**Run structured alignment sessions.** Do not just send a doc and ask for comments. Run a meeting designed to surface concerns, triage them, and build consensus.

**Do not ship without buy-in.** If key stakeholders are not aligned, you are taking on execution risk that will cost you later.

The next question is: what happens when your framing is technically sound and stakeholder-approved, but it still has to operate under hard limits? That is where constraint capture comes in — the discipline of documenting not just what the system should do, but what it cannot do and must respect under every operating condition.
