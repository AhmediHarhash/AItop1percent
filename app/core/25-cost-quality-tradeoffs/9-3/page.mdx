# 9.3 â€” When Multi-Model Routing Pays for Itself: The Complexity-Savings Crossover

Multi-model routing adds complexity. Complexity has costs: engineering time to build and maintain the router, monitoring overhead to verify that routing decisions are correct, latency variability from the routing decision itself, and operational surface area that creates new failure modes. The question is not whether routing saves money on inference. It almost always does. The question is whether the savings exceed the complexity costs. Below a certain volume, they do not. A team serving 20,000 requests per day that builds an ML-based routing system with quality monitoring, confidence scoring, and dynamic threshold adjustment has built infrastructure that costs more to maintain than it saves. Above a certain volume, routing savings dwarf the complexity costs by an order of magnitude. Finding that crossover, and investing in routing at the right level of sophistication for your current volume, is one of the highest-leverage cost decisions you will make.

The fundamental economics are simple. If you route 70 percent of your queries to a model that costs one-tenth as much as your primary model, and those queries are served at acceptable quality, your blended inference cost drops by roughly 63 percent. That is an enormous savings at any volume. But "acceptable quality" is doing a lot of work in that sentence. Verifying that the cheaper model is delivering acceptable quality on the queries routed to it requires evaluation infrastructure, quality monitoring, and ongoing calibration. Building the router itself, whether rule-based or ML-based, requires engineering investment. Operating the router adds a decision point that can fail silently, routing a complex query to a cheap model that handles it poorly, without anyone noticing until user complaints accumulate. The question is whether the 63 percent savings on inference is large enough in absolute dollars to cover these complexity costs.

## The Crossover Calculation

The **complexity-savings crossover** is the monthly request volume at which the dollar savings from routing exceed the dollar costs of building and operating the routing infrastructure. Calculating it requires estimating both sides of the equation.

On the savings side, start with your current single-model inference cost per month. Then estimate the blended cost under a routing strategy: what fraction of queries would go to the cheap model, what fraction to the expensive model, and what is the per-query cost of each? The monthly savings is the difference between the single-model cost and the blended cost.

A concrete example. A customer support system serves 300,000 queries per day using Claude Sonnet 4.5 at an average cost of $0.018 per query. Monthly inference cost: $162,000. Analysis of their query distribution shows that roughly 65 percent of queries are simple intent-matching questions, things like order status, return policies, and store hours, that a smaller model like Claude Haiku 4.5 can answer at comparable quality. Haiku's average cost for these queries: $0.002. The remaining 35 percent are complex queries requiring nuanced reasoning, complaint resolution, or multi-step problem solving, where Sonnet quality is necessary. Under routing, the blended monthly cost would be: 195,000 simple queries per day at $0.002 plus 105,000 complex queries per day at $0.018, totaling $390 plus $1,890 per day, or $68,400 per month. Monthly savings: $93,600.

On the cost side, estimate the total monthly cost of building and operating the routing infrastructure. This includes five components. First, the **router compute cost**: the inference cost of the routing classifier itself, which evaluates each incoming query and decides which model to use. A lightweight classifier adds $0.0003 to $0.001 per query, depending on whether it is rule-based, embedding-based, or uses a small language model. At 300,000 queries per day, the router compute cost is $2,700 to $9,000 per month. Second, the **quality monitoring cost**: the infrastructure to sample routed queries, evaluate their quality, and verify that the cheap model is performing acceptably on the queries sent to it. This typically costs $1,000 to $3,000 per month in compute and tooling. Third, the **engineering maintenance cost**: the ongoing time spent tuning thresholds, updating routing rules, investigating quality regressions, and adapting the router as query distributions shift. Estimate one to two engineering days per month at a fully loaded cost of $800 to $1,200 per day, or $800 to $2,400 per month. Fourth, the **error cost**: the expected cost of routing mistakes where a complex query gets sent to the cheap model and produces a poor-quality response. If the routing error rate is 3 percent and each error costs $2 in customer support escalation, the error cost at 300,000 queries per day is $540 per day, or $16,200 per month. Fifth, the **latency cost**: the additional latency introduced by the routing decision. If the router adds 30 milliseconds per query and your SLA has a financial penalty for latency violations, include the expected penalty cost. For most systems, this is zero or near zero because the routing latency is absorbed within the latency budget, but it matters for real-time and voice applications.

Total monthly routing cost for this example: approximately $22,700 to $30,600. Monthly savings: $93,600. Net benefit: $63,000 to $70,900 per month. At this volume, routing is overwhelmingly justified.

Now run the same calculation at 30,000 queries per day, one-tenth the volume. Single-model cost: $16,200 per month. Blended cost under routing: $6,840 per month. Savings: $9,360 per month. But the routing costs do not scale down proportionally. Router compute drops to $270 to $900 per month. Quality monitoring stays at $1,000 to $3,000 because the infrastructure has a minimum viable cost. Engineering maintenance stays at $800 to $2,400 because the time required does not scale linearly with volume. Error cost drops to $1,620 per month. Total routing cost: approximately $3,690 to $7,920 per month. Net benefit: $1,440 to $5,670 per month.

At 30,000 queries per day, routing still pays for itself, but barely. The net benefit is small enough that a bad month, a spike in routing errors or an unexpected quality regression that requires extra engineering time, could push it negative. This is the zone near the crossover where the decision depends on your confidence in the routing system's reliability rather than its theoretical savings.

At 10,000 queries per day, the math inverts. Single-model cost: $5,400 per month. Savings from routing: $3,120. Routing infrastructure costs: still $3,000 to $6,000 per month at minimum. Net benefit: negative $900 to positive $120. The routing infrastructure costs as much as it saves. This is below the crossover.

## The Crossover by Routing Sophistication

The crossover volume depends heavily on how sophisticated your routing is. Simpler routing has lower costs and therefore a lower crossover. More sophisticated routing delivers higher savings but requires higher investment, pushing the crossover higher.

**Rule-based routing** is the simplest approach. Define explicit rules that match query patterns to models. If the query matches a known FAQ intent, route to the cheap model. If it contains certain keywords or exceeds a complexity indicator like query length, route to the expensive model. The engineering investment is a few days to build and an hour per week to maintain. The compute cost is negligible because rule evaluation is essentially free. The quality risk is moderate because rules are brittle: they work well for the patterns you anticipated and fail on the patterns you did not. The crossover for rule-based routing is typically around 50,000 to 100,000 requests per month, or roughly 2,000 to 3,500 per day. Below this, the savings are not worth even the modest engineering investment. Above it, even simple rules deliver meaningful cost reduction.

**Embedding-based routing** uses a lightweight embedding model to classify query complexity and route accordingly. Each incoming query is embedded into a vector, and the vector is compared against cluster centroids that represent different complexity tiers. The embedding model adds 5 to 15 milliseconds of latency and a small per-query cost. The engineering investment is two to three weeks for initial implementation and tuning. The quality risk is lower than rule-based routing because embeddings capture semantic complexity that keywords miss. The crossover for embedding-based routing is typically 200,000 to 500,000 requests per month, or roughly 7,000 to 17,000 per day. Below this, the embedding infrastructure costs are not justified by the incremental savings over rule-based routing. Above it, the better routing accuracy delivers meaningfully higher savings.

**ML-based routing with quality monitoring** is the most sophisticated approach. A trained classifier, often a small language model itself, evaluates each query and predicts which model will achieve the best quality-to-cost ratio for that specific query. The system continuously monitors quality on routed queries and adjusts routing thresholds dynamically. This is what industry leaders like Martian, RouteLLM, and the built-in routing features of LLM gateways like Portkey and Requesty provide. The engineering investment is four to eight weeks for implementation plus ongoing tuning. The infrastructure cost is $2,000 to $8,000 per month. The quality risk is the lowest of the three approaches because the system self-corrects based on observed quality outcomes. The crossover is typically 500,000 to one million requests per month, or roughly 17,000 to 33,000 per day. Below this, the sophistication is not justified. Above it, the combination of high routing accuracy and dynamic adjustment delivers savings that simpler approaches cannot match.

The practical implication is clear: match your routing sophistication to your volume. Do not build an ML-based router for a system that serves 5,000 queries per day. Do not rely on rule-based routing for a system that serves 500,000 queries per day. The routing investment should grow with your traffic, just like every other infrastructure investment.

## Routing Maturity: A Progressive Investment

The smartest teams do not jump to their target routing sophistication on day one. They follow a **routing maturity progression** that adds complexity incrementally, justified at each step by the volume that warrants it.

**Stage one: single model, no routing.** The starting point for every system. Use one model for all queries. Spend your engineering time on prompts, evaluation, and product quality. This is correct for any system below 50,000 requests per month.

**Stage two: two-tier rule-based routing.** When volume crosses 100,000 requests per month, implement simple rules that route obvious easy queries to a cheaper model. Start with the highest-volume, lowest-complexity query types. A customer support system might route "where is my order" and "what is your return policy" to the cheap model while sending everything else to the primary model. Monitor quality on both tiers weekly. This stage saves 20 to 35 percent of inference costs with minimal complexity.

**Stage three: multi-tier embedding-based routing.** When volume crosses 500,000 requests per month, replace the rule-based router with an embedding classifier that handles the full spectrum of query complexity. Introduce three or more model tiers: a fast cheap model for simple queries, a mid-tier model for moderate complexity, and a frontier model for the hardest queries. The finer granularity captures more savings because many queries that rules would send to the expensive model are actually handleable by the mid-tier. This stage saves 40 to 55 percent of inference costs compared to single-model operation.

**Stage four: ML-based routing with dynamic thresholds.** When volume crosses two million requests per month, invest in a routing system that continuously learns from quality outcomes. The router observes which queries the cheap model handles well and which it does not, and adjusts routing decisions accordingly without human intervention. This stage saves 55 to 70 percent of inference costs and maintains quality within one to two percentage points of using the frontier model for everything. At this volume, the savings from routing typically exceed $50,000 per month, easily justifying the infrastructure and engineering investment.

A real progression illustrates the pattern. A legal document analysis company started in early 2025 with Claude Sonnet 4.5 for all queries, serving 40,000 document analysis requests per month at $0.032 per request. Monthly inference cost: $1,280. No routing needed.

By mid-2025, volume had grown to 180,000 requests per month. They implemented rule-based routing that sent simple queries, document classification and metadata extraction, to Claude Haiku 4.5, while keeping complex queries, clause analysis and risk assessment, on Sonnet. Simple queries accounted for 45 percent of volume. Monthly inference cost dropped from $5,760 to $3,744, saving $2,016. The rules took two days to build and required no ongoing infrastructure.

By early 2026, volume reached 800,000 requests per month. They replaced the rule router with an embedding-based classifier and added GPT-5-mini as a mid-tier option. Three-tier routing allocated 40 percent to Haiku, 35 percent to GPT-5-mini, and 25 percent to Sonnet. Monthly inference cost dropped from a projected $25,600 on a single model to $9,200, saving $16,400. The embedding infrastructure cost $1,200 per month and required three weeks of engineering to build.

By mid-2026, volume was approaching 2.5 million requests per month. They deployed an ML-based router with quality monitoring that dynamically adjusted thresholds based on weekly quality evaluations. The router identified that certain query subtypes that the embedding classifier had been sending to Sonnet were actually handled well by the mid-tier model, and vice versa. Monthly inference cost at this volume: $24,500 instead of a projected $80,000 on a single model. Monthly routing infrastructure cost: $4,800. Net monthly savings: $50,700.

At each stage, the team invested in routing complexity only when the volume justified it. They never over-built for their current scale, and they never under-invested for their growth trajectory.

## The Silent Failure: Routing Quality Degradation

The biggest risk in multi-model routing is not a dramatic failure. It is a silent one. The cheap model handles a complex query poorly, the user gets a mediocre response, and nobody notices because the system looks healthy from an infrastructure perspective. Latency is fine, costs are down, and the dashboards are green. But the user got a worse answer than they would have gotten without routing, and they may not come back.

**Routing quality degradation** happens when the router systematically misclassifies query complexity, sending queries to models that are not capable enough to handle them well. The degradation is slow because any individual misrouted query is a minor quality dip, not a catastrophic failure. A customer support query that needed nuanced empathy gets routed to a model that gives a technically correct but emotionally flat response. A contract analysis query that needed careful reasoning about ambiguous language gets routed to a model that gives a shallow, surface-level answer. Each instance is a small quality loss. Across thousands of queries per day, the accumulated effect is a measurable drop in user satisfaction, resolution rate, or downstream business metrics.

Detection requires comparing quality metrics between routed and unrouted traffic. Run a shadow experiment where a sample of queries, typically 2 to 5 percent, are processed by both the routed model and the primary model. Compare the quality scores. If the routed responses are consistently lower quality on a meaningful fraction of queries, your routing thresholds need adjustment. Specifically, track the **routing regret rate**: the percentage of queries where the routed model produces a response that is measurably worse than what the primary model would have produced. A routing regret rate below 3 percent is excellent. Between 3 and 7 percent is acceptable but worth optimizing. Above 7 percent, routing is degrading the user experience enough to offset a significant portion of the cost savings.

A B2B analytics company discovered in late 2025 that their routing regret rate had crept from 2.8 percent to 9.4 percent over three months. The cause was a gradual shift in query distribution: their users had started asking more complex analytical questions as they became more sophisticated with the product, but the router's complexity thresholds had not been updated. Queries that would have been classified as complex six months earlier were being classified as moderate because the thresholds were calibrated to the old distribution. They recalibrated the thresholds, dropping the regret rate to 3.1 percent, and implemented monthly distribution drift checks to prevent the same problem from recurring.

## The Organizational Cost: Who Owns the Router

Multi-model routing creates an organizational question that is easy to defer and expensive to ignore: who is responsible for routing quality?

The ML team built the router and understands how it works. The product team defines what quality means and owns user satisfaction. The infrastructure team operates the serving layer where routing decisions are executed. The finance team cares about the cost savings that routing delivers. When routing quality degrades, each team can plausibly argue that it is someone else's problem. The ML team says the router is working as designed. The product team says the model is producing bad responses. The infrastructure team says the system is serving requests within SLA. The finance team says costs are on target. Meanwhile, the user is getting worse answers and nobody has accountability.

The solution is explicit **routing ownership**: a single team, or a single person on an existing team, who is accountable for routing quality as measured by the routing regret rate and the quality parity metric (the difference in quality scores between routed and unrouted traffic). This owner does not need to build the router. They need to monitor its quality, trigger recalibration when metrics drift, and have the authority to adjust routing thresholds or temporarily disable routing for specific query types when quality degrades.

Without this ownership, routing becomes a set-and-forget system that slowly degrades. The savings continue to appear on the cost dashboard, so leadership assumes everything is fine. The quality degradation appears in user satisfaction metrics months later, disconnected from routing decisions in a way that makes root-cause analysis difficult. By the time someone connects the dots, the damage is measured in churned customers and eroded trust.

## The Build-or-Buy Decision for Routing

In 2026, you do not need to build a routing system from scratch. Multiple commercial and open-source options provide routing capabilities out of the box. LLM gateway platforms like Portkey, Requesty, and Martian offer built-in routing with quality monitoring. Open-source frameworks like RouteLLM provide routing classifiers you can deploy and customize. Major cloud providers offer routing features within their AI serving platforms.

The build-or-buy decision follows the same crossover logic as the routing decision itself. At low routing complexity, rule-based routing, building is trivial and buying adds unnecessary vendor dependency. At moderate complexity, embedding-based routing, building is a multi-week project that commercial platforms can replace with configuration. At high complexity, ML-based routing with dynamic thresholds, building requires months of specialized engineering work that commercial platforms have already invested in.

The crossover: if routing sophistication would take more than four weeks to build in-house, evaluate commercial alternatives first. If the commercial option costs less per month than two weeks of engineering time, buy it. If you need routing customization that no commercial platform supports, such as domain-specific quality classifiers or integration with proprietary evaluation systems, build the custom components on top of a commercial routing layer rather than building everything from scratch.

The exception is teams at true scale-regime volumes, above five million requests per day, where routing infrastructure costs are large enough that the marginal cost savings from a custom-built system justify the engineering investment. At this scale, the routing system is core infrastructure that deserves dedicated engineering ownership, just like your serving infrastructure and caching layer.

## When Not to Route

Not every system benefits from routing. Some applications have query distributions where routing saves little or adds unacceptable risk.

Systems with uniformly complex queries derive minimal benefit from routing because there are few queries to route to the cheap model. A medical diagnosis assistant where every query requires careful clinical reasoning cannot safely route 65 percent of queries to a lightweight model. The savings from routing 10 to 15 percent of genuinely simple queries, things like appointment scheduling and medication reminders, may not justify the routing infrastructure.

Systems with extremely tight latency budgets may not tolerate the additional latency of a routing decision. A voice assistant with a 300-millisecond time-to-first-token budget cannot afford 30 to 50 milliseconds for routing classification. In these cases, a single fast model is often preferable to a routing layer that adds latency variability.

Systems with small query volumes, below the crossover for their routing sophistication level, should not invest in routing. Spend the engineering effort on prompt optimization, caching, and model evaluation instead. The cost savings from better prompts, reducing average token consumption by 20 percent through more efficient system prompts, can match or exceed routing savings at low volume without any of the operational complexity.

The discipline is resisting the appeal of routing as an optimization in the abstract and evaluating it against the specific economics of your system. Routing is not inherently good. It is good when it saves more than it costs. Calculate both sides before deciding.

Multi-model routing optimizes how you spend on external APIs. But there is a deeper question that every growing system eventually confronts: should you be paying for APIs at all? The next subchapter examines the build-versus-buy cost curves, the volume at which self-hosted models beat API providers on unit economics, and the hidden costs that make the crossover higher than most teams expect.
