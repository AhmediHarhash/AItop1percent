# 10.2 â€” Tier-Based Quality Policies: Different Standards for Different Stakes

Not every feature in your product deserves the same quality investment. A medical diagnosis assistant and a casual content suggestion engine have fundamentally different quality requirements, and treating them the same wastes money on one and risks lives on the other. This is obvious when stated this directly, yet most AI teams operate as if all their features share a single quality standard: the highest one anyone in the room has ever argued for.

The consequence is predictable. Teams that apply a single quality standard across all features overspend on low-stakes use cases and simultaneously under-invest in the evaluation rigor that high-stakes use cases demand. The FAQ chatbot runs on the same frontier model as the compliance review engine. Both get the same evaluation frequency. Both get the same monitoring granularity. One of those decisions wastes $12,000 per month. The other puts the organization at regulatory risk because the evaluation cadence that is adequate for casual queries is dangerously insufficient for compliance decisions.

**Tier-based quality policies** solve this by making the implicit explicit. Instead of one quality standard, you define a small number of tiers, each with specific requirements for model selection, evaluation rigor, monitoring, caching, and fallback behavior. Every feature in your product gets classified into a tier. The tier determines the rules. The rules are documented, enforced, and reviewed, not negotiated from scratch every time someone proposes a cost optimization.

## The Four-Tier Framework

Four tiers cover the range of stakes that most AI products encounter. Fewer than four collapses important distinctions. More than four creates classification debates that consume more time than they save.

**Tier 0: Safety-Critical.** These are features where model failure can cause direct harm to people, create legal liability, or violate regulatory requirements. Medical diagnosis, financial advice that triggers transactions, content moderation for child safety, autonomous actions that affect physical systems, and any feature where an incorrect output has consequences that cannot be undone with an apology and a refund. Tier 0 features have no cost optimization. The best available model is used. Evaluation is continuous and comprehensive. Human review covers a large sample, often 10 percent or more of outputs. Caching is either prohibited or restricted to exact-match with short time-to-live windows. Fallback behavior is conservative: if the model's confidence is below threshold, the system declines to answer rather than guessing. The cost of Tier 0 is high by design. The cost of a Tier 0 failure is higher.

**Tier 1: High Business Impact.** These are features that directly affect revenue, customer retention, or brand reputation, but where failure does not create immediate harm. Customer-facing product recommendations that drive purchasing decisions. Enterprise contract analysis that informs business deals. Personalized financial summaries that customers rely on for decision-making. Tier 1 features use high-quality models but allow monitored cost optimization. You can use model routing to send simple queries to a cheaper model, but you maintain a quality floor and automated alerts when quality approaches the floor. Evaluation is frequent: daily or weekly quality scoring on sampled outputs. Caching is allowed with semantic matching, but with quality monitoring on cached responses. Human review covers 3 to 5 percent of outputs. The cost is significant but managed. The goal is high quality at sustainable cost, not maximum quality at any cost.

**Tier 2: Moderate Impact.** These are features that add value but where quality degradation causes inconvenience rather than harm or significant business loss. Internal productivity tools. Suggested email replies that users always edit before sending. Search result summaries that supplement but do not replace the underlying search results. Content tagging and categorization for internal workflows. Tier 2 features prioritize cost efficiency while maintaining a minimum quality bar. Mid-tier models are the default. Aggressive caching is encouraged. Evaluation is weekly or biweekly on sampled outputs. Human review is minimal, perhaps 1 percent of outputs or only triggered by automated anomaly detection. Fallback behavior can be more permissive: return a best-effort answer rather than declining.

**Tier 3: Low Stakes.** These are features where quality degradation has minimal consequence and cost optimization is the primary goal. Internal analytics summaries that feed into dashboards people glance at. Auto-generated metadata for internal content management. Draft suggestions that are always reviewed and heavily edited by humans before use. Experimental features in beta with explicit "this is AI-generated" disclaimers. Tier 3 features use the cheapest model that clears a basic functionality bar. Caching is maximally aggressive. Evaluation is monthly or triggered by complaints rather than scheduled. Human review is essentially zero outside of spot-checks. The quality bar is "acceptable," not "good." The cost should be as low as technically feasible.

## Classifying Features Into Tiers

The classification decision rests on four factors, and the highest-risk factor determines the tier. A feature that scores Tier 2 on three factors but Tier 0 on one is a Tier 0 feature. Risk classification rises to the maximum, never averages to the mean.

**User harm potential** is the first factor. Ask: if this feature produces a completely wrong output, what is the worst thing that happens to the user? If the answer is "they receive dangerous medical advice," that is Tier 0. If the answer is "they make a poor purchasing decision based on a bad recommendation," that is Tier 1. If the answer is "they see an irrelevant search result," that is Tier 2. If the answer is "an internal dashboard shows a slightly wrong number that nobody acts on directly," that is Tier 3.

**Revenue impact** is the second factor. What is the direct revenue consequence of quality degradation on this feature? Features that drive conversion, retention, or upsell belong in Tier 1 at minimum. Features that support revenue indirectly through internal efficiency belong in Tier 2 or Tier 3. A product recommendation engine that drives 15 percent of monthly revenue is a Tier 1 feature regardless of how simple the underlying task seems, because quality degradation directly translates into lost sales.

**Regulatory exposure** is the third factor. Does this feature operate in a regulated domain? The EU AI Act's tiered risk framework, which became enforceable for general-purpose AI in August 2025 and has a compliance window for high-risk applications extending to August 2026, provides a useful parallel. Features that fall under the EU AI Act's high-risk classification, including employment screening, financial credit scoring, and educational assessment, are Tier 0 or Tier 1 by default regardless of their business impact. HIPAA, SOX, GDPR, and industry-specific regulations impose similar constraints. If an incorrect output could trigger a compliance violation, the feature needs a tier that includes the evaluation rigor and audit trail to demonstrate compliance.

**Brand risk** is the fourth factor. Some features are low-stakes in terms of direct harm and revenue but high-stakes in terms of public perception. A customer-facing chatbot that occasionally produces offensive or nonsensical responses may not directly harm anyone or affect revenue in the short term, but a screenshot on social media can create a brand crisis that costs far more than the money saved by using a cheap model. Brand risk is hardest to quantify, but the heuristic is straightforward: if a failure on this feature could become a news story or a viral social media post, upgrade its tier by at least one level.

## How Tiers Translate Into Concrete Policies

The power of the tier framework comes from its translation into specific, enforceable policies. A tier is not an abstract label. It is a set of rules that constrain the decisions the team can make about that feature.

**Model selection policy.** Tier 0 features must use the highest-quality model available for the task, currently a frontier model such as Claude Opus 4.6, GPT-5.1, or Gemini 3 Pro, with no routing to cheaper alternatives. Tier 1 features may use model routing, but the fallback model must meet a documented quality threshold on the feature's eval suite, typically no more than 3 percentage points below the primary model's score. Tier 2 features can default to mid-tier models like Claude Sonnet 4.5, GPT-5, or Gemini 3 Flash with routing to smaller models for simple queries. Tier 3 features should default to the smallest model that meets the basic functionality bar, often Claude Haiku 4.5, GPT-5-mini, or similar compact models.

**Evaluation policy.** Tier 0 features require continuous evaluation with daily scoring on a statistically significant sample, minimum 200 outputs per evaluation cycle. Quality scores are tracked with control chart methodology, and any score below the established baseline triggers an immediate investigation. Tier 1 features require evaluation two to three times per week, with minimum 100 outputs per cycle and alerts on scores that drop more than 2 percentage points below baseline. Tier 2 features require weekly evaluation with minimum 50 outputs per cycle. Tier 3 features require monthly evaluation or evaluation triggered by user complaints, with minimum 30 outputs per cycle.

**Caching policy.** Tier 0 features restrict caching to exact-match only with short time-to-live periods, typically two to four hours, and require quality validation on cached responses at the same rate as fresh responses. Tier 1 features allow semantic caching with a high similarity threshold, 0.96 or above, and quality monitoring on 3 percent of cached responses. Tier 2 features allow aggressive semantic caching with a standard similarity threshold, 0.92 or above, and quality monitoring on 1 percent of cached responses. Tier 3 features allow maximum caching with longer time-to-live periods and minimal quality monitoring on cached responses.

**Fallback policy.** Tier 0 features decline to answer when the model's confidence is below threshold. They never serve a degraded response. If the primary model is unavailable, the system returns a message directing the user to a human specialist. Tier 1 features serve the best available response but flag low-confidence outputs for rapid human review within four hours. Tier 2 features serve the best available response with a quality indicator visible to the user when confidence is low. Tier 3 features serve whatever the model produces, with no confidence-based gating.

## The Cost Implications of Tiering

Tier-based policies create a cost structure that matches investment to risk. Instead of spending the same amount per request across all features, you concentrate spending where it matters and economize where it does not.

Consider a platform with four AI-powered features. Without tiering, the team runs all four on Claude Sonnet 4.5 with uniform evaluation and monitoring. Monthly cost: $86,000.

With tiering: the compliance review feature, classified as Tier 0, runs on Claude Opus 4.6 with daily evaluation and 10 percent human review. Cost increases from $22,000 to $31,000 per month. The customer-facing recommendation engine, classified as Tier 1, stays on Claude Sonnet 4.5 with three-times-per-week evaluation. Cost stays at $24,000. The internal search summarization tool, classified as Tier 2, moves to Claude Haiku 4.5 with weekly evaluation. Cost drops from $22,000 to $8,400. The content tagging pipeline, classified as Tier 3, moves to GPT-5-mini with monthly evaluation. Cost drops from $18,000 to $4,200.

Total cost after tiering: $67,600. The team saved $18,400 per month while simultaneously increasing investment in the highest-risk feature. The compliance review feature now has better evaluation and higher model quality than before. The low-stakes features now cost what they should have always cost. The savings from Tiers 2 and 3 more than fund the investment increase in Tier 0.

This is the core economics of tiering: it is not about spending less in total. It is about spending more where the stakes justify it and less where they do not, which often results in lower total cost and higher effective quality simultaneously.

## Managing Tier Classification Disputes

Tier classification is not always clean. The most common disputes occur when product wants a feature classified lower to enable cost optimization, when engineering wants it classified higher to avoid the risk of quality complaints, and when different stakeholders evaluate the four risk factors differently.

The resolution principle is simple: **ambiguity elevates.** When the classification is genuinely uncertain, assign the higher tier. The cost difference between Tier 1 and Tier 2 is meaningful but manageable. The consequence of misclassifying a Tier 1 feature as Tier 2 and missing a quality regression is potentially severe. It is cheaper to over-invest slightly in a feature that turns out to be lower-risk than to under-invest in one that turns out to be higher-risk.

The exception to this principle is Tier 0. Because Tier 0 carries the highest cost and the most restrictive policies, teams should resist the temptation to classify features as Tier 0 out of excessive caution. A feature is Tier 0 only if model failure can cause direct, irreversible harm or regulatory violation. "Our most important feature" is not the same as "our highest-risk feature." Importance determines business impact. Risk determines tier.

Document every tier classification with its rationale in the tradeoff register. When a classification is disputed, record the dispute and the resolution. When a feature's circumstances change, such as a new regulation applying to a previously unregulated domain or a feature gaining a new use case that increases harm potential, re-evaluate the tier. The tier framework is a living system, not a one-time classification exercise.

## Tier Migration: When Features Change Risk Profiles

Features do not stay in their initial tier forever. Business changes, regulatory changes, and usage pattern changes all affect classification.

**Upward migration** happens when risk increases. A content suggestion engine that was Tier 2 when it served optional recommendations becomes Tier 1 when product redesigns the experience so that suggestions are displayed as default selections that users must actively override. The user harm potential changed because passive suggestions became default actions. A document analysis tool that was Tier 1 when used for internal research becomes Tier 0 when sales starts showing its output directly to prospective clients as part of the sales process. The brand risk and user harm factors both escalated.

**Downward migration** happens when risk decreases, though it should be treated with more caution than upward migration. A customer-facing feature that was Tier 1 might migrate to Tier 2 if it is moved behind a human review step where every output is checked before the customer sees it. The human review layer absorbs the quality risk, allowing the underlying model to operate at a lower tier. But this only works if the human review layer is genuinely reliable and adequately staffed. Using a hypothetical human review layer that does not yet exist to justify a tier downgrade is a classification fraud that teams commit more often than they admit.

Review tier classifications quarterly, or whenever a feature undergoes a significant change in use case, user base, or regulatory environment. The cost-quality review meeting is the natural venue for these reviews. Add "tier classification audit" as a quarterly agenda item, cycling through one-quarter of the feature portfolio each time so that every feature gets re-evaluated annually.

## The Tier Framework as Communication Tool

Beyond its operational value, the tier framework gives the organization a shared language for cost-quality conversations. When product asks "can we make this feature cheaper," the response is not a vague "it depends" but a specific "that feature is classified as Tier 1, which means we can optimize with model routing but cannot drop below the quality floor defined in the Tier 1 policy." When finance asks "why is this feature so expensive," the answer is "it is Tier 0 because it operates in a regulated domain, and the Tier 0 policy requires frontier model usage and continuous evaluation."

This shared language eliminates the most common source of friction in cost-quality discussions: different mental models of what "good enough" means. Without tiers, "good enough" is whatever the most senior person in the room says it is. With tiers, "good enough" is defined by the tier policy, which was agreed upon in advance and documented in the tradeoff register. The debate shifts from "what quality level should this feature have" to "which tier should this feature be classified as," and the tier carries all the policy decisions with it.

The tier framework also accelerates decision-making for new features. When a new AI-powered capability is being designed, the first cost-quality question is "which tier is this?" Once the tier is established, the model choice, evaluation plan, caching strategy, and budget allocation follow directly from the tier policy. The team does not need to reinvent the cost-quality framework for every new feature. They need to classify it once, and the framework provides the rest.

The tier framework tells you what quality level each feature should have. The next question is how to allocate your total budget across the components that deliver that quality: inference, evaluation, safety, monitoring, and human review. The next subchapter addresses budget allocation across these components, where proportional spending is almost always wrong and ROI-based allocation is almost always right.
