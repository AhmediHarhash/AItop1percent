# 3.9 â€” Domain-Specific Guidelines: Legal, Medical, Financial, Safety

Eighty-seven percent accuracy on internal tests, three law firm contract cancellations in one week after launch. The citations were formatted correctly, topically relevant, accurately quoted. They were also professionally worthless and legally dangerous because they cited wrong jurisdictions, overturned precedents, and failed to distinguish binding from persuasive authority. Generic annotation guidelines written by product managers without legal training had treated all citations as equivalent if they matched topic and format, missing the jurisdictional correctness, precedential hierarchy, temporal validity, and unauthorized practice boundaries that make the difference between useful legal research and malpractice. The rebuild with attorney-authored guidelines cost $1.8 million and eight months, by which time the market opportunity had passed to a competitor who understood from day one that domain-specific annotation requires domain experts to write the guidelines, not just apply them. Medical accuracy, legal validity, financial compliance, and safety assessment each operate under epistemological frameworks that generic quality rubrics cannot capture. Product managers can specify that outputs should be accurate. Only domain experts can define the seventeen dimensions of domain-specific accuracy that matter.

Generic annotation guidelines fail catastrophically in specialized domains because they cannot encode the nuanced correctness standards that domain experts apply instinctively. Legal accuracy, medical safety, financial compliance, and content safety each operate under different epistemological frameworks, regulatory constraints, and harm models that generic quality rubrics cannot capture. A guideline that asks annotators to judge whether an output is accurate, relevant, and well-formatted works adequately for consumer-facing summarization or classification tasks. It fails immediately when applied to domains where accuracy has sub-dimensions that non-experts cannot perceive, where relevance is governed by external regulatory standards, and where formatting errors can constitute professional negligence or legal liability.

## Legal Domain Guidelines: Accuracy Beyond Correctness

Legal annotation guidelines must distinguish between factual accuracy and legal accuracy. A case citation can be factually accurate in the sense that a case with that name, citation number, and publication year exists, while being legally useless or actively harmful because it has been overturned, superseded by statute, or applies to a different jurisdiction. Your annotators cannot make these distinctions without explicit guidance written by attorneys who understand the hierarchy of legal authority. When you build guidelines for legal AI systems, you are not teaching annotators to verify that text matches a source. You are teaching them to apply the same professional judgment that a junior attorney applies when conducting legal research.

Your legal guidelines must specify jurisdictional correctness as a primary evaluation dimension. An output that cites California case law in response to a question about New York contract law is wrong regardless of citation accuracy. Your guidelines must define what constitutes the correct jurisdiction for different query types, provide decision trees for queries that span multiple jurisdictions, and specify when federal law preempts state law. You cannot expect annotators to know these rules inherently. You must provide jurisdiction lookup procedures, examples of correct and incorrect jurisdiction matching for ten to fifteen common query patterns, and explicit instructions to escalate queries where jurisdictional applicability is ambiguous. If your legal AI system operates across multiple countries, your guidelines must include conflict of law principles and specify which jurisdiction's law applies under which circumstances.

Your legal guidelines must include citation hierarchy and precedential value. Annotators must be taught to distinguish between binding precedent, persuasive authority, and non-precedential decisions. They must understand that a Supreme Court decision carries more weight than a circuit court decision, that a published opinion carries more weight than an unpublished memorandum, and that a decision from the controlling jurisdiction trumps a decision from a persuasive jurisdiction even if the persuasive case is more recent or better reasoned. These distinctions are not intuitive to non-lawyers. Your guidelines must provide explicit precedent ranking rules, examples showing why a lower-ranking citation is incorrect even when topically relevant, and instructions for annotating outputs that mix precedential values without appropriate qualification.

Your legal guidelines must address temporal validity. Case law gets overturned, statutes get amended, regulations get superseded. An output that cites a 1998 decision without noting that it was overruled in 2022 is producing professional malpractice, not a minor accuracy error. Your guidelines must require annotators to verify that cited authority is still good law, provide access to citator services like Shepard's or KeyCite, and specify clear labeling for outputs that cite overruled, questioned, or superseded authority. You must also define acceptable recency standards: for fast-moving areas like technology law or securities regulation, a citation from 2020 may be outdated; for well-settled contract principles, a citation from 1985 may be perfectly appropriate. Your guidelines must specify recency expectations per legal area and flag outputs that rely on outdated authority in contexts where law has evolved.

Your legal guidelines must specify disclaimer requirements and unauthorized practice of law boundaries. If your system produces legal information, your guidelines must define the boundary between permissible legal information and impermissible legal advice. Annotators must be trained to identify outputs that cross into advice, recommend specific actions without qualification, or purport to apply law to a user's specific circumstances without appropriate disclaimers. Your guidelines must include model disclaimer language, examples of outputs that require disclaimers, and clear criteria for rejecting outputs that constitute unauthorized practice of law. This is not a technical accuracy question. This is a regulatory compliance question that carries civil and criminal liability if your system practices law without a license.

## Medical Domain Guidelines: Clinical Accuracy and Harm Potential

Medical annotation guidelines must treat clinical accuracy as a pass-fail dimension, not a quality spectrum. In consumer applications, an output that is 80% accurate might be acceptable if the error does not mislead users significantly. In medical applications, an output that is 80% accurate might recommend a contraindicated medication, misinterpret symptom severity, or delay appropriate care. Your medical guidelines must define accuracy standards that match clinical practice standards, require annotators to verify outputs against authoritative medical sources, and specify zero-tolerance criteria for factual errors that could cause patient harm.

Your medical guidelines must include harm potential assessment as a mandatory evaluation step. Every medical output must be assessed not only for accuracy but for the potential harm if a patient or provider acts on it. Your guidelines must define harm categories: immediate life-threatening harm, serious but not immediately life-threatening harm, minor harm, and no harm potential. You must provide clinical scenarios illustrating each category, specify that any output with life-threatening harm potential receives an automatic fail label regardless of other quality factors, and require escalation to licensed clinicians for borderline harm assessments. Annotators without clinical training cannot reliably assess harm potential. Your guidelines must acknowledge this limitation and build in expert review checkpoints.

Your medical guidelines must specify when to escalate to licensed professionals. Annotators can be trained to verify that a medication dosage matches FDA labeling, but they cannot determine whether that dosage is appropriate for a patient with renal impairment. They can verify that a symptom description is factually accurate, but they cannot assess whether the described presentation constitutes a medical emergency. Your guidelines must define clear escalation triggers: any output involving diagnosis, treatment recommendations, medication selection, surgical procedures, emergency conditions, pediatric dosing, pregnancy-related care, or mental health crisis must be reviewed by a licensed physician, nurse practitioner, or pharmacist depending on the content domain. You must staff your annotation team with clinical reviewers or contract with clinical review services. You cannot rely on lay annotators for final medical accuracy determinations.

Your medical guidelines must address FDA and HIPAA implications for labeled data. If your labeled dataset will be used to train or evaluate a system that meets the FDA definition of a medical device, your labeling process must follow quality system regulations that govern device development. Your guidelines must document the clinical qualifications of reviewers, maintain audit trails of labeling decisions, and implement validation procedures that demonstrate labeling reliability. If your data contains protected health information, your guidelines must specify de-identification procedures, access controls, and annotator training requirements under HIPAA. Medical annotation is not just a technical task. It is a regulated activity that carries legal obligations.

Your medical guidelines must define clinical terminology standards and enforce their use. Medical language has precise meanings that differ from colloquial usage. Annotators must be trained to distinguish between medical terms that lay users conflate: a heart attack is not the same as cardiac arrest, a virus is not the same as a bacterial infection, a drug allergy is not the same as a drug side effect. Your guidelines must include a medical terminology glossary, provide examples of common lay-term confusion, and require annotators to flag outputs that use medical terms incorrectly or that conflate distinct clinical concepts. If your system operates in multiple languages, your guidelines must address medical translation accuracy and specify that medical terms must be translated using standardized medical dictionaries, not general translation tools.

## Financial Domain Guidelines: Regulatory Compliance and Fiduciary Standards

Financial annotation guidelines must encode regulatory compliance requirements that vary by product type, user role, and jurisdiction. A system providing investment research must meet different accuracy and disclosure standards than a system providing general financial education. A system serving retail investors must meet different suitability standards than a system serving institutional investors. Your guidelines must define these regulatory contexts, specify which compliance standards apply to each content type, and train annotators to evaluate outputs against those standards.

Your financial guidelines must address suitability and appropriateness standards for investment-related content. Under securities regulations, recommendations must be suitable for the intended investor based on their financial situation, risk tolerance, and investment objectives. Your guidelines must define suitability criteria, provide examples of unsuitable recommendations, and require annotators to flag outputs that recommend specific investments without appropriate qualification or that fail to disclose material risks. If your system operates in the European Union, your guidelines must also address appropriateness requirements under MiFID II, which apply even to execution-only services. Annotators must be trained to recognize when an output constitutes investment advice versus general information, and your guidelines must specify labeling standards that reflect this distinction.

Your financial guidelines must require disclosure accuracy for fees, risks, and conflicts of interest. Outputs that discuss financial products must accurately disclose all material costs, risks, and potential conflicts. Your guidelines must define materiality standards, provide examples of required disclosures per product type, and specify that outputs with missing or inaccurate material disclosures receive fail labels. If your system discusses mutual funds, your guidelines must require that expense ratios, sales loads, and redemption fees are accurately stated and appropriately contextualized. If your system discusses structured products, your guidelines must require clear explanation of downside risk, counterparty risk, and liquidity constraints. Annotators must be trained to verify disclosures against regulatory filings and product prospectuses, not just against the system's internal knowledge.

Your financial guidelines must address fiduciary duty implications for outputs that cross into advice. Under Department of Labor rules and state fiduciary standards, certain financial recommendations trigger fiduciary obligations that require the advisor to act in the client's best interest. Your guidelines must define the boundary between general education and fiduciary advice, train annotators to identify outputs that trigger fiduciary duties, and specify that such outputs must be reviewed by licensed financial advisors or compliance officers. If your system serves retirement plan participants, your guidelines must reflect the heightened fiduciary standards that apply to retirement advice under ERISA. You cannot treat fiduciary compliance as a technical accuracy question. It is a legal question that requires expert judgment.

Your financial guidelines must implement SOX audit trail requirements if labeled data is used in systems that support financial reporting or internal controls. Under Sarbanes-Oxley Act requirements, companies must maintain evidence that their financial reporting controls are operating effectively. If your AI system generates or validates financial data that flows into financial statements, your annotation process becomes part of the control environment. Your guidelines must specify documentation requirements, reviewer qualifications, version control procedures, and change management protocols that satisfy SOX auditor expectations. You must maintain records showing who labeled each data point, when they labeled it, what criteria they applied, and what review procedures were followed. This is not optional. If your labels feed financial reporting processes, your labeling operation must meet the same control standards as any other financial reporting system.

Your financial guidelines must define accuracy standards for numerical data and calculations. Financial outputs involve precise numbers: account balances, transaction amounts, interest rates, returns, tax calculations. Your guidelines must specify rounding conventions, require verification of all numerical outputs against source systems, and define tolerance thresholds for acceptable variance. An output that states an account balance of $10,234.56 when the actual balance is $10,234.58 might be acceptably accurate for conversational purposes but unacceptable for transaction processing. Your guidelines must define accuracy requirements that match the use case and specify how annotators should verify numerical accuracy.

## Safety Domain Guidelines: Harm Taxonomy and Severity Grading

Content safety annotation guidelines must treat different harm categories as distinct evaluation dimensions, not as a single safety spectrum. Self-harm content, violence, child safety, and hate speech each require separate rubrics with distinct severity grading, context considerations, and escalation procedures. A guideline that asks annotators to rate content as safe, borderline, or unsafe cannot capture the nuanced distinctions that professional trust and safety teams apply. Your safety guidelines must decompose harm into specific categories, define each category with clinical precision, and provide evaluation criteria that reflect current harm research and platform policy standards.

Your safety guidelines must define harm categories at sufficient granularity to support consistent labeling. Self-harm content must be subdivided into suicidal ideation, suicide methods, non-suicidal self-injury, and eating disorder promotion, because these subcategories require different policy responses and different severity thresholds. Violence content must be subdivided into graphic violence, violence glorification, threats of violence, and coordinated harm, because context and intent matter differently in each subcategory. Child safety content must be subdivided into child sexual abuse material, child sexualization, child endangerment, and minor safety risks, because legal obligations and platform responses differ across these categories. Hate speech must be subdivided by target group, severity, and context, because content that targets protected characteristics requires different handling than general incivility. Your guidelines must provide detailed definitions, boundary examples, and decision trees for each subcategory.

Your safety guidelines must implement severity grading that reflects both content characteristics and context. A post describing suicidal ideation in abstract terms as part of a mental health education resource is categorically different from a post providing detailed suicide methods with encouragement to act. Your guidelines must define severity levels for each harm category, specify content and contextual factors that elevate or mitigate severity, and provide annotator instructions for handling edge cases. Severity grading must account for audience: content that is acceptable in an adult-oriented creative writing platform may be unacceptable in a platform accessible to minors. Your guidelines must specify how annotator should assess audience context and adjust severity ratings accordingly.

Your safety guidelines must specify mandatory escalation procedures for high-severity content. Annotators should not be making final policy decisions about content that depicts imminent threats, child sexual abuse material, or credible violence plans. Your guidelines must define escalation triggers, specify which content types require immediate escalation to trust and safety leadership, and provide clear procedures for flagging content that may require law enforcement reporting. If your jurisdiction has mandatory reporting requirements for certain content types, your guidelines must specify those requirements and ensure annotators understand their legal obligations. Escalation is not a quality assurance step. It is a harm mitigation step that must happen in real time.

Your safety guidelines must implement annotator exposure limits and psychological safety protocols. Reviewing high volumes of harmful content causes measurable psychological harm to annotators. Your guidelines must specify exposure limits per content type, require rotation schedules that limit continuous exposure to high-severity content, and provide access to mental health support resources. If your annotation team reviews child sexual abuse material, your guidelines must comply with industry standards for CSAM reviewer wellness, including mandatory break schedules, access to counseling, and limits on total exposure hours. You cannot treat annotator safety as secondary to annotation throughput. If your safety annotation operation harms the people performing it, you have failed both ethically and operationally.

Your safety guidelines must account for cultural and linguistic context in harm assessment. Content that constitutes hate speech in one cultural context may be acceptable discourse in another. Slurs and coded language vary across languages and regions. Your guidelines must provide cultural context for annotators, specify when cultural expertise is required for accurate assessment, and avoid imposing a single cultural framework on global content. If your platform operates in fifteen countries, your safety guidelines must reflect fifteen different cultural contexts, with locally-informed severity standards and escalation procedures. You cannot export a US-centric harm taxonomy to markets where the salient harms differ.

## Domain Experts Must Write Guidelines, Not Just Apply Them

The fundamental error in domain-specific annotation is treating guideline development as a product management task and guideline application as an annotation task. This division fails because the knowledge required to write effective domain guidelines is the same knowledge required to evaluate whether outputs meet domain standards. A product manager can specify that legal citations must be accurate, but cannot specify the seventeen dimensions of legal accuracy that a practicing attorney evaluates instinctively. An annotation operations lead can specify that medical outputs must not cause harm, but cannot define the clinical decision tree that determines harm potential.

You must involve domain experts in guideline authoring, not just guideline review. The attorney, physician, financial advisor, or trust and safety professional must sit down and write the evaluation criteria, the boundary examples, the decision trees, and the escalation triggers. They must do this before you hire annotators, before you write your annotation platform spec, and before you scope your labeling timeline. Domain expert time is expensive. It is also non-negotiable. If you are building a legal AI system and your annotation guidelines were not written by an attorney, your labels are worthless. If you are building a medical AI system and your annotation guidelines were not written by a clinician, your labels are dangerous. If you are building a financial AI system and your annotation guidelines were not written by a compliance officer, your labels expose you to regulatory liability.

Domain experts must also review annotator output at statistically meaningful sample rates. Even with excellent guidelines, annotators will make errors that reflect the limits of their domain knowledge. Your quality assurance process must include expert review of a random sample of annotations, calculation of expert-annotator agreement rates, and feedback loops that update guidelines when systematic disagreement patterns emerge. If expert-annotator agreement is below 90% for high-stakes domains, your guidelines are underspecified or your annotators are under-trained. You must iterate guidelines and retrain annotators until agreement meets domain-appropriate standards.

Domain-specific annotation guidelines are not a one-time development artifact. They are living documents that evolve as domain knowledge evolves, as regulations change, as model capabilities improve, and as your understanding of failure modes deepens. Your legal guidelines must be updated when major court decisions change precedent. Your medical guidelines must be updated when FDA approvals or clinical practice guidelines change. Your financial guidelines must be updated when securities regulations change. Your safety guidelines must be updated when new harm vectors emerge or when platform policy evolves. You must assign ongoing ownership of guideline maintenance to domain experts and budget for regular guideline review cycles.

The cost of domain expert involvement in annotation guidelines is high. The cost of deploying AI systems in specialized domains without domain expert involvement is catastrophic. You will produce labels that miss the distinctions that matter, pass outputs that violate professional standards, and ship systems that create liability your organization cannot sustain. Domain-specific guidelines are not an annotation operations problem. They are a domain expertise problem that requires domain expertise to solve.

With domain-specific guidelines in place, your focus shifts from what to evaluate to who evaluates it and how you build annotation teams that can apply these guidelines consistently at scale, which requires careful workforce design and annotator management strategies we explore in the next chapter.

