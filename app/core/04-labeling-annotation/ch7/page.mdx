# Chapter 7 — AI-Assisted Labeling, Weak Supervision, and Human-in-the-Loop

In 2026, no serious labeling program is purely manual. AI assists labeling at every stage — proposing draft labels, routing edge cases to humans, and generating labels programmatically through weak supervision. But the human remains the source of truth. This chapter covers the full spectrum of AI-human collaboration in labeling, from LLM-as-judge through weak supervision to hybrid pipeline design.

---

## What This Chapter Covers

- **7.1** — The 2026 Reality: AI Proposes, Humans Dispose
- **7.2** — LLM-as-Judge: Using Models to Generate Draft Labels
- **7.3** — Confidence-Based Routing: What Gets Auto-Labeled vs Human-Reviewed
- **7.4** — Active Learning: Prioritizing the Most Informative Examples
- **7.5** — Human Override Patterns: When and How to Reject AI Labels
- **7.6** — Calibrating AI Labelers Against Human Ground Truth
- **7.7** — The Automation Ceiling: What AI Cannot Label Reliably
- **7.8** — Hybrid Pipelines: Designing AI-Human Labeling Workflows
- **7.9** — Weak Supervision and Programmatic Labeling: Rules, Heuristics, and Labeling Functions
- **7.10** — Mixing Weak Labels with Expert Labels: Noise-Aware Strategies
- **7.11** — Cost-Quality Tradeoffs in AI-Assisted and Programmatic Labeling

---

*We start with the current reality: AI is already labeling most of your data, whether you designed it that way or not.*
