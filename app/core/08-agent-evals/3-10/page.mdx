# 3.10 — Plan Validation: Safety Checks Before Execution Begins

On December 3, 2025, an AI agent at a fintech startup called PayStream was asked to "reconcile all outstanding invoices with customer payment records and send reminder emails to customers with overdue balances." The agent generated an elegant fifteen-step plan in ninety-two seconds. Step one: query invoice database for unpaid invoices. Step two: query payment database for recent payments. Step three: match invoices to payments by customer ID and amount. Steps four through fourteen: various data processing and matching logic. Step fifteen: for each customer with overdue balance, send a reminder email using the email API. The plan was structurally sound, logically coherent, and would have worked perfectly if executed. But no one checked the plan before execution began. The agent executed all fifteen steps flawlessly, sending four hundred and seventy-three reminder emails to customers. Of those, sixty-two were sent to customers who had already paid but whose payments had not yet cleared the three-day processing window. Eighteen were sent to enterprise customers who had negotiated ninety-day payment terms and were not overdue. Seven were sent to customers whose accounts were in dispute and flagged for manual review. And one was sent to the CEO of PayStream's largest customer, who had paid on time but was matched incorrectly due to a database encoding issue. The CEO forwarded the email to PayStream's CEO with the subject line "Is this how you treat your best customers?" PayStream lost the account three weeks later, representing one point two million dollars in annual recurring revenue. The cost of the mistake was not the four dollars in email API fees. It was the lack of a pre-execution validation step that would have caught the policy violations, data quality issues, and high-risk actions before any emails were sent.

You cannot catch every agent error, but you can catch many of them before execution begins by validating the plan. A plan is a data structure that represents intended actions. You can analyze that data structure for safety violations, budget overruns, impossible operations, policy violations, and logical errors. You can check whether dependencies are satisfied, whether steps are in feasible order, whether the plan actually addresses the user's request. You can identify high-risk actions that require human approval. All of this analysis happens before any tools are called, before any side effects occur, before any damage is done. Plan validation is not a theoretical nicety; it is a practical necessity for any agent system that operates in production environments where mistakes have consequences. In 2026, the agent systems that consistently avoid catastrophic failures are the ones that validate plans rigorously before execution.

## Pre-Execution Validation Categories: Safety, Budget, Feasibility, Policy

Plan validation falls into four broad categories, each addressing a different failure mode. Safety validation checks whether the plan could cause harm. Budget validation checks whether the plan will exceed cost limits. Feasibility validation checks whether the plan can actually be executed. Policy validation checks whether the plan complies with organizational rules and constraints. A comprehensive validation system implements checks in all four categories.

Safety validation is the highest priority because safety failures have the worst consequences. A plan that deletes production data, sends inappropriate communications, or exposes sensitive information must be caught before execution. Safety validation checks for operations that are inherently dangerous: delete operations on production systems, write operations to critical files, API calls that modify external state, communications sent to external parties. It also checks for patterns that are often associated with errors: bulk operations without filtering, actions taken without confirmation, modifications made without backups.

Safety validation is domain-specific. For a customer service agent, sending an email is a normal operation, but sending hundreds of emails in a single execution is suspicious and might indicate a bug. For a data analysis agent, reading database records is normal, but writing to the database is unusual and potentially unsafe. Your safety rules must reflect the risk profile of your domain.

Domain-specific safety rules require careful analysis of what can go wrong. Conduct a failure modes and effects analysis for your agent system. List every operation the agent can perform. For each operation, identify potential failure modes: what happens if this operation is executed with wrong parameters, at the wrong time, on the wrong data, or too many times? For each failure mode, assess the severity of consequences. Then design validation rules that catch high-severity failure modes before execution.

Some organizations use red team testing for safety validation. A team tries to craft requests that will cause the agent to take dangerous actions. Can you trick the agent into deleting important data by phrasing a request cleverly? Can you make it send emails to unauthorized recipients? Can you cause it to exceed rate limits and incur huge costs? Red team findings inform safety validation rules: if red team discovered that vague requests about "cleaning up old data" could cause production data deletion, add a rule that flags any plan involving delete operations on production systems.

Another valuable technique is safety validation layering. Implement multiple independent safety checks, not just one. A plan that deletes production data should be caught by a rule that flags all delete operations, another rule that flags all production database access, and a third rule that flags operations without explicit user confirmation. If one rule fails to catch the issue, others provide backup. Defense in depth is critical for high-stakes operations.

Safety validation should also consider cascading effects. An operation might be safe in isolation but dangerous in combination with other operations. Deleting a temporary file is safe. Deleting all files in a directory is risky. If the directory happens to be a mount point to production storage, it is catastrophic. Validation must consider the context and cumulative effect of operations, not just individual actions.

Budget validation checks whether the plan will exceed cost limits. Cost comes from multiple sources: API calls to external services, LLM inference for reasoning steps, compute resources for data processing, storage for intermediate results. A plan that makes ten thousand API calls to an expensive service might cost hundreds of dollars. If the task is supposed to be a quick analysis, this is clearly wrong. Budget validation prevents runaway costs.

Budget validation requires cost estimation. For each step in the plan, estimate the cost: a database query costs X, an LLM call costs Y, an API call costs Z. Sum the costs to get the total plan cost. Compare to a budget threshold. If the estimated cost exceeds the threshold, flag the plan for review or rejection. Cost estimation is imperfect because you do not know exactly how many times a step will execute or what parameters will be used, but rough estimates are sufficient to catch egregious problems.

Cost estimation granularity matters. Fine-grained estimation tracks costs for every operation: this specific database query will scan this many rows and cost this much. Coarse-grained estimation uses averages: database queries cost about one cent on average. Fine-grained estimation is more accurate but requires detailed analysis of each step. Coarse-grained estimation is faster but misses expensive outliers. Use fine-grained estimation for steps that could be very expensive—bulk data processing, large-scale API calls—and coarse-grained estimation for routine operations.

Some systems use tiered budget validation. Green tier: estimated cost under ten dollars, auto-approve. Yellow tier: estimated cost ten to one hundred dollars, flag for review. Red tier: estimated cost over one hundred dollars, require explicit approval. This categorization provides clear escalation paths and ensures that expensive plans get appropriate oversight.

Budget validation should account for all cost types, not just obvious ones. Direct costs include API calls, LLM inference, and compute resources. Indirect costs include storage for intermediate results, network bandwidth, and opportunity cost of long-running tasks blocking other work. Some tasks have external costs: if the agent calls a paid service or makes a purchase, those costs must be included. Comprehensive cost estimation prevents surprises.

Budget validation also enables cost optimization suggestions. If the validator detects that a plan will make one hundred sequential API calls, it can suggest batching them into ten parallel calls to reduce total time and potentially cost. If the plan queries the same data source multiple times, suggest caching. Budget validation is not just about preventing overruns; it is about encouraging efficient plans.

Another dimension is budget allocation across tasks. If your agent system handles hundreds of tasks per day, you have a daily or monthly budget. Budget validation can enforce per-task limits and aggregate limits. A single task might be under budget, but if you have already spent ninety percent of your daily budget, even a moderate-cost task might be rejected to preserve capacity for higher-priority tasks. This requires centralized budget tracking and coordination across agent executions.

Feasibility validation checks whether the plan can actually be executed given the current environment and available resources. A plan that references a file that does not exist is infeasible. A plan that calls a tool that is not available is infeasible. A plan that requires more memory than the system has is infeasible. Feasibility validation catches these errors before execution.

Feasibility checks include resource availability: are the required tools accessible, are the required APIs reachable, are the required files present? They include permission checks: does the agent have permission to perform the planned operations? They include constraint checks: does the plan violate rate limits, concurrency limits, or data size limits? Each check prevents a category of execution failures.

Policy validation checks whether the plan complies with organizational policies and regulations. Policies might require human approval for certain actions, prohibit access to certain data sources, mandate specific workflows for compliance, or restrict communication with external parties. A plan that violates policy might be technically feasible but organizationally unacceptable. Policy validation enforces these constraints.

Policy validation is often the most complex category because policies are expressed in natural language, not formal rules. Translating "all communications with enterprise customers must be reviewed by account managers" into executable validation logic is non-trivial. You need to identify which steps involve communication, which customers are enterprise customers, and which steps lack the required review. This requires semantic understanding of both the policy and the plan.

One approach to policy validation is to use LLMs for policy interpretation. Provide the agent with the organization's policies in natural language as part of the system prompt or context. After generating a plan, prompt the agent to check whether the plan complies with each policy. "Does this plan comply with the policy that all financial data must be encrypted at rest?" The agent reasons about the plan and the policy and identifies violations. This is flexible and handles nuanced policies, but it is not foolproof: LLMs can miss violations or hallucinate compliance.

Another approach is to formalize policies into rules. Work with compliance teams to translate high-level policies into specific, checkable conditions. "All communications with enterprise customers must be reviewed by account managers" becomes: if step involves send_email AND recipient is enterprise customer, then plan must include human_review step. These formalized rules can be checked mechanically without LLM reasoning. The challenge is that formalization loses nuance: edge cases and exceptions might not be captured.

A hybrid approach uses formal rules for clear-cut policies and LLM reasoning for ambiguous ones. Data retention policies, access control policies, and workflow approval policies are often formalizable. Ethical guidelines, brand voice requirements, and contextual appropriateness policies are harder to formalize and benefit from LLM judgment.

Policy validation should produce actionable feedback. Instead of just saying "this plan violates policy X," explain why and suggest fixes. "This plan violates the enterprise customer communication policy because step five sends an email to Acme Corp without account manager review. Add a human review step before step five." Actionable feedback enables plan revision rather than outright rejection.

Some organizations maintain a policy knowledge base that the agent can query. Instead of encoding all policies as rules, store them in a searchable database. When the agent generates a plan that might have policy implications, it queries the knowledge base: "Are there policies related to customer communications?" The knowledge base returns relevant policies, which the agent then checks against the plan. This scales better than hardcoding all policies into the validation logic.

Policy validation also needs version control. Policies change over time as regulations evolve and organizational practices adapt. The validation system must use the correct version of policies for each task. Timestamp plans and policies, and validate plans against policies that were in effect at the time of task creation. This prevents retrospective compliance issues where old plans are judged against new policies.

## Structural Validation: Dependencies, Ordering, Completeness

Beyond the four main categories, there is a layer of structural validation that checks the plan's internal coherence. Structural validation is about the plan itself, not its interaction with the environment. A plan might be unsafe, over-budget, infeasible, or policy-violating, but even if it passes all those checks, it can still be structurally invalid.

Dependency validation checks whether all dependencies are satisfied. If step five depends on the output of step three, step three must be executed before step five. This seems obvious, but agents sometimes generate plans with circular dependencies, missing dependencies, or out-of-order steps. Dependency validation constructs a dependency graph and checks that it is acyclic and that the execution order respects the dependencies.

A common error is assuming data is available when it has not been generated. A plan might include "analyze the customer feedback data" without a prior step to fetch the data. The plan implicitly assumes the data is already available, but it is not. Dependency validation catches this by checking that every data reference has a corresponding data generation step.

Ordering validation checks whether steps are in a feasible order. Some ordering constraints are logical: you cannot delete a file before creating it. Some are practical: you should gather data before analyzing it. Some are efficiency-based: you should deduplicate records before processing them, not after. Ordering validation checks for violations of known ordering constraints.

Ordering validation is weaker than dependency validation because it does not enforce hard constraints, only best practices. A plan that processes data before deduplicating is inefficient, not wrong. Ordering validation flags these inefficiencies so they can be corrected, but it does not necessarily block execution.

Completeness validation checks whether the plan fully addresses the user's request. This is the hardest structural validation because it requires semantic understanding. If the user asks to "research competitors and identify feature gaps," a plan that only researches competitors is incomplete. Completeness validation must compare the plan's goals to the user's request and verify that all aspects are covered.

One approach to completeness validation is to have the agent explain how the plan achieves the goal. "This plan addresses the request by: step one identifies competitors, steps two through six gather features, step seven compares features, step eight identifies gaps. Therefore all aspects of the request are covered." If the agent cannot produce a coherent explanation, the plan is likely incomplete.

Another approach is to use a checklist. For common task types, maintain a checklist of required components. For a "research competitors" task, the checklist might include: identify competitors, gather data about competitors, analyze data, produce summary. Validate that the plan includes steps for each checklist item. This works well for predictable, recurring task types.

Structural validation is language-agnostic: it works on any plan representation, whether the plan is expressed in natural language, JSON, a DAG, or a custom format. The key is to extract the structural properties—dependencies, ordering, coverage—and validate them.

Explicit dependency tracking enables better validation and optimization. If you know that step five depends on step three but not step four, you can parallelize steps four and five. If you know that steps six through ten all depend on step two, you can flag this as a potential bottleneck and suggest batching or caching step two's output. Dependency information also enables better error handling: if step three fails, you know that step five cannot proceed, but step four might still be viable.

Building dependency graphs from natural language plans is challenging. The agent must parse the plan, identify data flows between steps, and construct the graph. This requires understanding what each step produces and what each step consumes. Some systems use structured plan representations—steps are JSON objects with explicit input and output fields—to make dependency extraction mechanical. Others use LLM reasoning to infer dependencies from natural language descriptions.

Validation rules for dependencies vary by plan complexity. For simple linear plans, just check that steps are in a sensible order: data is gathered before it is analyzed, analysis is completed before results are summarized. For complex plans with branching or parallelism, validate that all paths through the plan satisfy dependencies, that parallel branches do not have hidden dependencies on each other, and that branches rejoin correctly.

Circular dependencies are a particularly insidious error. Step A depends on step B, which depends on step C, which depends on step A. No valid execution order exists. Circular dependencies usually indicate a flawed decomposition: the agent has misunderstood the task or created an impossible plan. Dependency validation must detect cycles and reject such plans. Topological sort algorithms naturally detect cycles: if the sort fails, a cycle exists.

Missing dependencies are another common error. The plan includes a step that uses data, but no prior step generates that data. The plan assumes data is magically available without being fetched or computed. Validation can detect missing dependencies by tracking data provenance: for each data reference in a step, trace back to the step that produced it. If no such step exists, the dependency is missing.

## Semantic Validation: Does the Plan Actually Solve the Problem

Semantic validation goes beyond structure to ask: does this plan actually achieve the user's goal? A plan can be structurally perfect, pass all safety and budget checks, and still be wrong because it solves the wrong problem. Semantic validation requires understanding both the user's intent and the plan's likely outcomes.

The most direct form of semantic validation is simulation. Execute the plan mentally or in a simulation environment, predict the outcomes, and check whether the outcomes match the goal. If the user asks for a list of overdue customers and the plan produces a list of all customers, simulation reveals the mismatch. Simulation is expensive because it requires reasoning through the plan's logic, but it is effective.

A lighter-weight approach is sanity checking. Apply common-sense rules to detect obviously wrong plans. If the user asks for a summary and the plan produces raw data without summarization, that is wrong. If the user asks for recent data and the plan queries historical archives, that is wrong. Sanity checks do not guarantee correctness, but they catch egregious errors.

Another approach is to compare the plan to reference plans for similar tasks. If the system has previously executed "research competitors" tasks successfully, it has a corpus of known-good plans. Compare the new plan to the reference plans. Large deviations are suspicious and merit review. Similar plans are more likely to be correct. This requires maintaining a library of reference plans and a notion of plan similarity, which adds complexity.

You can also use critique-based validation. After generating a plan, have a separate LLM critique it. "Review this plan. Does it fully address the user's request? Are there logical errors? Are there missing steps?" The critique identifies potential issues, which can then be fixed or flagged for human review. Critique-based validation is expensive—it requires an additional LLM call—but it catches errors that rule-based validation misses.

Semantic validation is inherently imperfect because you cannot know for certain whether a plan is correct without executing it. But you can detect many errors with high confidence. If a plan for "analyze Q4 sales" queries Q3 data, you can confidently say it is wrong. If a plan for "send reminder emails" sends emails without checking payment status, you can confidently say it is risky. Semantic validation is about catching the errors you can detect, not about achieving perfection.

## Safety Validation: Risk Tiers, Permissions, and Constraints

Safety validation is the most critical validation category for production systems. A detailed safety validation framework divides operations into risk tiers and enforces different rules for each tier. Low-risk operations like reading data or performing calculations can execute without special checks. Medium-risk operations like querying external APIs or writing to temporary storage require basic validation: check that parameters are reasonable, that rate limits will not be exceeded, that error handling is in place. High-risk operations like modifying production data, sending communications, or making purchases require strict validation and often human approval.

Risk tier assignment is domain-specific. For a data analysis agent, writing to a database is high-risk. For a data pipeline agent, writing to a database is normal and low-risk. Your risk tiers must reflect your domain's threat model. A useful heuristic is to ask: if this operation is executed incorrectly, what is the worst-case impact? If the worst case is catastrophic—data loss, customer harm, regulatory violation—the operation is high-risk.

Permission validation checks whether the agent is authorized to perform the planned operations. Permissions are usually role-based: the agent is granted certain roles, and each role allows certain operations. A plan that includes an operation not allowed by the agent's roles is rejected. Permission validation prevents agents from exceeding their authorized scope.

Permission systems should be granular. Instead of a single "admin" permission that allows everything, have specific permissions for each operation type: read_database, write_database, send_email, call_external_api. Grant the agent only the permissions it needs for its intended tasks. This principle of least privilege limits the damage from bugs or security vulnerabilities.

Constraint validation checks whether the plan respects system constraints. Constraints include rate limits: the plan should not call an API more times than the rate limit allows. Concurrency limits: the plan should not launch more parallel operations than the system can handle. Data size limits: the plan should not attempt to load more data than fits in memory. Budget limits: the plan should not exceed cost thresholds. Constraint validation prevents resource exhaustion and runaway costs.

Some constraints are hard: violating them causes immediate failure. If you exceed a rate limit, the API returns an error. Some constraints are soft: violating them degrades performance but does not cause failure. If you load too much data into memory, the system slows down but does not crash. Safety validation should enforce hard constraints strictly and soft constraints with warnings.

Pattern-based safety validation looks for dangerous patterns in plans. Bulk operations without filtering: if the plan says "for each record in the database, do X," check that there is a filter to limit the number of records. Actions without confirmation: if the plan sends emails or makes purchases, check that there is a confirmation step or human approval. Irreversible operations without backups: if the plan deletes files, check that there is a backup or versioning system. These patterns are not always wrong, but they are often associated with bugs.

## Human Review of Plans: When to Require Approval Before Execution

For high-risk plans, automated validation is not sufficient. You need human review. The question is: which plans require human review, and how do you integrate review into the agent workflow without making the system unusable?

The simplest rule is risk-based: high-risk plans always require human review, medium-risk plans require review if they fail certain validation checks, low-risk plans never require review. This categorization is automatic based on the operations in the plan. A plan that includes sending emails to customers is high-risk. A plan that only reads data is low-risk.

Another rule is cost-based: plans estimated to cost more than a threshold require human review. If a plan will cost one hundred dollars to execute, a human should verify that the expense is justified. Cost-based review prevents budget overruns and catches plans that are inefficiently designed.

A third rule is novelty-based: plans that use tools or patterns the agent has not used before require human review. Novel plans are more likely to contain errors because the agent has less experience with them. Once a plan type has been reviewed and approved multiple times, it can be moved to auto-approval. This gradually expands the agent's autonomy as it proves reliability.

When human review is required, the system should present the plan in a clear, understandable format. Show the user's original request, the agent's plan broken into numbered steps, the estimated cost and execution time, and any validation warnings or risks identified. Allow the human to approve, reject, or modify the plan. If the plan is rejected, collect feedback on why, and use that feedback to improve future plans.

Human review introduces latency. If the agent generates a plan and then waits for human approval, the task is paused until the human responds. This is acceptable for high-stakes tasks where correctness is more important than speed, but it is unacceptable for real-time applications. You need to balance safety and responsiveness.

One approach is asynchronous review for non-urgent tasks. The agent generates a plan, submits it for review, and moves on to other tasks. When the plan is approved, the agent resumes and executes it. This parallelizes work and reduces the effective latency of review.

Another approach is to batch review. Instead of reviewing plans one at a time, collect multiple plans and review them together. A human might review ten plans in a single session, approving or rejecting each. Batching reduces the per-plan review overhead and makes review more efficient.

You can also implement tiered review. Low-stakes plans are reviewed by junior staff or automated systems. High-stakes plans are escalated to senior staff or domain experts. This allocates review effort where it has the most impact.

Finally, build in review feedback loops. Track which plans were approved, which were rejected, and why. If certain types of plans are consistently rejected, the agent is generating bad plans and needs improvement. If certain types of plans are consistently approved without modification, they can be moved to auto-approval. Review data is valuable for tuning both the agent's planning and the validation rules.

## Automated Plan Validators: Rules, Heuristics, and Learned Models

Automated validators are the workhorse of plan validation. They run instantly, cost nothing beyond compute, and can enforce complex rules consistently. Building effective validators requires a mix of hardcoded rules, heuristics, and in some cases, learned models.

Hardcoded rules are the simplest validators. "If the plan includes a delete operation on a production database, reject it." "If the plan includes sending more than one hundred emails, flag for review." "If the plan calls an external API without error handling, reject it." These rules are deterministic, easy to understand, and easy to debug. The challenge is that you need to enumerate all the rules, and there are always edge cases you did not think of.

Heuristics are softer rules that flag potential issues without definitively rejecting the plan. "If the plan includes many similar steps, it might be inefficient." "If the plan queries multiple databases for the same information, it might be redundant." "If the plan does not include a summarization step but the user asked for a summary, it might be incomplete." Heuristics generate warnings that a human or the agent can evaluate.

Learned models use machine learning to predict whether a plan is correct. Train a model on a dataset of plans labeled as correct or incorrect. The model learns patterns that correlate with correctness: correct plans tend to have certain structures, use certain tools in certain orders, have certain properties. At validation time, the model scores the plan and flags low-scoring plans for review. This is more sophisticated than rules or heuristics, but it requires labeled training data and model maintenance.

A hybrid approach combines rules, heuristics, and learned models. Rules catch definite errors. Heuristics flag suspicious patterns. Learned models provide an overall correctness score. The combination is more robust than any single approach.

Validators should be fast. Plan validation happens before execution, and if validation takes too long, it negates the latency benefits of fast planning. Most validators are lightweight: they analyze the plan data structure without executing any steps. Validators that require external calls—checking if a file exists, querying database metadata—are slower and should be used selectively.

Validators should be composable. Each validator checks one aspect of the plan: safety, budget, dependencies, completeness. The validation system runs all applicable validators and aggregates the results. If any validator rejects the plan, execution is blocked. If multiple validators generate warnings, they are all presented together. Composability makes it easy to add new validators as you discover new failure modes.

## Practical Implementation for Your Agent System

When you implement plan validation in your agent system, start by identifying the failure modes you most want to prevent. What are the worst things your agent could do? Make a list: delete production data, send inappropriate emails, exceed budget, violate compliance rules. For each failure mode, design a validator that catches it.

Implement validators as separate functions or modules, not as monolithic code. Each validator takes a plan as input and returns a result: pass, fail, or warning with details. This makes validators easy to test, easy to add or remove, and easy to understand.

Decide on a validation policy: which validations are mandatory, which are optional, which cause rejection versus warnings. Document the policy clearly so that developers and users understand what will and will not be allowed.

Integrate validation into the agent workflow. After the agent generates a plan, before execution begins, run all applicable validators. If any validator fails with a rejection, block execution and report the error to the user. If validators generate warnings, decide whether to proceed with execution, flag for human review, or ask the user. The decision depends on your risk tolerance.

Make validation results visible. When a plan is validated, log the results: which validators ran, which passed, which failed, which generated warnings. This visibility is valuable for debugging and for understanding why certain plans were blocked.

Build feedback loops. Track which plans pass validation and succeed, which plans pass validation and fail during execution, and which plans fail validation. If plans that pass validation frequently fail during execution, your validators are not catching real errors and need improvement. If plans that fail validation would have succeeded, your validators are too strict and need relaxation. Use production data to tune your validators over time.

Start simple and add complexity as needed. Begin with a few critical safety rules. As you observe failures in production, add validators to catch those failures. Do not try to build a perfect validation system upfront; build a system that evolves based on real-world experience.

Finally, remember that validation is a defense layer, not a guarantee. Even with rigorous validation, some errors will slip through. Plan validation reduces the frequency and severity of errors, but it does not eliminate them. Combine validation with other safety mechanisms: monitoring during execution, rollback capabilities, circuit breakers for external APIs, rate limits on risky operations. Defense in depth is the key to robust agent systems.

Plan validation is unglamorous work. It does not involve cutting-edge AI research or impressive demos. But it is the difference between an agent system that is a research prototype and an agent system that is production-ready. The companies that deploy reliable, trustworthy agents in 2026 are the ones that take validation seriously.

## Advanced Validation Techniques: Simulation and Formal Methods

Beyond rule-based validation, advanced systems use simulation and formal verification. Plan simulation executes the plan in a sandboxed environment using mock tools and synthetic data. If the simulated execution produces the expected outcome, the plan is likely correct. If it fails or produces unexpected results, the plan has errors that should be fixed before real execution.

Simulation catches errors that static analysis misses. A plan might be structurally sound and pass all rule-based checks, but when executed, it produces garbage because of subtle logic errors. Simulation reveals these errors by actually running the plan's logic, not just analyzing its structure.

The challenge with simulation is cost and complexity. You need a simulation environment that accurately models real tools without causing real side effects. You need synthetic data that represents realistic scenarios. You need to run the simulation fast enough that it does not add excessive latency. These requirements make simulation expensive to implement and operate.

Lightweight simulation is more practical. Instead of fully executing each step, symbolically trace data flows. Given mock inputs to step one, what would step one produce? Use that mock output as input to step two. Continue until you reach the end. If the final mock output matches the expected result type and structure, the plan is probably correct. This is faster than full simulation but still catches many logic errors.

Formal verification uses mathematical techniques to prove plan correctness. Represent the plan as a formal specification, encode preconditions and postconditions for each step, and use automated theorem provers to verify that executing the steps satisfies the postconditions. This provides strong guarantees but requires significant expertise and tooling. In 2026, formal verification is rare in production agent systems, used only in safety-critical domains like medical devices or financial trading where correctness guarantees justify the cost.

Another advanced technique is adversarial validation. Generate variations of the plan that are subtly wrong—swap two steps, remove a dependency, change a parameter—and check whether your validators catch the errors. If they do not, your validation is incomplete. Adversarial validation tests the validators themselves, ensuring they are robust and not just rubber-stamping plans.

Some systems use historical data for validation. Maintain a database of past plans and their outcomes: which plans succeeded, which failed, and why. When validating a new plan, compare it to historical plans. If it is similar to successful plans, approve it. If it is similar to failed plans, flag it for review. Historical comparison leverages accumulated experience to improve validation accuracy.

Machine learning can enhance validation. Train a classifier on labeled plans: correct versus incorrect, safe versus unsafe, efficient versus wasteful. Use the classifier to score new plans. Low-scoring plans get extra scrutiny. This is complementary to rule-based validation: rules catch known failure modes, the classifier catches patterns that humans have not explicitly codified.

The optimal validation strategy combines multiple techniques. Use fast rule-based checks to catch obvious errors. Use lightweight simulation for logic errors. Use historical comparison for pattern matching. Use human review for high-stakes or novel plans. Layer these techniques to achieve high recall—catch most errors—without excessive false positives or cost.

## Validation Performance: Balancing Thoroughness and Speed

Validation adds latency to the agent workflow. The plan must be generated, then validated, then executed. If validation takes too long, it negates the latency benefits of fast planning and frustrates users. You must balance thoroughness—catching as many errors as possible—with speed—keeping validation time acceptable.

Measure validation latency and its impact on end-to-end task completion time. If validation takes two seconds and total task time is sixty seconds, the overhead is manageable. If validation takes ten seconds and total task time is fifteen seconds, validation is a bottleneck. Optimization is needed.

Optimization strategies include parallelization: run independent validation checks concurrently rather than sequentially. If safety validation and budget validation do not depend on each other, run them at the same time. This reduces total validation time to the maximum of individual check times rather than the sum.

Another strategy is early termination: if a high-priority validation check fails, stop validation immediately and report the error. Do not waste time running other checks if you already know the plan will be rejected. This is especially valuable when validation includes expensive operations like simulation or LLM-based policy checking.

Caching validation results can help for recurring tasks. If a user runs the same task repeatedly, and the plan is identical, reuse the previous validation result instead of re-validating. This assumes validation rules have not changed, which requires tracking validator versions and invalidating caches when rules update.

Asynchronous validation decouples validation from plan presentation. Present the plan to the user immediately, then validate in the background. If validation succeeds, proceed to execution. If it fails, notify the user and block execution. This reduces perceived latency: users see the plan quickly, even though validation is still running. The risk is that users might review and approve a plan before validation completes, only to have execution blocked afterward.

Tiered validation offers another tradeoff. Perform fast, high-value checks first—safety and budget—then proceed to slower checks like completeness or efficiency analysis. If fast checks pass, the plan can proceed to execution while slower checks continue in the background. If slower checks later identify issues, log them for future improvement but do not block the current execution. This prioritizes critical validation while allowing non-critical validation to complete at its own pace.

The right balance depends on your risk tolerance and performance requirements. High-stakes applications should prioritize thoroughness even at the cost of latency. Real-time applications should prioritize speed even if some errors slip through. Most applications fall in between and benefit from layered validation with fast critical checks and slower optional checks.

## Validation Feedback Loops: Learning from Errors

Validation is not a static system; it should evolve based on production experience. Track validation outcomes: which plans were rejected and why, which plans passed validation but failed during execution, which plans succeeded. Analyze patterns to identify gaps in validation coverage.

If plans frequently fail execution due to errors that validation did not catch, those are false negatives. Add validation rules to catch those errors in the future. If plans are frequently rejected by validation but would have succeeded if executed, those are false positives. Relax or refine validation rules to reduce unnecessary rejections.

False negatives are more dangerous than false positives. A false negative allows a bad plan to execute, potentially causing harm or wasting resources. A false positive rejects a good plan, causing frustration but no harm. Tune validation to minimize false negatives even if it increases false positives.

Some organizations use a shadow validation mode for new validators. Run the new validator on all plans but do not enforce its decisions. Just log what it would have done. Compare shadow results to actual outcomes. If the new validator would have caught errors that slipped through, promote it to enforcement mode. If it would have rejected good plans, refine it before enforcement.

User feedback on validation errors is valuable. When validation rejects a plan, ask the user if the rejection was correct. If the user says "yes, that plan was wrong," the validator is working. If the user says "no, the plan was fine," investigate why the validator flagged it. User feedback provides ground truth that pure outcome analysis misses.

Another feedback mechanism is A/B testing. Run variant A with strict validation and variant B with lenient validation. Compare error rates, user satisfaction, and task success rates. The variant with better outcomes informs validation policy tuning. Be careful with A/B testing in high-stakes scenarios where exposing some users to lenient validation risks harm.

Validation metrics should be dashboarded and monitored continuously. Track rejection rate, rejection reasons, false negative rate, false positive rate, validation latency. Set alerts for anomalies: if rejection rate suddenly spikes, investigate whether validation rules changed or incoming tasks changed. Continuous monitoring enables rapid response to validation issues.

Finally, document validation decisions. When a plan is rejected, log not just that it was rejected but which specific rules or checks caused the rejection and why. This documentation helps users understand errors, helps engineers debug validation logic, and provides audit trails for compliance. Good validation systems are transparent, not black boxes.

The best validation systems are those that learn from every plan, adapt to changing tasks and environments, and continuously improve their accuracy. Static validation catches known errors. Adaptive validation catches emerging error patterns. In 2026, the difference between good and great agent systems is often the sophistication of their validation and their commitment to continuous improvement based on production data.
