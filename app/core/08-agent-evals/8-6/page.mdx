# 8.6 â€” Budget Guardrails: Enforcing Cost and Token Limits

In June 2025, a SaaS company launched an AI agent that helped sales teams generate personalized outreach emails. The agent used GPT-4o and had access to a company database with prospect information, industry research, and past email templates. The product launched to 200 users on a Monday morning. By Wednesday afternoon, the company had burned through $47,000 in OpenAI credits. The finance team noticed the spike when an automated alert fired for unusual cloud spending. Engineering investigated and discovered the root cause: a single user had set up an automation that called the agent 12,000 times in a loop, generating emails for an entire prospect list. Each agent call made three LLM requests: one for research, one for drafting, one for refinement. At $0.03 per call, 36,000 requests cost $1,080. But the real problem was that the agent had no cost limit. When twelve other users saw how well the automation worked, they copied it. By the time engineering shut down the agent, 180 users had collectively made 890,000 LLM calls in 52 hours. The company's OpenAI account was nearly suspended for exceeding rate limits. The company had to refund customers, apologize to OpenAI, and disable the agent for three weeks while they built cost controls. The post-mortem conclusion was simple: they had shipped an agent with no budget guardrails. They assumed users would use the product reasonably. They were catastrophically wrong.

## The Uncapped Cost Risk

Agents are expensive. Every agent invocation consumes tokens. Every tool call, every retrieval query, every LLM inference adds cost. If you don't cap that cost, a single user or a single runaway process can burn thousands or tens of thousands of dollars in hours. This is not a hypothetical risk. It happens regularly. Teams ship agents without cost limits, users exploit them intentionally or accidentally, and cloud bills explode. Budget guardrails are the controls that prevent this. They enforce spending limits at the user level, query level, and system level. They ensure that no single request, no single user, and no single day can exceed a predefined cost threshold. Without these guardrails, your agent is a financial liability.

The core problem is that users do not see the cost of agent invocations. When a user sends a query to the agent, they do not know whether that query will cost $0.02 or $2.00. They do not know how many tokens it will consume. They do not know how many tool calls it will trigger. They just click submit and expect an answer. If the agent is fast and useful, they will use it heavily. If they can automate it, they will. If they can script bulk requests, they will. Users optimize for their own productivity, not for your API bill. You must enforce cost constraints programmatically, because users will not self-regulate.

The second problem is that agent costs are dynamic and unpredictable. Unlike traditional software where compute cost per request is roughly constant, agent costs vary by query complexity. A simple query might use 500 tokens and cost $0.01. A complex query might use 50,000 tokens, call four tools, retrieve 200 documents, and cost $1.50. You cannot predict cost from the query text alone. You can only measure it at runtime. This means you need real-time cost tracking and enforcement. You cannot rely on monthly spending reports or post-hoc analysis. By the time you notice the problem, you have already burned the money.

Budget guardrails solve this by enforcing limits at multiple layers. You set a maximum cost per query. You set a maximum cost per user per day. You set a maximum cost for the entire system per day. When any of these limits is reached, the agent stops processing new requests until the limit resets or the budget is increased. This is not user-hostile. It is responsible product design. Users understand rate limits and quotas. They do not expect unlimited free usage. What they do not tolerate is surprise bills or degraded service because other users exhausted the system budget. Budget guardrails protect both you and your users from runaway costs.

## Per-Query Cost Limits

The first and most important budget guardrail is a per-query cost limit. You define the maximum amount of money a single agent invocation is allowed to spend. If the agent exceeds that limit during execution, you terminate the request and return an error to the user. This prevents any single query from consuming unbounded resources. It also prevents adversarial users from crafting expensive queries to drain your budget.

Per-query limits are enforced by tracking token usage in real time. Before each LLM call, you estimate the cost based on the input token count and the model pricing. After each LLM call, you measure the actual cost based on the response token count. You maintain a running total for the query. When the total exceeds the threshold, you stop execution. You do not make additional LLM calls. You do not call additional tools. You return a message to the user: "This query exceeded the cost limit. Please simplify your request or contact support."

Setting the right per-query limit requires understanding your agent's typical cost distribution. You log the cost of every query for a week. You analyze the distribution. You find that 90 percent of queries cost less than $0.10. Five percent cost between $0.10 and $0.50. One percent cost between $0.50 and $2.00. A tiny fraction cost more than $2.00. You set your per-query limit at $1.00, which allows the 99th percentile to succeed but blocks the outliers. If a user hits the limit, you investigate. Is the query legitimately complex, or is the user trying to abuse the system? If legitimate, you allow the query through manually or raise the limit for that user. If abusive, you block the user.

Per-query limits also protect against infinite loops. If the agent gets stuck in a reasoning loop, calling tools repeatedly without making progress, the cost will grow unbounded. The budget guardrail terminates the loop when the cost limit is reached. This is a safety mechanism. It prevents the agent from running forever. It also prevents you from paying for wasted computation. Without a per-query limit, a buggy agent can burn hundreds of dollars on a single request before you notice.

One implementation detail: you need to estimate token usage before making the LLM call, not after. If you wait until after the call, you have already spent the money. The estimate allows you to reject the call proactively if it would exceed the limit. You estimate by counting input tokens and assuming a maximum output token count based on the model's limits. For example, if the input is 30,000 tokens and the model supports up to 4,096 output tokens, you assume worst-case cost. If that worst-case exceeds your limit, you reject the query before calling the model. This is conservative, but it prevents overspend.

Per-query limits are the most granular budget control. They operate at the request level. They are fast, deterministic, and enforceable. Every production agent must have a per-query cost limit. There is no excuse for skipping this.

## Per-User Budget Quotas

The second layer is per-user budget quotas. You allocate a spending limit to each user for a defined time period: per day, per week, or per month. When the user exhausts their quota, the agent stops accepting new queries from that user until the quota resets. This prevents any single user from monopolizing the system budget. It also prevents users from accidentally or intentionally running up massive bills.

Per-user quotas are enforced by tracking cumulative spending per user. Every time the agent processes a query, you record the cost and associate it with the user's account. You maintain a running total for the current period. Before processing a new query, you check whether the user has budget remaining. If yes, you proceed. If no, you reject the query with a message: "You have reached your daily usage limit. Your quota will reset at midnight UTC."

Quota limits should be generous enough for normal use but tight enough to prevent abuse. For a free-tier agent, you might set a quota of $1.00 per user per day. For a paid-tier agent, you might set a quota of $10.00 per user per day. For an enterprise agent, you might set a quota of $100.00 per user per day or disable quotas entirely and rely on contract-level spending caps. The quota should align with your pricing model and expected usage patterns. If legitimate users regularly hit the quota, it is too low. If abusive users can burn through the quota without consequences, it is too high.

Per-user quotas also enable usage-based pricing. If your business model charges users based on agent usage, the quota is the mechanism for enforcing that charge. You set the quota equal to the user's purchased credits. When they run out, they either buy more credits or wait for the quota to reset. This is standard for API-based products. It is equally applicable to agent products. Users pay for what they use, and the quota ensures they cannot use more than they paid for.

One important design choice is whether to hard-block users who exceed their quota or to soft-throttle them. Hard-blocking means rejecting all queries once the quota is exhausted. Soft-throttling means allowing queries to proceed but at a reduced rate or quality. For example, you might switch the user to a cheaper model, reduce the context window size, or disable certain tools. Soft-throttling provides a degraded experience instead of no experience. It keeps users engaged while still controlling costs. The choice depends on your product priorities. If cost control is paramount, hard-block. If user retention is paramount, soft-throttle.

Per-user quotas also protect against account compromise. If an attacker gains access to a user's account, they may try to abuse the agent to rack up costs or exfiltrate data. The quota limits the damage they can do. Even if they script thousands of queries, they will hit the quota quickly and be locked out. This is not a substitute for proper authentication and access control, but it is a useful secondary defense.

## System-Wide Cost Limits

The third layer is system-wide cost limits. You set a maximum total spend for the entire agent system per day or per month. When the system reaches that limit, the agent stops accepting new queries from all users until the limit resets or you increase the budget. This is the circuit breaker. It prevents runaway spending at the aggregate level. It ensures that no matter how many users you have or how they behave, your total agent costs cannot exceed a predefined cap.

System-wide limits are enforced by tracking total spending across all users. Every agent invocation increments a global counter. Before processing a new query, you check whether the system has budget remaining. If yes, you proceed. If no, you reject the query with a message: "The system is currently at capacity. Please try again later." This is a blunt instrument. It affects all users equally, regardless of whether they contributed to the overspend. But it is necessary. Without a system-wide cap, a sudden spike in usage can bankrupt your project.

Setting the system-wide limit requires forecasting expected usage. If you have 1,000 users and each uses the agent 10 times per day at an average cost of $0.05 per query, your daily cost is $500. You set your system-wide limit at $750 to allow headroom for growth and spikes. If usage exceeds $750 in a day, you investigate. Is this organic growth, or is something wrong? If organic, you increase the limit. If anomalous, you diagnose and fix the issue. The system-wide limit is not a permanent constraint. It is a safety threshold that triggers review and intervention.

System-wide limits also protect against distributed abuse. If multiple users collude to exhaust your budget, per-user quotas may not stop them. Each user stays under their individual limit, but collectively they exceed the system capacity. The system-wide limit catches this. It is the final safeguard. It ensures that total spending is bounded, no matter what users do individually.

One operational challenge is communicating system-wide capacity to users. If the system hits the limit and starts rejecting queries, users need to understand why. The error message should be clear and actionable: "The system has reached its daily usage capacity. Service will resume at midnight UTC. We apologize for the inconvenience." You also notify your team immediately when the system limit is reached, because it indicates either a usage spike or a cost control failure. This is a critical alert. It requires immediate investigation.

System-wide limits are the last line of defense. They prevent total cost from spiraling out of control. They are not a substitute for per-query and per-user limits. They are a complement. You need all three layers to enforce budget discipline at every level of the system.

## Token Budgets for Multi-Step Agents

Multi-step agents are particularly vulnerable to cost overruns because they make multiple LLM calls per query. Each step consumes tokens. Each tool call consumes tokens. If the agent takes ten steps to answer a query, it may consume ten times the tokens of a single-step agent. You need token budgets to cap the total tokens an agent can use per query, regardless of how many steps it takes.

Token budgets work like cost budgets, but they track tokens instead of dollars. You set a maximum token count per query, such as 100,000 tokens. The agent tracks cumulative token usage across all steps. When the total exceeds the budget, the agent terminates and returns the best answer it has so far, or an error if it has not made sufficient progress. This prevents the agent from consuming unbounded tokens in pursuit of a perfect answer.

Token budgets are especially important for agentic loops where the agent decides dynamically how many steps to take. If the agent is allowed to run indefinitely, it will. It will keep refining, keep retrieving, keep reasoning until it reaches a stopping condition. If the stopping condition is poorly defined, the agent may never stop. The token budget is a hard stop. It ensures the agent terminates even if its internal logic fails.

You configure token budgets based on the model's context window and your cost tolerance. If you are using a model with a 128,000-token context window, you might set a per-query token budget of 50,000 tokens. This allows the agent to use a substantial portion of the context window but prevents it from maxing out. If the agent needs more tokens, it must be more selective about what it retrieves and processes. This forces the agent to be efficient.

Token budgets also help with latency control. More tokens mean longer processing time. If you cap tokens, you implicitly cap latency. A query that uses 10,000 tokens completes faster than a query that uses 100,000 tokens. By enforcing a token budget, you ensure that queries complete within a reasonable time frame. This improves user experience and reduces the risk of timeouts.

One subtlety is distinguishing between input tokens and output tokens. Input tokens are the context you provide to the model. Output tokens are the text the model generates. Most models charge different rates for input and output tokens. Your token budget should account for both. You might set a budget of 80,000 input tokens and 20,000 output tokens, totaling 100,000 tokens. The agent tracks both separately and enforces both limits. This prevents the agent from either overloading the context or generating excessively long responses.

## Rate Limiting and Concurrency Controls

Budget guardrails are not just about total cost. They are also about rate of cost. Even if your total daily budget is sufficient, you can still hit problems if too many queries arrive at once. Rate limiting controls how many queries the agent processes per second. Concurrency controls limit how many queries the agent processes simultaneously. Both are essential for managing cost and infrastructure load.

Rate limiting prevents spikes in spending. If your agent costs $0.10 per query and you allow 1,000 queries per second, you could burn $100 per second, or $360,000 per hour. Even if no single user exceeds their quota, the aggregate rate can bankrupt you. Rate limiting caps the query rate at a sustainable level. You might allow 10 queries per second, or 100 queries per second, depending on your budget and infrastructure. Queries that exceed the rate limit are queued or rejected. Users receive a 429 error: "Too many requests. Please try again in a few seconds."

Concurrency controls prevent infrastructure overload. If 1,000 users submit queries simultaneously, and each query takes 5 seconds to process, you need infrastructure to handle 1,000 concurrent requests. That infrastructure costs money. It also has physical limits. You cannot scale infinitely. Concurrency controls cap the number of in-flight queries. If 100 queries are already processing, new queries wait in a queue until a slot opens. This smooths load, prevents crashes, and keeps costs predictable.

Rate limiting and concurrency controls are implemented at the API gateway or load balancer level, before queries reach the agent. This is important. If you enforce limits inside the agent, you have already consumed infrastructure resources to receive and queue the request. If you enforce limits at the gateway, you reject excess requests immediately without consuming resources. This is more efficient and more cost-effective.

One user-facing concern is that rate limiting and concurrency controls degrade responsiveness. If queries are queued or rejected, users wait longer or see errors. This is unavoidable. The alternative is uncapped spending or infrastructure collapse. You communicate limits clearly in documentation and error messages. You set limits generously enough that normal usage is unaffected. You monitor queue depths and rejection rates. If queues grow too long or rejection rates exceed 1 percent, you increase capacity or tighten per-user quotas to reduce load.

## Cost Monitoring and Alerting

Budget guardrails are reactive. They enforce limits when they are reached. But you also need proactive monitoring. You track spending in real time, detect anomalies, and alert your team before limits are hit. This allows you to intervene early, investigate root causes, and adjust limits or disable abusive users before damage is done.

Real-time cost dashboards show current spending, spending rate, and time until limits are reached. You display metrics like total spend today, spend per minute, top-spending users, most expensive queries, and budget utilization percentage. You update these metrics every minute. Your team reviews the dashboard daily. If spending spikes unexpectedly, you investigate immediately. You identify the cause: a bug, a user automation, a traffic surge, a model pricing change. You take corrective action: fix the bug, throttle the user, scale infrastructure, or adjust limits.

Automated alerts fire when spending exceeds thresholds. You set alerts at 50 percent, 75 percent, and 90 percent of daily budget. When an alert fires, you receive a notification: email, Slack, PagerDuty. You review the situation and decide whether to take action. At 50 percent, you watch. At 75 percent, you investigate. At 90 percent, you intervene. You may disable the agent, block high-spending users, or increase the budget if the spike is legitimate. Alerts give you time to respond before hard limits are reached and users are blocked.

Cost attribution is critical for monitoring. You need to know which users, which queries, and which tools are driving costs. You tag every LLM call with metadata: user ID, query ID, tool name, model name, timestamp. You log token counts and costs. You aggregate this data in a database or logging system. You query it to answer questions: which user spent the most today? Which tool is most expensive? Which model should we switch to for cost savings? Cost attribution turns spending from an opaque number into actionable insight.

One emerging best practice is cost forecasting. You use historical spending data to predict future spending. If your average daily cost is $500 and growing 10 percent per week, you forecast that you will hit $1,000 per day in seven weeks. You plan accordingly: increase budget, optimize agent efficiency, or adjust pricing. Forecasting prevents surprises. It ensures you are never caught off-guard by cost growth.

## Optimizing Agent Costs Without Sacrificing Quality

Budget guardrails enforce limits, but they do not reduce costs. To reduce costs, you need optimization strategies. You choose cheaper models where appropriate. You reduce token usage by compressing context. You cache repeated computations. You batch tool calls. You replace LLM calls with deterministic logic. These optimizations lower the baseline cost of each query, which allows you to serve more queries within the same budget.

Model selection is the highest-leverage optimization. GPT-4o costs significantly more than GPT-4o-mini. Claude 3.5 Opus costs more than Claude 3.5 Sonnet. If your task does not require the most capable model, use a cheaper one. Many agent tasks can be handled by smaller models without quality loss. You experiment with model tiers and measure quality impact. If GPT-4o-mini achieves 95 percent of the quality at 20 percent of the cost, you switch to GPT-4o-mini for those tasks. You reserve expensive models for tasks that truly require maximum capability.

Context compression reduces token usage without losing information. Instead of sending 50,000 tokens of retrieved documents to the model, you summarize them into 5,000 tokens. You use a small cheap model for summarization, then pass the summary to the larger model. The larger model processes fewer tokens, which reduces cost. The quality impact is minimal if the summarization is accurate. This technique is effective for retrieval-augmented agents where context is large and redundant.

Caching eliminates repeated computation. If ten users ask the same question, you cache the agent's response after the first query and return it to the next nine users without recomputing. Caching works well for queries that are common and have stable answers. It does not work for personalized queries or queries that depend on real-time data. You implement caching at the query level or the intermediate step level. You cache tool call results, retrieval results, or final agent responses. Cache hit rates of 20 to 40 percent are common for production agents, which translates to 20 to 40 percent cost savings.

Batching reduces API overhead. Instead of making ten separate LLM calls for ten queries, you batch them into a single call with ten prompts. Some models support batch inference, which is cheaper than individual inference. You trade latency for cost. Batching adds a delay because you wait to collect multiple queries before processing, but it reduces per-query cost significantly. This works for background tasks and non-latency-sensitive workloads.

Deterministic logic replaces LLM calls where possible. If a task can be solved with a regex, a database query, or a rule, use that instead of an LLM. LLMs are expensive and nondeterministic. Deterministic logic is free and reliable. Many agent tasks have deterministic components that do not require generative AI. You identify those components and replace LLM calls with code. This reduces cost and improves reliability simultaneously.

Cost optimization is not about cutting corners. It is about spending intelligently. You spend on capabilities that matter and avoid spending on capabilities that do not. You measure quality continuously and ensure that optimizations do not degrade user experience. You balance cost and quality, finding the efficient frontier where you deliver maximum value at minimum cost.

## Pricing Models and User Incentives

Budget guardrails are internal controls, but your pricing model shapes user behavior. If you charge users per query, they will be conservative. If you offer unlimited queries for a flat fee, they will be aggressive. Your pricing model must align with your cost structure and your capacity constraints. It must also align with user value. Users should pay proportional to the value they receive, and you should earn proportional to the cost you incur.

Usage-based pricing charges users per query or per token. This aligns cost and revenue perfectly. High-usage users pay more, low-usage users pay less. You never subsidize heavy users. The downside is that usage-based pricing creates unpredictability for users. They do not know how much they will spend each month. This friction can reduce adoption. You mitigate this by providing usage dashboards, spending alerts, and monthly caps.

Tiered pricing offers fixed monthly plans with usage limits. Free tier: 100 queries per month. Pro tier: 1,000 queries per month for $20. Enterprise tier: 10,000 queries per month for $200. Users know exactly what they will pay. You know exactly how much capacity you need to provision. The downside is that you may subsidize users who max out their tier, and you may lose revenue from users who underutilize their tier. You balance this by setting tier limits based on your cost structure and adjusting tiers based on observed usage patterns.

Hybrid pricing combines flat fees with overage charges. Users pay $50 per month for 500 queries, then $0.10 per additional query. This provides predictability up to the limit and flexibility beyond it. It is the most user-friendly model for agents with variable usage. Users get the benefit of a fixed budget and the option to pay more when they need more.

Your pricing model influences whether users abuse the agent. If queries are free, users have no reason to optimize. They will send redundant queries, automate bulk requests, and treat the agent as unlimited. If queries are expensive, users will be conservative, possibly too conservative. They may avoid using the agent even when it would provide value. The right pricing model creates the right incentives: users use the agent when it is valuable, and they avoid wasting queries when it is not.

Budget guardrails enforce the pricing model. Quotas, rate limits, and cost caps ensure that users stay within their plan limits. They prevent users from exceeding what they paid for. They also prevent you from delivering more service than you can afford. Pricing and guardrails work together to create a sustainable, scalable agent product.

## Building Cost-Aware Agent Architectures

Cost control is not just a guardrail layer. It is an architectural principle. Cost-aware agents are designed from the ground up to minimize spending while maximizing quality. They make cost-informed decisions at every step. They choose the cheapest model that meets quality requirements. They retrieve the minimum context necessary. They terminate early when the answer is good enough. They cache aggressively. They batch when possible. Cost awareness is embedded in the agent's logic, not bolted on afterward.

Cost-aware prompt design reduces token usage. Instead of verbose instructions, you write concise prompts. Instead of including entire documents in context, you include excerpts and summaries. Instead of asking the model to generate long explanations, you ask for short answers with optional elaboration. Every token you remove from the prompt reduces cost. You measure token usage per prompt template and iterate to minimize it without sacrificing quality.

Cost-aware tool selection minimizes expensive operations. If a tool requires an LLM call to interpret results, you avoid it in favor of tools that return structured data. If a tool fetches large datasets, you limit the result size or filter before retrieval. If a tool has a high latency or cost, you call it only when necessary, not speculatively. You rank tools by cost and quality, then choose the cheapest tool that solves the problem.

Cost-aware stopping conditions terminate the agent when further steps provide diminishing returns. Instead of running until the agent achieves perfect confidence, you stop when the agent reaches acceptable confidence. Instead of refining the output indefinitely, you stop after two refinement passes. Perfectionism is expensive. Good-enough is cheap. You define what good-enough means for each task, then stop when you reach it.

Cost-aware architectures are lean. They do not over-engineer. They do not add capabilities that users rarely use. They focus on the core task and execute it efficiently. They measure cost per query and optimize the entire pipeline to reduce it. This is not about being cheap. It is about being efficient. Efficient agents deliver value at sustainable cost. Inefficient agents burn money and fail to scale.

Budget guardrails protect you from runaway costs. Cost-aware design reduces baseline costs. Together, they ensure that your agent is financially viable. You can serve thousands or millions of users without bankrupting your project. You can grow usage without growing costs proportionally. You can operate sustainably and profitably. This is the foundation of a successful agent product.

In the next subchapter, we will examine action guardrails: how to control which tools the agent can invoke, which data it can access, and which actions it can take in the real world.
