# 10.11 — Token Budget Management: Enforcing Limits Without Breaking Tasks

A healthcare technology company deployed an appointment scheduling agent in March 2025. The agent worked beautifully in testing, handling complex multi-step bookings with natural conversation. Two weeks after launch, the finance team received the monthly API bill: $47,000, nearly four times the projected cost. The engineering team investigated and found that 60% of sessions exceeded their planned token budget. The agent would start a booking flow, retrieve patient history, check insurance eligibility, propose appointment slots, then revise based on patient preferences. Each revision added another retrieval cycle. The longest session consumed 890,000 tokens—more than $12 in a single conversation about rescheduling a routine checkup. The team had implemented no hard limits because they worried that cutting off mid-conversation would frustrate users. Instead, they got budget chaos and an executive directive to shut down the agent until costs were controlled. The root cause was not excessive model capability or wasteful prompting. It was the absence of **token budget enforcement**—the operational discipline of setting hard limits on token consumption per session, enforcing those limits at runtime, and designing graceful degradation when limits approach.

You cannot run production agents without token budgets. The argument that budgets might disrupt user experience is backwards. What disrupts user experience is an agent that gets shut down three weeks after launch because it burned through the quarterly cloud budget in eleven days. What disrupts trust is explaining to your CFO why a chatbot cost more than two full-time employees last month. Token budget management is not about penny-pinching. It is about predictable, sustainable operations. You set limits based on business value, you enforce those limits in code, and you design your agent to complete its job within the budget or fail gracefully when it cannot. This subchapter covers how to define token budgets, enforce them without breaking tasks mid-stream, and build agents that respect resource constraints while still delivering value.

## Defining Token Budgets per Session and Task Type

A token budget is a hard limit on the total number of tokens—prompt plus completion—that a session or task is allowed to consume. The budget is not aspirational. It is enforced. If the budget is 100,000 tokens, the agent stops at 100,000 tokens, period. The first step is setting the right budget for each task type. You do not use a single global budget for all agent activity. A five-minute chat helping a user find a knowledge base article should not have the same budget as a three-hour code review workflow. You tier budgets based on expected complexity and business value.

Start with historical data from your development and pilot phases. Track median and 95th percentile token consumption for representative tasks. If your agent handles customer support inquiries and the median successful session uses 18,000 tokens while the 95th percentile uses 62,000 tokens, you set your production budget somewhere above the 95th percentile but below runaway outliers. A budget of 80,000 tokens per session gives headroom for complex cases without allowing unchecked escalation. For a code generation agent, you might see median tasks at 35,000 tokens and 95th percentile at 210,000 tokens. You set a budget of 250,000 tokens, accepting that truly massive refactors might hit the limit but most work completes comfortably within bounds.

You also differentiate budgets by user tier or task priority. A free-tier user running a documentation search agent might get a 50,000-token budget per session. An enterprise customer running the same agent for onboarding automation gets 200,000 tokens because the business value justifies the cost. A background agent summarizing overnight support tickets gets a lower per-task budget than a real-time agent assisting a customer on a call. You are allocating finite resources to maximize total value, not treating every interaction as equally important. This is resource management, and it requires explicit prioritization.

The budget must include all token consumption: the system prompt, user inputs, tool call results, model outputs, and every intermediate chain-of-thought step. A common mistake is budgeting only the completion tokens and forgetting that the prompt tokens accumulate across every turn. If your system prompt is 8,000 tokens and you have a ten-turn conversation, you have consumed 80,000 prompt tokens from the system message alone before counting any user input or tool results. You account for the full cycle cost when setting budgets, not just the marginal cost of the final response.

## Implementing Budget Tracking and Pre-Emptive Warnings

Once you have defined budgets, you enforce them with runtime tracking. Your agent framework maintains a running count of tokens consumed in the current session. Every API call to the model returns token usage in the response metadata. You sum prompt tokens and completion tokens from every call and compare the total to the session budget. This is not estimated or sampled—it is exact, real-time tracking based on actual API responses. You do not trust the agent to stay within budget on its own. You measure and enforce.

You implement warning thresholds before hitting the hard limit. If your session budget is 100,000 tokens, you set a yellow warning at 70,000 tokens and an orange warning at 85,000 tokens. When the agent crosses 70,000 tokens, you inject a system message into the next prompt: "You have consumed 70% of the session budget. Prioritize completing the current task efficiently. Avoid unnecessary tool calls or exploratory steps." This is not a suggestion. It changes the agent's behavior. The model sees the budget constraint as part of the context and adjusts its strategy accordingly. At 85,000 tokens, you inject a more urgent message: "Budget critical. You have 15,000 tokens remaining. Complete the task immediately or summarize progress and terminate gracefully."

These warnings are most effective when the agent has been trained or prompted to understand resource constraints. During development, you include budget-aware prompts in your system instructions: "You operate under a strict token budget. If you receive a budget warning, immediately shift to the most direct path to task completion. Do not start new retrieval loops or exploratory subtasks when budget is constrained." You reinforce this in evaluations by running test cases that intentionally approach budget limits and verifying that the agent completes core objectives before running out of tokens. An agent that ignores budget warnings and continues exploring irrelevant context is not production-ready.

You also track budget consumption per task step, not just per session. If your agent has a planning step, three execution steps, and a synthesis step, you allocate sub-budgets to each phase. Planning gets 15% of the total budget, each execution step gets 20%, and synthesis gets 25%. If the planning phase consumes 30% of the budget, you trigger an alert and potentially abort the session before moving to execution, because you know the remaining steps cannot complete within the remaining budget. This prevents the pattern where an agent spends 80% of its budget on research and then fails to deliver the output because it ran out of tokens during synthesis.

## Graceful Degradation When Approaching Budget Limits

Budget enforcement is not binary. You do not let the agent run freely until it hits the limit and then cut it off mid-sentence. You design graceful degradation—a series of behavior changes as the budget tightens that preserve core functionality while shedding lower-priority activities. This is the difference between an agent that crashes when it runs out of budget and an agent that delivers a partial but useful result.

The first degradation step is reducing retrieval scope. If your agent normally searches five data sources and synthesizes results, it switches to searching two high-priority sources when it crosses the 70% budget threshold. If it normally retrieves the top ten documents, it retrieves the top three. You are trading recall for efficiency, accepting that you might miss some relevant context in order to complete the task. This is a deliberate, designed trade-off, not an accident. Your agent's system prompt includes fallback strategies: "If budget is constrained, limit retrieval to primary sources only and reduce result count to three documents maximum."

The second degradation step is simplifying reasoning. Under normal conditions, your agent might use chain-of-thought prompting with detailed intermediate steps. When budget is tight, it switches to direct answer generation without extensive reasoning traces. You might drop exploratory tools like "search for related concepts" or "validate edge cases" and focus only on the core tool calls required to complete the primary objective. A coding agent that normally generates tests, documentation, and refactoring suggestions drops the tests and documentation when budget is constrained and delivers only the core code change.

The third degradation step is scope reduction. If the user asked for a comprehensive analysis of quarterly sales trends across six regions, and the agent hits 80% of budget after analyzing three regions, it does not silently give up. It outputs a partial result: "I have analyzed the first three regions. Based on current token budget constraints, I am delivering these findings now. Request a follow-up session to analyze the remaining regions." The user gets immediate value from the partial result rather than waiting indefinitely or receiving nothing. This is particularly important for long-running workflows where partial progress is better than no progress.

You also implement task checkpointing for complex multi-step workflows. If the agent is processing a list of 50 customer support tickets and summarizing each one, you checkpoint every ten tickets. At checkpoint, you write the intermediate results to persistent storage and record the token consumption so far. If the agent hits the budget limit after 30 tickets, it saves the 30 summaries, records the stopping point, and returns a result indicating partial completion. A follow-up session can resume from ticket 31 without re-processing the first 30. This transforms a budget failure into a pagination strategy.

Graceful degradation requires explicit design. You cannot bolt it on after the fact. During agent development, you define the priority order of activities and the fallback behaviors for each budget tier. You test those fallbacks by running evaluations with artificially constrained budgets—set the limit to 50% of normal and verify that the agent still completes core objectives. If it fails, you redesign the workflow to front-load critical tasks and defer optional enhancements until budget allows.

## Setting Budget Limits per User Tier and Task Priority

Not all users and tasks deserve equal budgets. You implement tiered budgets based on business value and user segment. A free-tier user exploring your product gets a minimal budget—enough to experience core functionality but not enough to run extensive workflows. A paying customer gets a larger budget. An enterprise customer with a contracted SLA gets the largest budget and priority access to compute resources. This is standard SaaS resource management applied to AI agents.

You define budget tiers in your system configuration. Free tier: 20,000 tokens per session, maximum three sessions per day. Pro tier: 100,000 tokens per session, maximum 20 sessions per day. Enterprise tier: 500,000 tokens per session, unlimited sessions. These limits are enforced at the API gateway before requests reach your agent infrastructure. If a free-tier user exhausts their daily session quota, they receive a clear message: "You have reached the daily limit for your plan. Upgrade to Pro for higher limits." You do not silently degrade service or let them keep consuming resources. You enforce the boundary and offer a commercial path to more capacity.

You also set per-task priority levels that override user-tier defaults in specific scenarios. A high-priority incident response task gets a larger budget regardless of user tier because the business impact of resolving the incident justifies the cost. A background analytics job runs with a constrained budget because it is not time-sensitive. You might allow a normally low-budget user to request a one-time budget increase for a critical task, subject to approval or a one-time fee. This gives you operational flexibility without abandoning budget discipline.

Task priority also determines how you handle budget exhaustion. If a low-priority batch job hits its budget limit, you queue it for retry during off-peak hours when token costs are lower or capacity is more available. If a high-priority real-time user interaction hits the budget limit, you allow a temporary overage and flag it for review, because the cost of degrading the user experience exceeds the incremental token cost. You make these trade-offs explicit in your policy rules, and you track overage costs to ensure they remain exceptions rather than becoming the norm.

You review budget utilization weekly. You track which users and task types consume the most tokens, which sessions hit budget limits, and which tasks completed well under budget. If 80% of customer support sessions complete in under 30,000 tokens but your budget is 100,000, you are over-provisioned. You can reduce the budget to 50,000 and reallocate the savings to higher-value tasks. If 15% of sessions hit the limit and fail to complete, you are under-provisioned. You either increase the budget or optimize the agent to use fewer tokens per task. Budget management is iterative, informed by production data, and continuously tuned.

## Handling Budget Overruns and Emergency Shutoffs

Despite your best efforts, budget overruns will occur. A user triggers an edge case that causes a retrieval loop. A model update changes token consumption patterns. A malicious user deliberately tries to exhaust your budget. You need both detective controls to identify overruns quickly and reactive controls to stop runaway costs before they escalate.

Your monitoring system tracks token consumption per session, per user, and per hour. You set alert thresholds: if any user consumes more than 1 million tokens in an hour, trigger an alert. If total system token consumption exceeds 10 million tokens in an hour, trigger an alert. These alerts go to both engineering and finance, because runaway token costs are both a technical and a business issue. You do not wait for the end-of-month bill to discover that something went wrong. You detect anomalies within minutes and respond immediately.

When an alert triggers, you investigate the session logs. You identify which task caused the overrun, which tools were called repeatedly, and whether the overrun was legitimate or pathological. If a user is running a legitimate but unexpectedly complex task, you allow it to complete and adjust their budget or move them to a higher tier. If the overrun is due to a bug—a tool that returns too much data, a retry loop that never terminates—you terminate the session immediately and fix the bug. If the overrun is abusive—a user scripting requests to exhaust your budget—you block the user and escalate to your security team.

You implement emergency shutoff mechanisms that activate automatically when consumption exceeds critical thresholds. If a single session consumes 2 million tokens—ten times your maximum budget—the system terminates it regardless of completion status. If system-wide consumption in the last five minutes exceeds your hourly rate limit, you enable rate limiting that queues new requests until consumption normalizes. These shutoffs are failsafes, not routine operations. They exist to prevent catastrophic cost events, like the appointment scheduling agent that burned $47,000 in two weeks. You would rather terminate a handful of sessions than let unchecked consumption destroy your operating budget.

You also implement budget circuit breakers per user. If a user triggers five budget overruns in 24 hours, you automatically throttle their access—reduce their per-session budget by 50% and require manual review before restoring normal limits. This prevents both accidental and malicious abuse. A user who consistently hits budget limits either has a legitimate need for higher limits, in which case you upgrade their tier, or is using the agent inefficiently, in which case you provide guidance or restrict access.

Post-incident, you conduct a cost review for every significant overrun. You document what happened, why the existing controls did not prevent it, and what changes are needed to prevent recurrence. If a particular tool call pattern consistently causes overruns, you optimize the tool or add specific budget checks before invoking it. If a certain task type regularly exceeds budget, you either redesign the task to be more efficient or increase the budget and adjust pricing to cover the cost. Budget overruns are learning opportunities, not just operational failures.

## Building Budget Awareness into Agent Prompts and Tools

The most effective budget enforcement happens before limits are reached. You build budget awareness directly into your agent's system prompt and tool design so that the agent naturally operates within constraints rather than requiring constant external intervention. This is the difference between an agent that fights against budget limits and an agent that respects them as part of its operational context.

Your system prompt explicitly states the budget and the consequences of exceeding it: "You operate under a strict token budget of 100,000 tokens per session. Your goal is to complete the user's task within this budget. If you approach the budget limit, prioritize delivering a useful partial result over attempting a comprehensive result that exceeds the budget. Budget overruns result in session termination, which provides no value to the user." This is not background information. It is a core constraint that shapes decision-making at every step.

You reinforce budget awareness in tool documentation. Each tool description includes an estimated token cost: "search_knowledge_base: retrieves relevant articles, typical cost 3,000 to 8,000 tokens depending on result count." The agent sees these costs and factors them into planning. If the agent has already consumed 70,000 tokens and considers calling a tool that costs 15,000 tokens, it recognizes that doing so will consume 85,000 tokens, leaving only 15,000 for synthesis and response. A budget-aware agent might choose a lighter-weight tool or reduce the scope of the search to stay within budget.

You implement budget-aware tool wrappers that enforce per-call limits. If your knowledge base search normally returns up to 20 documents, your wrapper checks the remaining session budget before executing the search. If the remaining budget is less than 10,000 tokens, the wrapper automatically reduces the result count to five documents, ensuring that the retrieval completes within available budget. The agent does not need to manually calculate token costs—the infrastructure adapts tool behavior based on budget state.

You also provide the agent with a budget status tool that it can call to check remaining tokens: "get_budget_status: returns current token consumption, remaining budget, and budget utilization percentage." An agent that is planning a multi-step workflow can call this tool before each major step to verify that sufficient budget remains. If the remaining budget is low, the agent adjusts its plan—skipping optional steps, reducing retrieval scope, or proceeding directly to output generation. This is proactive budget management, not reactive damage control.

During evaluations, you test the agent's budget awareness by running scenarios with constrained budgets. You set the budget to 60% of normal and verify that the agent still completes core objectives by making smarter trade-offs. You set the budget to 150% of normal and verify that the agent does not waste tokens on unnecessary activities just because budget is available. An agent that uses all available budget regardless of task complexity is inefficient. An agent that uses the minimum necessary budget to complete the task is well-designed.

You update budget limits and tool costs as models evolve. When a new model version reduces token costs for certain operations, you adjust budgets downward to maintain cost efficiency. When token costs increase, you either increase budgets and pass costs to customers or optimize agents to do more with fewer tokens. Budget management is not a one-time configuration. It is an ongoing discipline that evolves with your infrastructure, your models, and your business.

Token budget management is the foundation of sustainable agent operations. Without it, you are running an unmetered service where costs scale unpredictably with usage. With it, you have predictable operating costs, graceful degradation under load, and agents that respect resource constraints while delivering value. You set budgets based on task complexity and business value, you enforce them with runtime tracking and hard limits, and you build graceful fallbacks that preserve functionality when budgets tighten. Budget overruns are detected immediately, investigated thoroughly, and prevented through continuous optimization. Your agents know their budgets, factor them into planning, and operate within constraints as a core design principle. This is how you run production agents at scale without budget chaos or executive directives to shut everything down.

The next subchapter covers model tiering for agents—routing different agent steps to different models based on complexity and cost to optimize total system efficiency while maintaining quality.
