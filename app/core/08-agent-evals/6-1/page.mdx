# 6.1 â€” Agent Memory Architecture: Working, Episodic, and Semantic

In March 2024, a healthcare AI startup called MediAssist burned through forty-seven thousand dollars in Claude Opus API costs in a single weekend. Their agent was supposed to help patients navigate insurance claims by remembering their policy details, previous claims, and ongoing cases. Instead, it asked the same questions every conversation, re-analyzed identical documents dozens of times, and generated duplicate summaries of cases it had already processed. The CEO discovered the problem Monday morning when their AWS bill alert triggered. The agent had no memory architecture at all. Every conversation started from scratch, every document analysis repeated work already done, and every patient interaction consumed the full context window as if meeting them for the first time. They had built an agent with amnesia.

The engineering team thought they were being clever by keeping things stateless. No database complexity, no storage costs, just pure API calls. What they missed was that memory is not a luxury feature for agents. Memory is the foundation of everything that makes an agent useful. Without memory, you cannot learn from past interactions. Without memory, you cannot maintain context across sessions. Without memory, you cannot build on previous work. You end up with an expensive chatbot that costs more every time someone uses it, because it never remembers anything.

## The Three Memory Systems

Human cognition researchers identified three distinct memory systems in the 1970s, and these map surprisingly well to agent architectures. Working memory holds what you are thinking about right now, the active context of your current task. Episodic memory stores specific events and experiences you can recall later. Semantic memory contains general knowledge about the world, facts and concepts independent of when you learned them. An agent needs all three, implemented correctly, to function as more than a stateless question-answering system.

Working memory in agents is your context window. This is the conversation history, the current task state, any intermediate results from tool calls, and the prompt instructions that guide behavior. For Claude Opus 4.5, that is 200,000 tokens of space where everything the agent is currently thinking about lives. This memory is volatile. When the conversation ends, working memory disappears unless you save it somewhere else. The entire architecture of modern LLM agents revolves around managing this limited, expensive, temporary space effectively.

Episodic memory captures what happened. Every conversation the agent has had with this user, every document it analyzed, every action it took and what resulted. These are specific events with timestamps, participants, and outcomes. A customer service agent needs episodic memory to recall that Sarah called three times about her broken laptop, that you already issued an RMA number, and that she mentioned she needed it fixed before her business trip on the fifteenth. Without episodic memory, every interaction starts fresh, and users get furious repeating themselves.

Semantic memory holds what the agent knows. Product specifications, company policies, domain expertise, user preferences, learned patterns from thousands of interactions. This is not about remembering a specific conversation but about accumulating structured knowledge over time. A financial advisor agent builds semantic memory about investment strategies, market dynamics, and regulatory requirements. A coding assistant builds semantic memory about your codebase architecture, your team's conventions, and common patterns in your domain. Semantic memory makes agents smarter over time instead of perpetually ignorant.

## Why MediAssist Failed: The Cost of Amnesia

The MediAssist team discovered their memory problem when a patient named Robert Chen contacted support, frustrated beyond measure. He had uploaded his insurance policy documents five times. Each time, the agent analyzed them as if seeing them for the first time, spending six minutes and approximately eight dollars in API costs to extract the same information. Robert's insurance claim required coordination across three different providers, and every conversation with the agent started from zero. The agent would ask for his member ID, his date of birth, the claim number, and the relevant policy sections. All information Robert had provided in previous sessions. All information the agent had processed before.

The engineering investigation revealed the architecture: a Next.js frontend that sent user messages to an API route, which called Claude with a system prompt and the current message history. No database. No state persistence. The message history lived in browser localStorage, which meant switching devices lost everything. But even on the same device, the agent had no access to previous sessions, no memory of documents it had analyzed, and no ability to reference past claim processing. Every interaction was a blank slate.

When they calculated the waste, the numbers were devastating. Of the forty-seven thousand dollars spent that weekend, approximately thirty-two thousand was pure redundancy. The same insurance documents analyzed repeatedly. The same eligibility checks run multiple times for the same patients. The same claim summaries generated over and over. They were paying full price for work already done, because the agent forgot everything the moment each conversation ended. The cost of amnesia was not just user frustration. It was burning money on repeated computation.

## Implementing Working Memory: Context Window Management

Your context window is your agent's immediate awareness, everything it can see and think about right now. For most agents in 2026, this ranges from 128,000 tokens for Claude Sonnet to 200,000 for Opus, with Gemini models reaching two million tokens in experimental configurations. This sounds like abundance until you start building real systems. A single conversation with a dozen messages, a few documents attached, some tool call results, and your detailed system prompt can easily consume fifty thousand tokens. After a few interactions, you are cutting context to stay under limits.

The fundamental pattern is the rolling context window. Keep recent messages, summarize or drop older ones, and maintain a persistent system prompt with critical instructions. MediAssist rebuilt their agent to maintain conversation history in PostgreSQL, loading the most recent twenty messages into each API call. Older messages existed in the database but did not consume context window space. This alone cut their token usage by forty percent, because they stopped sending hundred-message conversation threads to the API.

But working memory is not just message history. It includes task state. If your agent is processing a multi-step insurance claim, working memory needs to track which steps are complete, what information is still needed, and what the next action should be. Many teams make the mistake of trying to encode all task state in the conversation history, leading to bloated contexts where the agent has to read through its entire work log to figure out what to do next. Better architectures maintain explicit state objects that summarize task progress concisely.

The pattern that works is structured state plus selective history. Maintain a task state object that captures the current status: claim ID, patient info, required documents, processing steps completed, pending actions. Include this state object in your system prompt or as a dedicated user message. Then add only the relevant conversation history: recent messages and any past messages that contain critical information for the current task. This gives the agent full awareness of where it stands without drowning it in every message ever exchanged.

Tool call results present another working memory challenge. When your agent calls a function to query a database, analyze a document, or fetch external data, those results consume context. A single document analysis might return five thousand tokens of extracted information. After ten tool calls, your working memory is full of intermediate results. The solution is progressive summarization. After each tool call, the agent decides what information from the result is critical to keep in working memory and what can be discarded or saved to episodic memory. This requires explicit prompting: ask the agent to extract key findings, not just dump raw results into context.

## Building Episodic Memory: Recording What Happened

Episodic memory is your interaction log, the record of everything the agent has done and experienced. For MediAssist, this became a conversation archive in PostgreSQL with a simple schema: conversation ID, timestamp, user ID, messages, tool calls executed, and outcomes. Every conversation got saved in full. This seemed wasteful at first, storing thousands of messages that might never be accessed again. But episodic memory is not about replaying every conversation. It is about being able to recall relevant past experiences when needed.

The key challenge is retrieval. A database with ten thousand past conversations is useless if you cannot find the relevant ones when needed. MediAssist implemented semantic search using OpenAI embeddings. Every conversation got embedded into a vector, stored in pgvector, and could be retrieved by similarity to the current query. When Robert Chen started a new session asking about his claim status, the agent could search episodic memory for past conversations with Robert, find the three previous sessions where he discussed this claim, and load that context. Suddenly the agent remembered him.

Retrieval strategy determines episodic memory value. Simple keyword search misses paraphrased content and semantic connections. Pure vector similarity sometimes surfaces conversations that match topic but not intent. The most effective pattern combines multiple retrieval methods. Query by user ID to find all past interactions with this person. Query by semantic similarity to find topically related conversations. Query by structured filters like date range or specific entity IDs like claim numbers or document references. Combine results using a ranking function that weights recency, relevance, and user match.

But retrieval alone is insufficient. You also need summarization, because you cannot load ten past conversations into working memory. The pattern is hierarchical summarization. Store conversations in full for detailed reference, but also generate and store tiered summaries. A one-sentence summary of each conversation. A one-paragraph summary of related conversation clusters. A structured extract of key facts and decisions from each session. When the agent needs episodic context, it loads summaries first, decides which past episodes are most relevant, and then loads selected details from those episodes into working memory.

MediAssist discovered that episodic memory changes agent behavior fundamentally. Before episodic memory, their agent was reactive, responding to whatever the user said in the moment. After episodic memory, the agent became proactive. It could reference past conversations: "Last week you mentioned needing this resolved before your business trip. I see that is coming up soon, so I have prioritized your claim." It could avoid repeated mistakes: "I know the previous representative told you to submit form X, but I see that was incorrect based on your policy type. Let me get you the right form." Episodic memory transformed a stateless chatbot into an agent with continuity.

## Constructing Semantic Memory: Accumulated Knowledge

Semantic memory is what the agent knows, independent of when or how it learned it. For MediAssist, this meant building a knowledge base of insurance policies, claims procedures, common issues, and patient-specific information. Initially they tried to cram all this knowledge into their system prompt, which became a fifteen-thousand-token monster that consumed a quarter of their context window before the conversation even started. The agent was slow, expensive, and still did not know enough because they could not fit everything into the prompt.

The shift was from prompt-based knowledge to retrieval-based knowledge. They built a structured database of insurance information: policy types, coverage rules, claims procedures, provider networks, and regulatory requirements. When a patient asked a question, the agent first queried this semantic knowledge base to retrieve relevant information, then used that retrieved knowledge to answer. This pattern is retrieval-augmented generation, and it is the foundation of semantic memory in modern agents.

But semantic memory is not just static knowledge you load at deployment. It is knowledge the agent accumulates over time. Every time MediAssist's agent processed a claim, it encountered edge cases, learned policy interpretations, and discovered undocumented procedures. Initially this learning disappeared after each interaction. They rebuilt the architecture to capture learned knowledge. When the agent discovered something new, like a specific claim processing rule for a rare policy type, it would generate a structured knowledge entry and add it to the semantic database. Over weeks, their knowledge base grew from two hundred manually entered rules to over three thousand rules including hundreds of learned cases.

The key challenge is knowledge quality. Automatically accumulated semantic memory can include errors, outdated information, and misinterpretations. MediAssist implemented a validation layer. Learned knowledge entries were marked as unverified. A human reviewer queue showed new knowledge entries daily. Verified entries became part of the authoritative knowledge base. Rejected entries were deleted. This human-in-the-loop approach prevented the knowledge base from accumulating garbage while still allowing the agent to learn and improve continuously.

User-specific semantic memory is particularly powerful. General knowledge about insurance procedures helps all users, but personalized knowledge about Robert Chen makes the agent genuinely useful to Robert specifically. His preferred communication style, his policy details, his dependent information, his past claim patterns. MediAssist built user profile objects that stored this semantic information separately from episodic conversation logs. The profile was structured data: membership numbers, policy types, family composition, communication preferences. Every conversation could update the user profile with newly learned information, and every new conversation loaded the profile as part of the agent's semantic knowledge.

## The Memory Hierarchy: What Goes Where and Why

The most common mistake in agent memory architecture is putting everything in working memory. Teams try to load entire conversation histories, all relevant knowledge, and every past interaction into the context window, hitting token limits and spending hundreds of dollars per conversation. The correct mental model is a memory hierarchy, analogous to CPU cache and RAM and disk storage in computer architecture. Different memory types have different access speeds, different capacities, and different costs.

Working memory is your L1 cache: tiny, fast, expensive. Only the most critical information belongs here. The current task state, the immediate conversation context, the specific knowledge needed for the current step. MediAssist's optimized working memory for a claim status query contained the user's current message, the previous two messages for context, the claim record from the database, the relevant policy section, and the task state showing what steps they had already completed. Total: about eight thousand tokens. Everything else lived in episodic or semantic memory.

Episodic memory is your RAM: larger, slower to search, cheaper per byte. Past conversations, previous document analyses, historical interactions. You do not load all episodic memory into working memory. You search episodic memory to find relevant experiences, summarize them, and load the summaries into working memory. MediAssist stored full conversation logs in PostgreSQL but typically loaded only brief summaries of past relevant conversations, maybe five hundred tokens total, into the current working memory.

Semantic memory is your disk: massive capacity, requires explicit queries, very cheap. All the knowledge about insurance policies, all the learned rules, all the user profiles. The agent queries semantic memory with specific questions and gets back specific answers. A query like "what are the eligibility requirements for out-of-network claims under policy type HMO-Gold" returns a structured answer that might be two hundred tokens. That answer goes into working memory. The other two hundred thousand policy rules stay in semantic storage.

The hierarchy is not just about storage. It is about update frequency and volatility. Working memory changes every message. Episodic memory appends new entries after each conversation but rarely modifies old ones. Semantic memory evolves slowly, accumulating knowledge over many interactions and requiring validation before updates. This difference in update patterns affects your implementation choices. Working memory can be in-process state. Episodic memory needs persistent storage with append-only writes. Semantic memory needs structured databases with careful update controls.

## Architecture Patterns: Combining Memory Types Effectively

The pattern that emerged from MediAssist's rebuild is the memory coordination layer. A component that sits between the user input and the LLM call, responsible for assembling the right memory context. When a message comes in, the memory coordinator queries episodic memory for relevant past conversations, queries semantic memory for applicable knowledge, loads the current task state from working memory, and assembles a context package. This package goes to the LLM along with the user message. The LLM's response then updates working memory, potentially adds to episodic memory, and sometimes triggers semantic memory updates.

The coordination logic is critical. Naive approaches load too much memory. Over-optimized approaches load too little and the agent seems forgetful. The heuristic that works is relevance-based loading with token budgets. Allocate token budgets to different memory types: three thousand tokens for episodic context, two thousand for semantic knowledge, five thousand for working memory and conversation history, and the rest for the actual conversation and tool calls. The memory coordinator fills each budget with the most relevant items, ranked by a scoring function.

For episodic memory, relevance scoring combines recency, semantic similarity, and user identity. Conversations with the same user from the past week score higher than conversations with different users from months ago. For semantic memory, relevance scoring is based on query match and specificity. Specific rules about the exact policy type the user has score higher than general insurance knowledge. For working memory, recency dominates: the most recent task state and messages are always included.

The memory coordination layer also handles updates. After each agent turn, it decides what to persist. Always persist the conversation messages to episodic memory. Conditionally update task state in working memory if the agent made progress. Rarely update semantic memory, only when the agent explicitly signals that it learned something new worth remembering. This asymmetry prevents the semantic knowledge base from being polluted with conversational noise while ensuring you never lose episodic records.

MediAssist's final architecture had four components. A conversation service that handled message routing and maintained working memory state. An episodic service that stored and retrieved conversation history with vector search. A knowledge service that managed semantic memory with structured queries and validation workflows. And a memory coordinator that orchestrated all three, deciding what context to load and what updates to persist. This separation of concerns made each piece simple while allowing sophisticated memory behavior overall.

## How Memory Architecture Affects Capability and Cost

Memory architecture is not just about what the agent remembers. It fundamentally changes what the agent can do and how much it costs. Before memory, MediAssist's agent could only answer questions about information provided in the current conversation. After memory, it could track ongoing cases across weeks, learn from past claim processing patterns, and provide personalized service based on user history. The capability jump was discontinuous. They went from a chatbot to an actual agent.

Cost dynamics shifted dramatically. Their initial stateless architecture had low storage costs, zero database expenses, but massive API costs from redundant processing. After implementing memory, they added about three hundred dollars monthly in PostgreSQL hosting and vector database costs. But their API costs dropped from forty thousand dollars per month to nine thousand. The memory infrastructure paid for itself immediately by eliminating repeated work. When an agent remembers document analysis results instead of re-analyzing the same document ten times, the savings are enormous.

Working memory optimization delivered the fastest cost reduction. By implementing context window management and loading only relevant history, they cut average tokens per API call from thirty-two thousand to twelve thousand, a sixty-two percent reduction. This translated directly to lower per-conversation costs.
Episodic memory prevented redundant conversations, cutting support volume by twenty percent because users were not frustrated into repeat contacts. When users feel heard and remembered, they ask fewer follow-up questions and express clearer trust in the system.
Semantic memory reduced hallucination rates because the agent retrieved verified knowledge instead of generating plausible-sounding nonsense. The error rate on policy-related questions dropped from eighteen percent to under three percent after semantic memory deployment.

But memory also introduced new costs. Vector embeddings for episodic search required embedding API calls, about two cents per conversation. Over thousands of conversations monthly, this added meaningful expense.
Semantic memory validation required human reviewer time, approximately ten hours weekly. They hired a part-time domain expert specifically for this task, adding labor costs to the technology stack.
Memory storage grew continuously, eventually requiring database optimization and archival strategies. Their PostgreSQL instance needed regular vacuum operations and index maintenance. Old conversations needed migration to cheaper storage tiers.
The total cost of memory infrastructure was roughly four percent of their total agent operating costs, while reducing other costs by seventy percent. The ROI was obvious. Memory was not free, but forgetting was far more expensive.

The capability expansion was harder to quantify but more important. With episodic memory, their agent could handle complex cases that required multiple sessions to resolve. A patient dealing with a denied claim could return days later, and the agent would remember exactly where they left off.
With semantic memory, the agent could apply learned patterns to new situations, getting better over time instead of staying static. After processing fifty similar claims, it developed intuition about which documentation would satisfy which policy requirements.
With proper working memory management, it could engage in longer, more sophisticated conversations without hitting context limits. Patients could ask complex questions that required pulling together information from multiple sources, and the agent had the cognitive space to reason through the answer properly.
Memory transformed the agent from a tool that answered simple questions into a system that managed complex, ongoing tasks. The difference was night and day.

## Design Patterns That Work in Production

After eighteen months of iteration, MediAssist's memory architecture converged on patterns that generalize well. First, separate memory types physically. Do not try to build one unified memory system that handles everything.
Working memory lives in application state and Redis for session management. It needs fast read and write access with no persistence guarantees beyond the current session.
Episodic memory lives in PostgreSQL with pgvector for semantic search. It needs reliable persistence, good query performance, and vector similarity search capabilities.
Semantic memory lives in a separate PostgreSQL schema with strict validation rules. It needs transactional updates, versioning, and careful access controls to prevent corruption.
This separation makes each system simpler and allows independent scaling. You can optimize each memory tier for its specific access patterns and durability requirements.

Second, make memory queries explicit in your agent loop. Do not try to automatically load context based on heuristics that might misfire. Instead, give your agent tools to query memory deliberately.
A tool to search past conversations by user, by topic, or by date range. A tool to retrieve knowledge from the semantic database with specific queries. A tool to update the task state when progress is made.
This makes memory operations observable, debuggable, and controllable. You can see exactly when the agent decides to recall past context versus when it proceeds with current information alone.
You can audit what semantic knowledge the agent relied on for each decision. When something goes wrong, you can trace which memory the agent accessed and whether the retrieval was appropriate.

Third, implement memory summarization aggressively. Never load raw memory into working memory without processing it first. Always load summaries and extracts tailored to the current need.
A past conversation becomes a three-sentence summary plus any specific facts the agent needs for the current task. You do not need the full transcript unless the user explicitly asks about what was said.
A knowledge base article becomes the specific answer to the current query, not the entire article dumped into context. Extract the relevant paragraph or fact, not the whole document.
This discipline keeps working memory focused and prevents context pollution. Every token in working memory should earn its place by being directly relevant to the current task.

Fourth, build memory observability from the start. Log what memory gets loaded into each agent turn with timestamps and relevance scores. Track memory retrieval performance and relevance metrics over time.
Monitor semantic memory growth and quality. You need to know when your knowledge base is expanding, what new facts are being added, and whether those facts are accurate.
Alert when memory queries are slow or returning poor results. If vector search latency spikes or retrieval precision drops, you need to know immediately.
MediAssist built a memory analytics dashboard that showed which episodic memories were accessed most frequently, which semantic knowledge had the highest utilization, and where memory gaps caused agent failures. They could see patterns: certain policy types generated more memory queries, certain conversation types led to failed retrievals.
This observability drove continuous memory improvement. They knew where to invest in better knowledge coverage and where retrieval needed tuning.

Fifth, plan for memory lifecycle management. Episodic memories do not need to live in expensive, fast storage forever. Their value decays over time as they become less relevant to current interactions.
MediAssist implemented a tiering system: conversations from the past month in PostgreSQL with vector indexes for fast retrieval, conversations from the past year in cheaper storage with slower search, conversations older than a year archived to S3 with no search capability but available for compliance and rare manual review.
This tiering saved significant storage costs while keeping recent, relevant memories fast. The agent could still access old conversations if explicitly needed, but it did not pay for instant retrieval of year-old data.
Semantic memory required quality decay mechanisms. Knowledge learned six months ago got re-validated or deprecated to prevent outdated information from persisting. Insurance policies change, procedures evolve, and yesterday's correct answer becomes today's error.
They implemented expiration timestamps on learned knowledge entries. Facts older than six months without revalidation got flagged for human review before being used again.

The pattern that ties everything together is the memory-augmented agent loop. User message arrives. Memory coordinator queries episodic memory for relevant past context, searching by user ID and semantic similarity.
Memory coordinator queries semantic memory for applicable knowledge, pulling policy rules and user preferences. Memory coordinator assembles working memory from current task state and recent messages.
All memory contexts get packaged with the user message and sent to the LLM. The prompt now contains current context, relevant history, and applicable knowledge.
LLM generates response and potential tool calls. Tool calls execute and results are added to working memory. The agent can see what it just did and build on it.
Response is sent to user. Memory coordinator persists the full conversation turn to episodic memory and updates task state to reflect progress.
If the agent signaled new knowledge during processing, that knowledge entry goes into the semantic memory validation queue for human review.
This loop makes memory a first-class part of agent cognition, not an afterthought. Every turn reads from memory and writes to memory. The agent truly remembers.

## The Future: Memory as Agent Identity

The deeper insight from building memory systems is that memory is not just storage. Memory is identity. An agent without memory is not really an agent. It is a stateless function that happens to use natural language.
What makes an agent feel like an agent is continuity. The ability to say "I remember when we talked about this last week" is what creates the perception of persistence, of identity, of agency.
Users bond with agents that remember them. When an agent recalls your preferences, your past questions, your ongoing projects, you start to trust it as a persistent entity that knows you.
They disengage from agents that forget everything. Nothing kills user adoption faster than an agent that asks the same question it asked yesterday. It feels disrespectful, broken, and useless.

MediAssist discovered this when they surveyed users before and after the memory upgrade. Before memory, users described the agent as "the insurance chatbot" with language suggesting it was a tool they used occasionally.
After memory, users described it as "my insurance assistant" with language suggesting relationship and personalization. Users said things like "she remembers my case" and "he knows my situation already."
The agent had not become more intelligent in any measurable way. The underlying model was the same. The reasoning capability was identical.
It had become more continuous, and continuity created connection. Memory transformed impersonal tool usage into something that felt like an ongoing relationship.

The frontier in 2026 is richer semantic memory that captures not just facts but models. Instead of remembering that Robert Chen prefers email communication, remember a model of Robert's communication preferences, his risk tolerance, his decision-making style, and how these attributes interact.
Instead of remembering specific insurance rules as isolated facts, build causal models of how insurance policies work that allow reasoning about novel situations. Understand why certain rules exist and how they connect to broader regulatory frameworks.
This shift from memory as retrieval to memory as learned models is where agent capability will jump next. Retrieval-based memory makes agents consistent. Model-based memory will make them genuinely intelligent.
The technical path involves storing not just embeddings but learned representations, not just facts but probabilistic models of user behavior and domain dynamics. This requires moving beyond vector databases into learned memory structures that can generalize.

Your memory architecture is your agent architecture. How you structure memory determines what your agent can learn, what it can recall, how it improves over time, and whether it feels like a persistent entity or a disposable tool.
Build working memory for immediate task focus. Keep it small, keep it relevant, and manage it ruthlessly to avoid context bloat.
Build episodic memory for experience and continuity. Log every interaction, make it searchable, and retrieve it intelligently when context demands.
Build semantic memory for accumulated knowledge. Extract facts from experience, validate them carefully, and make them queryable for future use.
Coordinate these memory types with clear hierarchies and explicit queries. Do not let them blend together into an undifferentiated mess. Each memory type serves a different purpose and needs different infrastructure.
Make memory operations observable and measurable. You cannot improve what you cannot see. Log every retrieval, track every update, and monitor quality continuously.
And remember that the agent that forgets everything is not an agent at all. It is just an expensive way to answer questions you have already answered before. Memory is not optional. It is fundamental.
