# 7.3 — HITL Patterns: Pre-Approval, Post-Validation, and Escalation

Pre-approval, post-validation, or escalation—choosing the wrong human oversight pattern for a given decision type will either expose you to unacceptable risks or create unnecessary bottlenecks that destroy automation value. In November 2025, a supply chain management company called LogiFlow learned this when their inventory replenishment agent used post-validation for procurement decisions, misinterpreted a demand forecast spike, placed orders for seventeen million dollars worth of industrial fasteners, and no human saw the notifications until four hours later when most orders had already been confirmed and charged. The company lost four hundred thousand dollars. The post-validation pattern had been the right choice for their risk profile, but they had failed to implement the safety rails that make post-validation work.

You have three fundamental patterns for incorporating human oversight into agent operations: pre-approval where humans review before the agent acts, post-validation where the agent acts and humans verify afterward, and escalation where the agent operates autonomously but knows when to ask for help. Each pattern represents a different tradeoff between safety and speed, between human effort and automation efficiency, between risk mitigation and operational latency. Choosing the wrong pattern for a given decision type will either expose you to unacceptable risks or create unnecessary bottlenecks. The sophisticated approach is not to pick one pattern for all decisions, but to classify your decisions into risk tiers and apply the appropriate pattern to each tier.

## The Pre-Approval Pattern: Safety First

Pre-approval is the most conservative pattern. The agent analyzes the situation, determines what action should be taken, presents that proposed action to a human reviewer, and waits for explicit approval before proceeding. Nothing happens without human consent. This is the pattern you use when the cost of a wrong decision is high, the decision is difficult to reverse, or you are still building confidence in the agent's judgment. Early in your agent deployment, pre-approval lets you observe how the agent reasons without risking actual execution errors.

Consider a legal document review agent that suggests contract edits. The agent reads a customer contract, identifies clauses that deviate from your standard terms, and proposes specific language changes to bring the contract into compliance. Because contract changes can have significant legal and financial implications, the agent uses pre-approval. It shows a lawyer the proposed edits, explains why each change is recommended, and waits for the lawyer to approve before making any modifications. The lawyer might approve all changes, approve some and reject others, or reject everything and provide guidance that the agent uses to generate new proposals. No actual contract is modified until the lawyer explicitly approves.

The benefit of pre-approval is that you catch errors before they cause real-world harm. If the agent misunderstands a clause and proposes a change that would actually weaken your legal position, the lawyer sees this during review and rejects it. The cost is latency and human effort. Every decision requires human involvement, which means the agent cannot operate faster than humans can review. If you have ten agents generating proposals and only two lawyers available to review them, throughput is limited by lawyer availability, not agent capacity.

Pre-approval works well when decisions are relatively infrequent, reviewers have the expertise to evaluate proposals quickly, and the cost of delay is lower than the cost of errors. It works poorly when decisions are high-frequency, reviewer expertise is limited, or users expect immediate responses. An agent that needs pre-approval for every email it sends will create a review backlog that defeats the purpose of automation. You need to reserve pre-approval for decisions where the safety benefit justifies the latency cost.

## The Post-Validation Pattern: Speed with Oversight

Post-validation flips the sequence. The agent makes the decision, executes the action, and then notifies humans of what it did so they can validate the decision after the fact. If validation reveals an error, humans intervene to correct it. This pattern prioritizes speed and throughput while maintaining oversight through retrospective review. It works when most agent decisions are correct, errors are detectable through post-hoc review, and fixing errors after they occur is acceptable.

Return to the LogiFlow procurement agent. Post-validation made sense for their use case because suppliers typically allow order cancellations within a two-hour window, most procurement decisions are straightforward, and the procurement team wanted to eliminate the constant interruption of approval requests. The agent placing orders and then notifying managers let the team review decisions in batches rather than one at a time, improving both agent throughput and human productivity. The fatal flaw was not implementing proper guardrails. They should have set maximum order values that triggered pre-approval instead of post-validation, implemented anomaly detection to flag unusual patterns before execution, and required immediate acknowledgment of validation notifications rather than letting them pile up unread.

Post-validation requires robust monitoring and alerting. The notifications that the agent sends after acting must be prominent enough that humans actually see them promptly. I have seen teams implement post-validation where notifications went to a low-priority email folder that reviewers checked once per day. By the time they discovered errors, it was too late to fix them cheaply. Effective post-validation sends notifications through channels that demand attention, like Slack messages or dashboard alerts, and escalates if notifications go unacknowledged for too long.

You also need fast and easy correction mechanisms. If a reviewer sees that the agent made a wrong decision, they should be able to reverse or modify that decision with minimal effort. For the procurement agent, this might mean a one-click order cancellation button in the notification. For a content publishing agent, it might mean an immediate rollback function that unpublishes the content. If correcting an error requires navigating through multiple systems and forms, reviewers will be tempted to let small errors slide rather than dealing with the hassle, which defeats the purpose of validation.

The key insight is that post-validation is not "no oversight," it is "deferred oversight." You are betting that the time window between action and validation is short enough that errors can be caught and corrected before they cause significant harm. This bet is reasonable when error correction is cheap and your error rate is low. It is unreasonable when errors cascade quickly or are expensive to fix. An agent that posts to social media can use post-validation because you can delete a bad post within minutes. An agent that commits code to production should not use post-validation unless you have extremely robust automated rollback and your deployment pipeline includes safety checks.

## The Escalation Pattern: Autonomy with Safety Valves

The escalation pattern gives the agent full autonomy for decisions it can handle confidently, but requires it to recognize when it is out of its depth and ask for human help. The agent evaluates each situation, determines its own confidence level, and escalates to humans when confidence falls below a threshold. This combines the throughput benefits of full autonomy with the safety of human oversight for edge cases. It is the most sophisticated pattern and the hardest to implement well.

Imagine a customer support agent that handles refund requests. Most refund requests are straightforward: customer bought a product, did not like it, wants to return it within the return window. The agent can handle these autonomously with high confidence. Occasionally the agent encounters ambiguous situations: the return window expired but only by two days, the product was personalized, the customer claims the product was defective but the agent cannot verify that from the conversation. For these low-confidence scenarios, the agent escalates to a human support agent. The human reviews the escalated case, makes a decision, and that decision becomes a training example that helps the agent handle similar cases better in the future.

The critical challenge is teaching the agent when to escalate. Confidence scores from language models are notoriously poorly calibrated. A model might be seventy percent confident in a completely wrong answer and sixty percent confident in a correct answer. You cannot simply threshold on raw model confidence. You need to define escalation triggers based on multiple signals: model confidence, but also the presence of conflicting information, high-stakes decisions, patterns the agent has not seen before, or explicit user requests for human involvement.

Some teams implement rule-based escalation triggers. Any refund over five hundred dollars escalates automatically. Any request that mentions legal terms or lawsuits escalates. Any conversation where the customer has expressed anger or frustration escalates. These rules are crude but reliable. They ensure certain categories of risk always get human attention regardless of what the model thinks. Other teams use learned escalation, where they train a separate classifier to predict whether the agent's proposed action should be escalated. They label historical decisions as "agent got this right" or "agent got this wrong" and train a model to recognize the features that predict errors. When the escalation classifier predicts high error probability, the agent escalates even if its primary decision model is confident.

The user experience of escalation matters enormously. If a customer is chatting with an agent and suddenly gets transferred to a human without explanation, it feels jarring and suggests the agent failed. Better implementations make escalation smooth: "I want to make sure we get this right for you. Let me bring in a specialist who can review your specific situation. One moment please." The customer understands they are getting extra attention, not that the system broke down.

## The Risk-Latency Tradeoff

These three patterns sit on a spectrum from safest-but-slowest to fastest-but-riskiest. Pre-approval minimizes risk at maximum latency. Post-validation minimizes latency at higher risk. Escalation balances both but requires the agent to accurately assess its own limitations. The right choice depends on the specific decision, your error tolerance, and your latency requirements.

For a medical diagnosis agent, pre-approval is appropriate. The cost of a wrong diagnosis is patient harm and potential liability. Latency of a few hours for a doctor to review is acceptable for most non-emergency cases. You want every diagnosis reviewed by a qualified physician before being communicated to patients. For a marketing email personalization agent, post-validation works well. The cost of a poorly personalized email is low, latency needs to be minimal for real-time personalization, and you can review a sample of sent emails daily to catch systematic errors. For a fraud detection agent, escalation is ideal. Most transactions are clearly legitimate or clearly fraudulent, the agent can handle those autonomously with low latency, but ambiguous cases that fall in the middle should escalate to fraud analysts.

The latency difference is substantial. Pre-approval adds the full human review time to every decision, which might be minutes to hours. Post-validation adds only notification delivery time, typically seconds, with validation happening asynchronously. Escalation adds review time only for the subset of decisions that trigger escalation criteria, so average latency is much lower than pre-approval. If your agent makes one hundred decisions per hour and ten percent escalate, you only have human latency on ten decisions instead of all one hundred.

The risk difference is equally substantial. Pre-approval means no unreviewed action ever executes, so risk is limited to reviewers making bad approval decisions. Post-validation means every action executes before review, so risk is the product of your error rate and the time window before validation catches errors. Escalation means high-confidence decisions execute without review, so risk depends on how well your confidence estimation identifies truly risky decisions. A perfect escalation system would have zero risk because it would escalate every potential error. A broken escalation system has high risk because it fails to escalate decisions it should.

## Combining Patterns with Risk Tiers

The most sophisticated implementations do not pick one pattern for all decisions. They classify decisions into risk tiers and apply different patterns to different tiers. This lets you optimize the risk-latency tradeoff separately for each category of decision. You get the safety of pre-approval where you need it, the speed of post-validation where you can afford it, and the efficiency of escalation for everything in between.

A financial services company might classify decisions into four tiers. Tier one is high-risk irreversible decisions like wire transfers over ten thousand dollars or account closures. These always use pre-approval. Tier two is medium-risk reversible decisions like wire transfers between one thousand and ten thousand dollars. These use escalation, with the agent handling straightforward cases autonomously and escalating if it detects any anomalies. Tier three is low-risk high-frequency decisions like categorizing transactions or generating spending reports. These use post-validation with daily sampling of a random subset. Tier four is negligible-risk decisions like formatting display preferences or sorting transaction lists. These are fully autonomous with no human review.

The classification scheme is as important as the patterns themselves. You need clear criteria for assigning decisions to tiers. Monetary amount is common but insufficient. A one-dollar transaction to a sanctioned entity is higher risk than a ten-thousand-dollar transaction to a known vendor. You should consider factors like reversibility, compliance implications, user impact, error detectability, and historical error rates. A decision that is easy to reverse if wrong is lower risk than an irreversible one. A decision that would violate regulations if wrong is higher risk regardless of monetary value. A decision that affects many users is higher risk than one affecting a single user.

Some companies use dynamic risk classification where the same type of decision might be different risk tiers in different contexts. A refund request from a customer with a ten-year account history and no previous refunds is low risk. The same refund request from a customer who created their account yesterday is higher risk. The agent evaluates context and assigns the decision to the appropriate tier, then applies the corresponding HITL pattern. This is more complex to implement but captures risk more accurately than static classification.

## Real-World Pattern Selection Examples

A content moderation agent at a social media platform uses escalation as its primary pattern. Most content is clearly fine or clearly violates policies, the agent handles these autonomously with high confidence. Content that is borderline, ambiguous, or involves nuanced policy interpretation gets escalated to human moderators. The escalation rate is around eight percent of total decisions. This lets the agent handle the high volume of clear-cut cases instantly while ensuring difficult decisions get expert human judgment. They tried pre-approval first but the review queue became overwhelming, with twelve-hour backlogs. They tried post-validation but encountered too many cases where harmful content was live for hours before being caught in review. Escalation gave them the right balance.

An infrastructure-as-code agent at a cloud platform company uses pre-approval for production deployments and post-validation for development environment changes. Production changes can cause outages and affect customers, so every change is reviewed by a senior engineer before execution. Development environment changes only affect individual developers, errors are cheap to fix, so the agent makes changes immediately and the team reviews a summary report of all changes weekly. This tiering reflects the different risk profiles of the two environments.

An email response agent at a customer service company uses all three patterns for different types of responses. Simple acknowledgment emails like "we received your request and will respond within 24 hours" are fully autonomous with no review. Substantive responses to common questions use post-validation, with the agent sending the email immediately and a supervisor reviewing a sample of sent emails daily. Responses involving refunds, account changes, or complex issues use pre-approval, with a human reviewing and editing the draft before it is sent. They classify each email conversation into one of these categories based on the customer's inquiry and the agent's proposed response.

The pattern you choose is a strategic decision about where your agent sits on the autonomy spectrum. Full autonomy with no human involvement is fast but only appropriate when errors are rare and inconsequential. Full human control with agents only suggesting options is safe but captures minimal efficiency benefit. The three HITL patterns, pre-approval, post-validation, and escalation, let you find points between those extremes that match your specific risk tolerance and latency requirements. The art is in classifying your decisions accurately, implementing the patterns with proper safeguards, and evolving your classification as your agent's capabilities improve and you build confidence in its judgment.

Many teams start with pre-approval for everything while the agent is new and unproven. As they build confidence through observing many correct decisions, they gradually shift more decision types to escalation and then to post-validation. This progressive trust-building is sensible, but do not fall into the trap of leaving everything on pre-approval forever because "we have always done it that way." If your agent has made ten thousand correct decisions with zero errors in a category, it might be time to move that category to a less restrictive pattern. Track your error rates by decision type, review them quarterly, and adjust your risk classification accordingly. The goal is to continuously optimize the balance between safety and autonomy as your agent proves itself over time.
