# 7.13 — Review Queue Operations: SLAs, Backlog, Routing, and Prioritization

In mid-2025, a financial services company deployed an agent to handle mid-tier customer support escalations—cases that were too complex for the tier-one bot but did not require a senior specialist. The agent drafted responses and routed them to a review queue staffed by eight support agents. In the first month, the queue handled 140 reviews per day with an average wait time of 11 minutes. By month three, volume had grown to 420 reviews per day. The queue backlog ballooned to 1,900 items, average wait time hit nine hours, and high-priority cases—account lockouts, fraud alerts—sat in the queue alongside low-priority subscription questions. Customers who needed urgent help waited the same nine hours as customers asking about billing cycles. The team added four more reviewers, but the backlog kept growing. By month five, the queue had 3,200 items, the oldest case was 11 days old, and the company pulled the plug on the entire agent program. The agent had not failed. The review queue had failed. The team built a HITL system with no SLAs, no prioritization, no backlog management, and no plan for scale.

The failure was operational, not technical. The company treated the review queue as an afterthought—a simple FIFO buffer where reviewers would "just handle things." They did not define service level agreements for different case types. They did not route high-priority cases to the front of the queue. They did not monitor backlog growth or set thresholds for escalation. They did not staff the queue based on projected volume. When the system hit load, it collapsed. This is the reality of HITL at scale: human review is not a passive filter. It is an active operational system that requires SLAs, routing logic, backlog policies, and capacity planning. If you treat it as anything less, you will build a bottleneck that kills the value of the agent it was meant to support.

## Defining Service Level Agreements for Review Actions

A service level agreement is a commitment that a review will be completed within a defined time window. Without SLAs, review becomes best-effort, which in practice means low-priority items wait indefinitely and high-priority items wait too long. SLAs force you to define what "timely" means for each category of decision and to staff, route, and escalate accordingly.

The first step is segmenting review actions by urgency and impact. Not all reviews are equally time-sensitive. A fraud alert flagged by an agent needs review within five minutes. A blog post draft for next week's publication can wait 24 hours. A low-confidence product recommendation needs review before the email sends, which might be one hour. If you treat all three the same, you will miss the fraud alert while reviewers are reading blog posts. Segmentation is not optional. It is the foundation of any functional queue.

You define SLA tiers based on the consequences of delay. Tier one is critical: delays cause customer harm, revenue loss, or compliance violations. SLA is measured in minutes. Examples: fraud alerts, account lockouts, payment failures, content moderation of illegal material. Tier two is high-priority: delays degrade customer experience or create operational risk. SLA is measured in hours. Examples: support case responses, outbound sales emails, onboarding workflows. Tier three is standard: delays are inconvenient but not harmful. SLA is measured in business days. Examples: internal reports, marketing content drafts, non-urgent policy reviews.

Each tier gets a defined SLA target and a consequence for missing it. For tier one, the target might be 95 percent of reviews completed within five minutes. If a review is not picked up within five minutes, it auto-escalates to a senior reviewer or triggers an alert to the on-call manager. For tier two, the target might be 90 percent within two hours. For tier three, 85 percent within one business day. The targets are not aspirational. They are operational commitments that drive staffing, tooling, and process.

SLAs also require a default action if the SLA is missed. You cannot let items sit in the queue forever waiting for a reviewer. If no one picks up a tier one review within ten minutes, the system takes a predefined safe action: reject the agent output and fall back to a human workflow, or escalate the case to a manager, or auto-approve if the confidence exceeds a high threshold and the risk is bounded. The default action depends on the use case, but the principle is universal: SLA violations trigger automated responses, not indefinite waiting.

Defining SLAs forces clarity about what the agent is for. If you cannot tolerate a two-hour review delay, you probably should not be using HITL for that task—you need a fully automated agent or a fully manual process. If you can tolerate a two-hour delay, then you need to staff the queue to meet that SLA. The exercise of setting SLAs surfaces mismatches between use case requirements and operational capacity before they become production failures.

## Routing Logic: Matching Reviews to Reviewers

Routing logic determines which reviewer sees which review. Poor routing creates imbalance: some reviewers are overloaded while others are idle, some reviews sit unassigned while others get picked up instantly, and expertise is mismatched to task complexity. Good routing logic balances load, matches expertise to difficulty, and respects SLAs.

The simplest routing model is round-robin: each new review goes to the next available reviewer in rotation. Round-robin is easy to implement and guarantees even distribution, but it ignores reviewer expertise and case priority. A junior reviewer gets a high-stakes legal edge case. A senior reviewer gets a routine formatting check. Both are suboptimal. Round-robin works only if all reviewers have identical skills and all reviews have identical difficulty, which is never true in practice.

A better model is skill-based routing. Each reviewer has a defined skill set: junior, senior, legal-trained, product-specialist, multilingual. Each review has a required skill level based on the agent's confidence, the task type, or the content domain. The routing system matches required skills to reviewer capabilities. A low-confidence legal contract goes to a senior legal-trained reviewer. A high-confidence product FAQ goes to a junior reviewer. A non-English email goes to a multilingual reviewer. This improves decision quality and reduces escalation, because the right person sees the case on the first pass.

Skill-based routing requires metadata on every review. The agent must tag each output with required skills, estimated complexity, or risk level. If the agent cannot provide this, you infer it from proxy signals: confidence score, task type, user segment, content length. You also need a reviewer skill registry that maps each reviewer to their capabilities and availability. This adds operational overhead, but the payoff is faster, higher-quality reviews and better reviewer utilization.

Priority-based routing overrides skill matching when SLAs are at risk. If a tier one review enters the queue, it goes to the front of every reviewer's list, regardless of skill match. If no reviewer is available, it triggers an alert to bring someone online. Priority routing ensures that time-sensitive cases do not wait behind low-priority ones, even if that means temporarily mismatching expertise. You accept a slightly lower-quality review from a generalist on a tier one case rather than waiting 20 minutes for the specialist to finish their current batch.

Hybrid routing combines all three. New reviews are assigned based on skill match and priority, with load balancing to prevent any single reviewer from being overwhelmed. If a reviewer's queue exceeds a threshold—say, ten items—new reviews route to the next-best match. If all reviewers are at capacity, the system halts new assignments and triggers a capacity alert. The routing logic is dynamic, adjusting in real time based on queue depth, reviewer availability, and SLA risk.

Routing also includes negative signals. If a reviewer consistently rejects cases or has low inter-reviewer agreement, the system deprioritizes routing complex cases to them until they are retrained. If a reviewer is new, they get only low-complexity cases for the first two weeks. If a reviewer is about to go offline, they stop receiving new assignments 15 minutes before their shift ends, so they can clear their queue. These are not punitive measures. They are operational safeguards that prevent bad matches from degrading the system.

## Backlog Management: When the Queue Grows Faster Than Review Capacity

Backlog is the set of reviews waiting to be picked up. A healthy queue has a small, bounded backlog that flows steadily. An unhealthy queue has a growing backlog that accumulates faster than reviewers can clear it. Backlog growth is the early warning sign that your HITL system is under-resourced, misconfigured, or being overwhelmed by volume.

You measure backlog in two dimensions: depth and age. Depth is the count of items waiting. Age is the time since the oldest item entered the queue. A backlog of 50 items with a max age of 10 minutes is healthy. A backlog of 50 items with a max age of four hours is not—it means the queue is not draining fast enough. A backlog of 500 items, regardless of age, is a red flag. You set thresholds for both. If depth exceeds 100 or max age exceeds one hour, the system alerts the ops team.

When backlog grows, you have three options: add capacity, reduce inflow, or reduce review scope. Adding capacity means bringing more reviewers online—pulling from another team, adding contract reviewers, or hiring. This is the most expensive option and takes time to execute, so it is not viable for short-term spikes. You use it when the growth is sustained and the business justifies the cost.

Reducing inflow means tuning the agent to send fewer outputs to review. You raise the confidence threshold for auto-approval, tighten the rules for what qualifies as tier two versus tier three, or temporarily disable low-priority agent tasks. This trades off coverage for speed. You are choosing to let the agent operate with less oversight on marginal cases in order to preserve reviewer capacity for high-priority ones. This is acceptable if the marginal cases have low risk, but it requires explicit sign-off from Product and Risk.

Reducing review scope means simplifying what reviewers check. Instead of reading the full email, they check only the subject line and call-to-action. Instead of evaluating the entire document, they spot-check the first two paragraphs and the conclusion. This is a temporary degradation of review quality to maintain throughput. You do this only in crisis mode, and you revert as soon as backlog stabilizes. You also log which reviews received reduced-scope treatment so you can audit them later if issues arise.

Backlog also has a time-to-live policy. Items that exceed a maximum age are automatically resolved with a default action. If a tier three review sits in the queue for three days, it auto-approves if confidence is above 80 percent, or it auto-rejects and falls back to manual workflow if confidence is below 80 percent. This prevents the queue from becoming a permanent holding pen for edge cases no one wants to touch. It also signals to reviewers that the queue is active and flowing, not a graveyard.

You prevent backlog growth by monitoring leading indicators. If agent output volume grows 20 percent week-over-week, you project queue impact and add capacity before the backlog builds. If rejection rates spike, you investigate whether the agent needs retuning or the criteria need clarification. If average review time increases, you check for reviewer fatigue or ambiguous cases that are slowing people down. Backlog management is proactive, not reactive. By the time the backlog is 500 deep, you are already in crisis.

## Prioritization: Ensuring High-Impact Cases Get Reviewed First

Prioritization determines the order in which reviews are presented to reviewers. Without prioritization, the queue is FIFO: first in, first out. FIFO is simple but wrong. It means a tier three marketing email draft submitted at 9:00 AM gets reviewed before a tier one fraud alert submitted at 9:01 AM. FIFO treats all cases as equal, which they are not.

Priority-based ordering puts tier one cases at the front, tier two in the middle, tier three at the back. Within each tier, you can use secondary sort keys: confidence score, customer segment, or time in queue. A tier one case with 60 percent confidence gets reviewed before a tier one case with 85 percent confidence, because the low-confidence case is riskier. A tier two case affecting an enterprise customer gets reviewed before a tier two case affecting a free-tier user, because the enterprise customer has higher business value.

You implement priority as a score, not a category. Each review gets a priority score from 0 to 100 based on a weighted formula. Tier one cases start at 90. Tier two at 50. Tier three at 10. You add points for low confidence, high customer value, or regulatory sensitivity. You subtract points for high confidence or low impact. The queue sorts descending by score. This gives you fine-grained control without manual intervention.

Priority scoring also handles tied priorities. If two tier one cases enter the queue simultaneously, you break the tie with age: the older case goes first. If two tier two cases have the same score, you break the tie with reviewer availability: the case that matches an idle reviewer's skill set goes first. The tie-breaking rules are deterministic and transparent, so reviewers trust that the queue is feeding them the right cases.

Prioritization must be dynamic. A tier three case that sits in the queue for 24 hours without being picked up gets a priority boost to prevent indefinite waiting. A tier two case whose SLA is about to expire gets promoted to tier one urgency. A tier one case that has been escalated twice gets flagged for manager review rather than being routed back into the queue. The priority score updates in real time as conditions change.

You also deprioritize cases that are blocked. If a review requires additional context from the user and the user has not responded, the case moves to a separate "waiting for input" queue with low priority. It does not clog the active review queue. When the user responds, the case re-enters the active queue at its original priority. This keeps the active queue clean and focused on actionable items.

Prioritization breaks down if reviewers can cherry-pick cases. If reviewers see the full queue and choose which cases to work on, they will avoid difficult, ambiguous, or time-consuming cases in favor of easy ones. This defeats the purpose of prioritization. The system must present reviewers with the next-highest-priority case in their skill range, not a menu of options. The reviewer's job is to review the case they are given, not to curate their own workload.

## Capacity Planning: Staffing the Queue to Meet SLAs

Capacity planning is the process of determining how many reviewers you need, with what skills, at what times, to meet your SLAs. Under-staff the queue and you miss SLAs, build backlog, and frustrate customers. Over-staff and you waste payroll on idle reviewers. Right-sizing requires modeling demand, review time, and availability.

You start by projecting review volume. If the agent generates 500 outputs per day, and 40 percent require review, that is 200 reviews per day. If reviews are evenly distributed across a 10-hour workday, that is 20 reviews per hour. If each review takes five minutes, you need 100 minutes of review capacity per hour, which is 1.67 full-time reviewers. You round up to two reviewers to account for variance and breaks. This is the baseline.

But demand is not evenly distributed. Customer support spikes mid-morning and mid-afternoon. Marketing emails batch-send at 8 AM. Fraud alerts are random. You model hourly distribution, not daily average. If 60 reviews arrive between 10 AM and 11 AM, and each takes five minutes, you need five reviewers during that hour, even if you only need one reviewer at 3 PM. You staff to peak demand, not average demand, or you accept that off-peak reviews will miss SLAs.

You also account for reviewer availability. Reviewers are not productive 100 percent of their shift. They take breaks, attend meetings, handle escalations, and context-switch. Industry standard is 70 to 80 percent productive time. If you need 100 minutes of review capacity per hour, and reviewers are 75 percent productive, you actually need 133 minutes of scheduled reviewer time, which is 2.2 reviewers. Always apply a productivity discount to avoid under-staffing.

Skill-based routing complicates capacity planning. If 10 percent of reviews require legal expertise, and you only have one legal-trained reviewer, that reviewer becomes the bottleneck. You need to either cross-train more reviewers in legal topics, or accept that legal reviews will have longer SLAs, or hire additional legal-trained reviewers. Capacity planning is not just headcount. It is headcount by skill set.

You build capacity buffers for unexpected spikes. A product launch doubles agent usage. A news event triggers a wave of support cases. A model update changes agent confidence distribution and sends more outputs to review. You maintain 20 to 30 percent spare capacity—reviewers who can be pulled into the queue if demand surges. This might mean having generalist support agents who normally do other work but can review agent outputs when the queue is overloaded. It might mean contract reviewers on retainer for overflow. The buffer prevents a single bad day from turning into a multi-day backlog crisis.

You also plan for reviewer attrition and ramp time. If a reviewer leaves, it takes two to four weeks to hire and train a replacement. During that time, you are under-capacity. You either over-hire by one reviewer to absorb turnover, or you have a bench of trained contractors who can fill gaps, or you accept temporary SLA degradation. You do not assume the team will stay static.

Capacity planning is iterative. You start with a model, measure actual performance, and adjust. If actual review time is seven minutes instead of five, you revise the model and add capacity. If demand grows 15 percent per quarter, you schedule hiring two quarters ahead. If SLA miss rate exceeds 10 percent, you investigate whether the issue is capacity, routing, or reviewer speed, and you fix the root cause.

## Monitoring and Metrics: Real-Time Visibility into Queue Health

You cannot manage what you do not measure. Review queue operations require real-time dashboards, alerting, and post-hoc analysis to identify problems before they become failures. The key metrics are throughput, backlog, SLA compliance, reviewer utilization, and decision quality.

Throughput is reviews completed per hour, broken down by tier and reviewer. You track this to ensure the queue is draining at the expected rate. If throughput drops from 25 reviews per hour to 18, you investigate: are the reviews harder? Are reviewers fatigued? Is tooling slow? Throughput trends over days and weeks tell you whether the system is scaling or degrading.

Backlog is current queue depth and max age, tracked every five minutes. You set alert thresholds: if depth exceeds 100, if max age exceeds two hours, if tier one backlog is greater than zero for more than ten minutes. These alerts trigger ops interventions: pull in additional reviewers, escalate to management, or activate the backlog reduction playbook.

SLA compliance is the percentage of reviews completed within their target window, broken down by tier. You aim for 95 percent compliance on tier one, 90 percent on tier two, 85 percent on tier three. You track both current compliance and trailing seven-day compliance. A single bad day is tolerable. A week of 70 percent compliance is a structural problem.

Reviewer utilization is the percentage of time reviewers spend actively reviewing versus idle or in other activities. Low utilization—reviewers idle 40 percent of the time—means you are over-staffed or the queue is under-loaded. High utilization—reviewers at 95 percent—means you are at risk of burnout and have no buffer for spikes. Target utilization is 70 to 80 percent.

Decision quality metrics include rejection rate, escalation rate, and inter-reviewer agreement. If rejection rates spike from 8 percent to 18 percent, the agent may have regressed or the criteria may have changed. If escalation rates exceed 15 percent, reviewers are uncertain or under-trained. If inter-reviewer agreement is below 85 percent, the rubric is ambiguous or reviewers need calibration.

You also track reviewer-level metrics: reviews per hour, average review time, approval rate, escalation rate, and audit pass rate. These identify outliers—reviewers who are much faster or slower, much harsher or more lenient, or much less accurate than peers. Outliers get coaching, retraining, or reassignment. You do not use these metrics punitively, but you do use them diagnostically.

Real-time dashboards display current backlog, SLA compliance, throughput, and active reviewers. Ops leads check the dashboard every hour. Alerts fire in Slack or PagerDuty when thresholds are breached. Post-hoc analysis runs weekly: you pull the full dataset, segment by tier, time, and reviewer, and identify trends. You ask: are SLAs getting harder to meet? Is backlog growing? Are certain reviewers struggling? You turn the answers into action: adjust staffing, retrain reviewers, retune the agent, or refine the routing logic.

Review queue operations are not a side project. They are core operational discipline, like incident response or release management. You build the monitoring, the alerting, the playbooks, and the team processes to keep the queue healthy at scale. The HITL system is not a passive safety net. It is an active, load-bearing part of your agent architecture, and it requires the same rigor, tooling, and accountability as any production system.
