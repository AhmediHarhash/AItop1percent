# 2.1 — ReAct: The Foundation Pattern for Modern Agents

In February 2025, a startup building legal research agents shipped what they described as a "revolutionary AI lawyer" that could analyze case law, draft briefs, and prepare legal arguments. The architecture was built on the ReAct pattern: the agent would reason about what information it needed, search legal databases, read the results, reason about gaps, search again, and iteratively build up its understanding until it could draft a comprehensive legal document.

For simple research queries, it worked beautifully. A lawyer would ask "what is the precedent for duty of care in premises liability cases in California?" and the agent would search case law, identify relevant cases, extract key holdings, synthesize the pattern, and return a clear summary with citations. The whole process took 90 seconds and produced work that would have taken a junior associate an hour.

Then they tested it on a complex securities fraud case. The agent needed to understand the interaction between federal securities law, state corporate law, and recent regulatory guidance. The optimal approach would have been to first map out the legal landscape—identify the relevant federal statutes, find the governing state law, locate recent SEC guidance, identify the leading cases in each area—and then dive deep into each area in sequence. Instead, the ReAct agent did what ReAct agents do: it took one step at a time, greedily choosing the next search based on what it had just learned.

It started by searching for "securities fraud precedent." It found a case discussing Rule 10b-5. It read the case and decided it needed more information about scienter standards. It searched for scienter. It found cases discussing knowledge and recklessness. It decided it needed information about state law fraud standards. It searched for that. It found a case that mentioned Delaware corporate law. It decided it needed to understand Delaware corporate law. Fifteen searches in, the agent had wandered into an exploration of Delaware's business judgment rule, which was interesting but irrelevant to the securities fraud question.

After 45 searches and 12 minutes of execution, the agent had gathered a sprawling, disorganized collection of information with no coherent structure. It had never stepped back to ask "what is my overall strategy?" or "am I making progress toward the goal?" It had never planned a search sequence. It had taken each step greedily based on the immediate observation, and the greedy strategy led it down rabbit holes. When it finally attempted to draft the brief, the result was incoherent because the information gathering had been incoherent.

ReAct failed not because it was implemented incorrectly, but because the task exceeded what ReAct is good at. ReAct excels at tasks where local decisions lead to global success. It struggles with tasks that require upfront planning, long-horizon reasoning, and strategic information gathering. The startup learned that ReAct is foundational for a reason—it is simple, interpretable, and effective for a wide range of tasks—but it is not the right pattern for everything.

## What ReAct Is and How It Works

ReAct, short for Reasoning plus Acting, is the simplest and most widely deployed agent execution pattern. The core idea is that the agent alternates between two modes: reasoning about what to do next, and acting by calling a tool or taking an action.

The loop is straightforward:

The agent receives a task and the current state of the world. It reasons about what to do: what information is needed, what action would move toward the goal, what tool to call. It outputs its reasoning as text—a scratchpad, a chain of thought, an internal monologue. Then it decides on an action: which tool to call and with what parameters. It executes the action. It observes the result. It adds the result to its context. It reasons about what the result means and what to do next. It acts again. The loop continues until the agent decides it has achieved the goal or that the goal is unachievable.

The reasoning step is not just internal to the model. It is explicit, visible text. The agent writes out its thoughts: "I need to find the current weather in San Francisco. I will use the weather search tool with the query San Francisco." This explicit reasoning serves two purposes: it improves the quality of the agent's decisions by encouraging step-by-step thinking, and it provides an audit trail so you can see why the agent did what it did.

The acting step is equally explicit. The agent outputs a structured action: tool name, parameters. The orchestration layer executes the tool call, captures the result, and feeds it back to the agent. The result becomes part of the context for the next reasoning step.

The pattern is reactive, not proactive. The agent does not plan multiple steps ahead. It does not generate a detailed strategy. It reasons about the immediate next step based on what it knows right now. After taking that step and observing the outcome, it reasons about the next step. Each decision is local, informed by the history but not by a long-term plan.

This greedy, step-by-step approach is both ReAct's strength and its limitation.

## Why ReAct Became the Default Agent Pattern

ReAct became the default pattern for agent systems in 2024 and 2025 not because it is the most powerful, but because it hits an optimal balance of simplicity, effectiveness, and debuggability.

**Simplicity:** ReAct is easy to implement. You need a loop, a way to parse the agent's output to extract actions, a way to execute actions and return results, and a way to format context. There are no separate planning modules, no complex state machines, no replanning logic. The entire execution model fits in a hundred lines of code. For teams building their first agent, ReAct is the obvious starting point.

**Effectiveness:** For a large class of tasks—research, question-answering, simple troubleshooting, data retrieval—ReAct works well. The greedy step-by-step approach is often sufficient. If you need to answer "what is the weather in three cities?" the agent can search for the weather in city one, then city two, then city three, then synthesize the results. No upfront planning is required. The task decomposes naturally into sequential steps.

**Interpretability:** Because the agent's reasoning is explicit text, you can see exactly what it was thinking at each step. If the agent makes a bad decision, you can trace back through the reasoning to understand why. If the agent gets stuck, you can see where the reasoning went wrong. This transparency is invaluable for debugging and building trust.

**Debuggability:** When a ReAct agent fails, diagnosing the failure is straightforward. You read the trace: what did it reason, what did it do, what did it observe, what did it reason next? The failure is visible in the sequence of reasoning and actions. You can identify the bad step and understand what information the agent lacked or what reasoning was flawed.

**Flexibility:** ReAct does not assume a fixed workflow. It adapts to the task. If the first search returns the answer, the agent stops. If the first search returns partial information, the agent searches again. If a tool call fails, the agent can try a different tool. The agent is not committed to a plan; it reacts to what it observes.

These properties made ReAct the foundation pattern. By mid-2025, nearly every agent framework—LangChain, Haystack, AutoGPT, AgentGPT, and dozens of others—implemented ReAct as the default execution mode. The OpenAI Assistants API, Anthropic's Claude with tools, Google's Gemini function calling—all are designed to support ReAct-style execution.

ReAct is the baseline. You start with ReAct, and if ReAct is insufficient for your use case, you consider more sophisticated patterns.

## The Reasoning Trace as Planning and Audit

The explicit reasoning trace in ReAct serves dual purposes: it is both a planning mechanism and an audit trail.

As a planning mechanism, the reasoning trace encourages the agent to think before acting. By forcing the agent to articulate its reasoning—"I need to find X, so I will do Y"—you make the decision process more deliberate. The agent is less likely to take random actions or get stuck in loops because it has to justify each step to itself.

The reasoning also helps the agent maintain coherence across steps. When the agent reasons about the next action, it has access to its previous reasoning. It can refer back: "I previously searched for A and found B, now I need to search for C." This continuity helps the agent avoid repeating steps or forgetting what it has already learned.

As an audit trail, the reasoning trace provides full visibility into the agent's decision-making. If the agent produces a wrong answer, you can read the reasoning and identify where it went off track. Did it misinterpret a tool result? Did it reason incorrectly from correct information? Did it choose the wrong tool? The trace tells you.

This auditability is critical for trust. Users and developers can inspect the reasoning and build confidence that the agent is operating sensibly, or identify problems that need fixing. In high-stakes domains like legal research, medical diagnosis, or financial analysis, the ability to see the agent's reasoning is not optional—it is a requirement for responsible deployment.

The reasoning trace also enables human-in-the-loop interventions. If you are watching the agent execute and you see it reason incorrectly, you can stop it, correct the reasoning, and let it continue. The trace is the interface for oversight.

However, the reasoning trace is only as good as the model's ability to reason. If the model produces plausible-sounding but incorrect reasoning, the trace can be misleading. You might read the reasoning, think it makes sense, and trust the agent's decision, when in fact the reasoning is flawed. This is a known risk with chain-of-thought approaches: the reasoning looks good to humans even when it is wrong.

## ReAct's Strengths: When It Excels

ReAct is the right pattern for a large and important class of tasks. Understanding where it excels helps you recognize when to use it.

**Tasks with clear next steps:** When the next action is obvious given the current state, ReAct works well. If you are researching a topic and you realize you need a specific piece of information, the next step is clear: search for that information. ReAct does not require complex planning for tasks where each step naturally suggests the next.

**Tasks with short horizons:** When the goal can be achieved in a small number of steps—say, three to ten—ReAct is efficient. You do not need a detailed plan for a five-step task. You can take each step reactively and reach the goal quickly.

**Tasks with rapid feedback:** When each action provides clear feedback about whether you are making progress, ReAct adapts effectively. Search and you get results that tell you if you are on the right track. Call a calculation tool and you get the answer you need. The tight feedback loop allows the agent to correct course quickly.

**Tasks with independent steps:** When steps do not have complex dependencies, ReAct handles them smoothly. Gathering information from three different sources can be done sequentially without planning. Each search is independent. The order might not matter. ReAct can execute the steps in whatever order makes sense given the context.

**Tasks where exploration is valuable:** When you are not sure what information will be useful until you start looking, ReAct's exploratory nature is an advantage. You search, you learn something, that shapes what you search for next. The greedy approach allows the agent to adapt its information-gathering strategy as it learns.

Examples of tasks where ReAct excels:

- Answering factual questions by searching and synthesizing information.
- Troubleshooting issues by gathering diagnostic information step by step.
- Simple research tasks where the scope is narrow and the information needs are clear.
- Data retrieval from multiple sources followed by aggregation.
- Tasks that require trying a few approaches and seeing what works.

For these tasks, ReAct is fast, simple, and effective. You do not need the overhead of planning. The reactive approach is sufficient.

## ReAct's Weaknesses: Where It Fails

ReAct fails predictably on certain types of tasks, and understanding these failure modes is essential for knowing when to use a different pattern.

**No upfront planning:** ReAct does not generate a plan before acting. It decides the next step based on the current state, but it does not think ahead about the sequence of steps needed to reach the goal. For tasks that require strategic planning—where the order of steps matters, where some steps depend on others, where you need to gather information in a specific sequence—the greedy approach fails. The agent wanders, takes inefficient paths, or gets stuck because it never developed a coherent strategy.

**Greedy execution:** ReAct makes locally optimal decisions at each step, but locally optimal is not always globally optimal. The agent might choose the next action that seems most promising right now, but that action might lead down a path that makes the overall goal harder to achieve. Without a global plan, the agent cannot reason about long-term consequences of immediate actions.

**Poor at long-horizon tasks:** When a task requires many steps—say, 20 or 30 actions—ReAct struggles. The agent loses coherence. It forgets why it took earlier actions. It repeats steps. It wanders into irrelevant areas. Long traces become hard for the model to track, and without a plan to anchor the agent, execution degenerates into random exploration.

**No backtracking:** ReAct is forward-only. If the agent realizes it took a wrong turn five steps ago, it cannot easily backtrack. It can try to recover by taking corrective actions, but it cannot undo the previous steps and try a different path. This makes ReAct brittle on tasks where you might need to explore multiple approaches and abandon unproductive paths.

**Inefficient exploration:** When the search space is large and the path to the goal is not obvious, ReAct can waste time exploring unproductive areas. Without a plan to guide exploration, the agent might search in circles, repeat queries, or investigate dead ends.

**Lack of structure:** ReAct does not impose structure on the task. If the task has natural phases—gather requirements, design solution, implement, test—ReAct does not recognize these phases. It just takes one step at a time. For tasks where structure matters, the lack of explicit phases leads to disorganized execution.

**Difficulty with dependencies:** If step B requires the result of step A, and step C requires the result of step B, ReAct can handle this if it happens to do the steps in order. But if the dependencies are complex or non-obvious, ReAct might try to do step C before step A, fail, and get confused. Planning patterns handle dependencies explicitly; ReAct handles them implicitly through reasoning, which is less reliable.

Examples of tasks where ReAct fails:

- Complex research requiring a structured approach to multiple sub-topics.
- Software engineering tasks with many steps and dependencies.
- Long-running investigations where the agent must maintain a coherent strategy over many actions.
- Tasks where the optimal sequence of steps is not obvious from the initial state.
- Tasks where you need to try an approach, evaluate it, backtrack, and try a different approach.

For these tasks, you need a more sophisticated pattern that includes planning, structure, or backtracking.

## When ReAct Is the Right Choice

Despite its limitations, ReAct is the right choice for many production use cases. The decision comes down to task characteristics and tradeoffs.

Use ReAct when:

- The task naturally decomposes into sequential steps with clear next actions.
- The number of steps is small, typically fewer than 15.
- Each step provides clear feedback about progress.
- The order of steps is flexible or obvious.
- You value simplicity and debuggability over optimality.
- You are building a first version and want to start with the simplest pattern that could work.

Do not use ReAct when:

- The task requires upfront planning to avoid wasted effort.
- The number of steps is large, requiring long-horizon reasoning.
- The task has complex dependencies between steps.
- The agent needs to backtrack or explore multiple strategies.
- Efficiency is critical and greedy execution would be wasteful.

The tradeoff is simplicity versus capability. ReAct is simpler to implement, easier to debug, and sufficient for many tasks. More sophisticated patterns like plan-and-execute are more capable but also more complex, harder to debug, and only necessary when ReAct is insufficient.

Start with ReAct. If it works, you are done. If it does not, you have a clear trace showing where it failed, which informs what pattern to try next.

## Production Considerations for ReAct Agents

Deploying ReAct agents in production requires attention to failure modes, cost, latency, and monitoring.

**Loop detection:** ReAct agents can get stuck in loops, repeating the same action or sequence of actions. You need loop detection: track the agent's actions, detect when it repeats, and terminate if the loop persists. Simple loop detection might look for identical consecutive actions. Sophisticated loop detection might look for cycles in the action sequence.

**Maximum iterations:** ReAct agents need a hard limit on the number of steps. Without a limit, a poorly performing agent might iterate indefinitely, consuming resources and never terminating. Set a maximum iteration count based on the expected task complexity. If the agent hits the limit, terminate and return an error or escalate to human review.

**Termination criteria:** The agent must decide when it is done. This requires explicit termination logic: "I have gathered the information needed to answer the question, so I will stop and return the answer." If termination logic is weak, the agent might continue iterating even after achieving the goal, wasting resources.

**Cost control:** Each iteration is at least one LLM call, and likely a tool call as well. For tasks that take 10 or 20 iterations, costs add up. You need cost monitoring: track total cost per task, alert on anomalies, and enforce budgets. ReAct agents can be expensive if not monitored.

**Latency management:** Each iteration adds latency. If each LLM call takes two seconds and the task takes 15 iterations, the user waits 30 seconds. For user-facing applications, this latency is often unacceptable. You need to either optimize for fewer iterations, provide intermediate progress updates to the user, or run the agent asynchronously and notify the user when complete.

**Error recovery:** Tool calls fail. APIs are unavailable. Results are malformed. The agent must handle errors gracefully. In ReAct, error recovery is implicit: the agent observes the error, reasons about it, and tries a different approach. But you need to ensure the agent has enough context to understand errors and enough capability to recover. If a tool fails and the agent has no alternative, it must terminate and escalate rather than loop indefinitely.

**Reasoning quality:** The quality of the agent's output depends on the quality of its reasoning. If the model reasons poorly, the agent will make bad decisions. You cannot assume reasoning is correct. You need evaluation: test the agent on representative tasks, inspect the reasoning traces, identify patterns of poor reasoning, and iterate on prompts, models, or tools to improve reasoning quality.

**Observability:** You need full visibility into what the agent is doing. Log every reasoning step, every action, every observation. Store the full trace for every task. When something goes wrong, the trace is your primary debugging tool. When something goes right, the trace is your evidence that the agent operated correctly.

These considerations are not optional. They are the baseline for responsible ReAct agent deployment.

## The 2026 Landscape: ReAct as the Foundation, Not the Ceiling

By 2026, ReAct had become the foundation pattern that every agent developer understands and every framework supports. It is the starting point, the baseline, the pattern you reach for first.

But it is also understood to be a foundation, not a ceiling. Elite teams use ReAct for tasks where it is sufficient, and they use more sophisticated patterns—plan-and-execute, Monte Carlo tree search, hierarchical agents—for tasks where ReAct falls short.

The maturation of the agent ecosystem means you no longer have to choose one pattern for all tasks. You can use ReAct for simple research, plan-and-execute for complex software engineering, and hierarchical agents for long-running orchestration. The pattern is a design choice, not a religious commitment.

ReAct's role in this ecosystem is foundational. It is the simplest pattern that exhibits true agentic behavior: iteration, observation, adaptation. Understanding ReAct deeply—its strengths, its weaknesses, when it works, when it fails—is essential for building production agents, because even when you use more sophisticated patterns, those patterns often incorporate ReAct-style loops as components.

The legal research startup eventually rebuilt their system with a hybrid approach. For simple queries, they used ReAct: fast, simple, effective. For complex cases, they used a plan-and-execute pattern: the agent first generated a research plan outlining the areas of law to investigate, then executed ReAct loops within each area. The structured approach eliminated the wandering that had plagued the pure ReAct implementation.

The lesson was not that ReAct is bad. The lesson was that ReAct is a tool, and like all tools, it has appropriate and inappropriate uses. Used well, it is elegant and effective. Used poorly, it is frustrating and wasteful. The craft is in knowing which is which.
