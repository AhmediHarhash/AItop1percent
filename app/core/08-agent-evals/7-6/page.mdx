# 7.6 â€” Approval Routing: Assigning Reviews to the Right People

How do you ensure that the junior underwriter does not spend forty minutes reviewing a seven-figure loan they cannot approve while the chief credit officer reviews a twenty-thousand-dollar application that any junior could handle? In April 2025, a financial services company called LendFast deployed an agent system with twelve underwriters and varying approval authorities, then routed every loan recommendation to a shared queue that all underwriters could access on a first-come-first-served basis.

Within three weeks, the system was producing bizarre outcomes. Junior underwriters were spending forty minutes reviewing complex seven-figure loan applications that they did not have authority to approve, then passing them to the chief credit officer who had to re-review from scratch. The chief credit officer, trying to help clear the queue, was reviewing twenty-thousand-dollar loans that could have been handled by any junior underwriter. A high-value commercial real estate loan sat in the queue for six hours because it required expertise in real estate valuation, and the three underwriters who picked it up first did not have that background and had to put it back. Average approval time was nine hours, and underwriter frustration was skyrocketing. LendFast had built a human-in-the-loop system with no logic for matching reviews to reviewers, and the result was chaos.

You face this routing problem whenever you have multiple human reviewers with different skills, authority levels, or availability. Routing every request to a shared queue ignores the fundamental fact that not all reviewers are equally qualified to handle all requests. The speed and quality of your human review process depends not just on having enough reviewers but on getting each request to the right reviewer. Approval routing is the invisible infrastructure that makes human-in-the-loop systems work at scale, and most teams build it as an afterthought.

## Routing Criteria: The Dimensions That Matter

When an agent generates a decision that needs human review, you need to route that review request to a specific person based on multiple criteria. The most obvious criterion is authority level. Some actions require approval from people with specific organizational authority. A junior employee cannot approve a six-figure expenditure, and a regional manager cannot approve a company-wide policy change. Authority routing is table stakes. If your agent proposes an action that a reviewer does not have the authority to execute, the review is wasted time.

The second criterion is expertise match. Some decisions require domain knowledge that not all reviewers possess. A legal contract review should go to someone who understands contract law. A database schema change should go to someone who understands database design. A clinical decision should go to someone with the relevant medical training. Expertise routing ensures that the reviewer actually understands the decision they are being asked to approve. Without it, reviewers either spend excessive time researching the domain or approve things they do not understand.

The third criterion is availability. A perfectly qualified reviewer who is on vacation, in a meeting, or already handling five urgent reviews is not a good routing target. Availability routing considers current workload, working hours, time zones, and out-of-office status. The goal is to route to someone who can actually respond in a reasonable timeframe.

The fourth criterion is workload balance. If you have ten reviewers and all requests go to the three fastest responders, those three reviewers will burn out and start rubber-stamping approvals to clear their queues. Workload routing distributes reviews across your reviewer pool to prevent overload and maintain decision quality.

The fifth criterion is context and history. Some reviews benefit from going to someone who has context on the situation. If an agent is proposing a change to a customer account, it might make sense to route the review to the account manager who knows the customer's history. If an agent is proposing a code change, it might make sense to route to the engineer who wrote the original code. Context routing reduces the ramp-up time reviewers need to make informed decisions.

Most routing systems consider only one or two of these criteria. Authority-based routing is common. Workload balancing is less common. Expertise matching is rare. Context-based routing is almost nonexistent. The result is that reviews end up with people who are authorized and available but not qualified or informed, leading to slow reviews and poor decisions.

## Role-Based Routing and Authority Hierarchies

The simplest routing strategy is role-based routing. You define roles in your organization, assign authority levels to each role, tag agent decisions with required authority levels, and route to any reviewer with sufficient authority. A junior support agent can approve refunds under one hundred dollars. A senior support agent can approve up to five hundred dollars. A support manager can approve up to five thousand dollars. The VP of customer experience can approve anything. When the agent proposes a refund, it checks the amount and routes to the lowest role with sufficient authority.

In June 2025, an e-commerce company called ShopDirect implemented role-based routing for customer service agent decisions. The agent handled refund requests, order cancellations, and policy exceptions. Each type of decision had a defined authority threshold. Refunds under fifty dollars went to any available support agent. Refunds from fifty to two hundred dollars went to senior agents. Refunds above two hundred dollars went to team leads. Policy exceptions always went to team leads regardless of dollar amount. The routing logic was a simple lookup table: decision type, decision parameters, minimum required role.

This worked well for authority enforcement but created bottlenecks. Team leads were drowning in reviews because every high-value refund and every policy exception went to them. Senior agents were underutilized because most refunds were under fifty dollars, and they only received the narrow band of fifty-to-two-hundred-dollar cases. The routing system was treating all team leads as interchangeable and all senior agents as interchangeable, which was organizationally correct but operationally inefficient.

The fix was to add role pools and load balancing within roles. Instead of routing to the team lead role abstractly, the system maintained a pool of active team leads and distributed reviews among them based on current queue depth. If one team lead had eight pending reviews and another had two, new reviews went to the one with two. This balanced the load and reduced average review time from four hours to forty-five minutes.

Role-based routing is a starting point, not a complete solution. It handles authority requirements, but it does not handle expertise, context, or nuanced workload balancing. You need additional layers on top of role-based routing to build a system that actually works well.

## Skill-Based Routing and Expertise Matching

Not all reviewers with the same role have the same skills. Two senior engineers might both have authority to approve database schema changes, but one specializes in PostgreSQL performance tuning and the other specializes in application architecture. If the agent proposes adding an index to optimize a slow query, the PostgreSQL specialist is the better reviewer. If the agent proposes refactoring a table structure to support a new feature, the application architect is the better reviewer. Skill-based routing matches the nature of the decision to the expertise of the reviewer.

In August 2025, a DevOps automation company called DeployGenie built an agent that proposed infrastructure changes based on monitoring data. The agent might suggest scaling up a service, changing a caching policy, or modifying a load balancer configuration. All reviews went to the on-call site reliability engineer, whoever that happened to be. The problem was that the SRE team had specialists. Some engineers were experts in Kubernetes, some in database operations, some in network infrastructure. The on-call rotation meant that a Kubernetes expert might be reviewing a database change they did not fully understand, or a database expert might be reviewing a networking change they had to research.

The fix was to implement skill tagging and skill-based routing. Each SRE tagged their profile with areas of expertise. Each type of infrastructure change was tagged with required skills. When the agent proposed a change, the routing system looked for available reviewers whose skills matched the required expertise. If multiple people matched, it used workload balancing to pick among them. If no perfect match was available, it escalated to a generalist or to the on-call engineer as a fallback.

This reduced review time by thirty-eight percent because reviewers were working within their expertise zones. More importantly, it reduced the rate of approved changes that later caused incidents. Specialists caught subtle issues that generalists missed. A database expert noticed that a proposed index would lock a table during creation and suggested scheduling it during low-traffic hours. A network expert noticed that a proposed load balancer change would route traffic inefficiently and suggested an alternative. These catches did not happen when reviews were randomly assigned to whoever was on call.

Skill-based routing requires investment in metadata. You need to tag decisions with required skills and tag reviewers with available skills. You need to keep those tags up to date as people's expertise evolves. You need fallback logic for when no perfect match exists. It is more complex than role-based routing, but the payoff in review quality and speed is substantial.

## Round-Robin Versus Smart Routing

The simplest workload balancing strategy is round-robin routing. You maintain a list of qualified reviewers and assign each new review to the next person in the list, cycling through repeatedly. If you have five reviewers, the first review goes to reviewer one, the second to reviewer two, and so on, looping back to reviewer one after reviewer five. This ensures that everyone gets an equal number of reviews, which feels fair and prevents any one person from being overloaded.

Round-robin routing has a fatal flaw. It treats all reviews as equal and all reviewers as equally available. In reality, some reviews are quick and some are slow. Some reviewers are fast and some are thorough. Some reviewers are online now and some are in a meeting. Round-robin routing can easily create a situation where one reviewer has a queue of ten fast reviews and finishes them in an hour, while another reviewer has a queue of three slow reviews and is still working on them four hours later. Equal distribution of count does not mean equal distribution of load.

In October 2025, a legal tech company called ClauseAI built an agent that reviewed and suggested edits to contract clauses. The agent would identify risky terms, suggest safer alternatives, and route each suggestion to a lawyer for approval. The company had eight contract review lawyers and used round-robin routing to distribute reviews. Every lawyer was getting roughly the same number of reviews, but satisfaction scores were terrible. Some lawyers complained of being overwhelmed, while others complained of being underutilized.

The issue was heterogeneity. Some contract reviews were simple one-clause edits that took two minutes. Some were complex multi-clause restructurings that took thirty minutes. Some lawyers reviewed faster than others. Round-robin was assigning an equal count of reviews, but the actual workload was wildly unbalanced. One lawyer might get eight quick reviews, and another might get eight slow reviews, resulting in a four-to-one difference in actual time spent.

The fix was smart routing based on estimated review time and current queue depth. The system tracked historical review times for different types of edits and different reviewers. When a new review came in, it estimated how long it would take, looked at each reviewer's current queue, calculated the expected completion time if the review were added to that queue, and routed to the reviewer with the earliest expected completion time. This balanced actual load, not just review count. Average queue wait time dropped from ninety minutes to twelve minutes, and lawyer satisfaction improved significantly.

Smart routing requires more infrastructure than round-robin. You need to estimate review difficulty, track reviewer speed, and maintain real-time queue state. But if your reviews have variable complexity or your reviewers have variable availability, smart routing is the only way to avoid bottlenecks and underutilization.

## Escalation Chains and Fallback Logic

Not every review gets approved on the first try. Sometimes a reviewer is unavailable, unresponsive, or uncomfortable making the decision. Sometimes the decision is more complex than the routing system anticipated and requires higher authority or deeper expertise. When the primary reviewer cannot handle a review, you need escalation logic to route it to a backup.

In December 2025, a fraud detection agent company called SafePay built a system that flagged suspicious transactions and proposed account freezes. Reviews were routed to fraud analysts based on expertise and workload. The system worked well most of the time, but there were edge cases where a review sat in a queue for hours because the assigned analyst was unavailable. The system had no escalation logic. If the primary analyst did not respond within a reasonable time, the review just waited.

This became a crisis when a high-value fraud case was routed to an analyst who had stepped away from their desk for a family emergency. The review sat in that analyst's queue for three hours while a fraudulent transaction cleared. The company lost forty-seven thousand dollars because the routing system had no way to reroute when the primary reviewer was unavailable.

The fix was to implement escalation chains. Each review had a primary reviewer, a backup reviewer, and a manager escalation. If the primary reviewer did not respond within thirty minutes, the review automatically rerouted to the backup. If the backup did not respond within thirty minutes, it escalated to a manager. The system also allowed reviewers to manually escalate if they felt the decision was beyond their expertise or authority. Manual escalations came with a required note explaining why, which helped the routing system learn and improve its initial assignments.

Escalation chains are especially important for urgent reviews. If an agent detects a security incident and proposes a mitigation action, waiting hours for a reviewer to come back from lunch is not acceptable. The system needs to find someone who can respond now, even if that someone is not the perfect expertise match.

## Conflict of Interest Detection

Some reviews should not go to certain people because of conflicts of interest. If an agent is proposing a decision about an employee's compensation, that employee should not be the reviewer. If an agent is proposing a vendor selection, and one of the reviewers has a financial relationship with one of the vendors, that reviewer should be excluded. Conflict of interest detection is rare in human-in-the-loop routing systems, but its absence can create serious problems.

In January 2026, a procurement agent company called BuyRight built a system that recommended suppliers for purchase orders. Reviews were routed to procurement specialists based on category expertise. The system worked well until a procurement specialist approved a vendor they had previously worked for, and that vendor later turned out to be overcharging the company by eighteen percent. An internal audit revealed that the specialist had approved multiple purchases from their former employer, and while there was no evidence of intentional fraud, the appearance of conflict was damaging.

The fix was to add conflict-of-interest rules to the routing logic. Reviewers declared relationships with vendors, and the system automatically excluded them from reviews involving those vendors. The system also detected potential conflicts based on metadata. If a review involved an employee's direct reports, their manager, or their own projects, the system flagged it and either excluded them or required a secondary approval. This added complexity to routing, but it protected the integrity of the review process.

Conflict of interest detection requires you to maintain relationship data and to define what constitutes a conflict. This is not a purely technical problem. You need organizational policies that specify which relationships create conflicts and which do not. The routing system then enforces those policies automatically.

## Reviewer Pools and Load Balancing Strategies

When you have a large reviewer pool, routing logic becomes a resource allocation problem. You want to distribute reviews to keep everyone productive, minimize wait times, and maximize decision quality. There are several strategies for balancing these goals, and the right strategy depends on your constraints.

The simplest strategy is to maintain an active pool and an inactive pool. Reviewers who are online, available, and under their workload limit are in the active pool. Reviews only route to the active pool. This prevents routing to people who are out of office or overloaded. The challenge is keeping the pool status up to date. If people forget to mark themselves as unavailable when they step away, reviews pile up in their queues.

A more sophisticated strategy is dynamic pool sizing. The system monitors average review wait times and active reviewer count. If wait times are increasing, it expands the active pool by notifying additional reviewers to come online. If wait times are low and some reviewers are idle, it shrinks the pool to keep everyone engaged. This works well in environments where reviewers can flex their availability based on demand, such as support teams or on-call rotations.

A third strategy is priority-based routing. Reviews are tagged with priority levels, and high-priority reviews jump the queue. Critical security decisions route immediately to available experts. Low-priority routine approvals route to a general queue that people work through when they have spare capacity. This ensures that urgent decisions get fast reviews without slowing down less critical work.

The key to any load balancing strategy is feedback loops. You need to monitor routing outcomes, measure review times and quality, and adjust routing rules based on what you learn. Routing logic is not set-it-and-forget-it infrastructure. It is a living system that needs tuning as your team composition, review complexity, and workload patterns evolve.

## How Routing Quality Affects the Entire System

The quality of your routing logic has cascading effects on everything downstream. Good routing reduces review time, which reduces agent cycle time, which increases the throughput of your human-in-the-loop system. Good routing matches expertise to decisions, which increases approval accuracy and reduces the rate of bad decisions getting approved. Good routing balances workload, which prevents reviewer burnout and keeps decision quality consistent. Good routing builds trust because reviewers feel like they are being assigned work that makes sense for their skills and authority.

Bad routing does the opposite. Reviews go to the wrong people, who either take too long because they are out of their depth or approve things they do not understand. Reviews pile up in some queues while other reviewers sit idle. High-value decisions get stuck behind low-value decisions because there is no priority logic. Reviewers become frustrated with nonsensical assignments and start rubber-stamping approvals just to clear their queues. The human-in-the-loop system degrades into a bottleneck that slows everything down without adding meaningful oversight.

Most teams treat routing as a minor technical detail and implement the simplest possible logic, usually a shared queue or round-robin assignment. This works at very small scale with homogeneous teams, but it breaks as soon as you have multiple types of decisions, multiple levels of expertise, or variable workload. Investing in smart routing logic early pays off exponentially as your system scales. The difference between a well-routed system and a poorly routed system is not incremental. It is the difference between a system that works and a system that people route around because it is too slow and frustrating to use.
