# 10.10 — Agent Cost Model: Tokens, Compute, Tools, Memory, and Storage

In June 2025, a customer analytics platform launched an AI agent system that analyzed user behavior patterns and generated personalized marketing recommendations for enterprise clients. The product team projected costs based on model API pricing alone, estimating $8,000 per month for 500,000 agent requests at an average of 2,500 tokens per request. The agent launched successfully, delivered strong business value, and usage scaled rapidly to 2 million requests per month by September. In October, the finance team flagged that actual AI infrastructure costs had reached $127,000 per month, nearly four times the projected $32,000 based on linear scaling of the initial estimate. A detailed cost audit revealed the gap: model API calls represented only 34% of total costs. The remaining 66% came from sources the initial projection ignored: vector database queries for retrieval averaging $0.014 per request, Redis cache storage for conversation memory costing $18,000 per month, compute costs for 24 always-on orchestration containers at $2,400 per month, S3 storage for conversation logs and audit trails at $8,200 per month, and third-party API costs for data enrichment tools averaging $0.021 per agent request. The incomplete cost model led to under-pricing of the product, forcing an emergency 40% price increase that triggered customer complaints and contract renegotiations.

The root cause was not unpredictable costs but incomplete cost modeling. The team focused exclusively on the most visible line item—model API calls—and ignored the full cost stack required to run a production agent system. Agent economics involve multiple cost dimensions that scale differently: per-request token costs, fixed compute infrastructure, storage that grows with usage over time, tool and API costs that vary by agent behavior, and memory systems that combine per-request and persistent storage costs. A complete cost model accounts for all dimensions, projects how each scales with usage and complexity, and enables accurate pricing, budgeting, and optimization decisions. This subchapter teaches you how to build comprehensive cost models for agent systems, understand the scaling characteristics of each cost dimension, identify optimization opportunities, and establish monitoring that prevents cost surprises.

## Token Cost Modeling and Optimization

Token costs are the most obvious agent expense but require careful modeling because they depend on multiple variables: input tokens, output tokens, model tier, caching behavior, and reasoning traces. Model providers price input and output tokens differently, with output tokens typically costing 2x to 3x more than input tokens because generation requires more compute than encoding. For Claude 3.5 Sonnet, input tokens cost $3 per million and output tokens cost $15 per million as of January 2026. For GPT-4o, input tokens cost $2.50 per million and output tokens cost $10 per million. These prices change frequently as providers adjust pricing and release new model tiers, so your cost model must be updated regularly with current rates.

Calculate token costs per request by measuring actual usage, not assumptions. Instrument your agent to log input tokens and output tokens for every request, tagged by task type and user segment. Aggregate this data to calculate average token consumption patterns: median, p95, and p99 token counts for each task category. You will discover significant variance. Simple question-answering tasks might average 800 input tokens and 200 output tokens, while complex research tasks might average 6,000 input tokens and 4,500 output tokens. If you model costs using a single average across all tasks, you will systematically underestimate costs for heavy users and complex workflows. Model costs per task type, then weight by actual task mix to project total spending.

Account for prompt caching benefits in cost projections. Claude and GPT-4 both offer prompt caching that significantly reduces costs for repeated context. If your agent uses the same system prompt, knowledge base context, or tool definitions across many requests, caching can reduce effective input token costs by 50% to 90% for cached content. However, caching benefits depend on cache hit rates, which depend on request patterns. If every request has unique context, caching provides no benefit. If 80% of requests share a 5,000-token system prompt, you pay full price for the first request and 10% of input token costs for subsequent cached hits. Measure actual cache hit rates in production and factor them into your cost model rather than assuming theoretical maximum savings.

Model reasoning trace costs for models that expose extended thinking. Claude Opus 4 and similar models can generate internal reasoning traces before producing final outputs. These reasoning tokens are typically priced lower than regular output tokens but can represent significant volume. An agent request that generates 500 output tokens might generate 8,000 reasoning tokens internally. If reasoning tokens cost $1 per million and regular output tokens cost $15 per million, the reasoning adds $0.008 per request while the output adds $0.0075—nearly the same. Measure reasoning token generation in your agent workload and include it in cost projections. Some providers allow you to disable extended reasoning for cost-sensitive tasks; test whether disabling it degrades quality enough to justify the savings.

Implement token budgets per request to prevent runaway costs. Set maximum token limits for input and output that align with task requirements and cost constraints. For a simple Q&A agent, you might limit inputs to 4,000 tokens and outputs to 1,000 tokens. For a research agent, you might allow 32,000 input tokens and 8,000 output tokens. These limits serve dual purposes: they prevent individual requests from consuming excessive costs due to bugs or malicious inputs, and they force architectural discipline by requiring you to design agents that accomplish tasks within defined resource constraints. Monitor requests that hit token limits; if many tasks legitimately need more tokens, either increase limits or redesign the agent to use multi-turn interactions that spread token consumption across multiple cheaper requests.

Optimize prompts to reduce token consumption without sacrificing quality. Verbose prompts with unnecessary examples, redundant instructions, or lengthy formatting specifications waste tokens on every request. Measure token counts for each section of your system prompt and evaluate whether each section improves output quality enough to justify the cost. A detailed 1,200-token rubric for tone might improve outputs by 5% while adding $0.0036 per request. If you process 10 million requests per month, that rubric costs $36,000 per month. Is the quality improvement worth $36,000? Sometimes yes, often no. Test shorter versions of prompts and measure quality impact empirically. You may discover that a 400-token tone guideline achieves 95% of the quality benefit at one-third the cost.

## Compute Infrastructure Costs and Scaling

Compute infrastructure costs include the servers, containers, and orchestration systems that run your agent logic, manage request queues, execute tool integrations, and handle routing and fallbacks. Unlike token costs that scale linearly with requests, compute costs have both fixed and variable components. Fixed costs are the baseline infrastructure required to run the system at all. Variable costs scale with load but often in steps rather than smoothly: adding capacity in discrete units like additional container instances or larger instance types.

Model baseline compute costs for always-on components. Agent orchestration systems typically run persistent services: API gateways, request routers, queue managers, cache layers, monitoring systems. These services must run continuously even during low-traffic periods to handle requests with acceptable latency. Calculate the monthly cost of your baseline deployment: how many container instances, what instance sizes, what reserved capacity. For the customer analytics platform, 24 containers at $100 per month each represented $2,400 in fixed compute costs regardless of request volume. This fixed cost must be amortized across all requests; at 100,000 requests per month, that is $0.024 per request in overhead, while at 2 million requests per month, it is $0.0012 per request. Understand your fixed cost baseline and how it amortizes at different usage levels.

Project variable compute costs based on autoscaling behavior. As request volume increases, your orchestration layer scales horizontally by adding container instances or vertically by upgrading to larger instances. Measure the relationship between request rate and required compute capacity. If you can handle 500 requests per minute with 10 container instances, and you receive 2,000 requests per minute during peak hours, you need 40 instances during peaks. Calculate costs for peak capacity, not average capacity, because you pay for the maximum resources needed to meet demand. Factor in autoscaling lag: if your system takes 3 minutes to scale up and traffic spikes suddenly, you may need additional baseline capacity to handle spikes without degraded latency.

Account for cold start costs in serverless architectures. If you run agent orchestration on serverless platforms like AWS Lambda or Google Cloud Run, you avoid paying for idle capacity but incur cold start latency when functions are invoked after periods of inactivity. Cold starts can add 500ms to 3 seconds of latency to requests, degrading user experience for latency-sensitive tasks. To avoid cold starts, you can configure minimum provisioned instances, which creates a fixed cost floor similar to always-on containers. Model the trade-off: serverless with cold starts is cheapest but has latency variance, serverless with provisioned concurrency eliminates cold starts but costs more, always-on containers have predictable latency but highest fixed costs. Choose based on your latency requirements and traffic patterns.

Measure CPU and memory utilization to identify over-provisioning. If your agent containers run at 20% CPU utilization on average, you are paying for 80% unused capacity. Right-size your instance types to match actual resource consumption. Test whether smaller instance types with higher utilization deliver acceptable performance at lower cost. Be cautious with extreme optimization: running at 90% utilization provides little headroom for traffic spikes and can cause latency degradation. Target 60% to 70% utilization under normal load, leaving 30% to 40% headroom for spikes and ensuring that autoscaling can respond before capacity is exhausted.

Implement cost-aware request routing for multi-tier agent systems. If you run multiple agent configurations—a fast lightweight agent for simple tasks and a slower expensive agent for complex tasks—route requests to the appropriate tier based on complexity. The lightweight agent might use Claude Haiku with minimal tools and 2 container instances, costing $0.008 per request in combined token and compute costs. The complex agent might use Claude Opus 4 with extensive tools and 8 container instances, costing $0.14 per request. If 70% of tasks can be handled by the lightweight agent, routing appropriately saves significant costs compared to running all requests through the expensive tier. Build classification logic that predicts task complexity from the initial user input and routes accordingly.

## Tool and External API Cost Modeling

Tool costs include charges for every external API or service your agent calls: database queries, search APIs, CRM integrations, payment processors, data enrichment services, third-party AI models for specialized tasks. These costs scale with agent behavior, not just request volume. An agent that calls five tools per request incurs five times the tool costs of an agent that calls one tool. Modeling tool costs requires understanding both per-call pricing and agent usage patterns.

Catalog all tool integrations and their pricing structures. For each tool, document: cost per call, rate limits, whether pricing is tiered or flat, whether there are monthly minimums or commitments. Vector database queries might cost $0.001 per search. CRM API calls might be included in your license up to 100,000 calls per month, then $0.002 per additional call. Weather API might charge $50 per month for 10,000 calls, then $0.006 per call. Payment processing might charge 2.9% plus $0.30 per transaction. Create a reference table of all tool costs that can be updated as providers change pricing. The customer analytics platform's $0.014 per request vector database cost was invisible in initial planning because the team did not realize retrieval would be called on every agent request.

Measure tool call frequency per agent request. Instrument your agent to log every tool call with metadata: which tool, input size, output size, latency, success status. Aggregate to calculate average tool calls per request, broken down by task type. You may discover that simple tasks call 1.2 tools on average while complex tasks call 7.8 tools on average. If 40% of your requests are complex tasks, your average tool cost per request is weighted heavily by those expensive interactions. Model tool costs separately for each task type, then weight by task mix. Monitor tool call frequency over time; if agent behavior changes due to prompt updates or new capabilities, tool costs will change even if request volume stays constant.

Identify tools with high cost variance and implement budgets. Some tools have unbounded cost potential: a web scraping tool that charges per page scraped, a data enrichment API that charges per field returned, a compute-intensive analysis service that charges by processing time. An agent bug or poorly designed task could trigger thousands of dollars in tool costs in minutes. Implement per-request budgets: limit the agent to 3 web scraping calls, 10 enrichment fields, or 30 seconds of analysis time per request. Enforce these budgets in the orchestration layer so the agent cannot exceed them even if it wants to. Log budget limit hits as signals that tasks might need redesign or that limits are too restrictive.

Negotiate volume discounts and reserved capacity for high-usage tools. If you call a vector database 50 million times per month, you are a significant customer who can negotiate better pricing than pay-as-you-go rates. Providers often offer reserved capacity plans that reduce per-call costs in exchange for minimum monthly commitments. Calculate your baseline usage floor—the minimum tool calls you will make even in a slow month—and negotiate reserved pricing for that baseline. Pay-as-you-go pricing for overage above the reservation provides flexibility for traffic spikes without locking you into excessive fixed costs. The customer analytics platform could have reduced vector database costs by 40% through a reserved capacity agreement once usage patterns stabilized.

Implement tool call caching to reduce redundant API costs. If multiple requests within a short time window make identical tool calls, cache the results and reuse them instead of making duplicate API calls. For example, if ten users ask about weather in Seattle within five minutes, cache the weather API response and return it to all ten without making ten separate API calls. Define appropriate cache TTLs based on data freshness requirements: weather might cache for 30 minutes, stock prices for 1 minute, reference data for 24 hours. Measure cache hit rates and calculate cost savings. Even modest 20% hit rates can significantly reduce tool costs for high-frequency APIs.

## Memory and Context Storage Costs

Memory costs include the storage and retrieval systems that maintain conversation history, user preferences, session state, and long-term agent knowledge. These costs combine per-request access costs and persistent storage costs that grow over time. Unlike token or compute costs that scale primarily with request volume, memory costs scale with both request volume and data retention policies.

Model conversation memory storage costs based on retention policy. If you store full conversation history for every user session, storage costs grow indefinitely. A conversation with 20 turns averaging 1,500 tokens per turn generates 30,000 tokens of history, approximately 120 KB of text. At $0.023 per GB-month for S3 standard storage, that is $0.0000028 per conversation-month. Across 500,000 active users, that is $1,400 per month. If you retain conversations for 90 days on average, multiply by three. If you index conversations in a database for fast retrieval, add database storage costs at $0.10 to $0.25 per GB-month, 4x to 10x higher than S3. Define retention policies based on business requirements: keep recent conversations in fast storage for 7 days, archive to cheap storage for 90 days, delete after 90 days unless flagged for audit.

Calculate cache costs for session state and user context. Redis, Memcached, or similar in-memory caches provide fast access to active session data but cost significantly more than disk storage. Redis on AWS costs approximately $0.05 to $0.15 per GB-hour depending on instance type. If you cache 10 MB of context per active session and have 5,000 concurrent sessions, that is 50 GB of cache storage, costing $2,160 to $6,480 per month. The customer analytics platform's $18,000 per month Redis cost represented significant over-provisioning: they cached full conversation histories for all users when only recent context was needed for agent requests. By reducing cached data to the last 3 turns per session and moving older history to database storage, they cut Redis costs by 70%.

Implement tiered storage strategies that match access patterns to storage costs. Active session data that is accessed frequently should live in expensive fast storage. Warm data that might be accessed occasionally should live in mid-tier storage like databases. Cold data that is rarely accessed but must be retained should live in cheap archival storage like S3 Glacier. Design your memory system to automatically tier data based on age and access patterns. Move conversation history from Redis to database after 15 minutes of inactivity, and from database to S3 after 7 days. This tiering can reduce storage costs by 80% to 95% with minimal impact on user experience since most memory accesses are for recent data.

Model vector embedding storage costs separately from text storage. If you generate embeddings for all conversation turns, user messages, or knowledge base content, those embeddings consume storage and query costs. A 1,536-dimension embedding for a single text chunk is approximately 6 KB. One million embeddings are 6 GB of storage, costing $138 per month in vector database hosting plus per-query retrieval costs. Calculate embedding storage based on data volume and update frequency. If you re-embed content daily, you need pipeline costs for embedding generation in addition to storage costs. Evaluate whether all content needs embeddings or whether selective embedding of key content reduces costs without degrading retrieval quality.

Monitor memory storage growth rates and project long-term costs. Storage costs grow over time as you accumulate conversation logs, user profiles, agent outputs, and audit trails. If storage grows at 500 GB per month and your retention policy is 12 months, you will stabilize at 6 TB of storage, costing $138 to $1,500 per month depending on storage tier. If your retention policy is indefinite, storage costs will grow unbounded. Set alerts for unexpected storage growth: if storage increases 50% faster than request volume, you may have a data leak, inefficient serialization, or missing cleanup jobs. Review retention policies quarterly and delete or archive data that no longer serves business purposes.

## Cost Monitoring, Attribution, and Optimization

Cost monitoring makes spending visible, attributable to specific usage patterns, and actionable for optimization. Without detailed cost monitoring, you operate blind, discovering cost overruns only when monthly bills arrive. Real-time cost monitoring enables proactive optimization and prevents budget surprises.

Instrument your agent to emit cost metrics for every request. Each request should log: model API costs, token counts, tool calls made and their costs, memory operations performed, compute time consumed, estimated total cost. Tag these metrics with dimensions: user ID, task type, tenant ID for multi-tenant systems, agent version, model version. Aggregate costs over time windows and dimensions to calculate: cost per request, cost per user, cost per task type, cost per tenant. This granular visibility enables you to answer questions like "which customers drive the highest costs," "which task types are most expensive," "how did costs change after the last model update."

Implement cost anomaly detection to identify unexpected spending patterns. Calculate baseline cost per request for each task type based on historical data. Alert when costs deviate significantly: if the average cost per research task is normally $0.08 and suddenly increases to $0.23, investigate immediately. Cost spikes can indicate bugs, inefficient new code paths, unexpected tool call loops, or external API price increases. The customer analytics platform discovered through anomaly detection that a subset of requests were making 40x normal tool calls due to a prompt engineering mistake that caused the agent to repeatedly retry failed searches instead of gracefully handling errors.

Attribute costs to revenue or business value to understand ROI. For a customer-facing agent, calculate cost per user session and compare to revenue per session or customer lifetime value. For an internal automation agent, calculate cost per task completed and compare to the cost of manual task completion. This ratio tells you whether the agent is economically viable. A customer support agent that costs $0.12 per interaction and saves 8 minutes of human agent time worth $2.40 has a 20x ROI. A research agent that costs $1.50 per report and replaces 90 minutes of analyst time worth $45 has a 30x ROI. If costs approach or exceed value delivered, the agent is not economically sustainable at current efficiency.

Build cost dashboards that surface spending trends and optimization opportunities. Key dashboard views include: total spending over time with breakdown by cost category, cost per request trends, highest-cost users or tenants, highest-cost task types, tool call frequency and costs, token consumption percentiles, compute utilization, storage growth rates. Make these dashboards visible to both engineering and product teams. Product teams should understand cost implications of new features they propose. Engineering teams should see the impact of their optimization work. Shared visibility creates accountability and aligns teams around cost efficiency.

Establish cost budgets and alerts at multiple levels. Set budgets for total monthly spending, spending per customer segment, spending per feature area. Configure alerts at 50%, 75%, and 90% of budget consumption. These alerts provide escalating warnings that allow you to take corrective action before budgets are exceeded. Corrective actions might include: throttling expensive features for high-usage users, negotiating additional budget, optimizing inefficient code paths, or pausing low-value workloads. Budget alerts prevent the scenario where you discover on the 28th of the month that you have already spent 180% of your budget with no time to react.

Prioritize optimization efforts based on cost impact and engineering effort. Not all optimization opportunities are worth pursuing. Reducing token costs by 5% through prompt engineering might save $2,000 per month and require 8 hours of work, an excellent return. Reducing compute costs by 15% through code optimization might save $400 per month and require 40 hours of refactoring, a marginal return. Build a cost optimization backlog that quantifies potential savings and required effort for each opportunity. Prioritize high-impact low-effort improvements first. Track actual savings after optimization to validate projections and refine your estimation process.

## Pricing Strategy and Unit Economics

Cost modeling informs pricing strategy and unit economics: what you charge customers, what your margin is, what usage levels are profitable. Agent products must be priced to cover costs, provide acceptable margin, and remain competitive in the market. Mispricing can make a successful product unprofitable or price it out of the market.

Calculate fully-loaded cost per request including all dimensions. Sum token costs, compute amortization, tool costs, memory costs, storage costs, and operational overhead like monitoring and support. If your average request costs $0.05 in model tokens, $0.012 in compute, $0.021 in tools, $0.003 in memory, $0.002 in storage, and you allocate $0.01 in operational overhead, your fully-loaded cost is $0.098 per request. This is your floor: pricing below this level loses money on every request. In practice, you need margin for sales, marketing, customer success, R&D, and profit, so your target price is typically 3x to 10x fully-loaded costs. At 5x, you would price at $0.49 per request, providing 80% gross margin.

Model how costs scale with usage to design volume-based pricing tiers. Fixed costs amortize across more requests at higher volumes, reducing cost per request. Variable costs may benefit from volume discounts on tools and APIs. Compute autoscaling may achieve better utilization at higher sustained loads. If your cost per request at 10,000 requests per month is $0.12 due to high fixed cost amortization, but falls to $0.07 at 100,000 requests per month due to better amortization and volume discounts, you can offer tiered pricing that shares these savings with customers: $1,200 for 10,000 requests ($0.12 per) or $9,000 for 100,000 requests ($0.09 per). This incentivizes customers to increase usage while maintaining your margin.

Implement usage monitoring and alerts to prevent customer cost overruns. If customers are billed based on consumption, provide dashboards showing their usage in real-time, projected month-end spending, and alerts when they approach budget limits. This transparency builds trust and prevents surprise bills that damage customer relationships. Offer optional spending limits: customers can set a maximum monthly spend, and usage is throttled when the limit is reached. This prevents runaway costs from bugs or unexpected usage patterns and gives customers control over their spending.

Evaluate freemium or free-tier strategies based on cost structure. If your marginal cost per request is low due to high fixed cost amortization, offering a free tier can be economically viable as a customer acquisition strategy. A free tier of 1,000 requests per month costs you $70 in marginal costs if requests cost $0.07 each, but may convert to paid customers worth thousands in lifetime value. If your marginal cost per request is high and mostly variable, free tiers are harder to sustain and may attract unprofitable usage. Model expected conversion rates and lifetime value to determine whether free tier costs are justified by customer acquisition benefits.

Monitor unit economics by customer segment to identify profitable and unprofitable usage patterns. Some customers or use cases may have inherently poor unit economics: high usage of expensive features, low willingness to pay, high support costs. If enterprise customers average $0.08 cost per request and pay $0.40, they are highly profitable. If free users average $0.11 cost per request due to inefficient usage patterns and convert at 2%, they may be unprofitable in aggregate. Segment analysis helps you decide where to focus product development, which customer types to acquire aggressively, and which usage patterns to discourage or charge premium prices for.

A complete cost model accounts for all economic dimensions of running agent systems: token consumption, compute infrastructure, tool and API usage, memory and storage, and operational overhead. Token costs scale with prompt design and model choice. Compute costs have fixed and variable components that scale with load. Tool costs scale with agent behavior and external pricing. Memory and storage costs grow with data retention policies. Monitoring makes costs visible and actionable. Pricing strategy must cover fully-loaded costs while remaining competitive. Together, these elements determine whether your agent product is economically sustainable and profitable at scale. Understanding and optimizing agent economics is not optional for production systems; it is the foundation that enables you to deliver value sustainably.
