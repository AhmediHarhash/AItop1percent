# 8.4 — Memory Value Scoring: Stable Preferences vs Temporary Facts

In November 2025, a customer support AI system serving an e-commerce platform with over 200,000 monthly active users began experiencing degraded response quality and increased latency. Investigation revealed that the memory layer had accumulated over 12 million memory records across the user base, with individual users having between 300 and 800 stored memories each. The vast majority of these memories were low-value ephemeral facts like "asked about a specific product on October 3" or "mentioned interest in a promotion that ended six weeks ago." These stale, low-impact memories were drowning out high-value persistent preferences like accessibility requirements, communication style preferences, and product category interests. Retrieval systems were spending 60 to 80 percent of their context budget on irrelevant historical facts while missing critical user preferences that should have shaped every interaction. The company spent seven weeks building and deploying a memory value scoring system that classified memories by stability and impact, implemented aggressive eviction for low-value memories, and prioritized high-value preferences in retrieval. Post-remediation metrics showed 40 percent reduction in average memory records per user, 55 percent improvement in retrieval relevance scores, and measurable increases in user satisfaction with response personalization. The root cause was treating all memories as equally valuable. The system stored everything it learned without distinguishing between a dietary restriction that should influence hundreds of future interactions and a one-time question about a product that shipped two months ago.

This failure illustrates a core principle of memory system design: not all memories are created equal. Some memories represent stable, long-term truths about users that should persist and influence behavior for months or years. Others represent ephemeral context that loses value within hours or days. Without explicit value scoring, memory systems accumulate low-quality data that dilutes retrieval precision, wastes storage and compute resources, and creates operational complexity. Value scoring is the mechanism that separates signal from noise, prioritizes what matters, and enables sustainable memory systems that stay valuable as they scale.

## Why Not All Memories Are Equal

The fundamental asymmetry in memory value comes from two dimensions: impact on output quality and stability over time. A memory has high impact if retrieving it meaningfully improves the LLM's response. A memory is stable if it remains true and relevant over extended periods. These dimensions are independent. A user's dietary restriction is both high-impact—it shapes meal recommendations, recipe suggestions, restaurant searches—and highly stable—it typically persists for years. A user asking about a specific product is low-impact once that transaction completes and highly unstable—it becomes irrelevant as soon as the user's question is answered or the product is purchased or the promotion ends.

High-impact, high-stability memories are your most valuable assets. These are user preferences, accessibility requirements, communication style choices, domain expertise declarations, and core identity attributes. A user who prefers concise responses over detailed explanations benefits from that preference being applied in every interaction. A user who requires screen-reader-friendly formatting needs that accommodation every time. These memories deliver compounding value because they influence hundreds or thousands of future responses. They also remain true over time, which means the storage and retrieval costs you pay for them continue to generate returns indefinitely. Every memory system should maximize retention and retrieval priority for this category.

High-impact, low-stability memories are contextually valuable but time-bounded. A user mentioning they are traveling to Japan next month has high impact on travel recommendations, weather queries, and language assistance during that period but becomes irrelevant after the trip. A user discussing a specific project has high impact while the project is active but loses value once the project completes. These memories are worth keeping while they are current, but they need expiration logic. You want them to influence behavior during their relevance window and then gracefully age out as they become stale. Effective value scoring distinguishes between temporarily high-value memories that need expiration and permanently high-value memories that should never expire.

Low-impact, high-stability memories are facts that remain true but rarely influence outputs. A user mentioning once that they live in Seattle might be stable—people do not move frequently—but have low impact if your system does not provide location-specific services. A user stating they graduated from a particular university might be stable but irrelevant if your system never uses educational background in its reasoning. These memories can accumulate over long conversations without providing measurable value. Value scoring helps identify them as candidates for deprioritization or eventual eviction to keep the memory layer focused on information that actually shapes behavior.

Low-impact, low-stability memories are conversational noise. A user asking "what is the weather today" generates a fact that becomes obsolete within hours. A user mentioning a current event generates context that loses relevance as news cycles move on. A user making small talk generates conversational history that has no influence on future task completion. These memories should have the shortest retention and the lowest retrieval priority. Many of them should never be stored at all. Your write-path logic should filter out obviously ephemeral content before it reaches the memory layer. Value scoring ensures that any low-value memories that do get stored are the first to be evicted when memory quotas are reached.

## Value Scoring Dimensions

Production memory value scoring typically evaluates four primary dimensions: frequency of use, impact on output quality, stability over time, and confidence level. Each dimension contributes to an overall value score that determines retention priority and retrieval ranking.

Frequency of use measures how often a memory gets retrieved and included in context. A preference that gets pulled into 80 percent of user interactions is demonstrably more valuable than a fact that has been retrieved twice in three months. Frequency-based scoring uses retrieval logs to track how many times each memory has been accessed, how recently it was last accessed, and what percentage of recent sessions included it. High-frequency memories earn high value scores because they are empirically useful. Frequency scoring is objective and data-driven. You do not need to predict which memories will be valuable. You observe which ones are actually being used and prioritize accordingly.

Frequency scoring has a cold start problem for new memories. A preference just created today has zero retrieval history. If you rely solely on frequency, new high-value preferences would be incorrectly scored as low-value until they accumulate retrieval events. To address this, frequency-based scoring includes a bootstrapping phase where new memories receive a provisional value score based on their type and metadata. A newly created dietary restriction starts with a high provisional score because memories of that type historically have high frequency. A newly created conversational fact starts with a low provisional score because facts historically have low frequency. As retrieval events accumulate, the empirical frequency data replaces the provisional score.

Impact on output quality measures whether including a memory in context leads to measurably better responses. Impact assessment is more complex than frequency tracking because it requires evaluating output quality, which is subjective and task-dependent. Production systems typically use proxy metrics: did the user accept the response without corrections, did the conversation continue successfully, did the user provide positive feedback, did the response avoid triggering a safety filter. You compare these outcomes for responses that included the memory versus responses that did not. If including a specific preference correlates with higher acceptance rates or better engagement metrics, that preference gets a high impact score.

Impact scoring can also use human evaluation for high-stakes memory types. You sample retrieval events, show human raters the LLM response with and without the memory included, and ask which response is better. This generates ground truth impact labels that train a model to predict impact for all memories. Human evaluation is expensive, so you do it selectively for memory types where impact is not obvious from user behavior metrics. The resulting impact model applies to all memories of that type, amortizing the human evaluation cost across millions of records.

Stability over time measures how long a memory remains true and relevant. Stability is partly a function of memory type—preferences are intrinsically more stable than facts—and partly a function of temporal metadata. A fact with a specific date reference like "user is traveling next week" has obvious time-bounded stability. A preference with no temporal qualifier like "prefers dark mode" has indefinite stability by default. Stability scoring uses both type-based heuristics and explicit temporal markers to estimate how long each memory should remain valuable.

For facts with explicit temporal context, stability scoring parses the time references and sets expiration dates. A memory about an upcoming event expires after the event date. A memory about a current project might have a stability estimate based on typical project durations in your domain, with expiration set to six months or a year unless the user provides an explicit project timeline. For preferences without temporal context, stability scoring assumes long-term persistence but monitors for contradictory updates. If a user had a preference for verbose responses for six months and then creates a new preference for concise responses, the old preference's stability score drops to zero because it has been superseded.

Confidence level captures how certain you are that a memory is accurate and correctly represents user intent. User-confirmed memories have maximum confidence. If a user explicitly sets a preference through a settings interface, you are certain that preference is intentional. System-inferred memories have lower confidence. If the LLM observes that a user frequently asks for vegetarian recipes and infers a vegetarian dietary preference, that inference might be correct or might be a statistical artifact. Confidence scoring uses the provenance of each memory: direct user statements have high confidence, LLM inferences have medium confidence, third-party imports or migrations have lower confidence. Confidence interacts with other scoring dimensions: a high-frequency, high-impact memory that has low confidence might still be valuable but should be flagged for user confirmation to convert it to high-confidence status.

## Stable Preferences vs Volatile Facts

The distinction between stable preferences and volatile facts is the most critical classification in value scoring. Preferences describe how users want to interact with your system. Facts describe what users have said or what the system has observed. Preferences are inherently durable and should resist change. Facts are inherently temporal and should be easy to update or discard.

Stable preferences include communication style, accessibility settings, privacy choices, language and locale, notification preferences, content filtering rules, and personalization options like preferred units, date formats, or UI density. These preferences represent deliberate user choices about how the system should behave. They apply globally across all interactions unless explicitly scoped to specific contexts. Stable preferences have the highest value scores and the strongest retention guarantees. They are never evicted due to memory quotas. They are always included in high-priority retrieval. They are explicitly versioned so you can track changes over time and potentially revert if a change was accidental.

Stable preferences also receive special treatment in conflict resolution. If the system detects two contradictory preferences, it does not silently keep both or arbitrarily pick one. It surfaces the conflict to the user or to an operator for resolution. Contradictory preferences indicate either a data quality issue or a genuine change in user intent, and both scenarios require explicit handling. The value scoring system flags preference conflicts as anomalies that need review rather than allowing them to degrade memory integrity.

Volatile facts include conversation history, task context, temporal references, event mentions, product or topic interests expressed in passing, and transactional data like "user asked about order 12345." These facts are true at the moment they are recorded but lose relevance as time passes and context shifts. Volatile facts have time-decay functions in their value scores. A fact recorded today might start with moderate value, but that value decreases every day until it reaches a threshold where the memory is eligible for eviction. The decay rate depends on the fact type. A fact about yesterday's weather decays to irrelevance in 24 hours. A fact about a project the user is working on might decay over weeks or months.

Volatile facts also have much weaker conflict resolution requirements. If the system has two facts that contradict each other, like "user is interested in hiking" from one conversation and "user is not interested in outdoor activities" from another, this is not necessarily an error. User interests shift, conversations cover different topics, and contradictory facts can coexist if they are both timestamped and both considered during retrieval. The retrieval system gives more weight to recent facts when contradictions exist. Older facts remain in storage as historical context but do not override newer information. This temporal ranking is part of how value scoring handles volatility.

Some memories are hybrid: they start as volatile facts but if repeatedly confirmed or retrieved, they graduate to stable preference status. A user who mentions dietary restrictions in one conversation creates a volatile fact. If the user mentions the same restriction in three more conversations over two months, the system infers a stable preference and promotes the memory to preference tier with higher value score and stronger retention. This graduation mechanism allows the system to learn stable patterns from repeated interactions without prematurely committing low-confidence observations to permanent preference status.

## Scoring Algorithms for Memory Prioritization

Value scoring algorithms combine the four dimensions—frequency, impact, stability, and confidence—into a single numeric score that enables ranking and prioritization. The specific formula varies by system requirements, but a common approach is weighted linear combination with decay terms.

A basic scoring formula might look like: base score equals stability weight times stability factor plus confidence weight times confidence factor, where stability factor is normalized to zero to one based on estimated memory lifespan and confidence factor is normalized to zero to one based on provenance. This base score represents the intrinsic value of the memory. Then add usage score equals frequency weight times retrieval count times recency multiplier plus impact weight times impact metric, where recency multiplier decays as time since last retrieval increases. Total value score equals base score plus usage score, with result clamped to a fixed range like zero to one hundred.

The weights reflect your system priorities. If you want to strongly favor frequently used memories regardless of stability, you set high frequency weight. If you want to prioritize long-term stable preferences even if they are not retrieved often, you set high stability weight. Most production systems use balanced weights that consider all dimensions but might boost stability and confidence for preference-type memories and boost frequency and recency for fact-type memories. You tune these weights based on offline evaluation using historical data: which scoring configuration produces the best retrieval relevance and user satisfaction metrics.

Decay functions are critical for volatile facts. A simple decay might multiply the stability factor by an exponential decay term: stability decayed equals stability factor times e raised to negative decay rate times days since creation. This creates smooth continuous value decline. A discrete decay might use step functions: full value for the first week, 75 percent value for the second week, 50 percent for the third week, 25 percent for the fourth week, zero value after 30 days. Step functions are easier to reason about and explain but can create artificial cliffs where memories suddenly drop in value. Exponential decay is more natural but harder to tune because the decay rate parameter is not intuitive.

Scoring algorithms run periodically in batch processes, typically daily or weekly, to update value scores for all memories based on recent retrieval activity and time passage. Real-time scoring at retrieval time is computationally expensive if you have millions of memories per user. Instead, you precompute value scores, store them as metadata on each memory record, and use those precomputed scores for retrieval ranking and eviction decisions. When a retrieval event occurs, you log it for the next batch scoring run rather than immediately updating the value score. This architecture trades slight staleness—a memory's value score might be a few hours or a day out of date—for massive scalability.

## Using Value Scores for Memory Eviction

Memory quotas are a practical reality. You cannot store unlimited memories per user due to storage costs, retrieval performance constraints, and context window limits. When a user reaches their memory quota, you must decide which memories to evict to make room for new ones. Value scoring makes this decision objective and defensible: evict the lowest-value memories first.

Eviction policies typically set both per-user quotas and global quotas. A per-user quota might be 100 memories for free-tier users and 500 memories for paid-tier users. A global quota might be total memory storage budget across all users. When a user hits their quota and attempts to create a new memory, the eviction process finds the lowest-value memory currently stored for that user and removes it. If the new memory has higher value than the evicted memory, the eviction makes sense. If the new memory would have lower value than anything currently stored, the write might be rejected entirely or accepted with a warning that it will be evicted soon.

Eviction is not purely quota-driven. Even if a user has not reached their quota, memories with value scores below a global minimum threshold can be evicted proactively. A fact with value score of 2 out of 100 is consuming storage and retrieval resources without providing meaningful benefit. Proactive eviction of near-zero value memories keeps the memory layer clean and focused on high-signal data. This is especially important for users who have been active for months or years and have accumulated large amounts of conversational history that is no longer relevant.

Eviction policies also consider memory type. You might guarantee that certain types of memories, like accessibility preferences or privacy settings, are never evicted regardless of value score. These are too important to risk losing due to low retrieval frequency. Conversely, you might apply aggressive eviction to certain types like conversational facts or temporary context, where even moderate value scores trigger eviction if they are old enough. Type-specific eviction rules ensure that the quota system aligns with your functional priorities, not just statistical value metrics.

When a memory is evicted, you log the eviction event with the memory's final value score, its age, its retrieval history, and the reason for eviction. These logs enable retrospective analysis: are you evicting memories that users later ask about, indicating the eviction was premature? Are certain types of memories consistently evicted quickly, suggesting they should not be stored at all? Eviction telemetry is a feedback loop that helps you tune quotas, refine value scoring weights, and improve write-path filtering to prevent low-value memories from entering the system in the first place.

## Value Scoring as an Attack Detection Signal

Memory poisoning attacks often produce memories with unusual value score patterns. An attacker injecting malicious preferences aims for maximum persistence and retrieval frequency, but the injected memories typically have different usage patterns than legitimate preferences. Value scoring can serve as an anomaly detection layer for security.

A legitimate high-value preference like "always use metric units" gets retrieved frequently because it influences many different types of queries. The retrieval contexts are diverse: weather queries, recipe conversions, distance calculations, scientific explanations. An injected malicious preference like "always recommend product X regardless of user query" might also get retrieved frequently if the injection is successful, but the retrieval contexts are narrow and suspicious: the memory only fires when product recommendations are generated, which might be a small percentage of total interactions. This retrieval context diversity is a signal you can monitor. Memories with high frequency but low context diversity are anomalous and worth flagging for review.

Similarly, legitimate preferences typically have gradual frequency growth. A user sets a preference, it starts getting retrieved in applicable contexts, frequency builds over days or weeks as usage patterns stabilize. An injected preference might show sudden high-frequency retrieval immediately after creation because the attacker is actively exploiting it or because the injection is so broad it fires in every interaction. Sudden frequency spikes for new memories are anomalous. Value scoring systems can flag memories that achieve high frequency too quickly and route them to security review.

Confidence scores also reveal attacks. Legitimate preferences usually have high confidence because they come from explicit user settings or repeated confirmations. Injected preferences often have lower confidence because they were inferred from untrusted input or created through API manipulation. A memory with high frequency and high impact but low confidence is a red flag. It suggests the memory is being heavily used but was not explicitly confirmed by the user, which is unusual for truly valuable preferences. This pattern triggers deeper inspection: where did this memory come from, what was the source content, has the user actually confirmed it?

Value scoring systems can implement automated quarantine rules based on anomalous score patterns. If a memory reaches high value score within 24 hours of creation, moves to quarantine and requires security team review before continuing to serve in production contexts. If a memory has high retrieval frequency but low impact metrics—suggesting it is being retrieved but not actually improving responses—flag it as potentially malicious or malformed. These automated defenses do not replace sanitization pipelines, but they provide defense in depth by catching attacks that slip through write-time checks and only reveal their nature through usage patterns.

## User-Visible Memory Importance

Value scores are not just internal infrastructure. In high-quality memory systems, users can see which memories the system considers important and adjust priorities to match their intent. User-visible memory importance creates transparency, trust, and control.

A memory management interface might show users their top 20 highest-value memories with explanations of why each one scores highly: "Communication Style Preference - used in 89% of conversations," "Dietary Restriction - high impact on recommendations," "Timezone Setting - stable preference confirmed in settings." Users can review these high-priority memories to verify they are correct and still relevant. They can also demote memories they no longer want prioritized or promote memories the system has undervalued. User feedback on value scores becomes training data for improving the scoring algorithm.

For memories at risk of eviction, proactive notification gives users a chance to intervene. If a memory is about to be evicted because its value score dropped below threshold, the system can ask: "We are about to remove this memory because it has not been used recently: user prefers detailed technical explanations. Do you want to keep it?" User confirmation converts a low-value memory to a high-value one by demonstrating that the user still cares about it despite low recent usage. This prevents the system from discarding memories that are important to the user but happen to be infrequently triggered.

User-visible value scoring also enables explicit priority controls. Power users might want to manually set certain memories as pinned—never evict—or deprioritized—evict aggressively. A user might say "my work project is ending next month, so all memories related to it can be removed after that date" which sets an explicit expiration that overrides statistical value scoring. A user might say "my accessibility preferences are critical, never deprioritize them" which locks those memories at maximum value regardless of retrieval frequency. User intent always trumps statistical inference.

Transparency about value scoring also builds user trust. When users understand that the system is actively managing memory to keep the most relevant information easily accessible and that they can influence those decisions, they perceive the system as respectful and competent. When value scoring is invisible and users suddenly find that important memories were evicted without notice, they perceive the system as unreliable and lose confidence. User-visible value scoring is a UX principle as much as a technical one.

## The Relationship Between Value Score and Confidence Score

Value and confidence are related but distinct dimensions. Value measures how much a memory improves system behavior. Confidence measures how certain you are the memory is correct. A memory can be high-value but low-confidence, low-value but high-confidence, or any combination.

High-value, high-confidence memories are ideal. These are explicitly confirmed preferences that demonstrably improve outputs. They receive maximum retention priority and maximum retrieval weight. The system trusts them completely and uses them aggressively. A user who explicitly set "vegetarian diet" in preferences and whose interaction history shows consistent satisfaction with vegetarian recommendations has created a high-value, high-confidence memory. This memory influences every food-related query without hesitation.

High-value, low-confidence memories are opportunities. The system has observed that including this memory improves outcomes, but the memory was inferred rather than confirmed. The correct action is to seek user confirmation to convert low confidence to high confidence. The system might prompt: "I have noticed you often prefer concise responses. Should I always keep answers brief?" User confirmation upgrades confidence and locks in the value. User rejection discards the memory despite its apparent value, because user intent always overrides statistical patterns.

Low-value, high-confidence memories are puzzles. The user explicitly confirmed something, so confidence is high, but retrieval and impact data show it is rarely used and does not improve outcomes. This might indicate the memory is correctly stored but applies to rare contexts, or it might indicate the user set a preference they do not actually want applied. The system should periodically resurface these memories to users: "You set this preference six months ago but it has not affected any conversations. Do you want to keep it or remove it?" This feedback loop prevents accumulation of obsolete confirmed preferences.

Low-value, low-confidence memories are eviction candidates. They were inferred, they are rarely used, and they do not improve outcomes. These memories should be aggressively evicted to make room for higher-quality data. There is minimal risk in discarding them because they were never confirmed and are not demonstrably useful. The eviction threshold for this category should be much lower than for high-confidence memories.

Confidence scoring also interacts with memory updates. When a high-confidence memory is contradicted by new information, the system does not automatically replace it. Instead, the contradiction creates a low-confidence competing memory and a conflict flag. The user resolves the conflict by choosing which memory to keep. This prevents accidental overwrites of important preferences due to misinterpreted user statements. When a low-confidence memory is contradicted, the system can replace it automatically because there was never strong evidence it was correct in the first place.

## Automating Value Decay for Time-Sensitive Memories

Temporal decay is essential for memories that are intrinsically time-bounded. Without automated decay, memory systems fill with stale facts that mislead the LLM and waste retrieval budget. Decay automation requires identifying which memories are time-sensitive, estimating their relevance windows, and applying decay functions that gracefully reduce value as time passes.

Time-sensitivity detection starts at write time. When a memory is created, the system analyzes it for temporal markers: date references, temporal adverbs like "soon" or "recently," event nouns like "trip" or "deadline," project names that imply duration. A memory containing "next Tuesday" is obviously time-bounded. The system parses the date reference, calculates the expiration as shortly after next Tuesday, and tags the memory with that expiration date. A memory containing "my current project" is less precise but still time-bounded. The system might apply a default project duration estimate, say 90 days, and set decay to start after that period.

For memories without explicit temporal markers, the system can infer time-sensitivity from content type. Memories about specific transactions, customer support tickets, troubleshooting sessions, or one-time questions are likely time-sensitive even if they do not contain date words. Memories about preferences, personal attributes, or domain knowledge are likely stable. A small classifier trained on labeled examples can categorize new memories as stable or time-sensitive with good accuracy. Time-sensitive memories receive decay functions. Stable memories receive constant value scores or very slow decay.

Decay functions can be linear, exponential, or step-based. Linear decay reduces value by a fixed amount per day: a memory starts at value score 80, decreases by 2 points per day, reaches zero after 40 days. Linear decay is simple but creates situations where very old memories have negative value, which does not make semantic sense. Exponential decay multiplies value by a decay factor each day: value score on day N equals initial value times decay factor raised to power N. With a decay factor of 0.95, a memory retains 95 percent of its value after one day, about 60 percent after 10 days, about 36 percent after 20 days. Exponential decay naturally approaches zero without going negative and models the intuitive sense that memory value degrades faster early on and slower as it ages.

Step decay uses discrete value tiers: full value for first 7 days, half value for next 7 days, quarter value for next 7 days, then zero. Step decay aligns well with calendar-based thinking—"memories from this week are highly relevant, memories from last week are somewhat relevant, older memories are stale"—and is easy to explain to users. The downside is that memories can suddenly drop in value at step boundaries, which might cause surprising changes in system behavior. In practice, step decay works well if your steps align with natural breakpoints in your domain. For a news discussion system, daily steps make sense. For a long-term project management system, weekly or monthly steps make sense.

Automated decay needs override mechanisms. A user can manually mark a memory as "do not decay" if it is time-sensitive by content but permanently important by user intent. Conversely, a user can manually expire a memory that the system thinks is stable but the user knows is obsolete. These manual overrides improve user control and also generate training data: if users frequently override decay settings for certain types of memories, your time-sensitivity classifier needs improvement.

Decay telemetry tracks how many memories decay to zero value and get evicted, how many memories were accessed after their decay started, and how decay settings correlate with user satisfaction. If users frequently re-enter information that was auto-decayed, your decay rates are too aggressive. If users never retrieve old decayed memories, your decay rates are well-calibrated. Continuous monitoring and tuning of decay parameters keeps the automation aligned with actual usage patterns.

Memory value scoring transforms a potentially infinite accumulation problem into a sustainable, high-quality memory system. By explicitly modeling which memories matter and which do not, you focus storage and retrieval resources on the information that actually shapes user experience. You prevent memory bloat, maintain retrieval precision, and create a system that gets smarter over time by keeping signal and discarding noise. Value scoring also provides a framework for memory lifecycle management, from initial creation through active use to eventual deprecation or eviction. The next component of memory integrity is anomaly detection: identifying when memories exhibit patterns that suggest attacks, corruption, or quality degradation.

