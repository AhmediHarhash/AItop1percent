# 7.7 — Change Control for Org Memory: Approvals and Review Queues

In March 2025, a financial services company with 6,800 employees updated a memory entry in their organizational knowledge system. The update changed the documented wire transfer approval threshold from "two signatures required for transfers above $50,000" to "two signatures required for transfers above $500,000." The change was intended to reduce approval friction for a specific category of pre-approved vendor payments, but the memory entry did not specify that limitation. The updated memory went live immediately with no review. Over the next eleven days, the AI assistant guided 23 employees through wire transfer requests that should have required dual approval but received only single approval because the AI cited the updated memory as authoritative policy. The company caught the error during a routine audit, by which time $4.7 million in transfers had gone through the weakened control process. No fraud occurred, but the control failure triggered a regulatory inquiry, a complete review of all AI-assisted financial workflows, and a six-month project to implement formal change control for organizational memory. The cost in audit fees, consulting, and regulatory penalties reached $920,000.

The root cause was treating organizational memory like a wiki where anyone can edit anything at any time. Memory is not documentation that sits passively waiting to be read. It is operational knowledge that actively shapes behavior through AI systems that thousands of people interact with daily. Changes to that knowledge are changes to business processes, and changes to business processes require change control: review, approval, testing, and rollback procedures that ensure you do not accidentally break things that are currently working.

## Why Org Memory Needs Change Control

Organizational memory is infrastructure. When you change a memory entry about invoice approval workflow, you are changing how invoices get approved. When you change a memory entry about customer escalation procedures, you are changing how customer escalations get handled. When you change a memory entry about data retention policies, you are changing what data gets deleted and when. These are not documentation updates; they are system configuration changes that have real consequences if you get them wrong.

The impact of a single memory change can be enormous because the change propagates through every AI interaction that touches that knowledge. If 200 employees per day interact with the AI assistant about expense reporting, and you change the memory entry about expense policies, you have just changed the guidance that 200 people per day receive. If the change is wrong, you have just misinformed 200 people per day. Over a week, that is 1,400 people working from incorrect information. Over a month, it is 6,000 people. The blast radius of a memory change can exceed the blast radius of many code changes because memory affects behavior across the entire organization, not just within a single application.

Changes to organizational memory are also harder to detect when they go wrong. If you deploy a code change that breaks a feature, users immediately notice that the feature does not work and submit error reports. If you deploy a memory change that gives incorrect guidance, users do not know it is incorrect; they follow the guidance and create downstream problems that might not surface for days or weeks. The invoice that should have been escalated but was not. The data that should have been retained but was deleted. The approval that should have been obtained but was skipped. These failures are silent until they trigger audits, compliance violations, or operational incidents.

You cannot rely on memory authors to be careful. You cannot rely on review-before-publish workflows alone, because those workflows assume the initial publication was correct and do not apply the same scrutiny to updates. You need formal change control that treats every modification to organizational memory as a controlled change with documentation, approval, and rollback capability. This is not bureaucracy; this is basic operational discipline for infrastructure that affects thousands of users.

## Approval Workflows: Submit, Review, Approve, Publish

Change control starts with separating the act of proposing a change from the act of publishing it. When someone wants to update an existing memory entry, they submit a change request that includes the current text, the proposed new text, the reason for the change, and the expected impact. The change request enters a review queue. A designated reviewer—typically a domain editor or a cross-functional review committee for high-impact changes—evaluates the request against accuracy, policy alignment, impact scope, and risk. The reviewer can approve the change, request modifications, or reject it with explanation. Only after approval does the change go live.

The review process is structured, not ad hoc. You provide reviewers with a change review checklist. Is the proposed change factually accurate? Does it align with current organizational policy, or is it changing policy without proper authority? Does it contradict other memory entries, and if so, have those contradictions been resolved? What is the estimated impact scope: how many users or workflows will be affected? Are there any compliance, security, or financial control implications? Has the change been tested in a staging environment? Is there a rollback plan if the change causes problems?

For low-risk changes—corrections of typos, clarifications of existing wording, updates to contact information—the review can be lightweight, possibly even automated if the change passes syntax and duplication checks. For medium-risk changes—updates to process descriptions, modifications of procedural steps, changes to tool usage guidance—you require human review by a domain editor with sign-off typically within one to two business days. For high-risk changes—modifications to policy statements, changes to financial or legal procedures, updates to compliance-related memory—you require multi-level review, potentially including legal, compliance, or executive sign-off, with a more extended review period that allows for thorough evaluation.

The approval workflow generates an audit trail. Every change request is logged with submitter identity, submission timestamp, reviewer identity, review completion timestamp, approval decision, and any comments or modification requests made during review. If a change is rejected, the rejection reason is logged. If a change is approved but later causes problems, you have full traceability to understand how the change was reviewed and approved. This audit trail supports compliance requirements and provides the data you need for continuous improvement of your review process.

Some organizations implement a separation of duties requirement where the person who proposes a change cannot be the person who approves it, even if both individuals have editor privileges. This prevents self-approval, which is a common failure mode in systems without formal controls. The submitter and the approver must be different people, and for high-risk changes, the approver must be from a different reporting line than the submitter to avoid conflicts of interest. These controls are standard practice in financial systems and code deployment pipelines; they apply equally to organizational memory.

## Review Queues and SLAs for Memory Changes

Change requests sit in review queues until someone processes them. If the queue is not actively managed, requests accumulate, review times stretch from hours to days to weeks, and frustrated submitters start looking for ways to bypass the review process. You need service level agreements that define how quickly different categories of change requests must be reviewed, you need assigned responsibility for queue monitoring, and you need alerts when SLAs are at risk of being breached.

A typical SLA structure defines maximum review times by change risk category. Low-risk changes: reviewed within four business hours. Medium-risk changes: reviewed within two business days. High-risk changes: reviewed within one week, with initial acknowledgment within one business day so the submitter knows their request was received and who is reviewing it. Emergency changes: reviewed within one hour with expedited approval process. These SLAs are not aspirational; they are commitments that you measure and report on.

Queue management requires assigned ownership. For each domain or memory namespace, you designate a primary reviewer and a backup reviewer. The primary reviewer is responsible for meeting SLAs on change requests in their domain. The backup reviewer takes over when the primary is unavailable or when queue depth exceeds a threshold that one person cannot handle within SLA. Reviewer assignments are documented, monitored, and adjusted based on actual queue volumes and review capacity. If the HR memory queue consistently has 20 pending change requests and one reviewer, you either add reviewer capacity or adjust expectations about how quickly HR memory can be updated.

You instrument the queue to provide visibility. Reviewers have a dashboard showing pending change requests sorted by submission time, risk category, and time remaining until SLA breach. Submitters can check the status of their change requests and see where they are in the review process. Administrators can see cross-domain queue metrics to identify bottlenecks and capacity issues. The instrumentation turns queue management from a manual tracking problem into a data-driven operational process.

When SLAs are missed, you escalate. A change request that has been in the queue for twice the target review time generates an alert to the reviewer's manager. A change request that has been in the queue for three times the target review time generates an alert to the memory system administrator and to the submitter's manager, because at that point the delay is affecting the submitter's work. Repeated SLA misses trigger a review of reviewer capacity and workload. The SLA enforcement is not punitive; it is feedback that tells you when your review capacity does not match your change request volume.

Some organizations implement express lanes for routine changes. If a change request meets specific criteria—single-sentence modification, no policy implications, affects fewer than 100 users, submitted by a trusted contributor—it can go through automated approval with post-publication review. This reduces queue load for substantive changes that require careful human evaluation. The express lane is not a bypass of review; it is a risk-based triage that allocates review capacity where it provides the most value.

## Rollback Procedures for Bad Memory Updates

Even with careful review, some memory changes turn out to be wrong. The change was based on a misunderstanding of current policy. The change introduced an ambiguity that causes the AI to give inconsistent guidance. The change contradicted another memory entry that the reviewer did not know about. When a memory change causes problems, you need to roll it back quickly, before more users are affected.

Rollback starts with version control. Every memory entry has a version history that shows what it said before each change, who changed it, when, and why. When you need to roll back a change, you identify the problematic version, select the previous version, and restore it. The rollback is logged as a change event in the audit trail, with the reason for rollback documented. The person who made the original change is notified so they understand what went wrong and can submit a corrected change request if appropriate.

Fast rollback requires operational authority. You cannot make rollback subject to the same multi-day approval process as forward changes, or you perpetuate the problem while waiting for approval to fix it. Instead, you designate rollback authority to domain editors and administrators with a lightweight approval requirement. An editor can rollback a change in their domain immediately and must notify their manager within four hours with justification. An administrator can rollback any change immediately and must notify the affected domain owner within four hours. This gives you the speed to contain damage while maintaining accountability.

Some rollbacks affect multiple memory entries. If a change to the expense policy memory triggered related changes to the travel policy memory and the vendor payment memory, you need to rollback all three entries to restore consistency. Batch rollback follows the same approval and notification process as individual rollback but requires administrator execution to ensure all related entries are rolled back atomically. You do not want a partial rollback where some entries reflect the old policy and others reflect the new policy, because that creates contradictions that confuse the AI system.

Rollback does not mean the change is permanently rejected. It means the change is temporarily reverted while the issue is investigated and corrected. After rollback, the submitter or domain owner can submit a revised change request that addresses the problems identified during the rollback investigation. The revised request goes through normal review. The rollback procedure is not punitive; it is risk management that minimizes the impact of errors while preserving the ability to make necessary changes.

You track rollback frequency as a quality metric. If a particular domain or a particular reviewer has frequent rollbacks, that indicates a problem with the review process or with knowledge quality in that domain. You investigate root causes and implement corrective actions: better reviewer training, more detailed change request templates, cross-domain review for changes that affect multiple areas. Rollbacks are learning opportunities that make your change control process more effective over time.

## Versioning Org Memory: Track What Changed, When, By Whom

Every memory entry exists in multiple versions over its lifetime. The initial version published when the entry was first created. The second version published when someone corrected a typo. The third version published when a process changed and the memory needed to reflect the new procedure. Each version is a snapshot of the knowledge at a point in time, and each version is preserved so you can understand how organizational knowledge has evolved and so you can recover previous versions if needed.

Version metadata captures the essential information for each snapshot. The version number or timestamp that uniquely identifies this version. The full text of the memory entry as it existed in this version. The identity of the person who created this version. The timestamp when this version became active. The change reason or description provided by the submitter. The approval chain if applicable. References to related changes in other memory entries. This metadata turns the version history from a simple audit trail into a rich knowledge lineage that supports investigation, compliance, and understanding.

Version comparison capabilities let you see what changed between any two versions. You select version 5 and version 7 of a memory entry, and the system shows you a diff highlighting additions, deletions, and modifications. This is essential for understanding the impact of a change. If a memory entry has been updated five times since the last compliance review, the compliance auditor needs to see what changed across those five updates to assess whether any of them have compliance implications. Without version comparison, the auditor has to manually read all five versions and mentally track differences.

Version histories support compliance and legal requirements. When a regulatory inquiry asks "what did your employee expense policy say on June 15, 2025," you retrieve version history for the expense policy memory entry, identify the version active on that date, and provide it. When an employment lawsuit asks "what were the documented procedures for performance reviews when this employee was reviewed," you retrieve version history for the performance review memory entry, identify the version active during the relevant period, and produce it. Version history turns organizational memory into a reliable record system that can support legal and regulatory needs.

You also use version history for knowledge archaeology. When someone asks "why do we do this process this way," you can trace back through the version history to see when that process was documented, who documented it, and what the change reason was. Sometimes you discover that a procedure is a workaround for a system limitation that no longer exists, and you can update the process. Sometimes you discover that a procedure was implemented in response to a specific incident, and understanding that context helps you evaluate whether the procedure is still necessary. Version history provides institutional memory that complements the operational memory in the entries themselves.

## Testing Memory Changes Before Deployment

Code changes go through testing environments before production deployment. Configuration changes go through validation procedures. Organizational memory changes should follow the same discipline: test the change in an environment that mirrors production, verify it produces the expected AI behavior, then deploy to production. This catches problems before they affect real users.

A memory staging environment is a copy of your production memory system that is isolated from production AI interactions. When someone submits a memory change request, the change is applied to staging first. Reviewers and testers can query the staging environment with the same questions that users ask in production and verify that the AI responses reflect the intended change. If the change introduces problems—the AI gives contradictory answers, the AI misinterprets the updated memory, the AI cannot find the memory when it should—you catch it in staging and fix it before production deployment.

Testing is not just about correctness; it is about interaction effects. A change to the expense policy memory might be correct in isolation but might create ambiguity when combined with the travel policy memory and the vendor payment memory. Testing in staging lets you query scenarios that involve multiple memory entries and verify that the combined guidance is coherent. You test edge cases: what happens if a user asks about the policy for expenses that are both travel-related and vendor payments? Does the AI give a clear answer, or does it get confused by overlapping memory entries?

For high-risk changes, you implement additional testing rigor. You define a test suite of representative queries that should be affected by the change and queries that should not be affected. You run the test suite against staging before the change and after the change and verify that affected queries show the expected change in AI responses while unaffected queries remain unchanged. This structured testing catches subtle problems that ad hoc testing might miss.

Some organizations use A/B testing for memory changes that affect large user populations or that involve uncertain impacts. The change is deployed to 5% of production users while 95% continue to see the old memory. You monitor AI interaction quality, user satisfaction metrics, and downstream outcomes for both groups. If the change produces better outcomes, you roll it out to 100% of users. If the change produces worse outcomes or no measurable difference, you rollback and reevaluate. A/B testing is expensive in complexity and operational overhead, but for memory changes that affect critical workflows or large populations, the cost is justified by the risk reduction.

Testing memory changes is harder than testing code changes because memory affects AI behavior, and AI behavior is probabilistic and context-dependent. The same memory entry might produce different AI responses depending on the rest of the conversation context, the user's role, or even model randomness. You cannot achieve perfect test coverage, but you can achieve sufficient coverage to catch the majority of problems before they reach production. The goal is not perfection; the goal is reducing the risk of bad changes to an acceptable level.

## Emergency Memory Updates: Bypassing Normal Review for Urgent Corrections

Normal change control assumes you have time for review, testing, and approval. Emergency situations do not afford that time. When a memory entry is actively causing harm—guiding users to violate a legal requirement, contradicting a just-issued executive directive, directing users to a deprecated system that is about to be shut down—you need the ability to update memory immediately, even if it means bypassing normal review.

Emergency update procedures balance speed with accountability. An administrator or designated domain editor can execute an emergency update without prior approval, but they must document the emergency justification, notify leadership immediately, and submit the change for post-publication review within 24 hours. The emergency update is logged prominently in the audit trail. If the emergency justification is not deemed sufficient during post-publication review, the administrator or editor receives feedback and potential consequences for misusing the emergency procedure. This prevents emergency procedures from becoming routine shortcuts.

Emergency updates are scoped narrowly. You update the specific memory entry causing the immediate problem, not a batch of related entries. You make the minimum necessary change to stop the harm, not a comprehensive revision. Comprehensive revisions go through normal change control after the emergency is resolved. The narrow scope reduces the risk that the emergency update itself introduces new problems while you are trying to fix the original problem.

You define in advance what qualifies as an emergency. Active legal or compliance violations: emergency. Active safety risks: emergency. System outages where memory is directing users to non-functional services: emergency. Incorrect contact information during an ongoing incident: emergency. Routine corrections, clarifications, or process improvements, even if important: not emergency. The definition is documented and communicated to everyone with emergency update authority so that the procedure is used consistently and only when genuinely necessary.

Post-emergency review is mandatory. Within 48 hours of an emergency update, a review committee examines what happened: what was the problem, why was it an emergency, was the update appropriate, did it solve the problem, did it introduce new problems, and what process improvements would prevent similar emergencies in the future. The review findings are documented and used to improve both the memory content and the change control process. Emergency updates are learning opportunities that make your systems more resilient.

## Change Impact Assessment: How Many Users and Conversations Are Affected

Not all memory changes have equal impact. Updating a memory entry about conference room booking affects facilities staff. Updating a memory entry about customer refund policies affects customer service representatives, finance teams, and potentially thousands of customers. Before approving a memory change, you need to assess its impact scope: how many users will be affected, how many conversations will be influenced, and what the consequences are if the change is wrong.

Impact assessment starts with usage data. Your AI system logs which memory entries are retrieved during each user interaction. You aggregate this data to understand retrieval frequency: how often is this memory entry accessed per day, per week, per month. A memory entry accessed 500 times per day has higher impact than one accessed five times per month. High-frequency memory changes receive more rigorous review because errors propagate to more users.

You also assess user population scope. Some memory entries are relevant only to specific teams or roles. A memory entry about engineering deployment procedures affects engineers, not sales or HR. A memory entry about sales commission calculations affects sales teams and finance, not engineering or marketing. You tag memory entries with affected roles or departments, and when reviewing a change, you assess how many people in those populations interact with the AI system. A change affecting a 10-person team is lower risk than a change affecting a 1,000-person department.

Consequence analysis evaluates what happens if the change is wrong. Financial impact: could this change cause incorrect financial transactions, approvals, or reports? Compliance impact: could this change cause violations of regulations, policies, or contractual commitments? Security impact: could this change expose sensitive data or weaken access controls? Operational impact: could this change disrupt critical business processes? Changes with high consequence in any of these dimensions require elevated review and approval, regardless of user population size.

Impact assessment is documented in the change request. The submitter provides their assessment of impact scope and consequences. The reviewer independently evaluates impact as part of the review process. If there is significant discrepancy between the submitter's assessment and the reviewer's assessment, the change is escalated for additional review before approval. Impact assessment is not about blocking changes; it is about ensuring the level of review and testing is proportional to the risk.

## Notification Systems for Memory Changes

When a memory entry changes, affected users need to know. If the expense policy memory is updated to increase approval thresholds, employees submitting expenses need to be aware. If the customer escalation memory is updated to change the escalation procedure, customer service representatives need to be informed. If the data retention memory is updated to extend retention periods, teams managing data need to adjust their processes. Notification systems ensure that memory changes do not silently change behavior without user awareness.

Notification starts with subscription. Users or teams can subscribe to specific memory entries or memory namespaces that are relevant to their work. When a subscribed memory entry is updated, subscribers receive a notification with a summary of the change, a link to view the full change diff, and the effective date. The notification is delivered through the communication channels your organization already uses: email, Slack, Teams, or in-app notifications in the AI assistant itself.

Not all changes require broadcast notification. Typo corrections and minor clarifications might not warrant disturbing hundreds of subscribers. You implement notification thresholds: minor changes generate a digest notification sent weekly, medium changes generate individual notifications sent within 24 hours, major changes generate immediate notifications with high priority. The change reviewer designates the notification priority as part of the approval process based on impact assessment.

Some changes require acknowledgment, not just notification. For changes to compliance-critical memory, financial control memory, or safety procedure memory, you send notifications that require recipients to acknowledge they have read and understood the change. The acknowledgment is tracked, and users who do not acknowledge within a specified timeframe receive reminders. For certain high-risk memory, lack of acknowledgment might trigger a conversation with the user's manager to ensure awareness. Acknowledgment tracking provides evidence that you took reasonable steps to ensure organizational awareness of critical changes.

Notification also supports transparency. You maintain a public change log, accessible to all employees, that lists recent memory changes with dates, change descriptions, and affected domains. Users who do not subscribe to specific memory entries can still browse the change log to stay aware of organizational knowledge evolution. The change log is searchable and filterable so users can find changes relevant to their interests or responsibilities. Transparency builds trust in the memory system and encourages employees to keep their own knowledge current.

## The Balance Between Agility and Safety in Memory Updates

Change control creates safety, but it also creates latency and overhead. Every approval step adds time. Every review requirement adds workload. Every test cycle delays deployment. If change control is too heavy, the organizational memory becomes stale because nobody wants to navigate the bureaucracy required to update it. If change control is too light, the organizational memory becomes unreliable because changes are not adequately reviewed. You need the balance point where safety is sufficient without paralyzing agility.

The balance is risk-based, not uniform. High-risk memory—policies, compliance procedures, financial controls, safety protocols—gets heavy change control with multi-tier review, testing, and approval. Low-risk memory—team contact lists, internal process descriptions, tool tips—gets lightweight change control with rapid review and approval. Medium-risk memory—customer-facing procedures, operational workflows, support playbooks—gets moderate change control with single-tier review and selective testing. Risk calibration makes your control overhead proportional to consequences.

You also balance through automation. Automated checks for duplicate memory, contradictory memory, and policy keyword detection catch obvious problems without requiring human review time. Automated routing sends change requests to the right reviewers based on memory namespace and tags. Automated notifications keep stakeholders informed without manual communication effort. Automated rollback procedures let you fix problems quickly without scheduling an approval meeting. Automation removes the bureaucratic overhead from change control and leaves only the judgment and decision-making that genuinely requires human expertise.

Cultural factors matter as much as process design. If your organization treats every memory change as a high-stakes decision requiring executive approval, change control will be slow and people will work around it. If your organization treats memory changes as routine operational maintenance executed by trusted domain experts, change control will be fast and people will use it. You build trust through demonstrated competence: when memory changes consistently improve system behavior and when review processes catch real problems before they affect users, people trust the system and engage with it willingly. When memory changes frequently cause problems or when review processes seem arbitrary and slow, people lose trust and find workarounds.

You measure the balance through metrics. Average time from change request submission to deployment. Change request volume over time. Rollback frequency. User satisfaction with memory accuracy. Reviewer workload and queue depth. If deployment times are increasing but rollback rates are not decreasing, your control process is getting heavier without getting safer. If rollback rates are increasing, your control process is not catching problems effectively. If change request volume is decreasing while user complaints about outdated memory are increasing, your control process has become a barrier. These metrics guide continuous tuning of your change control procedures to maintain the right balance for your organization's risk tolerance and operational pace.

Change control for organizational memory is not optional overhead. It is the operational discipline that makes memory trustworthy at scale. Without it, you are building on sand: knowledge that shifts unpredictably, guidance that contradicts itself, trust that evaporates when errors compound. With it, you have infrastructure: knowledge that evolves in controlled ways, guidance that remains consistent, trust that grows as the system proves reliable. The investment in change control processes pays dividends in reduced incidents, improved compliance, and organizational confidence that the AI systems drawing on this memory are telling people the right things. As your memory system grows and its usage expands, the next frontier is not just keeping memory accurate—it is keeping it secure, defending it against adversaries who understand that corrupting organizational memory is a powerful attack vector that can compromise thousands of users without touching any code or infrastructure.
