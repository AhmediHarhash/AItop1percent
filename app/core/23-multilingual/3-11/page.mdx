# 3.11 â€” Budgeting for Multilingual: Adjusting Cost Models by Language

In early 2025, a startup building a customer service automation product budgeted $40,000 per month for inference costs. The budget was based on their English pilot: average query length, average response length, system prompt size, five few-shot examples per request, and the per-token pricing of their chosen API provider. The math was clean. The spreadsheet was approved. Then they launched in Japan and Korea. By the end of the first month, the invoice was $67,000 -- sixty-eight percent over budget. The CEO asked what went wrong. The engineering team had a single-sentence answer: nobody modeled the per-language cost. Every cost projection had been built on English token counts, and English token counts do not predict Japanese or Korean token counts. The token fertility ratio for Japanese on their chosen model was 2.6 times English. For Korean, it was 2.1 times. Every component of the cost model -- system prompt, few-shot examples, user input, model output -- was inflated by a multiplier that the budget did not account for. The startup spent the next quarter rebuilding their cost model from scratch, this time with language as a first-class variable.

This failure is not unusual. It is the default outcome when teams budget for multilingual AI using English-derived cost models. This subchapter teaches you how to build cost models that account for the token tax from day one, so your budget reflects reality before launch rather than after.

## Why English-Based Cost Models Are Wrong

The fundamental error is treating tokens as a language-neutral unit of measurement. They are not. A token is a unit of the tokenizer's vocabulary, and as the previous subchapters established, different languages consume different numbers of tokens to express the same semantic content. Building a cost model on English token counts and applying it to all languages is like measuring floor area in one building and assuming every building in the city has the same square footage per room.

The error compounds across every component of a request. Your system prompt might be 1,200 tokens in English and 3,400 tokens in Japanese. Your five few-shot examples might cost 800 tokens in English and 2,100 in Arabic. The user's input might average 45 tokens in English and 120 in Thai. The model's response might average 250 tokens in English and 650 in Korean. Add these together and the total token cost per request in a high-fertility language can be 2.5 to 3.5 times the English cost -- for the exact same task, producing the exact same semantic output.

If your cost model uses a single average tokens-per-request number derived from English usage, every non-English language will exceed budget. The higher the fertility ratio, the larger the overrun. And because you typically do not discover this until the first multilingual invoice arrives, the surprise comes after launch, when the budget has already been committed and the product has already been promised to customers in those markets.

## Per-Language Unit Economics

The fix starts with a deceptively simple principle: calculate cost-per-query for each language separately. Not as an average across languages. Not as a blended number with a safety margin. Per language.

The formula for a single request in language L requires five inputs. First, the system prompt token count in language L -- measured, not estimated from English. Second, the average few-shot example token count in language L. Third, the average user input token count in language L. Fourth, the average model output token count in language L. Fifth, the per-token prices for input and output on your chosen model.

For a concrete example, consider a customer support bot using a model priced at $3 per million input tokens and $15 per million output tokens. In English, the system prompt is 1,100 input tokens, five examples add 900 input tokens, the average user query is 50 input tokens, and the average response is 200 output tokens. The per-query cost is 2,050 input tokens at $3 per million ($0.00615) plus 200 output tokens at $15 per million ($0.003), totaling roughly $0.009 per query.

Now run the same calculation for Japanese, where the fertility ratio on this model is 2.5 times. The system prompt inflates to approximately 2,750 input tokens. The examples inflate to 2,250. The user query inflates to 125. The output inflates to 500. The per-query cost is 5,125 input tokens ($0.01538) plus 500 output tokens ($0.0075), totaling roughly $0.023 per query. That is 2.5 times the English cost. Not because the task is harder. Not because the model is slower. Because the tokenizer uses more tokens to represent Japanese.

Run this calculation for every language you serve. The numbers will differ for each one. Arabic will land somewhere between 2.0 and 3.0 times English. Thai will land between 2.5 and 3.5 times. German and French will land between 1.1 and 1.4 times. These ratios are specific to your tokenizer, your prompts, and your average query patterns -- which is why you must measure them, not estimate them from generic benchmarks.

## Blended Cost Modeling

Once you have per-language cost-per-query numbers, you need a blended projection that accounts for your expected traffic distribution across languages. This is where cost models become useful for budgeting.

The blended cost per query equals the sum of each language's cost-per-query multiplied by that language's share of total traffic. If 60% of your traffic is English at $0.009 per query, 20% is Japanese at $0.023, 10% is Korean at $0.018, and 10% is Spanish at $0.011, your blended cost per query is ($0.009 times 0.60) plus ($0.023 times 0.20) plus ($0.018 times 0.10) plus ($0.011 times 0.10), which equals $0.0054 plus $0.0046 plus $0.0018 plus $0.0011, totaling $0.0129 per query. At 500,000 queries per month, that is $6,450 -- compared to $4,500 if you had naively used the English rate for all traffic.

The difference between the naive English projection and the language-weighted projection is your token tax budget gap. In this example, the gap is $1,950 per month -- 43% higher than the English-only estimate. For products with higher non-English traffic shares, the gap can easily reach 60 to 100%.

The blended model has a critical fragility: it depends on the traffic distribution being stable. If a marketing campaign drives unexpected traffic from a high-fertility language, or if a new market launch shifts your language mix, the blended cost changes. Build your projections with three scenarios: the expected language distribution, a high-cost scenario where high-fertility languages grow to 150% of expected share, and a worst-case scenario where your most expensive language becomes the dominant traffic source. Budget for the expected case. Reserve for the high-cost case. Know the worst-case number so it does not surprise you.

## Language-Tier-Based Budgeting

Calculating per-language costs for three or four languages is manageable. Doing it for twenty or forty languages is tedious. The pragmatic solution is to group languages into fertility tiers and apply tier-level multipliers.

**Tier 1** includes languages with fertility ratios between 1.0 and 1.4 times English. These are primarily European languages that share Latin script and are well-represented in tokenizer training data: English, Spanish, French, German, Portuguese, Italian, Dutch. The cost multiplier for Tier 1 is 1.0 to 1.2 times your English baseline. Budget these languages at your English rate plus a small buffer.

**Tier 2** includes languages with fertility ratios between 1.4 and 2.2 times English. This tier covers languages with non-Latin scripts that still have reasonable tokenizer representation: Chinese, Korean, Russian, Hindi, Turkish, Vietnamese, Indonesian. On well-optimized tokenizers like Qwen for Chinese or Gemma 3 for broad multilingual coverage, some of these languages approach Tier 1 efficiency. On English-centric tokenizers, they sit firmly in Tier 2. The cost multiplier is 1.5 to 2.0 times English.

**Tier 3** includes languages with fertility ratios between 2.2 and 3.5 times English. This tier covers languages with complex scripts, rich morphology, or low tokenizer representation: Japanese, Arabic, Thai, Farsi, Hebrew, Bengali, Tamil. The cost multiplier is 2.0 to 3.0 times English. Japanese lands here on most tokenizers except those specifically optimized for CJK, where it can reach Tier 2.

**Tier 4** includes languages with fertility ratios above 3.5 times English. These are languages with very low representation in major tokenizer training data: Amharic, Burmese, Khmer, Lao, Georgian, many African and Southeast Asian languages. The cost multiplier is 3.0 to 5.0 times English. Supporting a Tier 4 language at scale requires either a specialized tokenizer or a budget that explicitly accounts for the premium.

Assign each of your supported languages to a tier based on measured fertility ratios on your specific tokenizer. Then use the tier multiplier in your budget projections. This is not as precise as per-language calculation, but it is accurate enough for planning and reduces the maintenance burden of tracking twenty individual cost models.

## Dynamic Budget Adjustment

Your language distribution is not static. Traffic patterns shift seasonally, geographically, and in response to business events. A product launch in the Middle East shifts traffic toward Arabic. A partnership with a Japanese enterprise client floods your system with Japanese queries. A viral social media mention in Brazil drives Portuguese traffic for two weeks. Each shift changes your cost structure.

The cost model must be dynamic. Build a monthly reconciliation process that compares projected language distribution against actual language distribution, and recalculates the blended cost accordingly. If Japanese traffic was projected at 15% and came in at 25%, your monthly costs will be higher than budgeted, and next month's projection needs to reflect the new reality.

Automate this where possible. Your logging system already records the language of each request -- if it does not, that is the first gap to close. Aggregate these logs weekly and compute the actual language distribution. Multiply by your per-language cost-per-query to produce a real-time cost projection. When the projection deviates from budget by more than 10%, alert the finance and product teams so they can adjust forecasts before the invoice arrives.

## The Revenue-Cost Alignment Problem

Here is the uncomfortable truth that most multilingual products avoid discussing: if your pricing is the same across all languages but your costs differ by language, some languages are profit-positive and some are profit-negative. An English query that costs $0.009 and generates $0.05 of revenue per interaction has a healthy margin. A Japanese query that costs $0.023 and generates the same $0.05 per interaction has a much thinner margin. A Thai query at $0.032 against $0.05 revenue is barely above breakeven. And if any language's per-query cost exceeds the per-query revenue, you lose money on every interaction in that language.

Most teams do not perform this analysis because the answer is uncomfortable. It suggests that either pricing should vary by language -- which creates a fairness and perception problem -- or that high-cost languages should receive less expensive service tiers -- which creates a quality equity problem. Neither option is appealing.

The pragmatic resolution is cross-subsidy. English and Tier 1 languages generate enough margin to subsidize the cost premium of Tier 3 and Tier 4 languages, as long as the blended margin across all languages remains positive. This is the same economics that telecom companies use for rural coverage: profitable urban areas subsidize expensive rural infrastructure because the business case is made at the portfolio level, not per-customer.

But cross-subsidy only works if you know the numbers. You need per-language cost-per-query, per-language revenue-per-query, and per-language margin-per-query. Without these numbers, you cannot verify that the cross-subsidy is sustainable, and you cannot detect when a shift in language mix pushes the blended margin negative.

## Building the Per-Language Cost Model

Assembling a per-language cost model requires gathering five categories of data.

First, fertility ratios. For each language on each model you use, measure the token count for a representative sample of inputs and outputs. The previous subchapters taught you how to measure fertility. Record the ratio for every language-model pair.

Second, expected traffic volume by language. Pull this from your analytics, market research, or business projections. Be specific: monthly query volume per language, with seasonal adjustments if your product has seasonal patterns.

Third, model pricing. Record the per-token input and output prices for every model you use. If you use model routing -- sending different languages to different models -- record the pricing for each model-language combination.

Fourth, prompt component sizes. Measure the token count of your system prompt, few-shot examples, and any fixed context in each language. These are your fixed costs per request. They do not vary with user input length, so they form the floor of your per-query cost.

Fifth, average variable sizes. Measure average user input length and average model output length per language. These vary by query and by language -- Japanese users may write shorter queries measured in characters but longer queries measured in tokens. Thai users may receive responses that are the same semantic length as English but twice the token count.

Multiply these inputs together for each language. The per-query cost for language L on model M equals the sum of system prompt tokens, example tokens, average input tokens, and average output tokens, each multiplied by the relevant per-token price for that model. Multiply by the expected monthly volume for that language to get the projected monthly cost. Sum across all languages for the total projected monthly inference cost.

Update this model monthly. Token prices change -- they have dropped 50 to 80% year-over-year for most providers between 2024 and 2026, and further drops are expected. Traffic distributions shift. Prompt optimizations reduce fixed costs. New model versions change fertility ratios. A cost model that was accurate in January may be 20% off by June if you do not refresh the inputs.

## Per-Language Cost Dashboards

The cost model is a planning tool. The dashboard is an operational tool. You need both.

Your per-language cost dashboard should display four metrics updated daily. First, cost per query by language -- the actual measured cost, not the projected cost. Second, total daily cost by language -- so you can see which languages are driving your bill. Third, token count per query by language, broken down by component: system prompt, examples, user input, model output. This breakdown reveals which component is the largest contributor to cost for each language. Fourth, cost trend by language over the past 30, 60, and 90 days -- so you can detect gradual increases before they become budget emergencies.

Set alerts on two conditions. First, when cost-per-query for any language exceeds its budgeted rate by more than 15%. This catches sudden changes -- a prompt update that increased token count, a model version change that altered tokenization, or a shift in user behavior that changed average query length. Second, when the language distribution shifts more than 10% from projections. This catches traffic pattern changes that will affect your blended cost even if per-query costs remain stable.

The dashboard should also show the margin view: revenue per query minus cost per query, per language. This is the number that tells you whether your business model is sustainable for each language you support. When a language's margin turns negative, you have a decision to make -- optimize costs for that language, adjust pricing, or accept the cross-subsidy from profitable languages.

## Forecasting for New Language Launches

When you plan to launch in a new language, the cost model should be your first planning tool, not an afterthought. Before committing to a new market, estimate the per-query cost for that language using measured fertility ratios on your chosen model, translated prompt token counts, and projected traffic volume.

The projection often changes the launch decision. A team that expects to spend $5,000 per month on a new language may discover that the language's fertility ratio makes the actual cost $14,000 per month. At that budget level, the business case requires a larger addressable market, higher per-user revenue, or a cost mitigation strategy like model routing or tokenizer optimization. Knowing this before launch lets you make the decision with data. Learning it after launch means scrambling to justify a cost you already committed to.

For Tier 3 and Tier 4 languages, always run a cost projection before launch. For Tier 1 and Tier 2 languages, the projections rarely produce surprises, but running them takes minutes and builds confidence that the budget is sound.

The next subchapter closes this chapter by translating everything you have learned about tokenization into a decision framework: when to accept an API provider's tokenizer, when to choose an open-weight model for its tokenizer advantages, and how to make that choice based on your specific language portfolio.