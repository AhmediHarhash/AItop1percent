# 1.2 — The Multilingual Market Reality: Users, Revenue, and Regulation Outside English

English is the language of AI development. It is not the language of AI users.

This distinction is the most expensive blind spot in the industry. The teams building AI products overwhelmingly speak English, work in English-speaking organizations, and benchmark against English-language standards. But the people buying and using those products increasingly do not. Roughly 75% of internet users worldwide are non-English speakers. The fastest-growing digital economies are in non-English markets. The most aggressive AI regulations are being written in non-English jurisdictions. If your product strategy assumes that English is the default and everything else is an add-on, you are building for a shrinking share of the global opportunity.

This subchapter lays out the market reality in concrete terms: who the users are, where the revenue is, and what the regulations demand. The numbers should change how you prioritize.

## The User Numbers That Should Reframe Your Roadmap

The scale of non-English internet usage is not a rounding error. It is the majority. As of 2025, approximately 5.6 billion people use the internet. English-language internet users represent roughly 25% of that total. Chinese speakers account for approximately 1.1 billion internet users. Spanish covers roughly 560 million speakers globally. Arabic reaches over 420 million. Hindi has surpassed 610 million. Bengali, Portuguese, Indonesian, Japanese, and Urdu each represent tens to hundreds of millions of additional users.

These are not projections. These are current numbers. And the growth trajectory is overwhelmingly non-English. Internet penetration in sub-Saharan Africa, South Asia, and Southeast Asia is still climbing rapidly. The next billion internet users will predominantly speak Hindi, Bengali, Bahasa Indonesia, Swahili, Yoruba, and Hausa. They will not speak English as a first language. Many will not speak it at all.

For AI products specifically, the user base is even more skewed than raw internet numbers suggest. Consumer-facing AI applications — chatbots, writing assistants, search, customer support, tutoring — serve whoever visits the product. If your AI writing assistant is available globally but only works well in English, you have not launched globally. You have launched in English-speaking markets and created a poor experience everywhere else. Users in non-English markets will try your product, encounter subpar quality, and leave. They will not file bug reports. They will not post on your English-language forum. They will simply churn, and you will never know why because your analytics do not segment by language.

The user reality demands a reframe. The question is not "should we support other languages?" The question is "how much of the global market are we excluding by not supporting them?" For most products, the answer is the majority.

## Where The Revenue Is Going

User counts matter, but revenue geography tells the sharper story. The majority of global GDP growth over the next decade is concentrated in non-English markets. Asia-Pacific already represents the largest regional share of global digital spending. China, India, Japan, South Korea, and Southeast Asia collectively generate more digital commerce revenue than North America and Europe combined. Latin America's digital economy is growing at double-digit rates annually, driven by Brazil, Mexico, Colombia, and Argentina. The Middle East and North Africa are investing aggressively in digital infrastructure, with the UAE, Saudi Arabia, and Egypt leading AI adoption initiatives backed by sovereign wealth funds.

Enterprise AI spending follows the same pattern. Multinational corporations headquartered in Tokyo, Seoul, Sao Paulo, Riyadh, and Jakarta are not evaluating AI products in English. They are evaluating them in their operating languages. A procurement team at a Japanese conglomerate will test your product in Japanese. A legal department at a Brazilian bank will test it in Portuguese. A customer service operation in Saudi Arabia will test it in Arabic. If your product fails those tests, you lose the deal. You do not get a second chance to come back with a localized version six months later. The competitor who showed up with native-language quality on day one wins the contract.

The revenue argument extends beyond direct sales. AI products that work in local languages benefit from network effects that English-only products cannot access. A customer support chatbot that handles Portuguese natively generates Portuguese training data, which improves Portuguese quality, which attracts more Portuguese-speaking customers, which generates more data. This flywheel compounds over time. The company that enters a market early with native-language quality builds a data advantage that later entrants cannot easily replicate. By the time the English-first competitor arrives with a translated product, the multilingual-native competitor has months or years of locally generated data and locally calibrated quality.

## The Regulatory Pressure Is Not Theoretical

In 2024, multilingual support was a nice-to-have. In 2026, it is becoming a legal requirement in multiple jurisdictions.

The EU AI Act is the most consequential regulation for multilingual AI. GPAI model obligations became enforceable in August 2025, with the full compliance window closing in August 2026 for systemic-risk models and August 2027 for models placed on the market before the enforcement date. The Act requires transparency about model capabilities and limitations. If your model is deployed across EU member states — which collectively use twenty-four official languages — regulators expect you to document how the model performs in each language it serves. The GPAI Code of Practice, published in July 2025 and updated through the Q&A document in September 2025, provides practical guidance on these obligations. You cannot claim transparency about a model's capabilities if you have never measured its performance in the languages it is deployed in.

GDPR adds a layer of language-specific obligation. The right to explanation — the requirement that users understand how automated decisions affecting them are made — must be exercised in the user's language. If a French citizen asks your AI system to explain a credit decision, the explanation must be in French. If the explanation is generated by a language model that produces lower-quality French than English, the explanation may be inadequate, exposing you to regulatory challenge.

China's AI regulations impose their own requirements. The Interim Measures for the Management of Generative AI Services, effective since August 2023, require that AI-generated content be accurate and not harmful. This standard is evaluated in Chinese, by Chinese regulators, against Chinese cultural and political norms. A product that works well in English but produces culturally inappropriate or factually incorrect content in Chinese is non-compliant. India's Digital Personal Data Protection Act and its evolving AI governance framework are adding language-specific data localization and consent requirements. Brazil's LGPD and proposed AI legislation carry language-specific obligations.

The regulatory landscape is clear: if you deploy AI in a jurisdiction, you must meet that jurisdiction's standards in that jurisdiction's language. English-only compliance is not compliance.

## Language as Market Segmentation

Most product teams think of language as a localization variable — the same product, different words. This is wrong. Language is a market segmentation variable. Different languages do not just encode different words. They encode different user expectations, different formality norms, different trust signals, and different cultural contexts. Treating language as a simple translation layer misses the entire segmentation dimension.

Consider formality. English has a relatively flat formality spectrum. You use the same pronoun "you" whether you are addressing a friend or a CEO. German distinguishes between "du" (informal) and "Sie" (formal). Japanese has an elaborate honorific system that encodes the speaker's relationship to the listener, the listener's status, and the social context. Korean has seven speech levels. An AI assistant that does not handle formality correctly in these languages is not just making a grammar mistake. It is making a social mistake. In Japanese business communication, using casual register with a senior executive is the equivalent of walking into a board meeting in pajamas. The user does not think "the grammar is slightly off." The user thinks "this product does not understand my world."

Formality is just one dimension. Arabic has significant dialectal variation — Modern Standard Arabic functions as a formal written language, but spoken communication in Egypt, Morocco, the Gulf, and the Levant uses mutually distinct dialects. An AI product that only handles Modern Standard Arabic will produce outputs that sound stilted and bureaucratic to an Egyptian user who expects conversational Masri. Spanish varies significantly between Spain, Mexico, Argentina, and Colombia in vocabulary, tone, and formality conventions. Portuguese in Brazil and Portugal differ not just in accent but in grammar, spelling, and cultural reference.

Each of these variations represents a market segment with distinct quality expectations. A product that treats "Arabic" as a single language serves none of its Arabic-speaking markets well. A product that distinguishes between Egyptian, Gulf, and Levantine Arabic serves each of those markets at native quality. The market segmentation is real, and the teams that understand it build products that fit. The teams that ignore it build products that feel foreign everywhere.

## The English First Translate Later Revenue Trap

The most common multilingual strategy in AI product companies is "English first, translate later." The plan sounds reasonable: build the product in English, validate product-market fit, then expand to other languages. The reality is that this strategy creates a revenue trap that is almost impossible to escape.

The trap works like this. You launch in English. You find product-market fit with English-speaking users. Your metrics, your feedback loops, your iteration cycles, your feature priorities — everything optimizes for English. You grow in English-speaking markets. Revenue comes in. The product works. Now you want to expand to Spanish-speaking markets. You discover that your prompt architecture does not generalize. Your eval suite has no Spanish coverage. Your annotation pipeline has no Spanish speakers. Your customer support has no Spanish capability. The expansion is not a translation project. It is a partial rebuild.

But the rebuild competes for resources with English-market features. Your English users are requesting improvements. Your English metrics show opportunities. Your English revenue is growing. Every dollar you spend on Spanish infrastructure is a dollar you are not spending on English features. The business case for Spanish is speculative — you do not know whether Spanish users will convert at the same rate. The business case for English improvements is concrete — you have data showing the return. Rational resource allocation keeps choosing English. Spanish keeps slipping.

Meanwhile, a competitor who built for Spanish from day one is capturing the Spanish market. They have Spanish-native evals, Spanish-speaking annotators, Spanish-optimized prompts. Their Spanish quality is high. Their Spanish users are loyal. By the time you finally ship your Spanish version, the competitor has a twelve-month head start, a data flywheel advantage, and a brand reputation you cannot buy. You spent more total money — the cost of the original English build plus the cost of the Spanish retrofit — than the competitor spent building multilingual from the start.

This is the revenue trap. English first does not save money. It shifts costs to the future and multiplies them. The retrofit is always more expensive than the original build because you are working against an architecture that was designed for one language. And the market opportunity cost is permanent. The users you lost during the gap between English launch and multilingual expansion do not come back.

## Companies That Built for Their Languages First

The evidence that multilingual-native strategy works is not theoretical. Real companies have built massive businesses by prioritizing their local languages over English.

Mercado Libre, the dominant e-commerce platform in Latin America, built its entire AI stack around Spanish and Portuguese from the beginning. Their search algorithms, recommendation engines, fraud detection models, and customer service automation were developed and evaluated in the languages their users actually speak. When they partnered with OpenAI in 2025 to build Verdi, their AI development platform, the integration was designed to serve Spanish and Portuguese use cases natively, not as translations of English workflows. The result is a platform that feels native to Latin American users in ways that a translated English platform never could.

Grab, the dominant ride-hailing and super-app platform in Southeast Asia, invested heavily in building AI capabilities specifically for Southeast Asian languages. In 2025, Grab developed its own visual language model for processing documents in Indonesian, Thai, Vietnamese, and Malay — languages where mainstream commercial models had significant accuracy gaps. They chose a foundation model with native Southeast Asian language support, built synthetic training data in local languages, and fine-tuned specifically for regional document formats. This was not a translation layer on top of an English system. It was a language-native build from the ground up.

These companies understood something that English-first companies consistently miss: the language you build in determines the market you win. If you build in English and translate, you win English markets and compete weakly everywhere else. If you build in the languages your users speak, you win those markets with a structural advantage that translated products cannot overcome.

## The Network Effects of Language-Native Quality

Language-native AI quality creates compounding advantages that go beyond the initial product experience. When your AI system works well in a specific language, it generates high-quality interaction data in that language. Users engage more, provide more feedback, create more content, and generate more signal about what good output looks like. This data feeds back into your quality improvement cycle, making the product better in that language, which attracts more users, which generates more data.

The compounding is especially powerful in languages where competitors have weak coverage. If you are the only AI writing assistant that produces publication-quality Korean, every Korean user who tries the market will end up with you. Their usage data becomes your training signal. Their feedback becomes your eval signal. Their retention becomes your revenue signal. A competitor entering the Korean market a year later faces a company with a year of Korean-language data, a year of Korean quality improvements, and a year of Korean user loyalty. The barrier to entry is not technology — it is the data flywheel you have already built.

This dynamic explains why the "translate later" strategy is so destructive. Every month you delay multilingual launch, you are not just missing revenue. You are allowing competitors to build data flywheels in markets you intend to enter. The longer you wait, the larger their advantage, and the more expensive it becomes to compete.

## The Demographic Shift in AI Development Itself

The workforce building AI is becoming more globally distributed, which is accelerating the demand for multilingual AI tools. In 2024, a Stanford report highlighted the growing digital divide in AI, where non-English speakers are systematically left behind by tools built for English-speaking developers. By 2026, AI engineering teams are increasingly based in India, Southeast Asia, Eastern Europe, Latin America, and the Middle East. These teams need AI development tools — code assistants, documentation generators, testing frameworks — that work in their languages and cultural contexts.

The shift matters because the builders of AI become the users of AI. An Indian AI engineer working in Bangalore uses an AI code assistant in English today because there is no better option. But the documentation they write, the comments they leave, the customer requirements they receive — much of this is in Hindi, Tamil, or Kannada. A code assistant that handles multilingual context seamlessly is not a luxury for this engineer. It is a productivity tool that meets them where they actually work.

The same pattern plays out in every non-English AI hub. Brazilian AI engineers working with Portuguese-speaking clients. Japanese AI engineers integrating with Japanese enterprise systems. Arabic-speaking AI teams building for Middle Eastern governments. The demand for multilingual AI is being generated by the AI industry itself as it globalizes.

## What This Means for Your Product Strategy

The market reality is unambiguous. The majority of users are non-English. The majority of revenue growth is non-English. The regulatory obligations are multilingual. The competitive advantages accrue to companies that build multilingual-native. The costs compound for companies that delay.

This does not mean every product must support every language from day one. That is impractical. What it means is that your architecture must be designed for multilingual expansion from the start, even if your first language is English. Your eval framework must have slots for non-English test suites. Your prompt architecture must support per-language templates. Your annotation pipeline must be designed for multi-language scaling. Your monitoring must disaggregate by language. Your cost models must account for per-language quality requirements.

The difference between "English first, translate later" and "English first, multilingual architecture from day one" is not large in initial effort. It is enormous in future cost. The team that builds the right architecture ships English first and adds German in three weeks. The team that builds an English-only architecture ships English first and spends seven months rebuilding before they can add German.

The market is not waiting. The regulations are not waiting. The competitors who build for the world's languages from the start are not waiting. The question is whether you will join them now or pay the compounding cost of catching up later.

The next subchapter examines the technical reality behind this market pressure: why the models that power your AI product perform dramatically worse in non-English languages, and what that performance gap actually looks like in practice.
