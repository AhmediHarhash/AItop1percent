# 7.6 â€” System Prompt Localization: Tone, Formality, and Register

The same product needs different voices in different languages. Your casual, friendly English tone -- the one that tested well with US users, the one your product team spent weeks calibrating -- translates to unprofessional in Japanese, disrespectful in Korean, and overly familiar in German. This is not a translation problem. It is a cultural design problem. Every language carries its own expectations for how a machine should address a person, and those expectations vary not just by language but by context, by relationship, and by the social contract between the user and the product.

Most teams discover this the hard way. They write a system prompt in English that says "be helpful, friendly, and concise," translate it into their target languages, and ship. The English output sounds warm and approachable. The Japanese output sounds like a foreign tourist trying too hard. The German output sounds like a stranger who skipped several layers of social protocol. The Arabic output sounds disrespectfully casual, as if the AI does not take the user seriously. Same prompt, same intent, radically different reception.

The fix is not better translation. It is per-language voice design -- understanding what "helpful, friendly, and concise" actually means in each language and culture, then encoding that understanding into system prompt variants that produce culturally appropriate output.

## Why Tone Is Not Universal

English-speaking cultures -- particularly American English -- have a relatively narrow formality spectrum in professional software. The tone space runs from "corporate formal" to "casual startup." Most AI products land somewhere in the middle: professional but approachable, using contractions, first names, and direct instructions. This middle register works because American business culture values informality as a signal of accessibility and confidence.

This middle register does not exist in many other languages. Japanese has an elaborate formality system with distinct grammatical structures for different levels of politeness. Korean has six or seven speech levels that change every verb ending in the sentence. German distinguishes between formal address (Sie) and informal address (du), and the choice signals the entire nature of the relationship. Arabic written communication carries centuries of rhetorical tradition where formality signals respect and brevity can signal dismissiveness. The "casual but professional" register that works in English has no direct equivalent in these languages.

When you instruct the model to "be friendly and professional" and the output language is Japanese, the model must decide how to interpret those adjectives within the Japanese formality system. Does "friendly" mean casual speech? That would be jarring in a business context. Does "professional" mean maximum politeness with full keigo? That might feel stiff for a consumer app. The model's interpretation depends on its training data, which includes a mix of Japanese formality levels from various contexts, and the result is often an inconsistent blend that sounds natural to nobody.

## Japanese: The Three Layers of Politeness

Japanese is the language where formality engineering matters most, because the formality system is the most granular and the consequences of getting it wrong are the most visible to users.

The Japanese language has three core levels of politeness. The base level is casual speech, called tameguchi or plain form, used between close friends and family. It is grammatically simple but socially loaded -- using it with a stranger or in a professional context signals disrespect or inappropriate intimacy. The second level is polite speech, the desu and masu forms, which is the standard for most public interactions including retail, customer service, and general professional communication. The third level is keigo, honorific language, which subdivides into sonkeigo (respectful language that elevates the listener's actions), kenjougo (humble language that lowers the speaker's actions), and teineigo (general politeness markers). Keigo is expected in formal business contexts, customer-facing corporate communication, and any situation where the speaker's organization is serving the listener.

For AI products, the choice of politeness level depends on the product's positioning. A consumer chatbot for casual use -- a recipe assistant, a trivia game -- can use polite desu/masu forms and sound natural. A business tool -- a financial advisor, a legal document assistant, a healthcare information system -- should use sonkeigo for describing the user's actions and kenjougo when referring to itself, because this mirrors how a professional service provider would speak to a client in Japanese. A product that uses casual plain form in a business context will feel like a waiter who addresses customers by their first names on the first visit. Technically functional, socially unacceptable.

Your system prompt for Japanese should specify the exact politeness level, not just "be polite." Include a directive like "use desu/masu forms as the baseline, use sonkeigo when describing the user's situation or actions, and use kenjougo when describing what you are doing on the user's behalf." Provide one or two examples that demonstrate the target politeness level in context. The model's compliance with Japanese politeness directives is actually quite high -- around 85 to 90 percent for desu/masu and 75 to 82 percent for consistent keigo -- because the politeness forms are well-represented in the model's Japanese training data.

## Korean: Speech Levels and Social Hierarchy

Korean formality presents a similar challenge to Japanese but with a different structure. Korean has a system of speech levels that affect the verb endings in every sentence. The six commonly recognized levels range from haerache (the highest deferential form, used in news broadcasts and formal speeches) to hae (the lowest intimate form, used with close friends and children).

For AI products, the relevant levels are hapsyoche (formal polite, used in professional settings and customer service), haeyoche (informal polite, used in casual but respectful interactions), and occasionally haerache for products that serve as formal information services. The difference between these levels is not just vocabulary -- it changes every verb ending in every sentence. A Korean user can identify the speech level within the first sentence, and a mismatch between the expected level and the actual level immediately undermines trust.

The most common mistake in Korean AI products is inconsistent speech levels. The model starts a response in hapsyoche (formal polite), shifts to haeyoche (informal polite) mid-paragraph, and occasionally drops to hae (intimate) for short confirmations like "yes" or "understood." This inconsistency reads to Korean users like a person who cannot decide what relationship they have with you. It signals that the AI does not understand Korean social norms, which by extension makes users doubt its competence in other areas.

Your system prompt for Korean should specify a single speech level and instruct the model to maintain it consistently throughout the response. The directive should be explicit: "Use hapsyoche (formal polite speech, ending sentences with -umnida and -seumnida forms) consistently throughout every response. Do not switch to informal forms for any part of the response including confirmations, transitions, and closing statements." Test compliance by checking verb endings across a sample of responses, because speech level consistency is testable at the character level.

## German: The Sie/Du Decision

German formality revolves around a binary choice that carries significant social weight: Sie (formal "you") or du (informal "you"). The choice affects pronouns, verb conjugations, and possessive forms throughout every sentence.

In traditional German business culture, Sie is the default. You use Sie with anyone you do not know well, with professional contacts, with customers, and with anyone in a position of authority. The switch to du requires explicit mutual agreement and signals a meaningful shift in the relationship. Using du with someone who expects Sie is a social violation roughly equivalent to calling your bank's customer service representative by a nickname they never offered you.

German digital culture has complicated this picture. Many tech companies, startups, and online services now use du by default, influenced by American-English informality and the du culture of Swedish-origin companies like IKEA and Spotify. In 2026, the German-speaking market is split: traditional industries (banking, insurance, healthcare, legal) expect Sie; tech-forward products and younger demographics may prefer du; and there is a wide uncertain middle where either could be appropriate.

Your system prompt for German must make an explicit decision about Sie versus du and enforce it consistently. For B2B products, professional services, and any product serving traditional industries, use Sie. For consumer products targeting younger demographics in casual contexts, du may be appropriate. For products that serve a mixed audience, Sie is the safer default -- nobody is offended by being addressed formally, but some users are offended by unsolicited informality.

The system prompt directive should be specific: "Address the user with Sie (formal). Use the corresponding formal verb conjugations and possessive forms. Do not switch to du under any circumstances unless the user explicitly requests it." Compliance is high for this directive -- around 90 to 93 percent -- because the Sie/du distinction is well-represented in the model's German training data.

## Arabic: Formality as Respect

Arabic written communication carries a deep tradition of formality that serves as a signal of respect, education, and seriousness. In Arabic-speaking cultures, the way you write communicates as much about you as what you write. Casual writing in a professional context suggests carelessness or disrespect.

Arabic AI products should default to Modern Standard Arabic (MSA) -- the formal written register understood across all Arabic-speaking countries -- rather than any dialectal Arabic. MSA is the language of business, media, education, and formal communication throughout the Arab world. Using dialectal Arabic (Egyptian, Gulf, Levantine, Maghrebi) is appropriate only when the product is explicitly positioned for a specific regional market and the use case is casual.

Beyond the MSA/dialect choice, Arabic formality manifests in rhetorical conventions that have no English equivalent. Opening a response with a blessing or polite phrase is culturally expected in many contexts. Direct imperative instructions ("Do this") can feel abrupt in Arabic, where a more indirect construction ("You may wish to consider" or "It is recommended that") is more natural in formal settings. The level of elaboration expected is higher than in English -- brevity can signal dismissiveness rather than efficiency.

Your system prompt for Arabic should specify MSA as the register and instruct the model to use formal rhetorical conventions. Include a directive about opening phrases, indirect instruction style, and the level of elaboration appropriate for your use case. If your product serves multiple Arabic-speaking regions, test with reviewers from at least two different regions (for example, one Gulf reviewer and one Egyptian reviewer) to ensure the MSA register sounds neutral rather than region-specific.

## Spanish and Portuguese: The Continental Divide

Spanish and Portuguese each contain a formality split that divides along continental lines, and the wrong choice makes your product sound foreign.

In Spanish, the formal "you" (usted) and informal "you" (tu) vary in usage by country. European Spanish uses tu broadly in casual and semi-professional contexts, reserving usted for formal situations and elderly people. Latin American Spanish varies dramatically: Colombian Spanish uses usted much more broadly, even among friends in some regions; Argentine Spanish uses vos instead of tu with its own verb conjugations; Mexican Spanish falls somewhere between European norms and more formal Latin American usage. A system prompt that enforces usted everywhere sounds overly stiff to a Spanish user. A prompt that uses tu everywhere sounds disrespectful to a Colombian user.

Portuguese has a parallel split. Brazilian Portuguese has largely abandoned the formal voce/o senhor distinction in everyday digital communication, and Brazilian users expect a relatively informal, warm tone from AI products. European Portuguese maintains a stronger formal/informal distinction, and products that sound too casual in European Portuguese lose credibility.

The practical solution for Spanish is regional variants. If you know the user's country, apply the appropriate formality norms: usted-default for Colombian, Mexican, and most South American markets; tu-default for Spain; vos-aware for Argentina and parts of Central America. If you do not know the user's country, default to usted as the safe universal formal address. For Portuguese, maintain separate Brazilian and European variants, because the differences extend beyond formality into vocabulary, spelling (pre- and post-reform conventions), and cultural references.

## French: Vous as Professional Default

French formality centers on the vous/tu distinction, and the professional default is clear: vous, always, in any AI product that serves a professional or semi-professional purpose.

Tu in French is reserved for close personal relationships, children, and informal contexts among peers who have established a tu relationship. Using tu with a user you do not know -- which describes every AI interaction at the start -- violates a basic social convention. Even products that target younger demographics should default to vous in French, because the social penalty for premature tu is higher than the social benefit of perceived informality.

The system prompt directive is straightforward: "Always address the user with vous. Use the corresponding formal verb conjugations. Do not switch to tu unless the user explicitly asks to be tutoyered." Compliance is high, around 92 to 95 percent, because the vous/tu distinction is strongly represented in the model's French training data and the instruction is unambiguous.

One subtlety: French formal writing avoids contractions more than informal writing, and it uses longer, more elaborated sentence structures. A product that uses vous but writes in choppy, short sentences can sound oddly robotic -- formally addressed but informally styled. Your French variant should also adjust the sentence length and elaboration level to match the formality of the address, creating a consistent register across all dimensions.

## The Per-Language Persona Approach

Rather than trying to translate a single English persona into multiple languages, design a separate persona for each major language. A persona is not just a formality level. It is a complete voice specification: how the AI introduces itself, how it handles uncertainty, how it delivers bad news, how it structures explanations, and how it signals warmth or authority.

An English persona might be "a knowledgeable colleague who explains things clearly and directly." The Japanese equivalent is not a translation of that description -- it is a redesign. The Japanese persona might be "a courteous professional service representative who provides thorough explanations and uses appropriate keigo while maintaining approachability through attentive language." The German persona might be "a competent specialist who addresses the user formally, provides well-structured answers, and respects the user's time by being thorough but not verbose." Each persona description maps to specific linguistic choices that the system prompt can enforce.

Document each persona with three to five example responses that demonstrate the voice in practice. Include examples for common interaction types: a greeting, a factual explanation, an error message, a clarification question, and a long-form response. These examples serve as both specification and test material. When you need to evaluate whether the model is hitting the right tone for a language, compare its output to the persona examples. When a new team member needs to understand the French voice, they read the French persona document and its examples.

The persona approach also helps prevent a subtle failure mode: the **Translated English Voice**, where the output is linguistically correct in the target language but culturally reads as American English that has been translated. Japanese output that uses English-style directness. German output that uses American-style casual warmth. Arabic output that is brief where elaboration is expected. The persona approach avoids this by designing the voice from within the target culture rather than translating it from English.

## Implementing Per-Language System Prompts

The architecture for per-language system prompts is straightforward. Maintain a system prompt library where each entry is keyed by language code (or language-region code for languages with significant regional variation, like es-CO for Colombian Spanish and es-ES for European Spanish). Each entry contains the complete system prompt for that language, including formality directives, persona description, tone examples, and any language-specific constraints.

At runtime, when the language detection layer identifies the user's language, the prompt assembly pipeline selects the appropriate system prompt variant. If no specific variant exists for the detected language, fall back to the closest available variant (Brazilian Portuguese for an Angolan Portuguese user) or to the English default.

The maintenance cost is real. Every change to the product's voice -- a new feature that requires a new instruction, a policy update that changes how the AI handles a topic, a tone adjustment based on user feedback -- must be propagated to every language variant. This is not just translation. It is re-adaptation, because a policy change that adds a sentence in English might require a paragraph in Arabic to convey the same intent within the cultural conventions, or might need to be restructured entirely in Japanese to fit the keigo framework.

Keep the language-specific elements separate from the language-neutral elements. Your system prompt probably contains a mix of universal instructions ("always cite your sources," "never provide medical diagnoses") and language-specific instructions ("use Sie for formal address," "use desu/masu as the baseline politeness level"). Structure the prompt as a base template with language-specific sections that can be swapped independently. This reduces the maintenance burden by letting you update universal instructions once and language-specific instructions only when the voice for that language needs to change.

## Testing Tone Across Languages

Tone is subjective, which makes it harder to test than structured output compliance. But it is not untestable.

The most reliable method is native-speaker review panels. For each major language, recruit three to five native speakers who represent your target user demographic. Present them with twenty to thirty AI responses and ask them to rate each response on formality appropriateness (is this the right level for a product like ours?), naturalness (does this sound like a competent native speaker wrote it?), and cultural appropriateness (does anything feel out of place for this language and context?). Aggregate the ratings into a per-language tone score.

Run these reviews after every major prompt change, every model update, and at regular intervals (quarterly for stable products, monthly during active development). The reviews surface problems that automated metrics cannot catch: the Japanese output that uses keigo correctly but sounds like a government document, the German output that uses Sie but has an American-style enthusiasm that feels inauthentic, the Arabic output that is formally correct but uses constructions that feel translated rather than native.

Automated metrics can supplement native-speaker review but not replace it. You can build classifiers that detect speech level consistency in Korean (by checking verb endings), Sie/du consistency in German (by checking pronoun usage), and politeness level consistency in Japanese (by checking verb forms). These classifiers catch the mechanical failures -- inconsistent speech levels, dropped formal address -- but miss the subtler cultural failures that only a native speaker perceives.

## The Formality Feedback Loop

User behavior tells you whether your tone is calibrated correctly, if you know how to read it.

Users who find the AI too formal tend to write shorter messages, use more casual language themselves, and abandon conversations earlier. The AI's formality creates a distance that discourages engagement. Users who find the AI too informal may also disengage, but they tend to do so after expressing frustration or asking the AI to "be more serious" or "be more professional."

Track these signals per language. If your German users are engaging deeply but your Japanese users have shorter session lengths and higher abandonment rates, investigate whether the Japanese tone is miscalibrated. Run a targeted native-speaker review focused on the interactions where users disengaged.

The feedback loop should also incorporate explicit user feedback when available. If your product includes a thumbs-up/thumbs-down mechanism, segment the feedback by language and look for systematic patterns. A high negative-feedback rate in a specific language may indicate a tone problem rather than a content problem, especially if the same queries produce positive feedback in other languages.

Tone calibration is never finished. Cultural expectations evolve, your user base shifts, and the model's behavior changes with updates. The teams that deliver consistently appropriate tone across languages are the ones that treat tone as a product metric, measure it regularly, and invest in the per-language voice design that makes each user feel like the product was built for them.

The next subchapter addresses the most dangerous consequence of the English-first development pattern: safety constraints that work in English but fail in other languages, creating vulnerability gaps that grow with every language you add.