# 5.7 â€” Terminology Management: Glossaries, Do-Not-Translate Lists, and Brand Voice

The Terminology Drift Pattern is the most common and most invisible consistency failure in multilingual products. It works like this: your product page calls the feature "machine learning" in its English-to-German translation, using the loanword "Machine Learning" as many German tech companies do. Your documentation team translates the same concept as "maschinelles Lernen," the formal German equivalent. Your marketing page splits the difference and uses "ML" without expansion. Your in-app help tooltip uses yet another variant. Each translator made a defensible choice. None of them coordinated. The user encounters four different terms for the same concept across four surfaces of the same product, and the product stops feeling like a product. It feels like four products, each built by a different team, none of which talked to each other.

Terminology drift does not cause dramatic failures. It causes a slow, steady erosion of user confidence. The user who sees different terms for the same feature wonders which one is official. They search the help center using one term and find nothing because the help center used a different term. They describe a problem to support using the term from the settings page, and the support agent uses the term from the documentation. Nobody is wrong. Everyone is inconsistent. And the cumulative effect is a product that feels amateurish in every language except the one where the original team works.

## Why Terminology Consistency Matters More Than You Think

Users learn your product through its vocabulary. Every label, every menu item, every status message teaches the user a word that becomes their mental model for that feature. When the English version of your product calls something "Workspace" everywhere -- in navigation, in documentation, in error messages, in onboarding -- the user internalizes "Workspace" as the concept. They think in that word. They search for it. They use it when talking to colleagues about your product.

Translation multiplies the surface area where vocabulary can diverge. In English, you have one term managed by one team. In fourteen languages, you have fourteen terms managed by different translators, at different times, with different reference materials. The probability that all fourteen languages maintain perfect terminological consistency without active management approaches zero. It is not a question of translator quality. It is a coordination problem. Excellent translators working independently will produce excellent but inconsistent translations, because "excellent" includes multiple valid options for most terms.

The cost of inconsistency is measurable but rarely measured. A B2B software company expanding into Japan discovered that their Japanese users submitted 40% more support tickets per user than their English-speaking users, despite comparable product satisfaction scores. Investigation revealed that the root cause was not product quality but terminology confusion. Users could not find features because the help documentation used different terms than the UI. Search within the product returned incomplete results because the same concept appeared under three different Japanese renderings. The company spent $180,000 on professional re-translation before realizing that what they needed was not better translation but a terminology glossary -- a $15,000 investment that would have prevented the problem entirely.

## The Terminology Glossary

A **terminology glossary** is a curated, authoritative list of terms with their approved translations in each target language. It is not a dictionary. A dictionary gives you all possible translations. A glossary gives you the one translation your product uses, along with the translations it explicitly rejects.

A well-built glossary entry contains five elements. The source term in your product's base language. The approved translation in each target language. Rejected alternatives -- translations that are technically correct but not what your product uses. A definition that clarifies the meaning of the term in your product's specific context, because the same word can mean different things in different products. And a usage note explaining where the term appears and any special handling rules. The definition matters because translators encounter ambiguous terms constantly. "Workspace" could mean a physical office, a digital project space, a computing environment, or an IDE configuration. The glossary definition tells the translator which meaning your product intends, which determines the correct translation.

Glossary size matters, and bigger is not better. A glossary with 5,000 entries becomes a reference that nobody consults because finding any single term takes too long and the sheer volume makes enforcement impossible. The most effective glossaries contain between 100 and 500 entries -- the terms that are central to your product, that appear frequently in user-facing content, that have multiple valid translations in target languages, and that have been sources of inconsistency in the past. Start with the 50 terms that appear most often across your product surfaces. Add terms whenever a translation review catches an inconsistency. Remove terms that have only one plausible translation in all target languages, because those do not need management.

Per-language entries are essential because the ambiguity landscape differs by language. "Account" has a straightforward translation in most European languages but maps to at least three common options in Japanese depending on whether you mean a user account, a financial account, or an organizational account. "Dashboard" is borrowed as a loanword in some languages, translated as a compound noun in others, and paraphrased as a descriptive phrase in still others. The glossary must capture these per-language decisions, not just the source-language terms.

## Do-Not-Translate Lists

The **Do-Not-Translate list** -- often called a DNT list -- is the glossary's defensive counterpart. Where the glossary tells translators how to translate a term, the DNT list tells them not to translate it at all. This distinction sounds simple. In practice, it is one of the most violated rules in multilingual AI systems.

Brand names top the list. Your company name, your product names, your feature names that function as brand identifiers. "Slack" must remain "Slack," not get translated as "lazy" or "loose" in any language. "Azure" must remain "Azure," not become "sky blue." "Copilot" must remain "Copilot," not become whatever the target language's word for a co-pilot is. These seem obvious until you realize that LLMs and NMT engines translate aggressively by default. They are trained to translate everything, and common English words that happen to be brand names are especially vulnerable because the model has seen those words translated thousands of times in its training data. Without explicit DNT instructions, your translation system will eventually translate "Outlook" as "perspective" in some language, and you will not catch it until a user files a confused support ticket.

Technical acronyms and standards form the second category. API, SDK, URL, HTTP, JSON, SQL, REST -- these should remain untranslated in virtually all contexts. Some languages have official translations for technical terms, and well-meaning translators sometimes use them. But users of technical products worldwide recognize the English acronyms, and translating them creates more confusion than clarity. If your German documentation translates "API" to "Programmierschnittstelle," the developer who searches for "API" finds nothing. The DNT list prevents this.

Feature names that double as UI labels are the trickiest category. If your product has a feature called "Smart Compose," do you translate it? If users see "Smart Compose" in the English UI and in your marketing, translating it to "Composition Intelligente" in French creates a disconnect between the marketing message and the product experience. But leaving it in English within a French-language product creates a jarring language switch. There is no universal right answer. The DNT list captures the decision your team made, and that decision must be consistent across all surfaces.

The DNT list is critical for AI translation systems specifically because LLMs translate contextually and aggressively. When you send a paragraph to an LLM for translation and the paragraph contains the sentence "Open the Workspace in Copilot," a model without DNT constraints might render "Workspace" as the local-language equivalent of "work area" and "Copilot" as the local-language equivalent of "co-pilot." You need to inject DNT terms into the translation prompt explicitly -- either as a list of terms to preserve untranslated, or as inline markup that the model is trained to respect.

## Brand Voice Guides Per Language

Terminology governs what words you use. Brand voice governs how you use them. A glossary ensures that every translator calls the feature "Workspace." A brand voice guide ensures that every translator describes the Workspace in the same register, the same level of formality, and the same personality.

Brand voice is not universal. A brand that is casual and witty in English may need to be warm but formal in Japanese, professional but approachable in German, and warm and slightly more elaborate in Brazilian Portuguese. These are not failures of localization. They are its purpose. The same brand personality expresses differently in different cultures because the social signals carried by language differ. Casual English reads as confident and friendly. Casual Japanese reads as rude or childish, depending on context. The brand voice guide for each language captures how the brand's core personality -- its values, its relationship with the user, its emotional register -- maps onto that language's social conventions.

A practical brand voice guide for translation contains four elements per language. First, the formality level: T-V distinction choices for languages that have them, keigo level for Japanese, speech level for Korean, register for Arabic. Second, the personality descriptors adapted for the culture: if the English brand is "friendly, expert, slightly irreverent," the Japanese adaptation might be "warm, knowledgeable, gently humorous" because irreverence carries different cultural weight. Third, sentence-level conventions: does the brand use short punchy sentences in this language, or does the language favor longer, more flowing constructions? German readers expect more elaborate sentence structures than English readers, and forcing English-style brevity onto German prose makes the brand feel clipped and unfriendly. Fourth, prohibited patterns: what the brand never does in this language. The Spanish brand voice guide might prohibit the imperative mood in user instructions because it reads as commanding rather than helpful in that market. The Japanese guide might prohibit certain casual particles that read as too informal for a professional product.

These guides should be created by native-speaking copywriters who understand both the brand and the culture, not by translators working from an English brand guide. The English brand guide is input. The per-language brand voice guide is a creative adaptation, not a translation.

## Injecting Terminology Into Translation Systems

Having a glossary and a DNT list is half the work. The other half is making your translation system actually use them. The injection method depends on the translation technology in your stack.

For LLM-based translation, glossary terms and DNT entries are included directly in the translation prompt. The most effective approach is to extract the relevant terms from the glossary -- only the terms that appear in the current source text, not the entire glossary -- and include them as explicit instructions. "Translate the following text into Japanese. Use the following term translations: Workspace translates to the approved Japanese term, Dashboard translates to the approved Japanese term. Do not translate the following terms: Copilot, API, SDK." This targeted injection avoids overwhelming the model with irrelevant terms while ensuring that every relevant term receives its mandated translation.

The retrieval approach scales better for large glossaries. When the source text enters the translation pipeline, a preprocessing step scans it for glossary terms using string matching or fuzzy matching. It retrieves the relevant entries and injects only those entries into the prompt. This is a focused application of retrieval-augmented generation -- the same pattern used in RAG systems for knowledge retrieval, applied here to terminology management. The retrieval step adds milliseconds of latency but prevents the model from ignoring relevant terms because they were buried in a 500-entry glossary that consumed half the context window.

For NMT engines, injection works differently. DeepL offers a built-in glossary feature that enforces term translations at the engine level. Google Cloud Translation supports glossary resources that override the engine's default translations for specified terms. Amazon Translate supports custom terminology files. These integrations are more rigid than LLM prompt injection -- they enforce exact string matches without the contextual flexibility that LLMs provide -- but they are deterministic. When the NMT glossary says "Workspace" translates to a specific Japanese term, the engine always produces that term. There is no probabilistic variation, no occasional deviation, no need to verify.

For MTPE workflows, both the translator's CAT tool and their working instructions must reference the glossary. Modern CAT tools like Trados, memoQ, and Phrase support terminology databases -- called termbases -- that display approved translations when the translator encounters a glossary term in the source text. The termbase flags unapproved translations, and QA checks at the end of the translation process can automatically catch glossary violations. This is the most reliable enforcement mechanism because it catches errors at the point of creation and gives the translator immediate feedback.

## Who Owns the Glossary

Terminology management fails when nobody owns it. A glossary created during the initial localization push and then abandoned becomes increasingly inaccurate as the product evolves. New features introduce new terms. Existing features get renamed. Industry terminology shifts. The glossary that was accurate six months ago now contains terms for features that have been deprecated, missing terms for features that have been launched, and approved translations that no longer match the product's evolved voice.

Glossary ownership typically falls to one of three roles. In organizations with a dedicated localization team, the localization manager owns the glossary, with input from product, engineering, and in-market linguists. In organizations without a localization team, product management owns the terminology decisions and an external localization vendor maintains the glossary. In organizations using primarily AI translation, the engineer responsible for the translation pipeline owns the glossary as a system artifact -- a configuration file that feeds into the translation prompt.

Regardless of who owns it, the glossary update process needs three triggers. First, a new product feature or renamed feature automatically triggers a glossary review: what is the source term, what are the approved translations, do any existing glossary entries need updating? Second, a quarterly audit cycle where in-language reviewers check current translations against the glossary and flag drift. Third, a feedback loop from support tickets and user research: if users in a specific market consistently use a term that differs from the glossary, the glossary might be wrong, not the users.

The update cadence matters. A glossary updated annually is a fossil. A glossary updated weekly is a burden nobody maintains. Monthly updates with real-time additions for new product launches strike the balance that most teams can sustain.

## The Cost of Not Managing Terminology

The consequences of terminology drift are not hypothetical. They are the support tickets that cost $15 each, multiplied by the users who cannot find the feature because it has a different name on the page they are looking at versus the page in the tutorial. They are the enterprise deal that stalls because the German prospect noticed three different terms for the same security feature across your product, documentation, and sales deck, and concluded that your product is not mature enough for their compliance requirements. They are the $200,000 re-translation project six months after launch when you finally measure the problem and realize that fixing it retroactively costs ten times what preventing it would have cost.

The subtlest cost is search failure. When your product uses multiple terms for the same concept, in-product search returns incomplete results. Help center search misses relevant articles. Users searching for help with the term they learned from the UI find nothing because the help center used a different term. Every failed search is a user who did not find the answer, filed a support ticket instead, or -- worse -- gave up and formed the opinion that your documentation is inadequate. You never see this cost in a single metric. You see it in aggregate NPS scores that are mysteriously lower in non-English markets, in support cost ratios that are higher per user in localized markets, and in churn rates that nobody can explain because the product works fine -- technically.

Managing terminology is not glamorous work. It is spreadsheets, review cycles, stakeholder alignment, and constant vigilance against drift. But it is the infrastructure that makes everything else in your translation pipeline coherent. Without it, every individual translation can be perfect and the product can still feel broken.

The next subchapter moves from terminology to the formatting layer that sits beneath translation -- dates, currencies, units, names, and addresses, where getting the format wrong tells users more loudly than any mistranslation that your product was not built for them.