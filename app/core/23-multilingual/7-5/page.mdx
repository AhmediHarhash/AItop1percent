# 7.5 â€” Output Format Control: Structured Output Across Writing Systems

Your structured output parser works perfectly in English. It extracts clean key-value pairs, validates field types, and feeds normalized data into your downstream pipeline without a hiccup. Then you deploy in Arabic, and the parser throws exceptions on every third response because the model inserted Unicode bidirectional control characters into the field names. You deploy in Japanese, and the parser rejects responses that look correct on screen but contain full-width colons and commas where the parser expects ASCII punctuation. You deploy in Thai, and the model wraps structured fields in a mix of Thai and Latin characters that no regular expression you wrote can reliably match. The structured output that was your most reliable feature in English becomes your most fragile one the moment you cross the writing system boundary.

This is not a model failure. It is a writing system clash. Structured output formats -- key-value pairs, numbered lists, delimited fields, labeled sections -- are conventions rooted in Latin-script computing. When the model generates structured output in a non-Latin writing system, it applies the structural conventions it knows best while simultaneously producing text in a script that has its own conventions for punctuation, directionality, and character width. The collision between these two convention sets produces output that looks structured but fails to parse.

## The Format Compliance Gradient

Structured output reliability follows the same compliance gradient described in subchapter 7.3, but the degradation is steeper because formatting constraints are among the first to fail in non-English contexts.

English structured output compliance sits around 95 percent for well-prompted models in 2026. When you ask GPT-5 or Claude Opus 4.6 to return a response with labeled fields -- a field called summary containing a paragraph, a field called status containing one of three allowed values, a field called confidence containing a number -- the model produces parseable output in English almost every time.

Tier 1 European languages (French, German, Spanish, Portuguese, Italian) maintain about 88 to 92 percent compliance. The structure holds, but the model occasionally uses locale-specific number formatting (a comma instead of a period for decimal separators) or inserts accented characters into field names that should be ASCII-only.

CJK languages (Chinese, Japanese, Korean) drop to 78 to 85 percent compliance. The primary failure mode is punctuation: the model switches to full-width punctuation because that is the standard in CJK text. A colon in Japanese text is not the same Unicode character as a colon in English text. They look identical in some fonts, but they have different code points, and a parser that checks for ASCII colon will not match a full-width colon.

Arabic and Hebrew fall to 68 to 76 percent compliance. Right-to-left text direction combined with left-to-right field names creates bidirectional formatting chaos. The model produces output that appears structured in a text editor but contains invisible directional control characters that reorder elements when rendered or parsed.

Thai, Burmese, and other Southeast Asian scripts sit at 72 to 80 percent. Word boundary ambiguity -- Thai does not use spaces between words -- means the model sometimes merges field labels with field values, producing output where the parser cannot tell where the label ends and the value begins.

These numbers should alarm you if structured output is part of your production pipeline. A 75 percent compliance rate means one in four responses will fail to parse, requiring either error handling, retry logic, or manual intervention -- all of which add latency, cost, and user-facing failures.

## The Right-to-Left Problem

Arabic and Hebrew present the most technically complex structured output challenge because they introduce bidirectional text -- text that flows right to left for the prose content but left to right for numbers, Latin-script field names, and punctuation marks.

When the model generates a key-value structure with an English field name and an Arabic value, the output contains two text directions in a single line. The field name "customer_name" reads left to right. The value -- an Arabic name -- reads right to left. Between them sits a delimiter (a colon, an equals sign, or similar). The Unicode Bidirectional Algorithm determines how these elements are ordered when rendered, and the algorithm's behavior depends on the surrounding context, the presence of explicit directional markers, and the rendering engine being used.

The result is that the same output string can appear in completely different visual orders depending on where it is displayed. In a left-to-right text editor, the field name appears first, followed by the delimiter, followed by the Arabic value. In a right-to-left rendering context, the Arabic value may appear first, followed by the delimiter, followed by the field name. The underlying bytes are the same, but the visual representation changes.

This is not just a display problem. When the model generates structured output, it sometimes inserts Unicode bidirectional control characters -- left-to-right marks, right-to-left marks, directional embedding characters -- to make the output look correct in the generation context. These invisible characters end up in your parsed data, contaminating field names and values with non-printing characters that break exact-match comparisons, database lookups, and downstream processing. A field name that appears to be "status" might actually be "status" followed by a right-to-left mark, and these two strings are not equal.

The mitigation is aggressive post-processing. Strip all Unicode bidirectional control characters (code points U+200E through U+200F and U+202A through U+202E and U+2066 through U+2069) from field names. Keep them in field values only if your downstream pipeline can handle bidirectional text. Normalize field names to ASCII before parsing, regardless of the language of the field values. And test your parser specifically with Arabic and Hebrew output -- not just with Arabic text in general, but with the specific mixed-directionality output that structured formats produce.

## The Full-Width Punctuation Problem

CJK writing systems use full-width punctuation as their standard. A Japanese comma is not the same character as an English comma. A Chinese colon is not the same character as an English colon. A Korean period is not the same character as an English period. These characters occupy a full character width in CJK text layout, matching the width of CJK ideographs, and they have distinct Unicode code points from their ASCII equivalents.

When the model generates structured output in Japanese, it naturally uses the punctuation it associates with Japanese text. If the output includes a labeled field -- a field name followed by a colon followed by a value -- the model might use a full-width colon (Unicode U+FF1A) instead of an ASCII colon (Unicode U+003A). If the output includes a comma-separated list, the model might use a full-width comma (Unicode U+FF0C) or the Japanese ideographic comma (Unicode U+3001) instead of an ASCII comma (Unicode U+002C).

This produces output that looks correct to a human reader. A Japanese user sees a properly formatted key-value pair with standard Japanese punctuation. But your parser, which splits on ASCII colon or comma, finds no delimiters at all. The entire line is treated as a single unparseable string.

The same issue applies to parentheses, brackets, quotation marks, and semicolons. Each of these has a full-width CJK variant that the model may use. Your parser must either handle all variants or your post-processing must normalize them.

The normalization solution is Unicode NFKC normalization. The NFKC normalization form (Normalization Form Compatibility Composition) maps full-width characters to their ASCII equivalents. Applying NFKC normalization to the model's output before parsing converts full-width colons to ASCII colons, full-width commas to ASCII commas, and full-width brackets to ASCII brackets. Every major programming language has a Unicode normalization function in its standard library. This is a one-line fix that solves the full-width punctuation problem across all CJK languages.

One caution: NFKC normalization also normalizes other character variants that you may want to preserve. It converts superscript and subscript characters to their base forms, normalizes certain ligatures, and can change the meaning of specialized text. Apply NFKC normalization to the structural elements of the output (delimiters, field names) but not necessarily to the content values, where the original characters may carry meaning.

## English Field Names, Localized Values

The single most effective structural decision for multilingual structured output is to keep all field names, keys, labels, and structural markers in English, while allowing field values to be in any language.

This is not a language purity decision. It is an engineering decision. English field names are ASCII-only, left-to-right, unambiguous to parse, and consistent across all writing systems. When your output has a field called "summary" containing Japanese text, a field called "sentiment" containing an English enum value, and a field called "customer_message" containing Arabic text, every parser in every programming language can extract these fields without any special handling for directionality, character width, or punctuation variants.

The model cooperates with this pattern when you explicitly instruct it. Include in your system prompt a directive that all field names, labels, and structural markers must be in English using ASCII characters only. Provide an example of the desired format in the system prompt that shows English field names with localized values. The model will follow this pattern with high reliability, even in languages where overall instruction compliance is lower, because the pattern is simple and concrete rather than abstract.

Teams that attempt localized field names -- field names in Arabic, Japanese, or Thai -- encounter every parsing problem described in this subchapter simultaneously. The field names inherit the writing system's directionality, punctuation conventions, and character width properties, making reliable parsing dramatically harder without meaningful benefit to the end user, who never sees the field names in most production systems.

## The Explicit Format Example Strategy

Abstract formatting instructions degrade across languages. Concrete examples do not -- at least not as steeply.

When you tell the model "return a response with three labeled fields: summary, sentiment, and confidence," the model must interpret this instruction, decide how to format each field, choose the appropriate delimiters, and construct the output. Each of these decisions introduces a point of failure that varies by language. In Thai, the model might choose different delimiters. In Arabic, the model might reorder the fields. In Japanese, the model might use full-width punctuation for the delimiters.

When you show the model an example of the exact output format you want, including the delimiters, the field names, and a sample value in the target language, the model has far less room for interpretation. It pattern-matches the example rather than constructing the format from an abstract rule. The example anchors the specific characters to use for delimiters, the specific order of fields, and the specific placement of field names relative to values.

For maximum reliability, include two examples in your prompt: one with short values and one with longer, multi-sentence values. This prevents the model from associating the format only with brief outputs and reverting to freeform text when the content is longer. Use real target-language text in the example values, not placeholder text, so the model sees the actual character set it will be working with alongside the structural elements.

The token cost of format examples is significant but justified by the compliance improvement. Two format examples add 150 to 300 tokens depending on the language, but they can improve structured output compliance by 10 to 20 percentage points in CJK and RTL languages. For a production pipeline where every parsing failure triggers a retry or an error, this investment pays for itself in reduced error rates.

## Constrained Decoding: Forcing Valid Structure

If you have access to constrained decoding -- and in 2026, most major API providers and open-source serving frameworks support it -- you can bypass the formatting problem entirely by constraining the model's token generation to produce only tokens that form valid structure.

Constrained decoding works by defining a grammar or schema that the model's output must conform to, then masking out tokens during generation that would violate the schema. The model can only select from tokens that maintain a valid structural state. If your schema specifies that a field name must be followed by an ASCII colon followed by a string value, the model cannot insert a full-width colon or skip the delimiter entirely, because those tokens are masked out during generation.

Modern constrained decoding engines like XGrammar and llguidance, both released in production-ready form during 2025, achieve near-zero overhead compared to unconstrained generation. OpenAI's Structured Outputs feature, Anthropic's tool-use schema enforcement, and open-source serving frameworks like vLLM all support schema-constrained generation. For structured output in multilingual contexts, constrained decoding is the closest thing to a guaranteed solution.

There are two limitations to be aware of. First, constrained decoding controls the structure but not the content. The model will produce valid key-value pairs with correct delimiters, but the values themselves are still generated freely. A field called "sentiment" constrained to one of three enum values ("positive," "negative," "neutral") will always contain a valid value. But a field called "summary" whose value is unconstrained free text will still exhibit all the language-specific quality variations described elsewhere in this chapter. Constrained decoding solves the parsing problem, not the quality problem.

Second, constrained decoding requires that you define the schema explicitly. For simple key-value structures, this is straightforward. For complex nested structures with conditional fields, the schema definition becomes a meaningful engineering effort. However, this effort is a one-time cost per output format, and the resulting reliability across all languages is worth the investment for any pipeline that depends on parseable structured output.

## Locale-Specific Formatting in Field Values

Even when your structure is reliable, the content within fields can exhibit locale-specific formatting that breaks downstream processing.

Numbers are the most common offender. The model may format numbers according to the locale conventions of the output language. In German, the decimal separator is a comma and the thousands separator is a period: what English writes as "1,234.56" German writes as "1.234,56." If your downstream pipeline parses the number from the field value using English locale conventions, "1.234,56" becomes 1.234 (dropping everything after the comma, which it interprets as a thousands separator followed by invalid characters).

Dates follow the same pattern. The model might format a date as "02/14/2026" for US English, "14/02/2026" for British English and most European languages, or "2026/02/14" for Japanese. If your pipeline assumes a specific date format, locale-variant dates will be misinterpreted or rejected.

Currency symbols, percentage formatting, and unit notation all vary by locale. The model may use a period for Indian lakhs notation, insert a space before the percent sign in French, or use locale-specific currency symbol placement.

The mitigation is to specify the exact formatting convention for numeric and date fields in your system prompt. Do not rely on the model's locale-default formatting. State explicitly: "format all numbers using a period as the decimal separator and no thousands separator," or "format all dates as year dash month dash day." This instruction overrides the model's tendency to use locale-specific formatting, though compliance is not perfect -- expect 85 to 92 percent compliance on number formatting instructions across languages, with the remaining cases requiring post-processing normalization.

## The Structured Output Test Matrix

Structured output compliance must be tested per language as part of your evaluation suite. This is not optional if structured output feeds into a downstream pipeline or a user-facing feature.

Build a test matrix with your supported languages on one axis and your structured output requirements on the other. Each cell contains a compliance percentage: how often the model produces output that your parser successfully extracts into the expected fields with correct types and values.

The requirements axis should include at minimum: correct field names (ASCII, no directional characters), correct delimiters (ASCII punctuation only), correct field count (no missing or extra fields), correct value types (numbers as numbers, not strings; enums within the allowed set), and parseable overall structure (the full output can be parsed by your extraction code without errors).

Run this matrix with at least 50 test cases per language. Use realistic queries, not toy examples, because the model is more likely to break structure on complex responses than on simple ones. A short response with a two-word summary and a single enum value will parse correctly in almost any language. A long response with a multi-sentence summary, a nuanced sentiment classification, and a confidence score based on ambiguous input will expose the failure modes that matter in production.

Update the matrix after every model change, every prompt revision, and every parser update. Structured output compliance is sensitive to all three variables, and a change to any one can shift the compliance landscape in ways that are invisible without testing.

## When Structure Fails: Graceful Degradation

No matter how carefully you design your prompts, provide examples, and apply constrained decoding, some percentage of structured output will fail to parse in some languages. Your system needs a plan for these failures.

The first tier of defense is retry with reinforcement. When a response fails to parse, re-prompt the model with an explicit correction: "Your previous response could not be parsed. Please respond using only ASCII colons as delimiters, English field names, and the exact format shown in this example." Include the format example again. This retry succeeds about 70 to 80 percent of the time, because the explicit correction and reinforced example narrow the model's output space.

The second tier is structural repair. Before rejecting a response entirely, attempt automated repair: normalize Unicode to NFKC, strip bidirectional control characters, replace common full-width characters with their ASCII equivalents, and re-attempt parsing. This catches 60 to 70 percent of structural failures that are caused by character issues rather than fundamental format violations.

The third tier is fallback to unstructured extraction. If the response has the right content but the wrong structure, use a second model call or a language-specific extraction pipeline to pull the information from the freeform text. This is expensive -- it doubles your model cost for failed responses -- but it recovers information that would otherwise be lost.

The fourth tier is human escalation or error response. Some responses cannot be salvaged. For these, return a clear error to the user or route the response to a human reviewer, depending on the use case and the cost of failure.

Design your pipeline to track which tier each response reaches and at what rate per language. If a particular language consistently triggers second- or third-tier fallbacks, that is a signal to invest in better prompting, more format examples, or constrained decoding for that language rather than absorbing the cost of repeated fallbacks.

The next subchapter addresses a dimension of multilingual system design that goes beyond structure and formatting: the localization of tone, formality, and register in your system prompt, where the same product must speak with culturally appropriate voices across languages that have fundamentally different social conventions for AI communication.