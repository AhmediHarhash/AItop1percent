# 2.6 — Arabic, Hindi, and the South Asian Language Gap

Arabic has 420 million speakers. Hindi has 610 million. Bengali has over 300 million. Together, these three languages alone represent more people than the entire English-speaking world. Yet most AI models treat them as afterthoughts — languages that appear in training data through translated web pages and news articles rather than through the diverse, colloquial, domain-rich text that makes English and Chinese models capable. The gap between population size and model quality is not a technology problem. It is an investment problem. And until the economics shift, teams building for these markets face a set of challenges that no single model selection can solve.

## Arabic: One Name, Thirty Languages

The word "Arabic" on a model spec sheet is almost meaningless without further qualification. Arabic is not one language. It is a family of languages bound together by a shared writing system and a formal prestige variety — Modern Standard Arabic — that no one speaks natively.

A user in Cairo speaks Egyptian Arabic. A user in Riyadh speaks Gulf Arabic. A user in Casablanca speaks Moroccan Arabic, which a Gulf Arabic speaker may struggle to understand. A user in Beirut speaks Levantine Arabic. These are not accents or dialects in the way that American and British English are dialects. They differ in vocabulary, grammar, pronunciation, and idiomatic structure to the degree that mutual comprehension can break down entirely between distant varieties. And yet, when model providers report "Arabic support," they almost invariably mean Modern Standard Arabic — the formal register used in news broadcasts, academic writing, and government documents. The Arabic that real users actually type into products is dialectal, colloquial, and frequently mixed with English or French loanwords.

This disconnect between what models learn and what users expect creates a specific failure pattern. A model trained predominantly on Modern Standard Arabic will respond to an Egyptian user with text that sounds stiff, overly formal, and alien — like a chatbot that speaks exclusively in the style of a BBC newsreader when the user expects casual conversation. The user does not think "this model knows formal Arabic well." The user thinks "this model does not understand Arabic."

Arabic's technical challenges compound the dialectal problem. The right-to-left script requires correct handling at every layer of the pipeline, from input processing to output rendering. Arabic's root-based morphology means that a single three-consonant root can generate dozens of derived forms with different meanings, and understanding which form is intended requires contextual analysis that models with limited Arabic training data handle inconsistently. Diacritical marks that disambiguate pronunciation and meaning are almost never written in casual text, forcing the model to infer meaning from context alone — a task that requires deep Arabic knowledge rather than pattern matching.

## Jais and ALLaM: The Arabic Specialists

The most promising development for Arabic AI is the emergence of Arabic-first models built by organizations in the Arab world itself.

**Jais**, developed by Inception (G42) in the UAE, is an open-source model trained on the largest Arabic-first dataset available, covering Modern Standard Arabic and several Gulf dialects. Jais 2, with 70 billion parameters, aims to cover a wide range of Arab dialects and to respond appropriately to cultural norms, values, and references specific to Arabic-speaking communities. This cultural grounding is precisely what global models lack. A model trained by an Emirati organization on data curated by Arabic speakers makes different decisions about what constitutes appropriate, natural, and culturally sensitive Arabic output than a model trained by an American organization on whatever Arabic text appeared in Common Crawl.

**ALLaM**, developed by Saudi Arabia's SDAIA, was trained on a 500-billion-token Arabic dataset — the world's largest — assembled by mobilizing 16 government entities. ALLaM is designed to understand classical Arabic, Modern Standard Arabic, and regional dialects including Saudi, Egyptian, Jordanian, and Lebanese varieties. The newest version, set for launch in early 2026 by the Saudi government's HUMAIN initiative, was built by a team of 40 PhD-level researchers in the Kingdom. ALLaM uses reinforcement learning from AI feedback to enhance instruction following and contextual understanding in Arabic, an approach that addresses one of the key weaknesses of Arabic support in global models — the tendency to follow English-language instructions well but Arabic-language instructions poorly.

For teams targeting Arabic-speaking markets, the practical question is whether these specialists outperform frontier API models enough to justify a multi-model architecture. The answer depends on the use case. For formal, factual Arabic tasks — answering questions, summarizing documents, classifying text — GPT-5.1 and Gemini 3 Pro provide acceptable quality in Modern Standard Arabic. For conversational applications, customer service, social media engagement, or any task where dialectal naturalness matters, Jais and ALLaM offer quality that no global model matches. The gap is widest in Gulf Arabic, where Jais's training data advantage is most pronounced, and in tasks that require understanding Arabic cultural context — Islamic finance concepts, Arabic naming conventions, regional etiquette norms — that global models handle superficially.

## Hindi: Six Hundred Million Speakers, One Percent of the Web

Hindi's position in the AI landscape is a case study in the disconnect between speaker population and digital presence. Over 600 million people speak Hindi natively. Hindi is the third most spoken language on Earth. Yet Hindi accounts for less than 1% of Common Crawl, the web corpus that most large language models use as their primary training data source. The internet is not a representative sample of humanity. It is a biased sample that overrepresents English, Chinese, and Western European languages. Hindi is a casualty of that bias.

The consequences show up in model quality. On MMLU-ProX, the gap between English and Hindi scores ranges from 12 to 18 percentage points across frontier models. On INCLUDE, which tests Hindi-specific knowledge using Indian professional examination questions, the gaps are even wider. A model that scores 88% on English medical questions may score 65% on Hindi medical questions — not because Hindi medicine is harder, but because the model has not learned enough about Indian medical terminology, Indian pharmacology conventions, Indian clinical practices, and the way Hindi-speaking doctors communicate.

Hindi's technical challenges are subtler than Arabic's but no less consequential. Devanagari script is well-supported by modern tokenizers, but Hindi's morphological complexity — agglutinative tendencies, postpositions instead of prepositions, a system of verb auxiliaries that encodes tense and aspect differently from English — means that English-trained models regularly produce Hindi output with grammatical patterns that sound translated rather than native. The verb typically comes at the end of the sentence in Hindi, and models that have internalized English subject-verb-object patterns sometimes generate Hindi with awkward word order that a native speaker would never produce.

Then there is **Hinglish** — the fluid mixture of Hindi and English that is the default language of Indian internet communication. Over 350 million Indians are estimated to be bilingual in Hindi and English, and their natural communication style blends both languages within single sentences. A user might type a question that is 60% Hindi and 40% English, switch between Devanagari and Latin scripts mid-sentence, and use English technical terms embedded in Hindi grammar. Models trained separately on Hindi and English text handle Hinglish poorly because they have not learned the code-switching patterns that native speakers use instinctively. A product that cannot handle Hinglish is a product that cannot serve the majority of India's internet-connected population naturally.

## The Hindi-Urdu Continuum

Hindi and Urdu share a spoken form — Hindustani — but use different scripts. Hindi uses Devanagari. Urdu uses a modified Arabic script called Nastaliq. The vocabulary overlaps heavily in everyday conversation but diverges in formal registers, where Hindi draws from Sanskrit and Urdu from Persian and Arabic. This continuum creates a specific model challenge: trained data labeled "Hindi" and data labeled "Urdu" often contain the same spoken language in different scripts, but models that treat them as separate languages may fail to transfer knowledge between them.

For teams building products that serve both Indian and Pakistani users, the Hindi-Urdu continuum means that a single model must handle both Devanagari and Nastaliq scripts for essentially the same spoken language while also understanding the formal register differences that distinguish Hindi literary prose from Urdu literary prose. No frontier model handles this well. Most conflate Hindi and Urdu in ways that produce output which is neither fully natural Hindi nor fully natural Urdu — a compromise that satisfies neither audience. Fine-tuning on balanced corpora from both language communities, with explicit annotations for script and register, is typically necessary to produce acceptable results for both user populations.

## The Dravidian Languages: A Separate World

South of the Hindi heartland lies a family of languages that share almost no structural similarity with Hindi or with each other's closest relatives in the Indo-European family. Tamil, Telugu, Kannada, and Malayalam — the four major **Dravidian languages** — have their own scripts, their own grammatical structures, their own literary traditions spanning millennia, and a combined speaker population exceeding 200 million.

These languages pose a double challenge for AI models. First, they are underrepresented in training data even relative to Hindi. Telugu has 83 million speakers but far less web text than Dutch, which has 25 million. Tamil has 78 million speakers and a rich digital ecosystem — Tamil internet culture is vibrant — but the diversity and domain coverage of Tamil training data in most models is thin. Second, Dravidian languages are structurally different from both Hindi and English. Tamil is agglutinative with a complex case system. Telugu has subject-object-verb order with extensive sandhi — sound-change rules at word boundaries that alter written forms. These structural features mean that positive transfer from English or Hindi training is minimal. A model that has learned to generate fluent Hindi does not automatically generate fluent Tamil, because the languages are as different as English and Finnish.

For products targeting specific Dravidian language markets, the honest assessment in 2026 is that no general-purpose model provides production-grade quality. Frontier models produce functional but noticeably non-native output. Accuracy on domain-specific tasks drops precipitously. The path to quality requires either fine-tuning on substantial native-language data or routing to specialized models where they exist.

## Bengali: The World's Seventh Language, Treated Like the Hundredth

Bengali — or Bangla — has over 300 million speakers, making it the seventh most spoken language in the world. It is the official language of Bangladesh and the second most spoken language in India. Its literary tradition won a Nobel Prize. And yet, in the AI model landscape of 2026, Bengali remains severely underrepresented.

BanglaBERT, developed by the BUET NLP group, provides a foundation for Bengali NLP tasks but is a BERT-class model — useful for classification and understanding tasks but not for the generative applications that define modern AI products. Aya Expanse includes Bengali in its 101-language coverage but with quality that falls short of production standards for complex tasks. The government-backed BharatGen initiative, which is launching a 17-billion-parameter model supporting 22 Indian languages at the India AI Impact Summit in February 2026, may improve the situation, but the model's quality on Bengali-specific tasks is yet to be proven in production.

The Bengali language gap has direct economic consequences. Bangladesh has 180 million people and a rapidly growing digital economy. West Bengal, the Indian state where Bengali is the primary language, has a population exceeding 90 million. A fintech, healthcare, or e-commerce company that wants to serve Bengali-speaking users with AI-powered features faces a stark choice: accept quality that is measurably lower than what English or Hindi users receive, invest heavily in fine-tuning and custom data collection, or wait for the model ecosystem to catch up. Most companies choose the first option, creating a two-tier user experience that Bengali speakers notice and resent.

## The Scale of the South Asian Gap

India alone has 22 official languages recognized by the constitution and 121 languages spoken by more than 10,000 people. No model covers more than five or six Indian languages well. AI4Bharat, the research initiative at IIT Madras, has made significant contributions — IndicTrans2 provides translation capability across all 22 scheduled languages, and the IndicBERT and IndicBART models offer understanding and generation for 12 major Indian languages — but these are research models, not production-ready systems optimized for the diverse tasks that commercial AI products demand.

The gap between what exists and what is needed is not primarily technical. It is economic. Building production-quality AI for Marathi, Gujarati, Punjabi, Odia, Assamese, or Malayalam requires training data that does not exist in sufficient quantity or diversity — domain-specific text, conversational data, technical vocabulary, formal and informal registers. Creating that data requires investment from organizations that see a return on serving those language communities. The return exists — India's digital economy is one of the fastest growing in the world — but the investment cycle has not yet caught up with the opportunity.

## Practical Recommendations

For teams building AI products for Arabic, Hindi, or South Asian language markets, the decision framework depends on which specific language and which specific use case you are targeting.

For Arabic applications where dialectal naturalness matters, evaluate Jais and ALLaM alongside frontier API models. The specialists' advantage is most pronounced for Gulf Arabic, Egyptian Arabic, and conversational use cases. For Modern Standard Arabic tasks — document processing, formal text generation, factual Q and A — frontier models are competitive and may be simpler to integrate.

For Hindi applications, GPT-5.1 and Gemini 3 Pro provide the best general-purpose Hindi quality among frontier models, but plan to invest in evaluation by native Hindi speakers who use the language daily — not Hindi scholars who speak formal textbook Hindi. If your users write in Hinglish, test extensively for code-switching quality, and be prepared to fine-tune.

For Dravidian languages, no general-purpose model is sufficient for production quality on complex tasks. Your strategy must include fine-tuning on native-language data, evaluation by native speakers, and realistic quality targets that acknowledge the current limitations. Setting the same quality bar for Tamil as for English is setting yourself up for failure or for a launch that never happens.

For Bengali, Urdu, and other South Asian languages, Aya Expanse provides the broadest baseline coverage, but quality requires supplementation through fine-tuning or hybrid approaches that use translation from a stronger language combined with native-speaker review.

Across all of these languages, one principle holds: the further a language is from the model's training data center of gravity, the more your investment must shift from model selection to data engineering. You cannot buy your way to production quality with a better API key. You build your way there with better training data, better evaluation, and better understanding of what your specific users need.

The next subchapter turns to the languages where the gap is widest of all — African and Indigenous languages that most AI models cannot serve at any acceptable quality level, and what that means for the billion-plus people who speak them.
