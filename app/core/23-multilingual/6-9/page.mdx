# 6.9 â€” Language-Specific Query Behavior: How Search Patterns Differ Across Cultures

Your query expansion strategy works because you tested it with English speakers. Users in Japan, Korea, Germany, and the Arab world search differently -- different query lengths, different structures, different assumptions about what the system understands. A retrieval pipeline tuned for English query patterns will produce systematically worse results for users who do not search the way English speakers do. Not because the retrieval engine is broken, but because it was optimized for one query style and deployed to users with many.

This is not a niche concern. If your system serves users in more than one language, those users are forming queries through the lens of their language's grammar, their culture's communication norms, and their prior experience with search systems built for different populations. Ignore these differences and your retrieval quality varies by market -- not because the content differs, but because the queries do.

## Query Length: When Four Characters Express a Complete Thought

English queries are verbose by global standards. The average English-language enterprise search query is four to six words. Users ask full questions: "How do I reset my password?" or type descriptive phrases: "quarterly revenue report template 2025." The words themselves carry the semantic signal, and the embedding model has plenty of tokens to encode the intent.

Japanese queries are shorter. Two to four words are typical, and a single word can carry the semantic weight of an entire English phrase. The word "keiyakusho" is one word in Japanese but translates to "contract document" in English. "Nenmatsu-chousei" is one compound noun meaning "year-end tax adjustment." A Japanese user typing that single compound expects the system to find everything related to year-end tax adjustments. An English user would type three or four words to express the same concept. The embedding model receives fewer tokens from the Japanese query, and if the model is better calibrated for longer English inputs, the shorter Japanese query may produce a less precise embedding.

Chinese queries are similarly compact. Chinese is a logographic language where a single character often represents a morpheme. Two to four characters can express a query that requires five to eight English words. A query like two characters meaning "refund" is complete, specific, and unambiguous to a Chinese speaker. The retrieval system receives a tiny input and must infer the full breadth of the user's intent from very little signal.

Korean sits between these extremes. Korean uses an agglutinative structure where suffixes attach to root words, producing queries that are compact but carry grammatical information. A Korean query may include particles that signal the user's intent (searching for a cause versus searching for a process, for example), but the total character count remains lower than an equivalent English query.

Arabic queries introduce a different kind of compactness. Arabic is a root-based language where three consonants form a root that generates dozens of related words through patterns of vowels and affixes. A user searching for information about "writing" might type the root form, expecting the system to match documents containing "writer," "written," "book," and "correspondence" -- all derived from the same root. An embedding model that treats each surface form independently may miss the deep morphological connections that an Arabic speaker takes for granted.

The implication for retrieval design is direct. If your system was tuned for English query lengths and you measure retrieval quality on English benchmarks, you are optimizing for the easy case. Short queries demand more from the embedding model's ability to encode dense semantic content. They also demand more from query expansion, because the user provided less signal for the system to work with.

## Query Style: Questions vs Keywords vs Compound Nouns

English speakers ask questions. "How do I file a claim?" "What is the return policy?" "When does the warranty expire?" The question structure provides grammatical context -- the question word signals the type of information expected, the verb signals the action, the object signals the topic. Embedding models trained predominantly on English learn these patterns and encode them effectively.

Japanese users lean toward keyword fragments. Rather than asking "How do I reset my password?" a Japanese user is more likely to type "password reset method" or just "password reset" in Japanese. The query omits the question word, the subject, and the verb. It assumes the system will understand that the user wants instructions for performing the action. This is not laziness -- it reflects how Japanese speakers naturally formulate search queries, shaped by decades of experience with search engines that worked better with keyword input.

German users produce compound nouns. German allows unlimited noun compounding -- stringing nouns together to form a single word that expresses a precise concept. "Datenschutzgrundverordnung" is one word meaning "General Data Protection Regulation." "Krankenversicherungsbeitragsberechnung" means "health insurance contribution calculation." German users type these compounds as single search terms. A tokenizer that splits on spaces will treat the entire compound as one token (or sub-tokenize it unpredictably), and the embedding model may struggle to extract the individual semantic components. An English user searching for the same concept would type four separate words, giving the model four distinct semantic anchors.

Korean users combine nouns with particles that modify meaning. The particle attached to a noun changes whether the user is searching for the noun as a subject, an object, a location, or a tool. "Seoul-e" means "to Seoul" while "Seoul-eseo" means "from Seoul" or "in Seoul." These particles carry retrieval-relevant information that keyword-based systems may strip during preprocessing, and embedding models may not weight appropriately.

Arabic users may include honorifics and formal phrases even in search queries. A query about a religious ruling might begin with a respectful invocation. A query to a government service might include a formal salutation. These cultural conventions add tokens that carry social meaning but not retrieval-relevant semantic content. If the embedding model encodes these tokens with equal weight, they dilute the semantic signal of the actual query.

## Formality Gradients in Search

Some cultures phrase search queries with a level of formality that English speakers reserve for email to the CEO. Others are so casual that the query is barely a sentence fragment. This formality gradient affects retrieval because it determines the vocabulary, grammatical complexity, and length of the query text.

Japanese has distinct formality registers. A query in casual Japanese uses different verb endings, different pronouns, and sometimes different vocabulary than a query in polite or formal Japanese. A support chatbot receiving queries from Japanese business professionals may see highly formal language, while a consumer product receives casual speech. The same question -- "how do I cancel my subscription" -- can be expressed in three or four different formality levels in Japanese, each using somewhat different words. If your training data skews toward one register, your embedding model performs better for that register than for others.

Korean has a similar formality structure, with six distinct speech levels that affect verb endings and vocabulary. Queries from younger users tend to be casual. Queries from older users or in professional contexts tend to be formal. A retrieval system that performs well on formal queries but poorly on casual ones (or vice versa) is effectively biased by age or professional context.

Arabic varies between Modern Standard Arabic and regional dialects. A user in Egypt may type in Egyptian Arabic, which uses different vocabulary and grammar than Modern Standard Arabic. A user in Saudi Arabia may type in Gulf Arabic. A user submitting a formal request may use Modern Standard Arabic. These are not minor variations -- they are closer to the difference between standard written English and Scots English. A system that indexes documents in Modern Standard Arabic and receives queries in Egyptian dialect will miss matches that a human would find obvious.

English has formality variation too, but it is narrower. The gap between "How do I reset my password?" and "password reset" is smaller than the formality gradients in Japanese, Korean, or Arabic. English speakers adjust tone more than vocabulary when shifting between formal and casual search.

## Vocabulary Variation and Synonym Complexity

Every language has synonyms, but the synonym landscape differs dramatically across languages, and these differences directly affect retrieval.

English synonym handling is well-studied. "Purchase" and "buy" are synonyms. "Vehicle" and "car" overlap. Embedding models trained on massive English corpora have learned most of these relationships and cluster synonymous terms together. Query expansion with English synonyms is a mature technique.

Chinese presents a different synonym challenge. Simplified Chinese (used in mainland China) and Traditional Chinese (used in Taiwan and Hong Kong) use different character sets for the same concepts. A query in Simplified Chinese may not match a document indexed in Traditional Chinese, even though the content is semantically identical. Beyond the script split, Chinese has extensive regional vocabulary variation. The word for "taxi" differs between mainland China, Taiwan, and Hong Kong. The word for "software" differs. The word for "internet" differs. A Chinese user from Taiwan searching for "computer" uses a different term than a user from Beijing, and both expect to find the same content.

Japanese compounds this with three writing systems. A single concept can be written in kanji (Chinese characters), hiragana (native phonetic script), or katakana (phonetic script used for foreign words). The word "computer" can appear as katakana-rendered "konpyuutaa," the kanji compound "denshi keisanki," or the abbreviated English loanword "PC." A human knows these are the same concept. An embedding model may or may not cluster them together, depending on its training data. Query expansion for Japanese must consider all three writing systems as potential variants.

Arabic morphology creates a different kind of variation. A root like k-t-b (related to writing) generates "kitaab" (book), "kaatib" (writer), "maktaba" (library), "maktoob" (written), and dozens more. An Arabic user searching with one form expects to find documents containing related forms. Stemming and lemmatization help, but Arabic morphology is complex enough that standard stemmers miss many valid connections. Embedding models that handle Arabic morphological relationships well retrieve significantly better than models that treat each surface form independently.

## Language-Aware Query Expansion

Query expansion -- adding related terms to a query to improve recall -- must be tuned per language. The techniques that work for English do not transfer directly.

For English, query expansion typically adds synonyms, hypernyms, and related phrases. "Car insurance claim" expands to include "automobile insurance claim," "vehicle insurance filing," "auto policy claim." The expansion terms are straightforward and well-covered by English-language thesauri and embedding-based nearest-neighbor lookup.

For Japanese, query expansion must consider reading variations. A kanji compound can be read in multiple ways, and users may search using any reading. The expansion should include katakana renderings of foreign terms, alternative kanji compounds for the same concept, and the hiragana spelling that a user might type if they cannot remember the correct kanji. A search for a technical term in katakana should also match the same term if it appears in kanji form in the document. This requires a Japanese-specific expansion dictionary or a model that has learned these cross-script relationships.

For Chinese, query expansion must bridge the simplified-traditional divide and handle regional vocabulary. Expanding a Simplified Chinese query should include the Traditional Chinese equivalent (and vice versa) to ensure cross-strait retrieval. It should also include regional synonyms. This is not optional for systems that serve Chinese speakers from multiple regions.

For Arabic, query expansion must handle morphological variation. Expanding a query based on the root allows the system to match documents that use different derived forms. Root-based expansion is more effective for Arabic than synonym-based expansion because the morphological family of a root is broader and more predictable than the synonym set of any individual word.

For German, query expansion should decompose compound nouns. "Krankenversicherungsbeitragsberechnung" should be decomposed into its constituent parts: health insurance, contribution, calculation. The decomposed parts can then be searched independently or used to expand the query, catching documents that express the same concept without the specific compound form.

## How Users Retry When Search Fails

When a search returns bad results, users reformulate their query. The reformulation strategy differs by culture and language, and understanding these differences helps you diagnose retrieval problems and design better fallback experiences.

English speakers tend to add words. If "reset password" does not work, they try "how to reset my account password." If that fails, they try "can't log in need new password." They make the query longer and more specific, adding context with each attempt. This works well with embedding models because more tokens provide more semantic signal.

Japanese speakers tend to change words rather than add them. If one keyword does not work, they replace it with a synonym or a related term rather than making the query longer. This reflects the keyword-oriented query style: the user is searching for the right keyword, not building a longer description. For retrieval pipelines, this means that a Japanese user's second and third attempts may use completely different vocabulary than the first attempt, while an English user's subsequent attempts are variations of the original.

Some users switch languages when their primary language fails. A German user who cannot find results in German may retype the query in English, assuming the English-language content is more extensive. A Japanese user in a multinational company may do the same. This language-switching behavior means your system should handle the transition gracefully -- when a user who has been querying in Japanese suddenly submits an English query, the system should not be confused by the session context.

Other users give up entirely. Studies of search behavior show that users in some markets abandon search after fewer failed attempts than users in other markets. If your retrieval quality is lower for a specific language and users in that market have a lower retry threshold, you lose those users faster. The combination of worse retrieval and lower tolerance produces disproportionate abandonment.

## Implications for RAG System Design

These behavioral differences have concrete implications for how you build and evaluate your retrieval pipeline.

**Chunk size should reflect expected query granularity.** If Japanese queries are shorter and more keyword-oriented, your Japanese-language chunks should be shorter and more focused. A 512-token chunk that covers three related topics works for English because the longer English query provides enough signal to match the relevant portion. A short Japanese keyword query may match the chunk but rank it poorly because only 20 percent of the chunk is relevant. Smaller, more focused chunks improve precision for keyword-style queries.

**Evaluation must use real queries from each market.** A test suite of English queries translated into Japanese does not test Japanese query behavior -- it tests English query behavior expressed in Japanese words. Real evaluation requires collecting actual queries from Japanese users, Korean users, Arabic users, and every other population you serve. These real queries exhibit the length distributions, formality patterns, and vocabulary choices that your system will encounter in production.

**Query understanding should be language-aware.** Before embedding the query, consider preprocessing it for the language's specific characteristics. Decompose German compound nouns. Normalize simplified and traditional Chinese characters. Apply Arabic root extraction. Expand Japanese queries across writing systems. This preprocessing is not a replacement for a good multilingual embedding model -- it is a complement that handles the cases the model may not.

**Retrieval metrics must be reported per language.** A global recall of 85 percent is meaningless if English recall is 92 percent and Arabic recall is 71 percent. The Arabic users experience a fundamentally different product. Per-language metrics tell you where your system is underserving users, and the behavioral patterns described in this subchapter help you understand why.

## Building Query Behavior Profiles

For each language your system supports, build a query behavior profile: a documented description of typical query patterns based on real usage data. The profile should include average query length in tokens and characters, common query structures (question, keyword, compound noun, phrase), typical reformulation patterns, frequency of code-switching with English, formality distribution, and common vocabulary variants.

Build these profiles from production data, not assumptions. Log a sample of queries per language, have native speakers annotate the patterns, and update the profiles quarterly as your user base evolves. New user populations, new product features, and seasonal patterns all shift query behavior.

These profiles inform every retrieval decision: chunk sizing, query preprocessing, expansion strategy, evaluation design, and the thresholds you set for each language. Without them, you are optimizing for one query style and hoping it generalizes. It does not.

The next subchapter addresses a problem that emerges after retrieval and generation are both working: when the model generates a response in one language based on source documents in another language, how do you verify that the response faithfully represents the source? Cross-lingual faithfulness is the final quality gate in multilingual RAG, and it is harder than it looks.