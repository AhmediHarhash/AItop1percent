Scope: Web3

# 6.4 â€” The Data Availability Layer: The Bill Nobody Sees

In early 2025, a gaming studio launched a rollup on the OP Stack to host their on-chain prediction market. They had done the math on execution costs â€” gas fees per transaction, sequencer margins, user subsidies â€” and projected monthly infrastructure spend at around 8,000 dollars. The first month came in at 47,000 dollars. Nearly 80 percent of the overrun was a single line item the team had not modeled: the cost of posting transaction data to Ethereum for verification. They had optimized everything above the data availability layer and ignored the layer that determined their actual unit economics.

That experience is common enough to be a pattern. The data availability layer is the most consequential cost center in the modular stack, and it is the one most builders discover only after they receive the bill.

## Where DA Fits in the Stack

In the previous subchapters, you saw how the settlement layer anchors truth and the execution layer runs computation. The data availability layer sits between them, performing a function that sounds mundane but is architecturally critical: it ensures that the data behind every transaction is published somewhere that anyone can access and verify.

Why does this matter? Because a rollup's security model depends on the ability to reconstruct state. An optimistic rollup is only secure if someone can challenge an invalid state root, and that challenge requires access to the original transaction data. A ZK rollup is only verifiable if the proof can be checked against the data it claims to represent. If the data is not available â€” if the sequencer posts a state root but withholds the underlying transactions â€” then no one can verify correctness, and the security model collapses.

**Data availability** is not data storage. Storage means the data is saved permanently. Availability means the data is published and accessible for long enough that any interested party can download it, verify it, and use it to reconstruct the chain's state. A DA layer does not need to keep data forever. It needs to keep it available for the verification window â€” typically seven days for optimistic rollups, or until the ZK proof is verified and accepted by the settlement layer.

This distinction is subtle but important. If you confuse DA with storage, you will overestimate costs and underestimate the design options available to you. The question is not "where does my data live permanently?" It is "where does my data live long enough for someone to catch fraud?"

## The Three DA Strategies

Every rollup in 2026 uses one of three strategies to make its transaction data available, and the choice determines the rollup's cost structure, security assumptions, and throughput ceiling.

**Ethereum calldata** was the original approach. Before EIP-4844, rollups posted compressed transaction data directly into the calldata field of Ethereum transactions. Calldata is stored permanently by every Ethereum node as part of the transaction history. This is maximally secure â€” the data inherits Ethereum's full security and availability guarantees â€” but extremely expensive. Every byte of calldata costs gas, and Ethereum's gas market is competitive. During peak periods in 2023 and early 2024, rollups like Arbitrum and Optimism were spending hundreds of thousands of dollars per month on calldata costs alone.

**Ethereum blobs** replaced calldata as the primary DA mechanism after the Dencun upgrade went live in March 2024, which introduced EIP-4844. Blobs are large binary objects attached to Ethereum transactions that are stored by consensus nodes for approximately 18 days, then pruned. They are not part of the permanent transaction history. They exist long enough for verification, then they disappear. The cost reduction was dramatic. Rollups that switched from calldata to blobs saw data posting costs drop by roughly 98 percent. Some rollups went from spending over 100,000 dollars per month on DA to spending a few thousand.

The tradeoff is capacity. Ethereum currently supports a limited number of blobs per block. For rollups with moderate transaction volume, this capacity is sufficient. For high-throughput rollups processing millions of transactions per day, Ethereum's blob space becomes a bottleneck. When demand for blob space exceeds supply, blob fees rise â€” and they can rise sharply during congestion events, recreating the cost unpredictability that blobs were designed to eliminate.

**Dedicated DA layers** are the third option. Celestia, EigenDA, and Avail are purpose-built networks that do one thing: store and serve data for rollups. They do not execute transactions. They do not settle disputes. They exist purely to make data available at low cost and high throughput. The cost difference is substantial. Data from Conduit's analysis in 2025 showed Celestia's data posting costs at a fraction of Ethereum blob costs â€” in some cases over 50 times cheaper per megabyte. Eclipse's data posting costs on Celestia averaged approximately seven cents per megabyte, compared to several dollars per megabyte for Ethereum blobs during the same period.

The tradeoff is security assumptions. When you post data to Ethereum blobs, you inherit Ethereum's validator set and economic security â€” over 100 billion dollars in staked ETH securing the data. When you post data to Celestia, you inherit Celestia's validator set and economic security, which is meaningful but smaller. For applications where the absolute highest security guarantees matter â€” large-scale DeFi, institutional products, anything holding billions in value â€” Ethereum DA may be worth the premium. For applications where cost efficiency matters more than maximum security â€” gaming, social, micropayment channels â€” a dedicated DA layer can reduce costs by orders of magnitude.

## How DA Connects to the Rest of the Stack

The DA layer's relationship to other stack layers is straightforward but has consequences that are easy to miss.

The settlement layer depends on DA because it needs to verify that state transitions are correct. If you are running an optimistic rollup, the settlement contract on Ethereum needs to know that the transaction data is available so that challengers can submit fraud proofs. If data is posted to Ethereum blobs, the settlement contract can reference it directly. If data is posted to Celestia or EigenDA, the settlement contract needs a separate mechanism â€” typically a data availability attestation or bridge â€” to confirm that the data was published. This adds a trust assumption and an additional point of potential failure.

The execution layer depends on DA because the cost of posting data flows directly into the fees users pay. When your rollup's sequencer batches transactions and posts them to the DA layer, the cost of that posting is spread across all the transactions in the batch. More transactions in each batch means lower per-transaction DA costs. Lower DA costs mean lower user fees. Lower user fees mean more users can afford to interact with your application. The DA layer does not touch your application logic, but it determines whether a user in Lagos or Manila can afford to use your product.

The sequencing layer also has a direct relationship with DA. The sequencer decides when and how to batch transactions for DA posting. A sequencer that batches aggressively â€” posting large, infrequent batches â€” minimizes DA costs but increases confirmation latency. A sequencer that posts frequently â€” small batches every few seconds â€” provides faster confirmations but pays more in DA fees. This tradeoff between latency and cost is one of the most important operational tuning decisions in rollup architecture, and the DA layer's pricing model determines the economics of that tradeoff.

## Why Builders Ignore DA and Regret It

The data availability layer is invisible to users. No one opens your application and thinks about where transaction data is posted. There is no user-facing feature called "data availability." It does not appear in marketing materials or product demos. This invisibility is exactly why it catches teams off guard.

The pattern repeats across the industry. A team designs their rollup, optimizes their execution environment, builds a slick front end, launches to real users, and then discovers that DA costs represent 60 to 80 percent of their total infrastructure spend. By that point, switching DA strategies requires redeploying the rollup's core contracts, migrating state, and potentially changing the trust assumptions that their security model depends on. It is not a trivial change.

The fix is simple in principle: model your DA costs before you commit to an architecture. Estimate your expected transaction volume. Calculate the data size per transaction. Multiply by the per-megabyte cost of your chosen DA layer. Add a margin for congestion spikes. Then compare that number against your revenue model. If DA costs consume more than your product can sustain, you need a different DA strategy â€” not a different execution layer, not a different front end. The DA layer.

## The DA Decision Framework

When choosing your data availability strategy, three variables matter.

Security requirements come first. If your rollup holds substantial value or serves institutional clients, Ethereum blobs provide the strongest security guarantees. The economic security of Ethereum's validator set is unmatched. If your rollup serves a consumer application where speed and cost matter more than maximum security, a dedicated DA layer like Celestia or EigenDA offers better economics at acceptable security levels.

Throughput needs come second. Ethereum's blob capacity is finite. If your application generates more data than Ethereum's blob space can absorb, you will either pay premium fees during congestion or you will need to use a dedicated DA layer that can scale capacity independently. High-throughput applications â€” gaming, social media, micropayments â€” almost always need dedicated DA.

Cost tolerance comes third. If your per-transaction margin is measured in dollars, Ethereum blob costs are a rounding error. If your per-transaction margin is measured in fractions of a cent â€” as it is for most consumer applications â€” DA costs can make or break your business model. The difference between seven cents per megabyte on Celestia and several dollars per megabyte on Ethereum blobs is not academic. It is the difference between a viable product and a product that bleeds money with every user interaction.

The Ethereum roadmap includes further upgrades that will increase blob capacity and reduce blob costs. The Fusaka upgrade, planned for 2025, aims to significantly expand the number of blobs per block. Over the long term, full danksharding promises to increase Ethereum's DA capacity by orders of magnitude. But "the long term" is not a business plan. Your architecture needs to work at today's costs, with today's capacity, while remaining flexible enough to adapt as the underlying DA layer evolves.

The data availability layer is where your rollup's economic reality lives. It is not the layer users see or the layer that generates conference talks. It is the layer that determines whether your product is financially sustainable. Ignore it at the planning stage and you will discover it on the invoice.

The DA layer determines what your data costs. But before that data is posted, someone has to decide the order in which transactions are processed and batched. That role belongs to the sequencer, and who controls it â€” and what they can do with that control â€” is the subject of the next subchapter.
