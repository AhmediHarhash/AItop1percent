Scope: Web3

# 3.7 â€” The Sequencer Problem: Centralization in Decentralized Clothing

**Decentralization Theater** is what happens when a system looks decentralized but has a single point of failure hiding in plain sight. The logos say "decentralized." The landing page says "trustless." The architecture diagram shows validators, provers, and a settlement layer on Ethereum. Everything looks distributed. Then you look at the one component that actually processes every transaction, and you find a single server, run by a single company, in a single data center, with a single team on call when it goes down.

That component is the sequencer. And in 2026, the vast majority of Layer 2 rollups â€” the scaling solutions that handle a growing share of Ethereum's transaction volume â€” rely on a centralized sequencer operated by the rollup's founding team.

This is not a secret. It is documented on every major L2's architecture page. L2BEAT, the leading independent tracker of rollup security, classifies sequencers as centralized or decentralized for every rollup it monitors. As of early 2026, Arbitrum One, Optimism, Base, zkSync Era, Starknet, Linea, Scroll, and Blast all use centralized sequencers. The entity that built the rollup is the entity that runs the sequencer. Offchain Labs sequences Arbitrum. OP Labs sequences Optimism. Coinbase sequences Base. Matter Labs sequences zkSync Era. There is no validator set. There is no election. There is no rotation. One company decides which transactions get included, in what order, and when.

## What a Sequencer Actually Does

To understand why this matters, you need to understand what a sequencer does. On an L2 rollup, the sequencer is the component that receives user transactions, orders them into batches, executes them against the current state, and posts the resulting data to the L1 settlement layer â€” in most cases, Ethereum.

Think of the sequencer as the combination of a mempool, a block producer, and an execution engine, all rolled into one. When you submit a transaction on Arbitrum, it does not go to a decentralized network of validators who compete to include it. It goes to a single server run by Offchain Labs. That server decides the order in which transactions are processed. It decides the timing of batch submissions to Ethereum. It decides, implicitly, whether your transaction gets included at all.

In a decentralized L1 like Ethereum, transaction ordering is determined by a competitive market. Block proposers are selected from a validator set of over a million participants. MEV-Boost creates an auction where block builders compete to produce the most valuable block. The proposer picks the highest bidder. Multiple parties are involved, incentives are aligned through economic competition, and no single entity controls the process.

On a centralized L2 sequencer, there is no competition. There is no auction. There is no selection from a validator set. There is one operator, and they do everything. The trust model is not "trust the consensus mechanism." It is "trust this specific company."

## The Three Risks of Centralized Sequencing

Centralized sequencers create three categories of risk that do not exist in truly decentralized systems.

The first risk is **liveness failure**. If the sequencer goes down, the L2 halts. No transactions are processed. No state updates occur. Users cannot interact with their funds. In August 2025, the Base sequencer experienced an outage that halted the network. Coinbase, the sole operator, had to diagnose and fix the issue before the chain could resume. During the outage, users with positions in DeFi protocols â€” leveraged positions, liquidity provisions, time-sensitive trades â€” could do nothing. They could not close positions, could not add collateral, could not withdraw. They sat and waited for a single company to fix a single server.

Arbitrum has experienced similar sequencer outages. In December 2023, the sequencer stalled during a period of high demand caused by an inscription craze. The chain stopped producing blocks. Offchain Labs resolved the issue, but during the downtime, Arbitrum â€” the largest L2 by total value locked â€” was functionally offline.

To be fair, centralized sequencers have generally maintained high uptime. Base's August 2025 outage was its first significant incident after nearly two years of continuous operation. But "generally reliable" is not the same as "cannot fail." A system with a single point of failure will eventually fail at that point. The question is not whether it will happen, but when, and how much damage occurs when it does.

The second risk is **censorship**. A centralized sequencer can choose which transactions to include and which to exclude. In practice, major L2 operators have not engaged in deliberate censorship. But the capability exists. If a government ordered Coinbase to stop processing transactions from specific addresses on Base, Coinbase would face a choice between compliance and defiance. Given that Coinbase is a publicly traded US company subject to SEC oversight, the outcome of that choice is not difficult to predict.

Rollups have a safety mechanism called **forced inclusion** â€” a process that allows users to submit transactions directly to the L1 settlement layer, bypassing the sequencer entirely. If the sequencer censors your transaction, you can, in theory, force it through by submitting it to Ethereum L1 and waiting for the rollup's derivation pipeline to pick it up. This is a real guarantee backed by the L1 smart contracts.

But forced inclusion is slow. On Optimism, the forced inclusion delay is currently 12 hours. On Arbitrum, it is roughly 24 hours. During that delay, your transaction is not processed. If you are trying to add collateral to a leveraged position that is approaching liquidation, a 12-hour delay is not a safety mechanism. It is a death sentence for your position. Forced inclusion is a backstop against permanent censorship, not a substitute for a responsive sequencer.

The third risk is **MEV extraction**. The sequencer controls transaction ordering. Transaction ordering determines who profits from front-running, sandwiching, and arbitrage. A centralized sequencer has the technical capability to extract maximal value from every transaction it processes â€” or to sell that capability to third parties.

Whether major L2 operators are actively extracting MEV from their users is debated. The sequencer's transaction ordering is not transparent in the way Ethereum's mempool and block builder auctions are transparent. Users cannot easily verify whether their transactions were ordered fairly or reordered for profit. The opacity itself is the problem. On Ethereum L1, MEV extraction is visible, studied, and increasingly mitigated through tools like Flashbots Protect. On centralized L2 sequencers, the sequencer has both the capability and the opacity to extract value without detection.

## The Revenue Incentive

Centralized sequencing is not just a temporary engineering shortcut. It is an enormously profitable business model. The sequencer collects transaction fees from users and pays a much smaller fee to post batch data to Ethereum L1. The difference â€” the spread between L2 fees collected and L1 data posting costs â€” is the sequencer operator's revenue.

Coinbase's Base sequencer is estimated to generate tens of millions of dollars in annual revenue. The Optimism sequencer generates revenue that funds the Optimism Collective. The Arbitrum sequencer generates revenue for the Arbitrum DAO. These are not trivial amounts. They are core revenue streams for the entities that control the sequencers.

This creates a structural misalignment. Decentralizing the sequencer means distributing this revenue across a validator set, which dilutes the income that currently flows to a single entity. The entity that controls the sequencer has a financial incentive to delay decentralization â€” and a narrative incentive to promise it. The result is a pattern that repeats across the industry: roadmaps that include "sequencer decentralization" as a future milestone, timelines that slip, and centralized sequencers that continue operating year after year.

## Shared Sequencing: The Promise and the Reality

The most ambitious solution to the sequencer problem is **shared sequencing** â€” a design where multiple rollups delegate their sequencing to a common, decentralized sequencer network. Instead of each L2 running its own centralized sequencer, all participating L2s would submit transactions to a shared network of sequencer nodes that orders transactions fairly and posts them to the respective L1 settlement layers.

Espresso Systems is the most prominent project pursuing this approach. Espresso's architecture uses HotShot, a Byzantine Fault Tolerant consensus protocol, to reach agreement among sequencer nodes on transaction ordering. The goal is a shared sequencing layer that is permissionless â€” anyone can run a sequencer node â€” and that provides ordering guarantees to multiple rollups simultaneously. Espresso's mainnet launched in phases starting in 2025, with the goal of scaling to thousands of participating nodes.

The appeal of shared sequencing is significant. It would eliminate the single-company dependency. It would enable atomic composability between participating rollups â€” the ability to execute transactions across multiple L2s in a single atomic operation. It would create a competitive market for sequencing, reducing the ability of any single operator to extract MEV or censor transactions.

But shared sequencing has faced serious headwinds. Astria, once a leading shared sequencer project that had raised 12.5 million dollars and launched its mainnet in late 2024, shut down entirely in early 2025. The Astria network recorded its final block at height 15,360,577 and ceased operations. The team did not disclose detailed reasons, but the shutdown underscored a hard truth: shared sequencing is technically demanding, commercially unproven, and difficult to bootstrap when existing L2 operators have no strong incentive to adopt it.

The L2 operators who would need to adopt shared sequencing are the same entities that currently profit from centralized sequencing. Asking Coinbase to give up control of Base's sequencer â€” and the revenue it generates â€” in favor of a shared network run by third parties is asking them to sacrifice a competitive advantage for a public good. The incentive alignment is backwards. The entities with the most to gain from shared sequencing are users and application developers. The entities with the most to lose are the L2 operators who would need to adopt it.

## Based Rollups: Let Ethereum Sequence Everything

A different approach to the sequencer problem is the **based rollup** â€” a rollup that delegates sequencing to Ethereum L1 validators themselves. Instead of running a separate sequencer, a based rollup lets Ethereum block proposers include L2 transactions directly in L1 blocks. Transaction ordering is determined by the same competitive builder market that orders Ethereum L1 transactions. No separate sequencer exists. No separate trust assumption is needed.

Based rollups inherit Ethereum's full decentralization for transaction ordering. They cannot be censored unless Ethereum itself is censored. They cannot go offline unless Ethereum goes offline. They cannot extract MEV in ways that are invisible, because the ordering happens through the same transparent builder auction that Ethereum uses.

The tradeoff is speed. Ethereum produces blocks every 12 seconds. A based rollup's transactions would confirm at Ethereum's cadence, not at the sub-second speeds that centralized sequencers can achieve. For applications that need the fastest possible confirmation â€” high-frequency trading, real-time gaming â€” this is a meaningful limitation. For applications where 12-second confirmation is acceptable â€” most DeFi, most NFT operations, most token transfers â€” based rollups eliminate the sequencer problem entirely.

Projects like Taiko, Surge, and Puffer's UniFi have been developing based rollup architectures through 2025. Ethereum's own roadmap includes improvements that would make based sequencing more practical, including preconfirmations â€” a mechanism where L1 validators can offer soft confirmations for L2 transactions before the L1 block is finalized, reducing the effective latency from 12 seconds to potentially sub-second speeds while maintaining L1-level decentralization for final ordering.

Based rollups are not yet the dominant model. They are earlier in development than centralized sequencer rollups, and the user experience gap â€” faster confirmations on centralized sequencers versus stronger guarantees on based rollups â€” creates a real adoption challenge. But they represent the most philosophically consistent answer to the sequencer problem: if the point of an L2 is to inherit Ethereum's security, then the sequencer should inherit Ethereum's decentralization.

## Metis: The Exception That Proves the Rule

Metis stands out as the first Ethereum L2 to operate a decentralized sequencer in production. Rather than relying on a single operator, Metis runs a sequencer pool where multiple independent nodes participate in transaction ordering. Sequencer nodes stake METIS tokens as collateral, and the protocol rotates block production among them. If a sequencer misbehaves â€” censoring transactions, going offline, or submitting invalid batches â€” their stake can be slashed.

Metis's approach demonstrates that decentralized sequencing is technically feasible on an L2. The chain has operated with its decentralized sequencer since early 2024, processing transactions and posting data to Ethereum without the single-point-of-failure risk that other L2s accept. In 2025, Metis launched a sequencer mining program to incentivize broader participation in the sequencer set.

But Metis is also instructive about the challenges of decentralization. Its total value locked and transaction volume are a fraction of Arbitrum's, Optimism's, or Base's. The decentralized sequencer has not given Metis a competitive advantage in attracting users or developers â€” at least not yet. The market, so far, has chosen speed, ecosystem size, and developer tooling over sequencer architecture. Users do not check L2BEAT before choosing an L2. They go where the applications and the liquidity are.

This creates an uncomfortable dynamic. The L2s with the most users have the most centralized sequencers. The L2 with the most decentralized sequencer has among the fewest users. Whether this changes as the market matures â€” as users and regulators begin to care more about trust assumptions â€” remains an open question.

## How to Evaluate Sequencer Risk

If you are building on an L2, sequencer centralization is a trust assumption you need to understand, document, and communicate to your users. Here is what to look for.

**Who runs the sequencer?** Check L2BEAT or the rollup's documentation. If a single entity operates the sequencer, your application's liveness depends on that entity's uptime and good behavior. Understand who they are, where they are incorporated, and what regulatory pressures they face.

**What happens if the sequencer goes down?** Check whether the rollup supports forced inclusion â€” the ability to submit transactions directly to L1. Check the forced inclusion delay. If the delay is 12 or 24 hours, model what happens to your application during that window. If your users have leveraged positions, time-locked funds, or time-sensitive operations, a multi-hour forced inclusion delay may not provide adequate protection.

**What is the sequencer's upgrade path?** Check the rollup's roadmap for sequencer decentralization. How specific is the timeline? Is there a testnet? Have they shipped any milestones? A roadmap item that says "decentralize sequencer â€” 2026" with no further detail is a promise, not a plan. A testnet running multi-node sequencing with a specific mainnet target date is substantially more credible.

**What is the sequencer's MEV policy?** Does the rollup operator disclose how transactions are ordered? Do they use a first-come-first-served policy, a priority fee auction, or something else? Is the ordering verifiable? If you cannot verify how your users' transactions are ordered, you cannot verify that they are being treated fairly.

**What is the exit path?** If you decide the sequencer risk is unacceptable, how do you migrate? Can your smart contracts be deployed on another L2? Can your users withdraw their assets without the sequencer's cooperation? The ability to exit is the ultimate check on sequencer power. If exit is costly, slow, or dependent on the sequencer's cooperation, the centralization risk is compounded by lock-in.

## Decentralization Theater Is Not Fraud â€” But It Is a Risk

It is important to be clear about what Decentralization Theater is and is not. The L2 operators running centralized sequencers are not hiding this fact. The information is public, documented, and tracked by independent observers. These teams are building real technology that provides real value â€” lower fees, higher throughput, and access to Ethereum's security for settlement and data availability. Many of them genuinely intend to decentralize their sequencers over time.

The theater is not in the engineering. It is in the narrative. When an L2 markets itself as "decentralized" or "trustless" while running a centralized sequencer, it is making a claim about its trust model that does not match its current architecture. Users who believe that claim may take on risks they do not understand â€” concentrating funds on a chain that can halt, censoring transactions they assumed were uncensorable, accepting MEV extraction they cannot detect.

As a builder, your responsibility is to see through the narrative to the architecture. Check who runs the sequencer. Check what happens when it fails. Check whether the decentralization roadmap is credible. Design your application to handle sequencer failures gracefully â€” with circuit breakers, fallback paths, and clear communication to users about the trust assumptions they are accepting.

The sequencer determines what happens inside a single chain. But many applications also depend on information from outside the chain â€” asset prices, weather data, election results, sports scores. Getting that external data on-chain reliably and securely is the oracle problem, and it introduces yet another trust assumption that most builders underestimate. That is the subject of the next subchapter.
